<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Jung-taek Lim on Medium]]></title>
        <description><![CDATA[Stories by Jung-taek Lim on Medium]]></description>
        <link>https://medium.com/@heartsavior?source=rss-b3a8812e9a3b------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*8i3jxvUf5YcdVuK7rBVcdw.jpeg</url>
            <title>Stories by Jung-taek Lim on Medium</title>
            <link>https://medium.com/@heartsavior?source=rss-b3a8812e9a3b------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sun, 12 May 2019 08:22:34 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/@heartsavior" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Spark flatMapGroupsWithState API 를 이용한 “이벤트 타임” 세션 윈도우 구현]]></title>
            <link>https://medium.com/@heartsavior/spark-flatmapgroupswithstate-api-%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9D%B4%EB%B2%A4%ED%8A%B8-%ED%83%80%EC%9E%84-%EC%84%B8%EC%85%98-%EC%9C%88%EB%8F%84%EC%9A%B0-%EA%B5%AC%ED%98%84-de9e9ad6503?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/de9e9ad6503</guid>
            <category><![CDATA[structured-streaming]]></category>
            <category><![CDATA[spark-streaming]]></category>
            <category><![CDATA[apache-spark]]></category>
            <category><![CDATA[how-to]]></category>
            <category><![CDATA[windowing]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Mon, 22 Oct 2018 07:34:17 GMT</pubDate>
            <atom:updated>2018-10-22T07:40:00.606Z</atom:updated>
            <content:encoded><![CDATA[<p>현재 Spark 2.3.x 기준으로 Spark 는 map/flatMapGroupsWithState API 를 이용하여 세션 윈도우를 구현하도록 권장하고 있으며, 이에 대한 예시 구현을 제공하고 있다.</p><p><a href="https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala">apache/spark</a></p><p>예시 구현은 mapGroupsWithState API 의 아주 단순한 활용 사례이기 때문에 해당 구현을 이해할 수 있어야 제시하는 구현도 이해할 수 있을 것이다. 해당 코드를 처음 본다면 시간을 내어 코드와 map/flatMapGroupsWithState API 문서를 먼저 읽어보기 바란다.</p><p>예시 구현은 프로세싱 타임을 기준으로 세션 윈도우를 정의하고 있다. 프로세싱 타임의 경우에는 늦은 이벤트가 들어오지 않기 때문에 특정 시점에 유효한 세션은 그룹 키당 단 하나만 존재하며, 예시 코드처럼 아주 단순한 타임아웃 처리로도 구현이 가능하다.</p><p>이벤트 타임의 경우에는 늦은 이벤트가 들어올 수 있기 때문에 더 많은 경우를 고려해야 한다. 예를 들어 단순히 세션의 간격이 10 초인 세션 윈도우를 상정하고 현재 아래와 같은 세션들이 있다고 가정해 보자. 세션 표현은 (세션 시작 시간, 세션 끝 시간) 으로 하자.</p><p>(30, 40) (45, 55) (70, 80)</p><p>이벤트 타임의 경우 늦게 도착하는 이벤트 유입이 허용되기 때문에 워터마크의 진행에 따라 여러 세션들이 특정 시점에 동시에 유효할 수 있다.</p><p>늦게 도착하는 이벤트들이 허용된다고 하면, 새로운 이벤트가 만들어내는 경우의 수는 프로세싱 타임이 만들어내는 2가지 (기존 세션을 확장, 맨 뒤에 새로운 세션 추가) 가 아니라 총 4가지가 된다.</p><ol><li>맨 앞에 새로운 세션 추가</li><li>기존 세션을 확장</li><li>기존 세션을 확장 &amp; 확장된 세션이 다음 세션과 합쳐져 재확장</li><li>맨 뒤에 새로운 세션 추가</li></ol><p>하나씩 살펴보자. 1번의 예시는 시간이 15 인 이벤트가 유입되는 것이다. 이벤트가 적용되었을 때 세션들은 아래와 같이 업데이트된다.</p><p>(15, 25) (30, 40) (45, 55) (70,80)</p><p>2번의 예시는 시간이 32 인 이벤트가 유입되는 것이다. 업데이트된 세션들은 아래와 같다.</p><p>(30, 42) (45, 55) (70, 80) // 세션 (30, 40) 와 (32, 42) 가 병합 되어 확장</p><p>4번의 예시는 시간이 85 인 이벤트가 유입되는 것이다. 업데이트된 세션들은 아래와 같다.</p><p>(30, 40) (45, 55) (70,80) (85, 95)</p><p>3번은 1, 2, 4 에 비해서 덜 직관적이고 놓치기 쉽다. 3번의 예시는 시간이 37 인 이벤트가 유입되는 것이다. 업데이트된 세션들은 아래와 같다.</p><p>(30, 55) (70, 80) // (30, 40) 과 (37, 47) 이 merge 되어 (30, 47) 로 확장, (30, 47) 과 (45, 55) 가 merge 되어 (30, 55) 로 확장</p><p>경우의 수는 살펴보았으니 실제로 state function 을 어떻게 구현해야 할 지 살펴보자. 시작 전, <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.streaming.GroupState">GroupsWithState 클래스 문서</a> 를 먼저 한 번 정독하는 것을 추천한다. (약간 길지만, 주의해야 할 점과 어떻게 동작하는지에 대한 정보가 상세히 적혀 있다.) 문서에 대한 이해가 있으면 왜 이렇게 구현을 했는지에 대한 추측을 쉽게 할 수 있다.</p><p>먼저, 세션의 저장용 중간 상태와 출력 상태를 정의해야 한다. 위에서도 언급했지만, 여러 세션들이 동시에 존재할 수 있고 state 에 기록되어야 한다. 즉, 여러 개의 중간 상태들을 저장해야 한다. 최적화된 구현체가 있을 수 있겠지만, 여기서는 단순히 리스트에 기록하기로 하자.</p><p>state function 은 크게 두 부분으로 나눌 수 있다. (1) 유입된 데이터를 반영하는 부분, (2) 워터마크가 지나간 유효하지 않은 세션들을 내보내는 부분이다.</p><p>코드가 길어 별도 라인 단위 설명은 하지 않고, 적용된 알고리즘과 놓치기 쉬운 부분들에 대한 설명만 하려 한다. 상세한 내용은 <a href="https://gist.github.com/HeartSaVioR/9a3aeeef0f1d8ee97516743308b14cd6#file-eventtimesessionwindowimplementationviaflatmapgroupswithstate-scala-L32-L189">링크된 코드</a>를 읽어보기 바란다. (코드와 설명을 같이 읽는 독자들을 위해 코드를 먼저 링크한다. 설명 마지막에 링크가 한 번 더 나온다.)</p><p>(1) 부터 살펴보자.</p><p>세션 윈도우를 가장 직관적으로 처리하는 방법은 기존 세션 및 이벤트를 정렬한 다음 세션 병합을 적용하는 것이다. 하지만 클래스 문서에는 “이벤트에 대한 정렬은 보장되어 있지 않다&quot; 고 명시되어 있다. 즉, 기존 세션 리스트가 정렬되어 있어도 병합 정렬은 사용할 수 없다. 그러므로 차선으로 기존 세션 리스트는 정렬 상태를 유지하고 삽입 정렬 형태로 이벤트를 기존 세션 리스트에 반영하도록 한다.</p><p>반영시 주의할 점이 있다면, 경우의 수 2 번처럼 이벤트가 기존 세션 리스트에 포함되어 세션이 확장되는 경우, 경우의 수 3 번을 다루기 위해 확장된 세션이 앞/뒤 세션과 겹치는지 다시 한 번 확인하고 겹치는 경우 세션을 병합해 줘야 한다는 것이다. 병합 시에 하나의 기존 세션이 삭제되므로 이 부분에 대한 처리도 해 주어야 한다.</p><p>모든 이벤트를 반영한 후, 유효하지 않은 세션을 내보내기 위한 타임아웃을 설정해야 한다. 클래스 문서에서도 알 수 있듯이 타임아웃을 설정하지 않으면, watermark 진행으로 인해 유효하지 않은 세션이 발생해도 해당 key 에 대한 이벤트가 유입되지 않으면 세션을 내보낼 수 없다.</p><p>여기서 주의해야 할 사항은 state 에 대한 타임아웃은 하나만 설정 가능하다는 것이다. 모든 세션들의 세션 끝 시간에 타임아웃을 설정하는 것이 불가능하다. 우리는 이 기능을 최소한의 트리거 정도로 활용하고, 타임아웃이 트리거되었을 때 유효하지 않은 세션을 직접 찾아서 모두 내보내는 것으로 대응하도록 한다. 타임아웃을 맨 처음 세션의 세션 끝 시간으로 설정한다. 여기서 하나 더 염두에 둘 사항은 watermark 가 타임아웃 시간을 ‘지나가야&#39; 트리거된다는 것이다 .</p><p>이제 결과만 정의하면 된다. Append mode / Update mode 에 맞게 적당히 결과를 반환하도록 한다. 여기서는 Update mode 인 경우에만 결과가 발생한다. 필자는 Update mode 에서 실제로 업데이트가 일어난 세션들만 반환하기 위해 로직이 약간 복잡해졌는데, 단순히 특정 키에 업데이트가 일어난 경우 모든 세션을 반환하는 것으로 정의하면 로직이 단순해진다. (의미론 상 세션이 그룹 키에 포함되는 것으로 보아 “그룹키 + 세션” 을 기준으로 변경 사항에 대해 처리했다.)</p><p>이제 (2) 에 대해 살펴보자. 위에서도 언급했듯이, 우리는 타임아웃이 트리거되었을 때 유효하지 않은 세션을 직접 찾아서 모두 내보낼 것이다. 세션들이 정렬되어 있다는 점을 활용하면 (유효하지 않은 세션 목록, 유효한 세션 목록) 으로 쉽게 두 부류로 가를 수 있다. 유효한 세션 목록이 존재하지 않는다면, state 를 삭제할 수 있다. 유효한 세션 목록이 존재한다면, state 를 업데이트하고, 타임아웃을 같은 방법으로 다시 적용한다.</p><p>그리고 (1) 과 같은 방법으로 결과를 정의한다. 여기서는 Append mode 인 경우에만 결과가 발생한다.</p><p>구현된 코드는 아래와 같다. 위의 설명과 비교해 보면서 코드를 읽으면 더 쉽게 이해할 수 있을 것이다.</p><p><a href="https://gist.github.com/HeartSaVioR/9a3aeeef0f1d8ee97516743308b14cd6#file-eventtimesessionwindowimplementationviaflatmapgroupswithstate-scala-L32-L189">https://gist.github.com/HeartSaVioR/9a3aeeef0f1d8ee97516743308b14cd6#file-eventtimesessionwindowimplementationviaflatmapgroupswithstate-scala-L32-L189</a></p><p>위의 코드를 이해하면 단순 시간 간격으로 정의된 세션 윈도우 외에도 “세션 끝” 이벤트 등을 반영하거나 이벤트 별로 시간 간격이 다르게 정의되는 세션 윈도우 등을 큰 틀에서 비슷하게 구현할 수 있다.</p><p>… 마치며 …</p><p>ps. 단순 시간 간격 세션 윈도우의 경우 현재의 타임 윈도우와 동일한 방법으로 사용 가능하도록 하는 패치가 제안되어 있습니다. 위에 링크된 코드에도 SPARK-10816 으로 예시가 포함되어 있습니다. 해당 기능(또는 구현) 에 관심이 있으면 이슈 페이지 <a href="https://issues.apache.org/jira/browse/SPARK-10816">SPARK-10816</a> 를 방문해 주시고 VOTE 도 해 주시면 감사하겠습니다. (이상 광고였습니다…!?)</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=de9e9ad6503" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Exactly-once?]]></title>
            <link>https://medium.com/@heartsavior/exactly-once-f5c561678f61?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/f5c561678f61</guid>
            <category><![CDATA[exactlyonce]]></category>
            <category><![CDATA[distributed-systems]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Sat, 08 Jul 2017 14:40:52 GMT</pubDate>
            <atom:updated>2017-07-08T14:54:55.937Z</atom:updated>
            <content:encoded><![CDATA[<ul><li><a href="https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/">Exactly-once Semantics is Possible: Here&#39;s How Apache Kafka Does it</a></li><li><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging">KIP-98 - Exactly Once Delivery and Transactional Messaging - Apache Kafka - Apache Software Foundation</a></li><li><a href="https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f">Exactly-once Support in Apache Kafka</a></li></ul><p>주변에서 Jay Kreps 의 Kafka exactly-once 관련 작성한 글이 돌아다니길래 한 번 훑어 봤다. (영어 실력이 미천해서 정독은 정말 시간을 많이 들여야 되어서… 일단 먼저 훑어봄)</p><p>새로운 방법이라도 나온 건가 했는데, 일단 훑어본 걸로는 현재 사용되고 있는 방법을 사용하고 있는 듯 하다. 디테일에 대한 부분은 첫 링크의 Confluent 블로그 글이나 두번째 링크의 KIP 위키 페이지를 보는 것이 더 나아 보인다.</p><p>멱등성을 이용하거나 트랜잭션을 이용한 exactly-once 는 Storm trident 때부터 지원한 고전적인 방법이다.</p><p>단 한 번 보내는 게 아니라 여러 번 보내되 단 한 번의 시도만 유효하게 만드는 방법이 사용되기 때문에 exactly-once 가 아니라 exactly-once semantic 이라는 주장이 많이 있다. 일반적으로 데이터를 기록하는 연산이 멱등성을 가지고 있거나 트랜잭션을 지원해야 하는 제약사항이 있다.</p><p>다른 방법으로 deduplicating 이라고 해서 처리된 메시지의 unique key 를 보관하고 한 번만 처리하는 방법도 사용되고 있다. (Google MillWheel)<br><a href="https://blog.acolyer.org/2015/08/21/millwheel-fault-tolerant-stream-processing-at-internet-scale/">https://blog.acolyer.org/…/millwheel-fault-tolerant-stream…/</a></p><p>Storage 로써의 Kafka 는 side-effect 를 고민하지 않아도 되지만, Distributed computation framework 입장에서 보면 state 의 저장만 exactly-once 로 처리되는 것이지 전체 파이프라인이 한 번만 처리되는 게 아니기 때문에 중간 연산에 side-effect 가 없어야 유저가 기대하는 exactly-once 처럼 동작하게 된다.</p><p>exactly-once 는 결국 제약사항을 충족해야 달성할 수 있는 건데 정작 홍보할 때는 제약사항은 잘 언급되지 않는다. 그게 반대론자(?) 들이 exactly-once 에 대한 주장을 공격하는 이유 중 하나가 되기도 한다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f5c561678f61" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Java DriverManager 와 Driver 구현체 간의 deadlock 발견 및 해결 과정 정리]]></title>
            <link>https://medium.com/@heartsavior/java-drivermanager-%EC%99%80-driver-%EA%B5%AC%ED%98%84%EC%B2%B4-%EA%B0%84%EC%9D%98-deadlock-%EB%B0%9C%EA%B2%AC-%EB%B0%8F-%ED%95%B4%EA%B2%B0-%EA%B3%BC%EC%A0%95-%EC%A0%95%EB%A6%AC-db6278cf6bae?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/db6278cf6bae</guid>
            <category><![CDATA[apache-storm]]></category>
            <category><![CDATA[deadlock]]></category>
            <category><![CDATA[jdbc]]></category>
            <category><![CDATA[java]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Thu, 25 May 2017 17:22:45 GMT</pubDate>
            <atom:updated>2017-05-25T18:04:52.643Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://github.com/hortonworks/streamline">Streamline</a> 프로젝트 개발 작업 중 JDBC 관련 테스트를 하다가 이상하게 Storm worker 에서 초기화가 완료되지 않는 문제가 발견되었다. 보통은 stack dump 를 뜨면 deadlock 상태인 게 눈에 보이는데 (thread 들이 어떤 lock 을 쥐고 있고 어떤 lock 을 기다리고 있는지 id 기준으로 확인하면 얽히고 섥힌 게 보임) 이번에는 의심되는 thread 들이 모두 RUNNABLE 상태였다.</p><p>한참을 이리저리 보고 구글링도 했는데, 결과는 클래스 static 초기화 block 이 문제였다.</p><p>worker 의 jstack 결과 중 deadlock 과 관련된 두 개의 executor thread 만 뽑아 보면 아래와 같다.</p><pre>&quot;Thread-17-641-JDBC-RDB-executor[4 4]&quot; #52 prio=5 os_prio=0 tid=0x00007f8aedb6f800 nid=0x742 in Object.wait() [0x00007f8a99036000]<br>   java.lang.Thread.State: RUNNABLE<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)<br> at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)<br> at java.lang.reflect.Constructor.newInstance(Constructor.java:423)<br> at java.lang.Class.newInstance(Class.java:442)<br> at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)<br> at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)<br> at java.util.ServiceLoader$1.next(ServiceLoader.java:480)<br> at java.sql.DriverManager$2.run(DriverManager.java:603)<br> at java.sql.DriverManager$2.run(DriverManager.java:583)<br> at java.security.AccessController.doPrivileged(Native Method)<br> at java.sql.DriverManager.loadInitialDrivers(DriverManager.java:583)<br> at java.sql.DriverManager.&lt;clinit&gt;(DriverManager.java:101)<br> at com.mysql.jdbc.Driver.&lt;clinit&gt;(Driver.java:49)<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)<br> at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)<br> at java.lang.reflect.Constructor.newInstance(Constructor.java:423)<br> at java.lang.Class.newInstance(Class.java:442)<br> at com.zaxxer.hikari.HikariConfig.setDriverClassName(HikariConfig.java:326)<br>...</pre><pre>&quot;Thread-7-631-JDBC-PHOENIX-executor[3 3]&quot; #42 prio=5 os_prio=0 tid=0x00007f8aed6ea000 nid=0x738 in Object.wait() [0x00007f8a99a42000]<br>   java.lang.Thread.State: RUNNABLE<br> at org.apache.phoenix.jdbc.PhoenixDriver.&lt;clinit&gt;(PhoenixDriver.java:128)<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)<br> at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)<br> at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)<br> at java.lang.reflect.Constructor.newInstance(Constructor.java:423)<br> at java.lang.Class.newInstance(Class.java:442)<br> at com.zaxxer.hikari.HikariConfig.setDriverClassName(HikariConfig.java:326)<br>...</pre><p>두 executor thread 들의 상태가 모두 RUNNABLE 인데, in Object.wait() 가 표기되어 있다. SO 가라사대 이런 경우는 static block 에서 deadlock 발생했을 가능성이 높다고 한다. (링크는 잃어버려서 패스…) 이를 바탕으로 추적해보자.</p><p>일단 첫번째 thread 에서 HikariCP 가 MySQL 의 Driver 클래스를 로딩하면서 클래스 초기화가 수행되고, 클래스 초기화 과정에서 DriverManager 클래스 초기화가 호출된 것을 stack trace 에서 확인할 수 있다.</p><pre>at java.sql.DriverManager.&lt;clinit&gt;(DriverManager.java:101)<br> at com.mysql.jdbc.Driver.&lt;clinit&gt;(Driver.java:49)</pre><p><a href="http://grepcode.com/file/repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.34/com/mysql/jdbc/Driver.java#Driver">http://grepcode.com/file/repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.34/com/mysql/jdbc/Driver.java#Driver</a></p><pre>    //<br>    // Register ourselves with the DriverManager<br>    //<br>    static {<br>        try {<br>            java.sql.DriverManager.registerDriver(new Driver());<br>        } catch (SQLException E) {<br>            throw new RuntimeException(&quot;Can&#39;t register driver!&quot;);<br>        }<br>    }</pre><p>DriverManager 에 객체를 등록하려고 시도하고 있다.</p><p>DriverManager 의 클래스 초기화 코드를 보면…</p><p><a href="http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/sql/DriverManager.java?av=f#101">http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/sql/DriverManager.java</a></p><pre>    /**<br>     * Load the initial JDBC drivers by checking the System property<br>     * jdbc.properties and then use the {@code ServiceLoader} mechanism<br>     */<br>    static {<br>        loadInitialDrivers();<br>        println(&quot;JDBC DriverManager initialized&quot;);<br>    }<br>...</pre><pre>   private static void loadInitialDrivers() {<br>        String drivers;<br>        try {<br>            drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() {<br>                public String run() {<br>                    return System.getProperty(&quot;jdbc.drivers&quot;);<br>                }<br>            });<br>        } catch (Exception ex) {<br>            drivers = null;<br>        }<br>        // If the driver is packaged as a Service Provider, load it.<br>        // Get all the drivers through the classloader<br>        // exposed as a java.sql.Driver.class service.<br>        // ServiceLoader.load() replaces the sun.misc.Providers()<br><br>        AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() {<br>            public Void run() {<br><br>                ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);<br>                Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();<br><br>                /* Load these drivers, so that they can be instantiated.<br>                 * It may be the case that the driver class may not be there<br>                 * i.e. there may be a packaged driver with the service class<br>                 * as implementation of java.sql.Driver but the actual class<br>                 * may be missing. In that case a java.util.ServiceConfigurationError<br>                 * will be thrown at runtime by the VM trying to locate<br>                 * and load the service.<br>                 *<br>                 * Adding a try catch block to catch those runtime errors<br>                 * if driver not available in classpath but it&#39;s<br>                 * packaged as service and that service is there in classpath.<br>                 */<br>                try{<br>                    while(driversIterator.hasNext()) {<br>                        driversIterator.next();<br>                    }<br>                } catch(Throwable t) {<br>                // Do nothing<br>                }<br>                return null;<br>            }<br>        });<br><br>        println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers);<br><br>        if (drivers == null || drivers.equals(&quot;&quot;)) {<br>            return;<br>        }<br>        String[] driversList = drivers.split(&quot;:&quot;);<br>        println(&quot;number of Drivers:&quot; + driversList.length);<br>        for (String aDriver : driversList) {<br>            try {<br>                println(&quot;DriverManager.Initialize: loading &quot; + aDriver);<br>                Class.forName(aDriver, true,<br>                        ClassLoader.getSystemClassLoader());<br>            } catch (Exception ex) {<br>                println(&quot;DriverManager.Initialize: load failed: &quot; + ex);<br>            }<br>        }<br>    }</pre><p>여기서 포인트는 <a href="https://docs.oracle.com/javase/7/docs/api/java/util/ServiceLoader.html">ServiceLoader</a> 이다. ServiceLoader 가 class path 내 jar 들을 뒤져서 java.sql.Driver interface 의 구현체가 META-INF.services 디렉토리 내 등록되어 있는 지 확인하고(인터페이스명의 파일을 만들고 파일 내용에 구현체 클래스 명을 작성한다), 등록되어 있는 클래스들을 모두 초기화한다.</p><p>쭉 생략하고 실제로 Class 를 다루는 부분을 보자. 아래는 ServiceLoader$LazyIterator.nextService() 구현이다.</p><p><a href="http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/util/ServiceLoader.java?av=f">http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/util/ServiceLoader.java?av=f</a></p><pre>        private S nextService() {<br>            if (!hasNextService())<br>                throw new NoSuchElementException();<br>            String cn = nextName;<br>            nextName = null;<br>            Class&lt;?&gt; c = null;<br>            try {<br>                c = Class.forName(cn, false, loader);<br>            } catch (ClassNotFoundException x) {<br>                fail(service,<br>                     &quot;Provider &quot; + cn + &quot; not found&quot;);<br>            }<br>            if (!service.isAssignableFrom(c)) {<br>                fail(service,<br>                     &quot;Provider &quot; + cn  + &quot; not a subtype&quot;);<br>            }<br>            try {<br>                S p = service.cast(c.newInstance());<br>                providers.put(cn, p);<br>                return p;<br>            } catch (Throwable x) {<br>                fail(service,<br>                     &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;,<br>                     x);<br>            }<br>            throw new Error();          // This cannot happen<br>        }</pre><p>Class.forName() 호출 시 class 초기화를 하지 않도록 되어 있다. 그래서 stack trace 상 해당 부분에서 멈추지 않았고, c.newInstance() 로 객체를 만들 때 멈추었다.</p><p>이제 다음 thread 를 살펴보자. reflection 관련 라인들 제외하면 맨 윗 라인이 포인트이다.</p><pre>at org.apache.phoenix.jdbc.PhoenixDriver.&lt;clinit&gt;(PhoenixDriver.java:128)</pre><p>두 번째 thread 는 PhoenixDriver 의 클래스 초기화에서 멈췄다.</p><p>여기서 PhoenixDriver 의 코드를 잠깐 보자면…</p><p><a href="http://grepcode.com/file/repo1.maven.org/maven2/org.apache.phoenix/phoenix-core/4.5.0-HBase-1.1/org/apache/phoenix/jdbc/PhoenixDriver.java#PhoenixDriver">http://grepcode.com/file/repo1.maven.org/maven2/org.apache.phoenix/phoenix-core/4.5.0-HBase-1.1/org/apache/phoenix/jdbc/PhoenixDriver.java#PhoenixDriver</a></p><pre>public static final PhoenixDriver INSTANCE;</pre><pre>static {<br>        try {<br>            INSTANCE = new PhoenixDriver();<br>            try {<br>                // Add shutdown hook to release any resources that were never closed<br>                // In theory not necessary, but it won&#39;t hurt anything<br>                Runtime.getRuntime().addShutdownHook(new Thread() {<br>                    @Override<br>                    public void run() {<br>                        closeInstance(INSTANCE);<br>                    }<br>                });<br><br>                // Only register the driver when we successfully register the shutdown hook<br>                // Don&#39;t want to register it if we&#39;re already in the process of going down.<br>                DriverManager.registerDriver( INSTANCE );<br>            } catch (IllegalStateException e) {<br>                logger.warn(&quot;Failed to register PhoenixDriver shutdown hook as the JVM is already shutting down&quot;);<br><br>                // Close the instance now because we don&#39;t have the shutdown hook<br>                closeInstance(INSTANCE);<br><br>                throw e;<br>            }<br>        } catch (SQLException e) {<br>            throw new IllegalStateException(&quot;Unable to register &quot; + PhoenixDriver.class.getName() + &quot;: &quot;+ e.getMessage());<br>        }<br>    }</pre><p>singleton 으로 Driver 객체 하나 생성하고 shutdown hook 하나 등록하고 결국 생성한 Driver 객체를 등록하기 위해 DriverManager.registerDriver() 를 호출한다.</p><p>그리고 MySQL 과 Phoenix 모두 jar 파일 내 ServiceLoader 에 Driver 와 PhoenixDriver 를 등록하기 위한 준비를 해 두었다. 편의성 측면에서 훌륭하지만, 운이 나쁘게도 이 상황에서는 문제를 일으키게 된다.</p><p>code 와 stack trace 를 끼워맞추어 상황을 종합해 보면,</p><ol><li>첫 번째 thread 의 Driver (MySQL) class 초기화 진입이 좀 더 빨랐고 DriverManager.registerDriver() 를 먼저 실행했음을 유추할 수 있다.</li><li>DriverManager 의 class 초기화에서 ServiceLoader 를 이용하여 Driver 들을 모두 초기화하기 시작했다.</li><li>두 번째 thread 가 Phoenix Driver class 초기화 진입이 이루어졌고 DriverManager.registerDriver() 를 실행했다. 하지만 class 초기화가 아직 끝나지 않았기 때문에 (classloader 계층 내에서 class 가 처음 로드 될 때만 초기화가 실행됨) 대기하게 된다.</li><li>첫 번째 thread 는 결과적으로 Phoenix Driver 를 초기화하려고 시도하게 된다. (ServiceLoader 에 등록되어 있으므로) 하지만 Phoenix Driver 도 class 초기화가 아직 끝나지 않았기 때문에 대기하게 된다.</li><li>결국 두 thread 는 서로의 class 초기화가 끝나길 기다리게 되어 deadlock 상태에 빠진다.</li></ol><p>해결 방안은 사실 간단하다. ‘multi thread 에서 동시 초기화하지 않는다’ 같은 뻔한 걸 제외하면 크게 두 가지가 있다.</p><ol><li>Driver class 를 직접 Class.forName() 등으로 초기화하지 않고 ServiceLoader 에게 맡긴다.</li></ol><p>사실 HikariCP 가 초기화를 안하면 DriverManager 가 알아서 초기화해 줄 것이다. HikariCP 가 ServiceLoader 를 지원하지 않는 driver 를 위해 옛날 방법으로 초기화한 것이 최신 방법과 부딛히게 된 것인데, 지원하는 driver 인지 먼저 확인하고 지원한다면 초기화하지 않게 driverClassName 을 비워두면 된다. (나중에 보았는데 비우고 먼저 시도해보라고 가이드도 되어 있다…)</p><p><a href="https://github.com/brettwooldridge/HikariCP#essentials">https://github.com/brettwooldridge/HikariCP#essentials</a></p><p>참고로 Phoenix 가 DataSource 구현체를 지원하지 않기도 하고 MySQL 의 DataSource 구현체가 network timeout 지원 관련 이슈가 있는 것으로 나와 있어서 Driver 구현체를 썼는데, DataSource 구현체를 지원하는 드라이버는 DataSource 구현체를 사용하도록 HikariCP 를 초기화하면 된다. HikariCP 도 이쪽을 더 권장한다.</p><p><a href="https://github.com/brettwooldridge/HikariCP#popular-datasource-class-names">https://github.com/brettwooldridge/HikariCP#popular-datasource-class-names</a></p><p>2. Driver class 초기화 전에 DriverManager class 초기화를 실행한다.</p><p>나의 경우 bolt class 의 static block 에 DriverManager.getDrivers() 를 한 번 호출해 주었다. 일반적으로 bolt 객체는 serialization 된 상태로 전달되고 worker 에서 deserialization 되기 때문에 일반적으로 worker 프로세스에서 발생해야 할 초기화들은 prepare() 메소드에 작성하지만, class 초기화는 관계없이 두 곳 모두 발생하므로 static block 에 작성해 주어도 동작한다. 이 workaround 는 근본 원인을 피해가는 것이라서 ‘모든 thread 에서 Driver class 초기화 전에 DriverManager class 초기화를 먼저 수행한다’ 는 조건만 만족시키면 문제를 완전히 피해갈 수 있다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=db6278cf6bae" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Log4j2 Async logger 와 shutdown hook 을 동시 사용할 경우 주의할 점]]></title>
            <link>https://medium.com/@heartsavior/log4j2-async-logger-%EC%99%80-shutdown-hook-%EC%9D%84-%EB%8F%99%EC%8B%9C-%EC%82%AC%EC%9A%A9%ED%95%A0-%EA%B2%BD%EC%9A%B0-%EC%A3%BC%EC%9D%98%ED%95%A0-%EC%A0%90-8c95369948b9?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/8c95369948b9</guid>
            <category><![CDATA[troubleshooting]]></category>
            <category><![CDATA[apache-storm]]></category>
            <category><![CDATA[jvm]]></category>
            <category><![CDATA[log4j2]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Mon, 09 Jan 2017 10:23:17 GMT</pubDate>
            <atom:updated>2017-01-09T10:23:17.048Z</atom:updated>
            <content:encoded><![CDATA[<p>Log4j2 에서는 low-latency 로 로그를 남길 수 있도록 Asynchronous logger 를 지원하고 있다. Storm 프로젝트에서도 0.10 버전부터 Logback 에서 Log4j2 로 건너오면서 Async logger 를 설정하여 사용하고 있다.</p><p>최근 1.1.0 릴리즈 준비로 남은 이슈들을 해결하면서 한 이슈에서 worker 의 shutdown 시작 이후의 로그가 불안정하게 기록된다는 것을 발견했다. 정확하게는 높은 확률로 어느 시점 이후의 로그가 기록되지 않았다. 초기에는 worker 가 해당 시점에 종료되는 것으로 생각했는데 좀 더 파고들어보니 로그만 기록되지 않는 것으로 파악되었다.</p><p>원인은 나름 심오했는데, JVM 의 shutdown hook 동작과 Log4j2 Async logger 의 리소스 정리가 맞물려서 발생한 증상으로 파악되었다.</p><p>먼저 JVM shutdown hook 의 특성을 살펴보면…</p><ol><li>여러 shutdown hook 들을 등록할 수 있다.</li><li>JVM 은 shutdown hook 들의 실행 순서를 보증하지 않는다.</li><li>shutdown hook 들은 concurrent 하게 실행된다.</li><li>(관련성은 적지만) shutdown hook 에서 System.exit() 를 호출하면 deadlock 이 된다. 강제 종료하고 싶으면 Runtime.getRuntime().halt() 를 실행해야 한다.</li></ol><p>Storm 의 경우 worker 프로세스의 정리를 shutdown hook 으로 걸어 두고, supervisor 에서 worker 를 종료할 때 SIGTERM 을 날려 worker 프로세스의 shutdown hook 이 실행되도록 하고, 몇 초 대기 후 프로세스가 종료되지 않았으면 SIGKILL 로 강제 종료한다. 프로세스 정리 중에도 정리 상태를 남기기 위해 로그를 기록하고 있다.</p><p>문제는, Log4j2 또한 리소스 정리를 shutdown hook 에 걸어 두고, 리소스 정리하는 과정이 완료되면 로그를 처리하지 않게 된다는 것이다. JVM shutdown hook 의 특성 2, 3 에 따르면 Log4j2 의 리소스 정리 hook 은 다른 shutdown hook 들보다 먼저 끝날 수 있고, 그 이후부터 다른 shutdown hook 들의 로그 기록은 실패하게 된다.</p><p>Storm 에서 사용하는 Log4j2 버전이 낮아 (2.1, 사이트에서는 2.3 도 legacy 메뉴에 있다.) 다른 좋은 방안은 찾지 못했고, 가장 쉬운 방안인 shutdown hook 을 disable 하는 것으로 우선 <a href="https://github.com/apache/storm/pull/1864">패치</a>를 제출해 두었다.<br>(방법은 간단하다. configuration 태그에 shutdownHook=”disable” 을 추가하면 된다.)</p><p>리소스 정리 hook 을 끄는 거라 조금 찜찜해서 Log4j2 상위 버전에서 더 깔끔한 종료 방안이 있으면 버전도 올리면서 방법도 바꿀 계획이다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8c95369948b9" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[그러게요 ㅎㅎ 이불킥할 일이었긴 했지만 나름대로 새로운 경험 해서 좋았어요 ㅎㅎ]]></title>
            <link>https://medium.com/@heartsavior/%EA%B7%B8%EB%9F%AC%EA%B2%8C%EC%9A%94-%E3%85%8E%E3%85%8E-%EC%9D%B4%EB%B6%88%ED%82%A5%ED%95%A0-%EC%9D%BC%EC%9D%B4%EC%97%88%EA%B8%B4-%ED%96%88%EC%A7%80%EB%A7%8C-%EB%82%98%EB%A6%84%EB%8C%80%EB%A1%9C-%EC%83%88%EB%A1%9C%EC%9A%B4-%EA%B2%BD%ED%97%98-%ED%95%B4%EC%84%9C-%EC%A2%8B%EC%95%98%EC%96%B4%EC%9A%94-%E3%85%8E%E3%85%8E-bfb5b0a750aa?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/bfb5b0a750aa</guid>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Sat, 15 Oct 2016 06:45:26 GMT</pubDate>
            <atom:updated>2016-10-15T06:45:26.552Z</atom:updated>
            <content:encoded><![CDATA[<p>그러게요 ㅎㅎ 이불킥할 일이었긴 했지만 나름대로 새로운 경험 해서 좋았어요 ㅎㅎ</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=bfb5b0a750aa" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[라이트닝 토크 후루룩 말아먹은 후기]]></title>
            <link>https://medium.com/@heartsavior/%EB%9D%BC%EC%9D%B4%ED%8A%B8%EB%8B%9D-%ED%86%A0%ED%81%AC-%ED%9B%84%EB%A3%A8%EB%A3%A9-%EB%A7%90%EC%95%84%EB%A8%B9%EC%9D%80-%ED%9B%84%EA%B8%B0-f2ce006f50b4?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/f2ce006f50b4</guid>
            <category><![CDATA[streamingsql]]></category>
            <category><![CDATA[라이트닝토크]]></category>
            <category><![CDATA[망쳤다]]></category>
            <category><![CDATA[캐망]]></category>
            <category><![CDATA[어차피-early-stage]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Sat, 15 Oct 2016 04:15:02 GMT</pubDate>
            <atom:updated>2016-10-15T04:35:38.018Z</atom:updated>
            <content:encoded><![CDATA[<p>마이크 잡고 하는 발표 자체가 처음이라 라이트닝 토크가 그나마 나을 것 같았는데… 어제 망한 듯 하다. 그래도 처음 한 거니 후기…</p><p><a href="http://www.slideshare.net/kabhwan/streaming-sql-67150827">http://www.slideshare.net/kabhwan/streaming-sql-67150827</a></p><p>1. 발표 잘하는 것도 타고나는 것이 있겠지만… 그래도 경험이 0인 거랑 있는 거랑은 차이가 있을 것 같다. 앞으로 얼마나 두들겨 맞아서 내성이 생겨야 발표가 하고 싶어질까? 아님 역시 타고나는 거?</p><p>2. 5분 진짜 짧다. 괜히 현재 상황 뜬구름 두 가지 모두 커버한다고 고생했는데 뜬구름 잡을거면 그냥 뜬구름만 잡고 상상력을 발휘하세요 끗 이렇게 하고, 현 상황만 얘기할꺼면 그냥 여기까지만 돼요 나머진 찾아보세요 끗 이랬어야 됐다.</p><p>3. 몇 장이었으면 5분에 깔끔하게 끝났을까? 누가 처음 해보는 거 아니랄까봐 대놓고 덜덜대고 어버버대는 바람에 늦어진 것도 있긴 한데 발표 자료를 다시 봐도 20장을 5분에 할 거라는 생각은 많이 오버였던 것 같다…ㅋㅋㅋ 적당한 장 수 라는게 있을라나?</p><p>4. 라이트닝 토크가 세션을 찾아와서 듣는 게 아니라서 청중이 관심이 있는지 없는지, 기반 이해는 하고 있는 사람들이 듣는건지 파악하는 게 중요한 듯 하다. 결국 스트리밍 처리에 대한 이해를 바탕으로 뜬구름을 잡는 건데 청중 수준을 먼저 파악하고 잘 모르는구나 싶으면 마지막 장에 GUI 만 보여주고 잡설 하고 끝냈어야 됐다. 앞에 기술내용 들어가기 전 슬라이드까지 다 해도 2분이면 끝났을 듯 하다.</p><p>5. 특정 커뮤니티 모임에서 특정 이야기로 라이트닝 토크 할 게 아니면 최대한 일반적인 얘기 하는 게 답일 수도 있겠다. 캘리포니아 출장 사진 공유하면서 원격근무 삶에 대해 하소연하고 사람들을 부들부들하게 만들고 내려왔다면…ㅋㅋ (실제로 원격근무 힘들어요…ㅠㅠ)</p><p>6. 그래도 발표로 안한 건 잘한 것 같다. 아직은 early stage 라서 1시간이나 떠들 거리는 아니다. 30분도 못 떠들 것 같다.</p><p>7. 이제 회사 행사 발표 준비해야된다. 어제 망친건 내 이름 건거라 뭐 잃을 게 쥐뿔도 없었지만 이건 현재/잠재 클라이언트 모시는 행사라 장난 아니다… 망치면 다시 구직하러 나와야 되나…ㅠㅠ 지인 분들 잘 부탁드려요 (?)</p><p>ps. 어제 자신에게 좀 화가 나서 긴 버전을 슬라이드던 문서던 한 번 만들어볼까 생각했는데 Storm 에 표기되어 있는 Experimental 은 내가 메꿔야 된다…ㄷㄷ 발표자료에도 있고 6번에도 얘기했지만 early stage 이고 지금은 되는 게 뭐 없는데 (다른 프레임워크들도 일단 내놓고 기능 붙이자 이런 주의로 달리고 있어서 되는 게 뭐 없긴 하다) 뭐가 좀 되면 그 때 좀 약(?) 을 팔아봐야겠다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f2ce006f50b4" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Gotcha When Using ZooKeeper Ephemeral Nodes]]></title>
            <link>https://medium.com/@heartsavior/a-gotcha-when-using-zookeeper-ephemeral-nodes-2df0ff56d97c?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/2df0ff56d97c</guid>
            <category><![CDATA[troubleshooting]]></category>
            <category><![CDATA[본격-ps가-본문보다-정보가-더-많아진-글]]></category>
            <category><![CDATA[apache-storm]]></category>
            <category><![CDATA[gotchas]]></category>
            <category><![CDATA[zookeeper]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Mon, 04 Jul 2016 13:11:47 GMT</pubDate>
            <atom:updated>2016-07-04T22:21:14.513Z</atom:updated>
            <content:encoded><![CDATA[<p>미디엄을 만들어 놓고 너무 놀리고 있는 것 같아서 오래간만에 troubleshooting 시도하다가 발견한 골치아픈(?) 케이스를 공유</p><p>한글로 제목을 뽑아보려고 했는데 마땅한 제목이 떠오르지 않아서 참고한 문서의 제목을 훔쳐(?) 왔다.</p><ul><li><a href="https://www.box.com/blog/a-gotcha-when-using-zookeeper-ephemeral-nodes/">A Gotcha When Using ZooKeeper Ephemeral Nodes | Box Blog</a></li><li><a href="https://issues.apache.org/jira/browse/STORM-1941">[STORM-1941] Nimbus discovery can fail when zookeeper reconnect happens. - ASF JIRA</a></li></ul><p>ephemeral node 는 session 이 종료되면 삭제되는 것으로 보통 알고 있고 이를 기반으로 service discovery 등을 구축하는 데 사용하는데, node 의 삭제가 Zookeeper 서버 단에서 발생하기 때문에 Zookeeper 와의 연결이 비정상적으로 끊어진 경우 클라이언트에서 session 이 닫혔다고 로그가 남아도 Zookeeper 가 재시작되었을 때 ephemeral node 가 바로 삭제되지 않는 경우가 있다.</p><p>(추가) dump 를 보니 Zookeeper 서버 재실행 시 기존 Session Tracker 의 정보까지 다시 로드하는 듯 보인다. 즉, Zookeeper 서버를 내려도 session 들이 바로 close 되지 않고, 서버를 다시 실행해도 기존 session 들을 바로 expire 하지 않는 듯 보인다. 이런 이유로 session 은 유효하지 않은데 (클라이언트 기준) ephemeral node 가 남아 있을 수 있다. 내공이 얕아 또 다른 이유가 있는지는 모르겠다.</p><p>그래서 reconnect 이벤트 핸들러에서 해당 값을 재등록하도록 구현한 경우 이전 session 과 연관된 ephemeral node 가 현재 시점에 삭제되지 않았을 수도 있음을 감안해야 한다. <strong>더 중요한 건, 해당 session 은 닫힌 상태이기 때문에 node 는 언젠가 (eventually) 삭제되게 되므로 해당 node 에 값을 기록하면 값을 날리게 된다는 것이다. (‘A’ session 이 만든 ephemeral node 에 ‘B’ session 이 값을 기록해도 ephemeral owner 는 바뀌지 않는다.) 안전한 구현은 node 를 먼저 삭제하고 기록하는 것이다.</strong></p><p>ps. 너무 정보가 없는 것 같아서 transaction log 를 여는 방법과 snapshot 을 여는 방법이라도 남겨두려고 한다. 물론 출처는 Stack Overflow.</p><p>A. transaction log 읽기: zookeeper 설치 디렉토리에서 아래 명령 실행</p><blockquote>java -cp zookeeper-3.4.6.jar:lib/log4j-1.2.16.jar:lib/slf4j-log4j12–1.6.1.jar:lib/slf4j-api-1.6.1.jar org.apache.zookeeper.server.LogFormatter version-2/log.xxx</blockquote><p>B. snapshot log 읽기: zookeeper 설치 디렉토리에서 아래 명령 실행</p><blockquote>java -cp zookeeper-3.4.6.jar:lib/log4j-1.2.16.jar:lib/slf4j-log4j12–1.6.1.jar:lib/slf4j-api-1.6.1.jar org.apache.zookeeper.server.SnapshotFormatter version-2/snapshot.xxx</blockquote><p>ps2. 사실 이런 좋은 글을 찾긴 했었는데 실제로 빌드해서 돌려보니 NPE 가 발생해서 안 썼다. 일단 글의 설명으로는 상당한 기능을 갖고 있는 유틸리티이다. 작성자도 Zookeeper PMC 멤버인 듯 하다.</p><p><a href="https://medium.com/@ivankelly/mining-zookeeper-s-transaction-log-to-track-down-bugs-63b4c653bb6">Mining Zookeeper’s transaction log to track down bugs</a></p><p>ps3. transaction log 에서 ephemeral node 를 추적할 때 삭제되는 시점을 알고 싶으면 ephemeral node 의 owner session 이 closeSession 으로 나타나는 로그를 찾으면 된다. deleteNode 로 로깅되지 않으니 주의.</p><blockquote>7/5/16 5:56:10 AM KST <strong>session 0x155b7b136300007</strong> cxid 0x0 zxid 0x280542 <strong>createSession</strong> 20000<br>7/5/16 5:56:10 AM KST <strong>session 0x155b7b136300007</strong> cxid 0xd zxid 0x280544 <strong>create</strong> ‘<strong>/storm/nimbuses/&lt;host&gt;:6627</strong>,#1fffffff8b80000000ffffffe36660646060ffffffe036ffffffb434ffffffd23334ffffffb3ffffffd033ffffffd0ffffffb3ffffffe460606260ffffff907cffffffccffffffc1ffffffc01c5e7536ffffff8bffffff89ffffff81ffffff85ffffff81ffffff9bffffff8115ffffffa8ffffff86ffffffd510286bffffffc400ffffffe1ffffff80fffffffd5f31000,v{s{31,s{‘world,’anyone}}},T,214<br>7/5/16 6:00:10 AM KST <strong>session 0x155b7b60ee60003</strong> cxid 0x3 zxid 0x280555 setData ‘<strong>/storm/nimbuses/&lt;host&gt;:6627</strong>,#1fffffff8b80000000ffffffe36660646060ffffffe036ffffffb434ffffffd23334ffffffb3ffffffd033ffffffd0ffffffb3ffffffe460606260ffffff907cffffffccffffffc1ffffffc01c5e7536ffffff8bffffff89ffffff81ffffff85ffffff81ffffff9bffffff8115ffffffa8ffffff86ffffffd510286bffffffc400ffffffe1ffffff80fffffffd5f31000,1<br>7/5/16 6:00:30 AM KST <strong>session 0x155b7b136300007</strong> cxid 0x0 zxid 0x280557 <strong>closeSession</strong> null</blockquote><p>ps4. session 및 ephemeral node 추적에는 zookeeper server 로 dump 를 날리는 것도 나쁘지 않다. session expire 예정 시간과 session 에 물려 있는 ephemeral node 들이 모두 나타난다.</p><blockquote>echo ‘dump’ | nc localhost 2181 &gt; zk-dump-`date +%Y-%m-%d-%H-%M-%S`.log</blockquote><p>결과는 아래처럼 나타난다. (3.4.7 버전 기준)</p><blockquote>SessionTracker dump:<br>Session Sets (7):<br>4 expire at Tue Jul 05 06:00:30 KST 2016:<br> 0x155b7b136300006<br> 0x155b7b136300007<br> 0x155b7b136300005<br> 0x155b7b136300008<br>0 expire at Tue Jul 05 06:00:32 KST 2016:<br>0 expire at Tue Jul 05 06:00:38 KST 2016:<br>0 expire at Tue Jul 05 06:00:40 KST 2016:<br>2 expire at Tue Jul 05 06:00:42 KST 2016:<br> 0x155b7b60ee60001<br> 0x155b7b60ee60000<br>2 expire at Tue Jul 05 06:00:44 KST 2016:<br> 0x155b7b60ee60003<br> 0x155b7b60ee60002<br>1 expire at Tue Jul 05 06:00:48 KST 2016:<br> 0x155b7af6d610000<br>ephemeral nodes dump:<br>Sessions with Ephemerals (3):<br>0x155b7b136300005:<br>0x155b7b136300007:<br> /storm/nimbuses/&lt;host&gt;:6627<br> /storm/blobstore/test-topology2–4–1467185073-stormconf.ser/&lt;host&gt;:6627–1<br> /storm/blobstore/test-topology2–4–1467185073-stormcode.ser/&lt;host&gt;:6627–1<br> /storm/blobstore/test-topology2–4–1467185073-stormjar.jar/&lt;host&gt;:6627–1<br>0x155b7b60ee60002:<br> /storm/leader-lock/_c_88cee421-b78e-4795-a1df-61ea1abc9efc-latch-0000000221</blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2df0ff56d97c" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[이거 구글 빅테이블 논문 보고 야후가 하둡 만든것처럼 알파고 논문 보고 구현한거야 ㅎㅎ]]></title>
            <link>https://medium.com/@heartsavior/%EC%9D%B4%EA%B1%B0-%EA%B5%AC%EA%B8%80-%EB%B9%85%ED%85%8C%EC%9D%B4%EB%B8%94-%EB%85%BC%EB%AC%B8-%EB%B3%B4%EA%B3%A0-%EC%95%BC%ED%9B%84%EA%B0%80-%ED%95%98%EB%91%A1-%EB%A7%8C%EB%93%A0%EA%B2%83%EC%B2%98%EB%9F%BC-%EC%95%8C%ED%8C%8C%EA%B3%A0-%EB%85%BC%EB%AC%B8-%EB%B3%B4%EA%B3%A0-%EA%B5%AC%ED%98%84%ED%95%9C%EA%B1%B0%EC%95%BC-%E3%85%8E%E3%85%8E-2f6ecfe824ce?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/2f6ecfe824ce</guid>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Mon, 14 Mar 2016 00:29:32 GMT</pubDate>
            <atom:updated>2016-03-14T00:29:32.593Z</atom:updated>
            <content:encoded><![CDATA[<p>이거 구글 빅테이블 논문 보고 야후가 하둡 만든것처럼 알파고 논문 보고 구현한거야 ㅎㅎ</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2f6ecfe824ce" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[감사합니다! 올 한 해 좋은 일 가득하시길 바랍니다 :)]]></title>
            <link>https://medium.com/@heartsavior/%EA%B0%90%EC%82%AC%ED%95%A9%EB%8B%88%EB%8B%A4-%EC%98%AC-%ED%95%9C-%ED%95%B4-%EC%A2%8B%EC%9D%80-%EC%9D%BC-%EA%B0%80%EB%93%9D%ED%95%98%EC%8B%9C%EA%B8%B8-%EB%B0%94%EB%9E%8D%EB%8B%88%EB%8B%A4-7a63a3a14b75?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/7a63a3a14b75</guid>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Fri, 12 Feb 2016 23:12:29 GMT</pubDate>
            <atom:updated>2016-02-12T23:12:29.136Z</atom:updated>
            <content:encoded><![CDATA[<p>감사합니다! 올 한 해 좋은 일 가득하시길 바랍니다 :)</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7a63a3a14b75" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ironic?]]></title>
            <link>https://medium.com/@heartsavior/ironic-19ac3d640fad?source=rss-b3a8812e9a3b------2</link>
            <guid isPermaLink="false">https://medium.com/p/19ac3d640fad</guid>
            <category><![CDATA[clojure]]></category>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[apache-storm]]></category>
            <dc:creator><![CDATA[Jung-taek Lim]]></dc:creator>
            <pubDate>Tue, 26 Jan 2016 23:20:26 GMT</pubDate>
            <atom:updated>2016-01-26T23:20:26.487Z</atom:updated>
            <content:encoded><![CDATA[<p>Nathan Marz 가 Clojure 관련 팟캐스트에 출연해서 Storm 과 기타 본인의 새로운 OSP 관련 얘기를 한 듯 하다. <a href="http://blog.cognitect.com/cognicast/095">http://blog.cognitect.com/cognicast/095</a></p><p>아이러니하게도 Nathan 의 대표작인 Storm 은 Yahoo! 와 Alibaba 개발자들이 주축이 되어 Java 로의 전환을 준비하고 있다. (이미 일부 작업되어 pull request 들이 올라오고 있다.)<br>JStorm 과의 합병이 전환점이 되었지만, 합병 결과물이 Java 언어로 만들어진다는 것은 사실 Clojure 언어 자체가 진입 장벽이었음에 모두의 컨센선스가 맞춰진 것으로 보인다.</p><p>솔직히 Clojure 공부는 책 한두 번 정도만 봤고 이것저것 만들어 보면서 더 열심히 해야 되나 생각을 가끔 했는데, Storm 외에 쓸 일이 없다보니 정이 안 간다. <br>Storm 이 Java 로 전환되면 Clojure 잊고 살 듯…</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=19ac3d640fad" width="1" height="1">]]></content:encoded>
        </item>
    </channel>
</rss>