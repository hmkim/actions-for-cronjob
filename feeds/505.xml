<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
  xmlns:content="http://purl.org/rss/1.0/modules/content/"
  xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
>
	<channel>
		<title><![CDATA[Ssup2 Blog]]></title>
		<description><![CDATA[Ssup2's Personal Blog]]></description>
		<link href="https://ssup2.github.io/" />
		<atom:link href="https://ssup2.github.io/feed.xml" rel="self" type="application/rss+xml" />
    
		
		<item>
      <title><![CDATA[ELK Stack]]></title>
      <link>https://ssup2.github.io/theory_analysis/ELK_Stack/</link>
      <pubDate>Fri, 10 May 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[ELK (Elasticsearch, Logstash, Kibana)를 분석한다. 1. ELK Stack ELK Stack은 Elasticsearch, Logstash, Kibana를 조합을 의미한다. ELK Stack을 이용하여 Data를 수집하고 분석하는 Platform을 쉽게 구축할 수 있다. [그림 1]은 ELK Stack을 나타내고 있다. 2. Elasticsearch Elasticsearch는 분산형 Data 검색 및 분석 엔진 역활을 수행한다. 논리적으로는 JSON 형태와 같은 Document 형태로 Data를...]]>
      </description>
      <content:encoded>
        <![CDATA[ELK (Elasticsearch, Logstash, Kibana)를 분석한다.

1. ELK Stack



ELK Stack은 Elasticsearch, Logstash, Kibana를 조합을 의미한다. ELK Stack을 이용하여 Data를 수집하고 분석하는 Platform을 쉽게 구축할 수 있다. [그림 1]은 ELK Stack을 나타내고 있다.

2. Elasticsearch

Elasticsearch는 분산형 Data 검색 및 분석 엔진 역활을 수행한다. 논리적으로는 JSON 형태와 같은 Document 형태로 Data를 저장하며, 물리적으로는 Columnstore (Column-oriented) 형태로 Data를 저장하여 대용량의 Data를 빠르게 분석할 수 있는 구조를 갖고 있다. 또한 Elasticsearch는 Full-text Search시 Inverted Index를 이용하고, 숫자 및 위치 Data 처리시에는 BKD Tree를 이용하여 빠른 Data 검색이 가능하도록 설계되어 있다. Elasticsearch는 Master-elibigle, Data, Ingest, Coodinating 4개의 Node Type으로 구성되어 있다. Node Type이 4개이지만 하나의 Node에 4개의 Node Type을 모두 적용할 수도 있다.

2.1. Master-elibigle Node

1
2
3
node.master: true 
node.data: false
node.ingest: false


[설정 1] Master Node 설정 Configuration


Master-eligible Node는 Elasticsearch Cluster를 전반적으로 관리하는 Node이다. Cluster를 구성하는 Node들의 상태를 관리하고, Index를 관리하고, Data를 어느 Shard에 저장할지 결정한다. Cluster에서 다수의 Master-elibigle Node가 있는 경우 실제로 Master 역활을 수행하는 Node는 하나이며, 나머지 Master-elibigle Node는 Failover시 Master가 될 수 있는 예비 Node 역활을 수행한다. [설정 1]은 Master-elibigle Node를 설정하는 Configuration이다.

2.2. Data Node

1
2
3
node.master: false 
node.data: true 
node.ingest: false 


[설정 2] Data Node 설정


Data Node는 Shard를 저장하고 관리하는 Node이다. [설정 2]는 Data Node를 설정하는 Configuration이다.

2.3. Ingest Node

1
2
3
node.master: false 
node.data: false
node.ingest: true 


[설정 3] Ingest Node 설정


Ingest Node는 Data Pre-processing Pipeline을 수행하는 Node이다. 따라서 Logstash가 수행하는 Data 전처리를 Ingest Node에서도 수행할 수 있다. [설정 3]은 Ingest Node를 설정하는 Configuration이다.

2.4. Coodinating (Client) Node

1
2
3
node.master: false
node.data: false
node.ingest: false


[설정 4] Coodinating Node 설정


Coodinating Node는 외부의 (Logstash, Kibana) 요청에 따라서 Master Node, Data Node, Coodinating Node에 적절한 요청을 보내고, 요청 결과를 받아 다시 외부로 전달하는 Load Balaner 또는 Proxy 역활을 수행한다. [설정 4]는 Coodinating Node를 설정하는 Configuration이다.

3. Logstash

Logstash는 다양한 Data Source로부터 Data를 수집하고 가공하여 Elasticsearch에게 전송하는 역활을 수행한다. Data Source에는 Log 파일, App의 Rest API 호출을 통해 전달되는 Data, Beats를 통해 전달되는 Data가 있다. Logstash는 기본적으로 Data Source로부터 받은 Data를 In-memory Queue에 넣기 때문에, Logstash 장애 발생시 Data 유실이 발생한다. 이러한 Data 유실을 방지하기 위해서 Logstash는 Persistent Queue를 제공한다. Persistent Queue는 Data를 Disk에 저장하여 Data 손실을 방지한다. Persistent Queue는 Kafka, RabbitMQ와 같은 Message Queue를 대신하여 Data Buffer의 역활로도 이용될 수 있다.

3.1. Beats

beats는 Data 수집기이다. Beats는 다양한 Data 수집을 위하여 다양한 Plugin을 제공하고 있다.

4. Kibana

Kibana는 Elastic Search를 통해서 분석한 Data를 시각화하는 Tool이다.

5. 참조


  https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html
  https://www.elastic.co/guide/en/elasticsearch/guide/2.x/important-configuration-changes.html#_minimum_master_nodes
  https://www.elastic.co/kr/blog/writing-your-own-ingest-processor-for-elasticsearch
  https://blog.yeom.me/2018/03/24/get-started-elasticsearch/
  https://www.slideshare.net/AntonUdovychenko/search-and-analyze-your-data-with-elasticsearch-62204515
  https://m.blog.naver.com/PostView.nhn?blogId=indy9052&amp;logNo=220942459559&amp;proxyReferer=https%3A%2F%2Fwww.google.com%2F
  https://www.popit.kr/look-at-new-features-elasticsearch-5/
  https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781784391010/9/ch09lvl1sec50/node-types-in-elasticsearch
  http://tech.javacafe.io/2017/12/12/logstash-persistent-queue/

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Kubernetes Service Proxy]]></title>
      <link>https://ssup2.github.io/theory_analysis/Kubernetes_Service_Proxy/</link>
      <pubDate>Mon, 06 May 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[Kubernetes는 iptables, IPVS, Userspace 3가지 Mode의 Service Proxy를 지원하고 있다. 각 Mode에 따른 Service Network를 분석한다. 1. iptables Proxy Mode Chain KUBE-SERVICES (2 references) pkts bytes target prot opt in out source destination 0 0 KUBE-MARK-MASQ tcp -- * * !192.167.0.0/16 10.103.1.234 /* default/my-nginx-cluster: cluster IP */ tcp dpt:80 0...]]>
      </description>
      <content:encoded>
        <![CDATA[Kubernetes는 iptables, IPVS, Userspace 3가지 Mode의 Service Proxy를 지원하고 있다. 각 Mode에 따른 Service Network를 분석한다.

1. iptables Proxy Mode



Chain KUBE-SERVICES (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-MARK-MASQ  tcp  --  *      *      !192.167.0.0/16       10.103.1.234         /* default/my-nginx-cluster: cluster IP */ tcp dpt:80
    0     0 KUBE-SVC-52FY5WPFTOHXARFK  tcp  --  *      *       0.0.0.0/0            10.103.1.234         /* default/my-nginx-cluster: cluster IP */ tcp dpt:80
    0     0 KUBE-MARK-MASQ  tcp  --  *      *      !192.167.0.0/16       10.97.229.148        /* default/my-nginx-nodeport: cluster IP */ tcp dpt:80
    0     0 KUBE-SVC-6JXEEPSEELXY3JZG  tcp  --  *      *       0.0.0.0/0            10.97.229.148        /* default/my-nginx-nodeport: cluster IP */ tcp dpt:80
    0     0 KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL


[Table 1] KUBE-SERVICE 


Chain KUBE-NODEPORTS (1 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-MARK-MASQ  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/my-nginx-nodeport: */ tcp dpt:30915
    0     0 KUBE-SVC-6JXEEPSEELXY3JZG  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/my-nginx-nodeport: */ tcp dpt:30915 


[Table 2] KUBE-NODEPORTS 


Chain KUBE-SVC-6JXEEPSEELXY3JZG (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-SEP-6HM47TA5RTJFOZFJ  all  --  *      *       0.0.0.0/0            0.0.0.0/0            statistic mode random probability 0.33332999982
    0     0 KUBE-SEP-AHRDCNDYGFSFVA64  all  --  *      *       0.0.0.0/0            0.0.0.0/0            statistic mode random probability 0.50000000000
    0     0 KUBE-SEP-BK523K4AX5Y34OZL  all  --  *      *       0.0.0.0/0            0.0.0.0/0      


[Table 3] KUBE-SVC-XXX 


Chain KUBE-SEP-QQATNRPNVZFKMY6D (1 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-MARK-MASQ  all  --  *      *       192.167.1.138        0.0.0.0/0
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp to:192.167.1.138:53 


[Table 4] KUBE-SEP-XXX 


Chain KUBE-MARK-MASQ (23 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 MARK       all  --  *      *       0.0.0.0/0            0.0.0.0/0            MARK or 0x4000 


[Table 5] KUBE-MARK-MASQ 


Chain KUBE-POSTROUTING (1 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 MASQUERADE  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring SNAT */ mark match
0x4000/0x4000 


[Table 6] KUBE-POSTROUTING 


iptables Proxy Mode는 Kubernetes가 이용하는 Default Proxy Mode이다. [그림 1]은 Service로 전송되는 Packet이 지나는 Host의 NAT Table 경로를 나타내고 있다. [Table 1] ~ [Table 6]는 [그림 1]의 각 NAT Table의 실제 내용을 보여주고 있다. [그림 1]의 NAT Table들은 Kubernetes Cluster를 구성하는 모든 Node에 동일하게 설정된다. 따라서 Kubernetes Cluster를 구성하는 어느 Node에서도 Service로 Packet을 전송할 수 있다.

대부분의 Pod에서 전송된 Packet은 Pod의 veth를 통해서 Host의 Network Namespace로 전달되기 때문에 Packet은 PREROUTING Table에 의해서 KUBE-SERVICE Table로 전달된다. Host의 Network Namespace를 이용하는 Pod 또는 Host Process에서 전송한 Packet은 OUTPUT Table에 의해서 KUBE-SERVICE Table로 전달된다. KUBE-SERVICE Table에서 Packet의 Dest IP와 Dest Port가 ClusterIP Service의 IP와 Port와 일치한다면, 해당 Packet은 일치하는 ClusterIP Service의 NAT Table인 KUBE-SVC-XXX Table로 전달된다. Packet의 Dest IP가 Localhost인 경우에는 해당 Packet은 KUBE-NODEPORTS Table로 전달된다.

KUBE-NODEPORTS Table에서 Packet의 Dest Port가 NodePort Service의 Port와 일치하는 경우 해당 Packet은 NodePort Service의 NAT Table인 KUBE-SVC-XXX Table로 전달된다. KUBE-SVC-XXX Table에서는 iptables의 statistic 기능을 이용하여 Packet은 Service를 구성하는 Pod들로 랜덤하고 균등하게 분배하는 역활을 수행한다. [Table 3]에서 Service는 3개의 Pod으로 구성되어 있기 때문에 3개의 KUBE-SEP-XXX Table로 Packet이 랜덤하고 균등하게 분배되도록 설정되어 있는것을 확인할 수 있다. KUBE-SEP-XXX Table에서 Packet은 Container IP 및 Service에서 설정한 Port로 DNAT를 수행한다. Container IP로 DNAT를 수행한 Packet은 CNI Plugin을 통해 구축된 Container Netwokr를 통해서 해당 Container에게 전달된다.

Service로 전달되는 Packet은 iptables의 DNAT를 통해서 Pod에게 전달되기 때문에, Pod에서 전송한 응답 Packet의 Src IP는 Pod의 IP가 아닌 Service의 IP로 SNAT되어야 한다. iptables에는 Serivce를 위한 SNAT Rule이 명시되어 있지 않다. 하지만 iptables는 Linux Kernel의 Conntrack (Connection Tracking)의 TCP Connection 정보를 바탕으로 Service Pod으로부터 전달받은 Packet을 SNAT한다.

1.1. Masquerade



KUBE-MARK-MASQ Table은 Packet Masquerade를 위해서 Packet에 Marking을 수행하는 Table이다. Marking된 Packet은 KUBE-POSTROUTING Table에서 Masquerade 된다. 즉 Packet의 Src IP가 Host의 IP로 SNAT 된다. Masquerade가 필요한 경우중 하나는 Pod에서 자신이 소속되어있는 Service의 IP로 Packet을 전송하여 자기 자신에게 Packet이 돌아올 경우이다. [그림 2]는 이러한 경우를 나타내고 있다. Packet은 DNAT되어 Packet의 Src IP와 Dest IP는 모두 Pod의 IP가 된다. 따라서 Pod에서 돌아온 Packet에 대한 응답을 보낼경우, Packet은 Host의 NAT Table을 거치지 않고 Pod안에서 처리되기 때문에 SNAT가 수행되지 않는다.

Masquerade를 이용하면 Pod에게 돌아온 Packet을 Host에게 넘겨 SNAT가 수행되도록 만들 수 있다. KUBE-SEP-XXX Table에서 Packet의 Src IP가 DNAT 하려는 IP와 동일한 경우, 즉 Pod이 Service로 전송한 Packet을 자기 자신이 받을경우 해당 Packet은 KUBE-MARK-MASQ Table을 거쳐 Marking이 되고 KUBE-POSTROUTING Table에서 Masquerade 된다. Pod이 받은 Packet의 Src IP는 Host의 IP로 설정되어 있기 때문에 Pod의 응답은 Host의 NAT Table 전달되고, 다시 SNAT, DNAT 되어 Pod에게 전달된다.

2. IPVS Proxy Mode

3. Userspace Proxy Mode

4. 참조


  https://www.slideshare.net/Docker/deep-dive-in-container-service-discovery
  http://www.system-rescue-cd.org/networking/Load-balancing-using-iptables-with-connmark/
  https://kubernetes.io/docs/concepts/services-networking/service/

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Kubernetes Architecture]]></title>
      <link>https://ssup2.github.io/theory_analysis/Kubernetes_Architecture/</link>
      <pubDate>Mon, 06 May 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[Kubernetes Architecture를 분석한다. 1. Kubernetes Architecture [그림 1]은 Kubernetes Architecture를 나타내고 있다. Kubernetes는 Kubernetes를 관리하는 Master Node와 배포된 Application이 동작하는 Worker Node로 구성되어 있다. Kubernetes의 설정에 따라서 Master Node는 Worker Node의 역활도 수행할 수 있다. 1.1. Master Node Master Node는 Kubernetes Cluster를 관리하는 Node이다. HA (High Availability)를 위해서 일반적으로 다수의...]]>
      </description>
      <content:encoded>
        <![CDATA[Kubernetes Architecture를 분석한다.

1. Kubernetes Architecture



[그림 1]은 Kubernetes Architecture를 나타내고 있다. Kubernetes는 Kubernetes를 관리하는 Master Node와 배포된 Application이 동작하는 Worker Node로 구성되어 있다. Kubernetes의 설정에 따라서 Master Node는 Worker Node의 역활도 수행할 수 있다.

1.1. Master Node

Master Node는 Kubernetes Cluster를 관리하는 Node이다. HA (High Availability)를 위해서 일반적으로 다수의 홀수개의 Master Node를 이용한다. Master Node에는 etcd, kube-apiserver, kube-scheduler, kube-controller-manager가 동작한다.


  
    etcd - etcd는 분산 key-value storage로 Kuberetes Cluster 관련 Data를 저장하고 있다. 다수의 Master Node가 동작하는경우 etcd들은 etcd Cluster를 구성하여 동작하며, etcd Cluster의 etcd 사이의 Data Consistency는 Raft 알고리즘을 통해서 유지된다. etcd는 Data가 변경될 경우 해당 Data를 감시하고 있는 Client에게 Data 변경 Event를 전달하는 Watcher 기능을 제공한다. 이러한 Watcher 기능을 이용하여 Kubernetes Cluster는 etcd Cluster를 Event Bus처럼 이용하기도 한다.
  
  
    kube-apiserver - Kubernetes를 제어하는 REST API를 제공하는 Server이다. 또한 etcd와 통신하는 유일한 구성요소이다. 따라서 etcd에 Kubernetes Cluster 관련 Data를 저장하거나, etcd의 Data 변경 Event를 수신하기 위해서는 반드시 kube-apiserver를 이용해야 한다. [그림 1]에서 Kubernetes 대부분의 구성요소가 kube-apiserver와 통신하는것을 확인할 수 있다.
  
  
    kube-controller-manager - Kubernetes에서는 Kubernetes가 정의하는 yaml 문법을 통해 생성하는 객체를 Object라고 정의한다. Pod, Deployments, Statefulset, Configmap 등이 Object의 예가 된다. 그리고 이러한 Object를 제어하는 구성요소를 Controller라고 정의한다. kube-controller-manager는 이러한 Controller들을 관리한다. Controller는 kube-apiserver를 통해서 제어하려는 Object의 상태정보를 얻어오고, 얻은 상태정보를 바탕으로 다시 kube-apiserver를 통해서 Object를 제어한다.
  
  
    kube-scheduler - Pod의 Scheduling을 담당한다. kube-scheduler는 kube-apiserver를 통해서 각 Worker Node의 Pod의 상태 및 Resource 상태 정보를 얻어오고, 얻은 상태정보를 바탕으로 다시 kube-apiserver를 통해서 Pod Scheduling을 수행한다.
  


1.2. Worker Node

Worker Node는 Kubernetes 사용자가 배포한 Application이 동작하는 Node이다. Worker Node에는 kubelet, coredns가 동작한다.


  
    kubelet - kube-apiserver로부터 명령을 받아 Docker를 통해서 Pod을 생성/삭제하거나 관리하는 역활을 수행한다. 또한 CNI Plugin을 통해서 생성한 Pod의 Network를 설정하는 역활도 수행한다.
  
  
    coredns - Pod의 IP는 언제나 바뀔수 있기 때문에 Pod과 통신하기 위해서는 Pod의 IP를 직접 이용하는것 보다는 DNS를 통해서 Pod의 IP를 얻는 방식을 이용하는 것이 좋다. coredns는 Pod안에서 다른 Pod의 IP를 찾을수 있는 DNS 역활을 수행한다. 이와 유사하게 Kubernetes의 Service IP도 언제든지 바뀔수 있기 때문에, coredns는 Pod안에서 Service IP를 찾을수 있는 DNS 역활도 수행한다.
  
  
    CNI Plugin - Pod의 Network를 설정할때 이용한다. CNI (Container Network Interface)를 준수하기 때문에 CNI Plugin이라고 불린다.
  


1.3. All Node

kube-proxy, Network Daemon 둘다 Daemonset의 Pod로 동작한다. 따라서 Kubernetes Cluster를 구성하는 모든 Node에서 kube-proxy, Network Daemon이 동작한다.


  
    kube-proxy - Kubernetes의 Service를 Kubernetes Cluster 내부나 외부에 노출시킬 수 있도록 Proxy Server 역활을 수행하거나, iptables를 제어하는 역활을 수행한다.
  
  
    Network Daemon - Pod 사이에 통신이 가능하도록 Node (Host)의 Network를 설정한다. Network Daemon은 Host Network Namespace에서 동작하고 Network 설정을 변경할 수 있는 권한을 갖고 있기 때문에 Node의 Network 설정을 자유롭게 변경할 수 있다. 어떠한 CNI Plugin을 이용하냐에 따라서 Network Daemon이 결정된다. flannel의 flanneld, calico의 calio-felix, cilium의 cilium-agent가 Network Daemon이라고 볼수 있다.
  


2. 참조


  https://www.aquasec.com/wiki/display/containers/Kubernetes+Architecture+101

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Couchbase Memcached 호환]]></title>
      <link>https://ssup2.github.io/theory_analysis/Couchbase_Memcached_%ED%98%B8%ED%99%98/</link>
      <pubDate>Fri, 03 May 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[Couchbase의 Memcached 호환 기능을 분석한다. 1. Couchbase Memcached 호환 Couchbase는 기존의 Memcached를 Couchbase로 대체할 수 있도록 하는 Memcached 호환 기능을 제공한다. 기존의 Memcached Cluster를 Couchbase Cluster로 교체하면 Data 처리 성능은 떨어지지만, Memcached Cluster가 제공하지 못하는 Data Replication, HA, Data Rebalancing 기능을 이용할 수 있게 된다. 또한 Couchbase Type Bucket을 이용하면...]]>
      </description>
      <content:encoded>
        <![CDATA[Couchbase의 Memcached 호환 기능을 분석한다.

1. Couchbase Memcached 호환



Couchbase는 기존의 Memcached를 Couchbase로 대체할 수 있도록 하는 Memcached 호환 기능을 제공한다. 기존의 Memcached Cluster를 Couchbase Cluster로 교체하면 Data 처리 성능은 떨어지지만, Memcached Cluster가 제공하지 못하는 Data Replication, HA, Data Rebalancing 기능을 이용할 수 있게 된다. 또한 Couchbase Type Bucket을 이용하면 Memcached에서 모든 메모리 공간을 이용할때 Data 덮어쓰기로 인해 발생하는 Data 손실도 방지할 수 있다.

[그림 1]은 Couchbase와 Moxi를 이용하여 기존의 Memcached를 대체하는 방법을 나타내고 있다. Couchbase Library, Server Side Moxi, Client Side Moxi 3가지 방법을 제공한다. Moxi는 Memcached Client와 Couchbase Server 사이에서 Memcached Procotol을 Couchbase Protocol로 변환하는 작업을 수행하는 Proxy 서버이다.


  
    Couchbase Library - 기존의 Memecached Library를 Couchbase Library로 변경하는 방법이다. 성능 저하를 최소화 할 수 있지만 기존의 Application을 수정해야하는 단점을 갖고 있다.
  
  
    Server Side Moxi - Server Node에 Moxi를 구동하여 Memcached Procotol을 Couchbase Protocol로 변경하는 방법이다. SPOF (Single point of failure) 문제로 인하여 현재는 권장하지 않는 방법이다.
  
  
    Client Side Moxi - Client Node에 Moxi를 구동하여 Memcached Procotol을 Couchbase Protocol로 변경하는 방법이다. Memcached Library가 Server Node의 Memcacehd가 아닌 Client Node의 Moxi에 접속하도록 Appliation을 수정해야 한다.
  


2. 참조


  https://forums.couchbase.com/t/moxi-with-memcached-bucket/18438

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Couchbase]]></title>
      <link>https://ssup2.github.io/theory_analysis/Couchbase/</link>
      <pubDate>Wed, 01 May 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[Couchbase를 분석한다. 1. Couchbase Couchbase는 JSON처럼 계층을 이루는 Key-Value Data를 저장하는 Document-Oriented DB이다. [그림 1]은 Couchbase가 관리하는 Document가 Node에 어떻게 Mapping 되는지를 나타내고 있다. Couchbase의 Document는 Bucket이라고 불리는 Document Group에 위치한다. Document는 Document의 Key를 CRC32 Hashing 알고리즘을 통해서 vBucket이라고 불리는 Shard에 분리되어 저장된다. Couchbase는 vBucket 단위로 Replication, Rebalancing을 수생한다. vBucket은...]]>
      </description>
      <content:encoded>
        <![CDATA[Couchbase를 분석한다.

1. Couchbase



Couchbase는 JSON처럼 계층을 이루는 Key-Value Data를 저장하는 Document-Oriented DB이다. [그림 1]은 Couchbase가 관리하는 Document가 Node에 어떻게 Mapping 되는지를 나타내고 있다. Couchbase의 Document는 Bucket이라고 불리는 Document Group에 위치한다. Document는 Document의 Key를 CRC32 Hashing 알고리즘을 통해서 vBucket이라고 불리는 Shard에 분리되어 저장된다. Couchbase는 vBucket 단위로 Replication, Rebalancing을 수생한다. vBucket은 각 Bucket마다 1024개씩 존재한다. vBucket은 다시 vBucket-Node Map을 통해서 Couchbase Cluster를 구성하고 있는 특정 Node로 Mapping된다.

Couchbase는 Memcached를 기반으로하는 Built-in Cache를 갖고 있다. 대부분의 Data관련 동작은 Built-in Cache, 즉 Memory에서 수행되기 때문에 빠른 Data 처리가 가능하다. Built-in Cache에 저장되거나 변경된 Data는 Disk에 비동기적으로 기록될 수 있도록 설계되어 있다. Couchbase는 Built-in Cache를 활용하여 기존의 Memcached를 Couchbase로 대체할 수 있도록 Memcached 호환 기능도 제공한다.

1.1. Bucket

Bucket은 Couchbase에서 관리하는 Document Group이다. 하나의 CouchBase Cluster에 여러개의 Bucket이 존재할 수 있으며, 각 Bucket마다 Resource 사용량을 제한할 수 있다. Bucket에는 Couchbase, Ephemeral, Memcached 3가지 Type이 존재한다.


  
    Couchbase - memory + disk를 이용하는 Bucket Type이다. Data는 Memory와 Disk에 저장되며, Memory가 가득찬 경우 Memory에 Data는 덮어씌워 진다. 하지만 Data는 Disk에 남아있기 때문에 Data의 손실로 이어지지는 않는다. Replication, Rebalancing을 지원한다.
  
  
    Ephemeral - memory만 이용하는 Bucket Type이다. Data는 Memory에만 저장되며, Memory가 가득찬 경우 기존의 Data는 덮어씌워진다. 이는 곧 Data의 손실로 이어진다. Replication, Rebalancing을 지원한다.
  
  
    Memcached - memory만 이용하는 방식이다. memcached처럼 Ketama consistent hashing을 이용하여 Data를 저장한다. Replication, Rebalancing을 지원하지 않는다.
  


1.2. Replication

Couchbase의 Replica는 오직 HA를 위해서 존재한다. Replica는 Failover로 인하여 Active 상태가 되기전까지 다른 Client에게 제공되지 않는다. Couchbase Cluster는 Client의 Write 동작에 대하여 다음과 같은 4가지 ACK 옵션을 제공한다.


  Memory - Data가  Memroy에 저장되면 ACK를 전송한다.
  Memory, Disk - Data가 Primary Node의 Memory와 Disk에 저장되면 ACK를 전송한다.
  Memory, Replica - Data가 Primary Node의 Memory, Secondary Node의 Memory에 저장되면 ACK를 전송한다.
  Memory, Disk, Replica - Data가 Primary Node의 Memory와 Disk, Secondary Node의 Memory에 저장되면 ACK를 전송한다.


2. 참조


  https://docs.couchbase.com/server/5.0/architecture/core-data-access-buckets.html
  https://docs.couchbase.com/server/6.0/learn/buckets-memory-and-storage/vbuckets.html
  https://docs.couchbase.com/server/4.1/concepts/data-management.html

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Kafka Cluster, Replication]]></title>
      <link>https://ssup2.github.io/theory_analysis/Kafka_Cluster_Replication/</link>
      <pubDate>Mon, 15 Apr 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[Kafka의 Cluster, Replication 기법을 분석한다. 1. Kafka Cluster Kafka Broker는 일반적으로 Load Balancing 및 HA (High Availability)를 위해서 다수의 Node 위에서 Cluster를 이루어 동작한다. [그림 1]은 Kafka Cluster를 나타내고 있다. Kafka Broker는 Message를 수신, 관리, 전송하는 Kafka의 핵심 Server이다. Zookeeper는 Cluster를 이루는 각 Kafka Broker의 동작 상태를 파악하고 상태 정보를...]]>
      </description>
      <content:encoded>
        <![CDATA[Kafka의 Cluster, Replication 기법을 분석한다.

1. Kafka Cluster



Kafka Broker는 일반적으로 Load Balancing 및 HA (High Availability)를 위해서 다수의 Node 위에서 Cluster를 이루어 동작한다. [그림 1]은 Kafka Cluster를 나타내고 있다. Kafka Broker는 Message를 수신, 관리, 전송하는 Kafka의 핵심 Server이다. Zookeeper는 Cluster를 이루는 각 Kafka Broker의 동작 상태를 파악하고 상태 정보를 Producer 및 Consumer에게 전달한다.

Producer는 Kafka Cluster으로부터 Message를 전달하려는 Topic의 Partition 위치를 파악한 다음, Partition이 있는 Kafka Broker에게 직접 Message를 전달한다. Producer는 하나의 Topic에 다수의 Partition이 있는경우 기본적으로 Round-robin 순서대로 Message를 전달할 Partition을 선택한다. 만약 다른 Partition 선택 알고리즘이 필요하면, Producer 개발자는 Kafka가 제공하는 Interface를 통해 Partition 선택 알고리즘을 직접 개발 및 적용할 수 있다. Consumer도 Producer와 유사하게 Kafka Cluster으로부터 Message를 전달 받으려는 Topic의 Partition 위치를 파악한 다음, Consumer는 Partition이 있는 Kafka으로부터 Message를 직접 전달 받는다.

Kafka Cluster는 Partition을 최대한 각 Node에 분산시켜 Load Balancing을 수행하고 Message 처리량도 높인다. Kafka Cluster를 구성하면 일부의 Kafka Broker가 죽어도 Producer와 Consumer는 Kafka를 계속 이용할 수 있지만 Message 손실을 막을 수 없다. 이러한 Message 손실을 막기위해 필요한 기법이 Replication이다.

2. Kafka Replication



Kafka는 Partition Replication을 지원한다. Replica는 [그림 2]는 Topic A와 Topic B는 Replica 2, Topic C는 Replica 3으로 설정한 상태를 나타내고 있다. Partition이 Replication이 되어도 Producer와 Consumer는 오직 하나의 Partition만을 이용한다. Kafka에서는 Producer와 Consumer가 이용하는 Partition은 Leader라고 부르며 나머지 복재본은 Follower라고 부른다. Leader Partition과 Follower Partition 사이의 Replication은 Producer의 ACK 설정에 따라서 Sync 방식, Async 방식 둘다 이용이 가능하다.

3. 참조


  https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/
  https://www.tutorialspoint.com/apache_kafka/apache_kafka_cluster_architecture.htm
  https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f
  https://www.linkedin.com/pulse/partitions-rebalance-kafka-raghunandan-gupta/
  https://grokbase.com/t/kafka/users/1663h6ydyz/kafka-behind-a-load-balancer

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[RabbitMQ ACK]]></title>
      <link>https://ssup2.github.io/theory_analysis/RabbitMQ_Ack/</link>
      <pubDate>Mon, 01 Apr 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[RabbitMQ의 ACK를 분석한다. 1. RabbitMQ ACK RabbitMQ는 Producer와 Consumer 사이의 Message 전달을 보장하기 위한 기법으로 ACK를 제공한다. [그림 1]은 RabbitMQ의 ACK 과정을 나타내고 있다. RabbitMQ에서는 Producer가 RabbitMQ에게 Message를 전송한 다음 RabbitMQ으로부터 ACK를 받는 기법을 Producer Confirm이라고 명칭한다. 이와 유사하게 RabbitMQ에서는 RabbitMQ가 Consumer에게 Message를 전송한 다음 Consumer으로부터 ACK를 받는 기법을 Consumer...]]>
      </description>
      <content:encoded>
        <![CDATA[RabbitMQ의 ACK를 분석한다.

1. RabbitMQ ACK



RabbitMQ는 Producer와 Consumer 사이의 Message 전달을 보장하기 위한 기법으로 ACK를 제공한다. [그림 1]은 RabbitMQ의 ACK 과정을 나타내고 있다. RabbitMQ에서는 Producer가 RabbitMQ에게 Message를 전송한 다음 RabbitMQ으로부터 ACK를 받는 기법을 Producer Confirm이라고 명칭한다. 이와 유사하게 RabbitMQ에서는 RabbitMQ가 Consumer에게 Message를 전송한 다음 Consumer으로부터 ACK를 받는 기법을 Consumer Acknowledgement라고 명칭한다.

ACK 기법은 Message가 최소 한번 이상은 전달되는 것을 보장한다. 송신자는 Message를 전송한 이후에 수신자로부터 ACK를 받지 못한다면, 수신자에게 ACK를 받을때까지 반복해서 Message를 전송해야 한다. 따라서 Producer는 ACK를 받지 못하면 Message를 재전송 하도록 구현되어 있어야한다. 송신자가 Message를 처리한 다음 수신자에게 ACK를 전송하여도 일시적 장애로 인하여 수신자에게 ACK가 전달되지 않을 수 있다. ACK를 받지 못한 송신자는 동일한 Message를 다시 수신자에게 전송할 수 있다. 즉 수신자는 동일한 Message를 2번이상 받을 수 있다. 따라서 Consumer는 동일한 Message를 수신하더라도 동작에 이상이 없도록 구현되어 있어야한다. 이러한 성질을 멱등성 (Idempotent)라고 표현한다.

1.1. Producer Confirm

Producer가 RabbitMQ에게 Message를 전송하면, RabbitMQ는 받은 Message를 Exchange에게 전달한다. Exchange는 Exchange에 설정된 규칙에 따라서 받은 Message를 버리거나, Queue 또는 다른 Exchange에게 전달한다. 만약 Message가 버려진다면 RabbitMQ는 Producer에게 바로 ACK를 전송한다. Message가 Queue로 전송되면 Queue가 Message를 저장한 이후에 Producer에게 ACK를 보낸다. 이때 Queue가 Mirroring 되어 있다면 Message는 Mirroring된 모든 Queue에 복사된 이후에 Producer에게 ACK를 보낸다. Producer는 Producer의 설정에 따라서 ACK를 기다리지 않을 수도 있다.

1.2. Consumer Acknowledgement

RabbitMQ가 Consumer에게 Message를 전송하면, Consumer는 받은 Message를 처리한 다음 RabbitMQ에게 ACK를 전송한다. RabbitMQ는 Consumer의 설정에 따라서 ACK를 기다리지 않을 수도 있다.

2. 참조


  https://www.rabbitmq.com/reliability.html
  https://www.rabbitmq.com/confirms.html

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Jekyll 설치, Build - Ubuntu 18.04]]></title>
      <link>https://ssup2.github.io/record/Jekyll_%EC%84%A4%EC%B9%98_Build_Ubuntu_18.04/</link>
      <pubDate>Mon, 01 Apr 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Record]]></category>
      <description>
        <![CDATA[1. Build 환경 Ubuntu 18.04 LTS 64bit, root user 2. Ubuntu Package 설치 Jeykll 구동에 필요한 Ubuntu Package를 설치한다. # apt install ruby-full build-essential zlib1g-dev 3. Ruby Gem, Jekyll 설치 Jekyll 구동에 필요한 Ruby Gem 및 Jekyll을 설치한다. # gem install bundler -v '1.16.1' # bundle install # gem install...]]>
      </description>
      <content:encoded>
        <![CDATA[1. Build 환경


  Ubuntu 18.04 LTS 64bit, root user


2. Ubuntu Package 설치


  Jeykll 구동에 필요한 Ubuntu Package를 설치한다.


# apt install ruby-full build-essential zlib1g-dev


3. Ruby Gem, Jekyll 설치


  Jekyll 구동에 필요한 Ruby Gem 및 Jekyll을 설치한다.


# gem install bundler -v '1.16.1'
# bundle install
# gem install jeykll


4. Jekyll Build &amp; Serve


  Jekyll Build &amp; Serve를 통해서 Local에서 Jekyll Blog를 확인한다.
    
      Jekyll Blog의 Root 폴더에서 아래의 명령어를 실행한다.
      명령어 실행 후 127.0.0.1:4000으로 접속하여 Jekyll Blog를 확인한다.
    
  


# jekyll serve


5. 참조


  https://jekyllrb.com/docs/installation/ubuntu/

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Visual Studio Code 설치, 설정, 사용 - Windows 10]]></title>
      <link>https://ssup2.github.io/record/Visual_Studio_Code_%EC%84%A4%EC%B9%98_%EC%84%A4%EC%A0%95_%EC%82%AC%EC%9A%A9_Windows_10/</link>
      <pubDate>Thu, 14 Mar 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Record]]></category>
      <description>
        <![CDATA[1. 환경 2. Docker for Windows 설치 3. WSL Ubuntu 설치 4. Visual Studio Code 설치, 설정 5. 사용법 6. 참조 1. 환경 Windows 10 Pro 64bit Hyper-V를 이용하기 위해서는 Pro 이상의 Version이 필요하다. Bios에서 Virtualization 기능을 ON해야 한다. WSL (Windosws Subsystem for Linux)를 이용하기 위해서 Windows를 Update한다. 2. Docker...]]>
      </description>
      <content:encoded>
        <![CDATA[


  1. 환경
  2. Docker for Windows 설치
  3. WSL Ubuntu 설치
  4. Visual Studio Code 설치, 설정
  5. 사용법
  6. 참조




1. 환경


  Windows 10 Pro 64bit
    
      Hyper-V를 이용하기 위해서는 Pro 이상의 Version이 필요하다.
      Bios에서 Virtualization 기능을 ON해야 한다.
      WSL (Windosws Subsystem for Linux)를 이용하기 위해서 Windows를 Update한다.
    
  


2. Docker for Windows 설치


  Visual Studio Code의 Terminal에서 Docker 이용을 위한 Docker for Windows를 설치한다.
    
      https://docs.docker.com/docker-for-windows
    
  
  설치 완료후 Docker for Windows를 실행하여 Hyper-V를 활성화한다.
    
      Docker for Windows는 Hyper-V로 생성한 VM에서 Docker를 실행하는 구조이다.
    
  





  WSL Ubuntu에서 Docker에 접근할 수 있도록 Docker Daemon을 2375 Port로 개방한다.





  Windows에서 Container의 IP에 바로 접근할 수 있도록 Routing Rule을 추가한다.
    
      Default Docker Network인 172.17.0.0/24 Network 관련 Routing Rule을 추가한다.
      PowerShell을 관리자 권한으로 실행하여 아래의 명령어를 실행한다.
    
  


&gt; route add  172.17.0.0 MASK 255.255.0.0 10.0.75.2


3. WSL Ubuntu 설치


  WSL (Windows Subsystem for Linux) Bash를 활성화한다.
    
      개발자 기능 사용을 검색하여 실행한다.
      아래와 같이 개발자 모드로 변경한다.
    
  





  Windows 기능에서 WSL을 활성화 한다.





  WSL Ubuntu 설치한다.
    
      Store에서 Ubuntu를 검색하여 설치하고 재부팅한다.
    
  





  WSL Ubuntu의 root 계정을 생성한다.
    
      WSL Ubuntu를 설치 후 처음으로 실행하면 WSL Ubuntu에서 이용할 User와 Password를 입력 받는다.
      WSL Ubuntu에서 아래의 명령를 실행한다.
    
  


$ sudo passwd root
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully



  WSL Ubuntu가 Default 계정으로 root를 이용하도록 설정한다.
    
      WSL Ubuntu를 종료한 다음, PowerShell을 관리자 권한으로 실행하여 아래의 명령어를 실행한다.
    
  


&gt; ubuntu config --default-user root



  Docker, Docker Compose 설치 및 설정한다.
    
      WSL Ubuntu를 실행하여 Docker Client를 위해서 Docker Package를 설치한다.
      Docker for Windows의 Docker와 연결하기 위해서 Bash에 Docker Host를 지정한다.
      WSL Ubuntu에서 아래의 명령어를 입력한다.
    
  


# apt update
# apt install docker.io
# apt install docker-compose
# echo "export DOCKER_HOST=tcp://localhost:2375" &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc



  git Client를 설치
    
      git Client를 설치한다.
      git Client가 CRLF를 LF로 자동으로 변경하도록 설정한다.
      WSL Ubuntu에서 아래의 명령어를 입력한다.
    
  


# apt install git
# git config --global core.autocrlf input



  WSL Ubuntu를 종료한다.


4. Visual Studio Code 설치, 설정


  Visual Studio Code 설치
    
      https://code.visualstudio.com/
    
  
  Visual Studio Code의 Default Shell을 WSL Ubuntu로 바꾼다.
    
      Ctrl + Shift + P를 눌러 Command Palatte를 실행하고 Terminal: Select Default Shell을 선택한다.
      WSL Ubuntu를 선택한다.
    
  


5. 사용법

6. 참조


  https://nickjanetakis.com/blog/setting-up-docker-for-windows-and-wsl-to-work-flawlessly
  https://forums.docker.com/t/connecting-to-containers-ip-address/18817
  https://webdir.tistory.com/543

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Hyper-V NAT 설정 - Windows 10]]></title>
      <link>https://ssup2.github.io/record/Hyper-V_NAT_%EC%84%A4%EC%A0%95_Windows_10/</link>
      <pubDate>Thu, 14 Mar 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Record]]></category>
      <description>
        <![CDATA[1. 설정 환경 NAT Network Network - 172.35.0.0/24 Gateway - 172.35.0.1 Switch Name - NAT-Switch Network Name - NAT-Network VM Address - 172.35.0.100 2. Switch 생성 및 NAT 설정 Powershell 관리자 권한에서 아래의 명령어 수행한다. &gt; New-VMSwitch -SwitchName "NAT-Switch" -SwitchType Internal &gt; $AdapterName=(Get-NetAdapter -Name "vEthernet (NAT-Switch)").Name &gt; New-NetIPAddress -IPAddress 172.35.0.1...]]>
      </description>
      <content:encoded>
        <![CDATA[1. 설정 환경


  NAT Network
    
      Network - 172.35.0.0/24
      Gateway - 172.35.0.1
      Switch Name - NAT-Switch
      Network Name - NAT-Network
    
  
  VM
    
      Address - 172.35.0.100
    
  


2. Switch 생성 및 NAT 설정


  Powershell 관리자 권한에서 아래의 명령어 수행한다.


&gt; New-VMSwitch -SwitchName "NAT-Switch" -SwitchType Internal
&gt; $AdapterName=(Get-NetAdapter -Name "vEthernet (NAT-Switch)").Name
&gt; New-NetIPAddress -IPAddress 172.35.0.1 -PrefixLength 24 -InterfaceAlias $AdapterName
&gt; New-NetNat -Name NAT-Network -InternalIPInterfaceAddressPrefix 172.35.0.0/24


3. VM


  NAT로 구성한 Network 안에는 DHCP Server가 없기 때문에 수동으로 IP 설정이 필요하다.
    
      /etc/netplan/50-cloud-init.yaml 파일을 아래와 같이 설정한다.
    
  


# This file is generated from information provided by
# the datasource.  Changes to it will not persist across an instance.
# To disable cloud-init's network configuration capabilities, write a file
# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:
# network: {config: disabled}
network:
    ethernets:
        eth0:
            addresses:
                - 172.35.0.100/24
            dhcp4: false
            gateway4: 172.35.0.1
            nameservers:
                addresses:
                    - 8.8.8.8
                search: []
    version: 2


[파일 1] /etc/netplan/50-cloud-init.yaml



  변경된 Network를 적용한다.


# netplan apply


4. 참조

  https://deploywindows.com/2017/06/01/missing-nat-in-windows-10-hyper-v/

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[PostgreSQL Replication]]></title>
      <link>https://ssup2.github.io/theory_analysis/PostgreSQL_Replication/</link>
      <pubDate>Sun, 10 Mar 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[PostgreSQL의 HA(High Availabilty)를 위한 Replicaiton 기법을 분석한다. 1. PostgreSQL Replication PostgreSQL의 Replication은 기본적으로 Master-Slave Replication에 기반을 두고 있다. Master-Slave Replication은 하나의 Master DB와 다수의 Slave DB들을 통해 Replication을 수행하는 방식이다. [그림 1]은 Master-Slave Replication을 나타내고 있다. Master는 Client로부터 받은 DB 변경 Query에 따라 DB를 변경하고, 변경 내용을 Slave DB에게 전달하여...]]>
      </description>
      <content:encoded>
        <![CDATA[PostgreSQL의 HA(High Availabilty)를 위한 Replicaiton 기법을 분석한다.

1. PostgreSQL Replication



PostgreSQL의 Replication은 기본적으로 Master-Slave Replication에 기반을 두고 있다. Master-Slave Replication은 하나의 Master DB와 다수의 Slave DB들을 통해 Replication을 수행하는 방식이다. [그림 1]은 Master-Slave Replication을 나타내고 있다. Master는 Client로부터 받은 DB 변경 Query에 따라 DB를 변경하고, 변경 내용을 Slave DB에게 전달하여 Replication을 수행한다. 따라서 Master는 Read/Write Mode로 동작하고 Slave들은 Read Mode로 동작한다. Client는 Write 요청을 반드시 Master에게 전달해야 하고, Read 요청은 적절한 Master 또는 적절한 Slave에 전달하면 된다. 일반적으로 Slave앞에는 LB(Load Balancer)를 두어 Slave로 오는 Read 요청을 분산시키고, Read 성능을 높인다.

1.1. Replication

Replication 방식에는 WAL (Write Ahead Log) 방식과 Streaming 방식 2가지를 지원한다.

1.1.1. WAL (Write Ahead Log) Replication



WAL (Write Ahead Log) Replication을 이해하기 위해서는 WAL을 이해해야 한다. WAL은 의미그대로 Write 동작으로 인한 DB 변경 내용을 실제 Disk에 반영하기 전에 기록하는 Log이다. MySQL의 DB Engine인 InnoDB가 기록하는 Redo Log과 동일하다고 보면 된다. PostgreSQL은 Disk 접근을 최소화 하기 위해서 DB 변경 내용을 Buffer Memory와 WAL에 기록했다가 Checkpoint라는 동작을 통해서 한번에 Disk에 반영한다. 이때 Disk에 반영된 WAL은 삭제되기 때문에 WAL은 계속 Disk에 유지 되지 않고 일정한 규칙에 의해서 주기적으로 삭제되는 특징을 갖는다. WAL은 Replication 뿐만 아니라 Query 재실행, Query Rollback등의 다양한 Query 관련 동작에서도 이용된다.

WAL Replication은 WAL을 Slave에 전달하여 Replication을 수행하는 기법이다. [그림 2]는 WAL Replication을 나타내고 있다. WAL은 주기적으로 삭제되는 특징을 갖고있기 때문에 WAL Replication이 설정된 PostgreSQL은 WAL을 주기적으로 Archive에 복사한다. Slave DB는 Master DB의 Archive에 있는 WAL을 복사하여 가져온뒤 WAL에 있는 DB 변경 내용을 자신의 WAL에 반영하여 Replication을 진행한다.

WAL Replication은 WAL을 저장하는 파일 단위인 Segment 단위로 수행되기 때문에, Master DB의 변경 내용이 쪼개져 Slave DB에 자주 전달되는 방식이 아니라 많은 변경 내용이 한꺼번에 전달되는 방식이다. 따라서 갑작스러운 Master DB의 죽음은 많은 Data의 손실로 이어질 수 있고, Slave DB에 Master DB 변경 내용이 적용되는데 시간이 걸리는 기법이다. 이러한 단점을 해결하기 위해서 나온 기법이 Streaming Replication이다.

1.1.2. Streaming Replication



Streaming Replication은 WAL에 기록된 변경 내용을 바로 Slave DB에게 전달하는 기법이다. [그림 3]은 Streaming Replication을 나타내고 있다. Master DB는 WAL Sender를 통해 WAL에 기록된 Master DB 변경 내용을 Slave DB의 WAL Receiver에게 전달한다. Slave DB는 WAL Receiver을 통해 받은 Master DB의 변경 내용을 자신의 WAL에 기록하여 Replication을 수행한다. Streaming Replication은 Master DB의 변경 내용을 변경 내용 단위인 Record 단위로 바로 Slave DB에게 전달하기 때문에 갑작스러운 Master DB의 죽음으로 인한 Data 손실을 최소화 할 수 있다.

Streaming Replication은 Archive에 있는 WAL을 이용하지 않고 원본 WAL을 이용하여 수행된다. 따라서 Checkpoint으로 인해서 삭제된 WAL안의 Master DB 변경 내용은 Streaming Replication을 통해서 Slave DB에게 전달되지 못한다. 다시 말해 시간이 오래 경과된 Master DB 변경 내용은 Streaming Replication을 통해서 Slave DB에게 전달되지 못한다는 의미이다. 이러한 문제를 해결하기 위해서 PostgreSQL은 Streaming Replication 이용시 WAL Replication을 보조로 이용할 수 있다. WAL Replication을 보조로 이용하는 Slave DB는 먼져 Master DB의 Archive에 있는 WAL을 복사하여 가져와 Replication을 수행한다. 그 뒤 Streaming으로 넘어오는 WAL Record를 통해서 Replication을 마무리한다. Streaming Replication은 Sync, Async 2가지 방식 모두 지원하고 있으며, 기본 설정은 Async 방식을 이용하도록 설정되어 있다.

1.2. Pgpool-II



Pgpool-II은 PostgreSQL과 App사이에서 다양한 역활을 수행하는 Middleware이다. [그림 4]는 Pgpool-II와 같이 동작하는 PostgreSQL을 나타내고 있다. Pgpool-II가 수행하는 첫번째 역활은 Connection Pooling이다. Pgpool-II는 PostgreSQL들과 일정한 수의 Connection을 미리 맺어 Connection Pool을 생성한다. 그 후 App이 Pgpool-II과 Connection을 맺을때 마다 Pgpool-II는 Connection Pool의 Connection을 해당 App에게 할당한다. Connection Pooling을 통해서 Pgpool-II는 과도한 수의 App의 Connection을 방지 할 수 있고, Connection Filtering도 가능하다. 또한 Failover로 인하여 Master DB와 Slave DB가 바뀌어도 App은 Pgpool-II에만 Connection을 맺는 구조이기 때문에 Pgpool-II는 App에게 Auto Failover를 지원가능하다.

Pgpool-II의 두번째 주요기능은 Read 요청 (Select Query) Load Balancing이다. Pgpool-II는 Master DB와 Slave DB들 사이에서 적절하게 Read 요청을 Load Balancing 하여 Read 성능을 높일 수 있다. 각 DB마다 Weight를 설정 할 수 있어 Weight에 비례하여 Read 요청을 분배할 수 있다. Replication을 Async 방식을 이용할 경우 Master DB와 Slave DB의 Data 차이가 발생할 수 있는데, Pgpool-II는 Slave DB가 Master DB와 특정 용량 만큼 Data가 차이날 경우 해당 Slave DB에 Read 요청을 보내지 않도록 하는 기능도 갖고 있다. Master DB와 Slave DB의 Data 차이 때문에 만약 Master에게만 Read 요청을 보내는 Endpoint를 App에게 제공하고 싶다면, 별도의 Pgpool-II을 구동하여 App에게 제공해야 한다. Write 요청은 Pgpool-II에 의해서 언제나 Master DB에게만 전달된다.

Pgpool-II은 HA를 위해서 다수의 Pgpool-II을 Active-standby로 묶는 기능을 제공한다. App은 VIP를 통해서 항상 Active Pgpool-II로만 접근한다. Pgpool-II은 Watchdog를 내장하고 있으며, Watchdog를 통해서 외부의 Pgpool-II의 상태를 감시한다. 만약 Active Pgpool-II가 죽는다면 Standby Pgpool-II는 App이 자신에게 접근 할 수 있도록 VIP를 자신에게 설정하고, Active Pgpool-II로 승격하여 동작을 이어나간다.

2. 참조


  Replication - https://severalnines.com/blog/postgresql-streaming-replication-deep-dive
  Replication - https://blog.2ndquadrant.com/basics-of-tuning-checkpoints/
  Pgpool-II - https://www.cybertec-postgresql.com/en/connection-pooling-intro-pgbouncer-and-pgpool-ii
  Pgpool-II - https://boilerbuzzni.wordpress.com/2017/12/22/postgresql-10-logical-replication-pgpool-ii/

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[RabbitMQ Clustering, Mirroring]]></title>
      <link>https://ssup2.github.io/theory_analysis/RabbitMQ_Clustering_Mirroring/</link>
      <pubDate>Thu, 28 Feb 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[RabbitMQ의 HA (High Availability)를 위한 RabbitMQ의 Clustering, Mirroring 기법을 분석한다. 1. RabbitMQ Clustering RabbitMQ Clustering은 다수의 RabbitMQ를 하나의 RabbitMQ처럼 묶어서 사용하는 기법이다. [그림 1]은 RabbitMQ Cluster를 나타내고 있다. RabbitMQ Cluster를 구성하는 RabbitMQ는 Queue를 제외한 모든 정보를 공유한다는 특징을 갖는다. 따라서 동일 Cluster안에 있는 모든 RabbitMQ는 동일한 Exchange를 갖고 있다. [그림...]]>
      </description>
      <content:encoded>
        <![CDATA[RabbitMQ의 HA (High Availability)를 위한 RabbitMQ의 Clustering, Mirroring 기법을 분석한다.

1. RabbitMQ Clustering



RabbitMQ Clustering은 다수의 RabbitMQ를 하나의 RabbitMQ처럼 묶어서 사용하는 기법이다. [그림 1]은 RabbitMQ Cluster를 나타내고 있다. RabbitMQ Cluster를 구성하는 RabbitMQ는 Queue를 제외한 모든 정보를 공유한다는 특징을 갖는다. 따라서 동일 Cluster안에 있는 모든 RabbitMQ는 동일한 Exchange를 갖고 있다. [그림 1]에서 모든 RabbitMQ는 Exchange A를 갖고 있는것을 확인 할 수 있다. 또한 RabbitMQ Cluster에서 기본적으로 Queue는 한개만 존재한다는 특징도 갖는다. [그림 1]에서 Queue A와 Queue B는 Cluster에서 하나만 존재하는 것을 확인 할 수 있다. 동일 Cluster안의 있는 모든 RabbitMQ는 Erlang Cookie라고 불리는 비밀키를 공유한다. Erlang Cookie를 통해서 RabbitMQ는 상대방 RabbitMQ가 동일한 Cluster에 있는 RabbitMQ인지 확인한다. 또한 Cluster를 제어하는 CLI Tool 또한 Cluster의 Erlang Cookie를 갖고 있어야 해당 Cluster를 제어 할 수 있다.

Client는 일반적으로 Cluster의 모든 RabbitMQ와 Connection을 맺지않고 오직 하나의 RabbitMQ와 Connection을 맺는다. 즉 각 Producer/Consumer는 Cluster의 RabbitMQ 중에서 하나의 RabbitMQ와 Connection을 맺는다. Cluster안의 모든 RabbitMQ는 동일한 Exchange를 갖고 있기 때문에 Producer는 어떠한 RabbitMQ와 Connection을 맺어도 상관없다. Exchange는 Producer 모르게 Message를 전달해야할 Queue가 있는 RabbitMQ에게 Message 다시 전달하기 때문이다. 이와 비슷하게 Subsciber 또한 반드시 이용할 Queue가 있는 RabbitMQ와 직접 Connection을 맺을 필요없다. Consumer와 Connection을 맺은 RabbitMQ는 Queue가 있는 RabbitMQ으로부터 Message를 얻어 Subsriber에게 전달하기 때문이다.

Client는 Cluster의 RabbitMQ중에서 하나의 RabbitMQ와 Connection을 맺지만, HA를 위해서 Client는 Cluster의 모든 RabbitMQ와 Connection을 맺을 수 있는 환경이어야 한다. 그래야 Cluster의 특정 RabbitMQ가 죽을경우 Client는 다른 RabbitMQ와 Connection을 맺어 계속 RabbitMQ를 이용 할 수 있기 때문이다. 일반적으로 Client와 RabbitMQ Cluster 사이에 Load Balancer를 두어, Client에게 Cluster의 모든 RabbitMQ에 접속할 수 있는 환경 제공 및 Connection Load Balancing을 수행한다. 또는 Client가 Cluster의 모든 RabbitMQ의 IP(Domain), Port 접속 정보 갖고 있어, Client 스스로 RabbitMQ 장애 감지 및 Connection Load Balancing을 수행하는 방법을 이용한다.

Cluster를 구성하는 각 RabbitMQ는 Disk, RAM 2가지 Mode를 이용할 수 있다. Disk Mode는 Default Mode이다. RAM Mode는 Message, Message Index, Queue Index, 다른 RebbitMQ의 상태 정보를 제외한 나머지 모든 정보를 Memory (RAM)에만 저장하고 구동하는 Mode이다. RAM Mode에서도 Message와 관련된 정보는 여전히 Disk에 저장되기 때문에 RAM Mode를 이용해도 Message 처리량은 증가하지 않는다. 하지만 Exchange, Queue, Binding 등의 정보가 굉장히 많고 설정이 자주 변경되는 환경에서는 RAM Mode를 이용하여 빠르게 설정을 변경 할 수 있다. Cluster 구성시 반드시 하나 이상의 RabbitMQ는 반드시 Disk Mode로 동작시켜야 한다. RAM Mode의 RabbitMQ는 재시작시 Disk Mode가 갖고 있는 RabbitMQ의 정보를 받아서 초기화하기 때문이다.

Client가 Cluster의 모든 RabbitMQ와 Connection을 맺을 수 있어 Client는 언제나 RabbitMQ를 이용 할 수 있다고 하더라도, Queue는 Cluster에 하나만 존재하기 때문에 장애가 발생한 RabbitMQ의 Queue에 있는 Message의 손실 까지는 막을수 없다. 이러한 Message 손실을 방지하기 위해 적용하는 기법이 Mirroring이다.

2. RabbitMQ Mirroring



RabbitMQ Mirroring은 RabbitMQ Cluster 안에서 Meesage를 다수의 RabbitMQ에 복사하여 저장하는 기법이다. RabbitMQ Cluster 기법과 RabbitMQ Mirroring 기법을 이용하여 RabbitMQ HA (High Availability)를 구성할 수 있다. [그림 2]는 RabbitMQ Cluster와 Mirroring이 같이 적용된 상태를 나타내고 있다. Mirroring 구성시 Queue는 Master Queue와 Slave Queue로 구성되며, 1:N 관계를 갖는다. Master Queue는 원본 Queue를 의미하며 Slave Queue는 Master Queue를 복제한 Queue를 의미한다. 각 Master Queue마다 다른 개수의 Slave Queue를 설정 할 수 있다. Master Queue는 RabbitMQ 문서에서는 Queue Master라고 불린다.

Master Queue와 Slave Queue 사이의 Mirroring은 기본적으로 Sync 방식이다. 즉 Producer가 Mirroring된 Queue에게 Message를 전송하면 RabbitMQ는 받은 Message를 Master Queue에만 넣고 Producer에게 ACK를 보내는 것이 아니라, 모든 Slave Queue와 Mirroring이 완료된 후에야 Producer에게 ACK를 보낸다. 따라서 Slave Queue의 개수가 많아질 수록 오히려 Message 처리량이 떨어진다. RabbitMQ에서는 Slave Queue의 개수를 정족수를 만큼만 구성하는 것을 추천한다. 예를들어 Cluster가 5개의 RabbitMQ로 구성되어 있다면 정족수인 3을 맞추어 1 Master Queue, 2 Slave Queue를 구성하면 된다.

Mirroring을 통한 Slave Queue는 HA를 위한 기법이지 Message 처리량 향상을 위한 기법이 아니다. Slave Queue가 있어도 Producer의 모든 Message는 오직 Master Queue로만 전달되고, Consumer에게 전달되는 Message는 오직 Master Queue로부터 전송되는 Message이다. Slave Queue는 오직 Master Queue와 Mirroring하는 동작만을 수행한다. 따라서 Slave Queue의 개수를 늘려도 Message 처리량은 분산되지 않는다. 언제나 Master Queue가 기준이 되기 때문에 Producer가 보낸 Message 순서대로 Consumer에게 전달되는 것을 알 수 있다.

Mirroring 정책이 변경되거나, Cluster에 새로운 RabbitMQ가 추가되면서 새로운 Slave Queue도 추가 될 수 있다. 새로운 Slave Queue는 처음에는 아무런 Message가 없는 빈 상태를 유지한다. 즉 Slave Queue는 Master Queue가 갖고 있던 기존의 Message를 복사하여 가져오지 않는다. 오직 Slave Queue가 생성된 이후 Master Queue가 받은 새로운 Message들만 복사하여 가져온다. 따라서 처음에 새로운 Slave Queue가 갖고 있는 Message는 Master Queue가 갖고있는 Message와 다르다. 이러한 상태를 RabbitMQ에서는 Unsynchronised 상태라고 표현한다. 시간이 지남에 따라서 Master가 기존의 Message들을 Consumer가 소비하기 때문에 Unsynchronised Slave Queue는 결국 Synchronised Slave Queue가 된다.

Master Queue가 있는 RabbitMQ가 죽으면 일반적으로 Slave Queue 중에서 가장 오래된 Slave Queue가 Master Queue로 승격된다. 이때 RabbitMQ는 기본적으로 Unsynchronised Slave Queue를 승격 대상에서 제외시킨다. 만약 모든 Slave Queue가 Unsynchronised 상태에서 Master Queue의 RabbitMQ가 죽는다면, Master Queue의 RabbitMQ가 복구될때까지 해당 Queue는 이용하지 못한다. 만약 Master Queue의 RabbitMQ를 복구하지 못한다면 Message 손실이 발생한다. 설정을 통해서 RabbitMQ가 Unsynchronised Slave Queue를 Master로 승격시키도록 만들 수 있지만 Message 손실을 피할 수는 없다.

3. RabbitMQ Cluster 확장

RabbitMQ Cluster는 동작중에도 RabbitMQ를 추가할 수 있다. RabbitMQ는 Peer Discovery Plugin을 통해서 Cluster에 추가된 RabbitMQ를 자동으로 발견하고, 자동으로 Clustering까지 수행한다. Peer Discovery Plugin은 현재 4가지를 지원하고 있으며 각각 Consul, etcd, Kubernetes, AWS를 기반으로 하고 있다. RabbitMQ Cluster에 RabbitMQ를 추가하였어도 추가된 RabbitMQ에 Queue가 없다면, 추가된 RabbitMQ로는 부하가 제대로 분산되지 않는다. 따라서 Cluster에 RabbitMQ를 추가한 뒤에는 Queue Rebalancing을 통해서 Cluster 부하를 분산시켜야 한다. Queue Rebalancing 작업은 RabbitMQ에서 제공하는 Script 수행이나 Queue Rebalancing Third-party Plugin을 통해서 진행이 가능하다.

4. 참조


  https://www.rabbitmq.com/clustering.html
  https://www.rabbitmq.com/ha.html
  https://www.rabbitmq.com/cluster-formation.html
  https://www.rabbitmq.com/distributed.html
  https://www.rabbitmq.com/reliability.html
  https://www.rabbitmq.com/confirms.html
  https://m.blog.naver.com/tmondev/221051503100
  https://www.slideshare.net/visualdensity/rabbit-fairlyindepth
  https://tech.labs.oliverwyman.com/blog/2015/12/18/the-end-to-end-principle-and-rabbitmq-queue-mirroring/
  https://github.com/Ayanda-D/rabbitmq-queue-master-balancer

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Memcached]]></title>
      <link>https://ssup2.github.io/theory_analysis/Memcached/</link>
      <pubDate>Mon, 25 Feb 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[다양한 System에서 분산 Cache로 많이 이용되고 있는 Memcached를 분석한다. 1. Memcached Memcached는 의미 그대로 다양한 Data의 Caching을 위해 설계된 분산 Key-Value Storage이다. Caching System의 핵심은 Data의 빠른 Read/Write 성능이다. 따라서 Memcached도 Data의 빠른 Read/Write 성능에 중점을 두고있다. Memcached는 Data 저장시 Disk를 이용하지 않고 오직 Memory만 이용하여 Data의 Read/Write 성능을 극대화...]]>
      </description>
      <content:encoded>
        <![CDATA[다양한 System에서 분산 Cache로 많이 이용되고 있는 Memcached를 분석한다.

1. Memcached

Memcached는 의미 그대로 다양한 Data의 Caching을 위해 설계된 분산 Key-Value Storage이다. Caching 
System의 핵심은 Data의 빠른 Read/Write 성능이다. 따라서 Memcached도 Data의 빠른 Read/Write 성능에 중점을 두고있다. Memcached는 Data 저장시 Disk를 이용하지 않고 오직 Memory만 이용하여 Data의 Read/Write 성능을 극대화 하고 있다. Memory에만 Data가 저장되어 있기 때문에 Data는 언제든지 유실 될 수 있지만, Caching System에서 Data 유실은 치명적이지 않기 때문에 크게 문제되지 않는다. Memcached는 Client와 통신시 Text Protocol과 Binary Protocol 둘다 지원하지만 성능을 위해서는 Binary Procotol을 이용하는 것이 좋다.

1.1. Cluster



Memcached는 일반적으로 Cluster를 구성하여 이용된다. [그림 1]은 Memcached의 Cluster를 나타내고 있다. Memcached Cluster는 엄밀히 말하면 Cluster라고 보기는 힘들다. Memcached는 서로 어떠한 Data도 주고 받지 않고, 오직 Client의 요청에 따라 Data를 Read/Write하는 단순한 동작만 수행하기 때문에다. Memcached 사이의 Data 분배, Cluster를 구성하는 각 Memcached 상태 파악의 등 Cluster 관련 기능은 대부분 Client Lib (Library)에서 수행된다. 따라서 Memcached Cluster 기능은 Client Lib에 따라 결정된다.

일반적으로 Client Lib은 단순한 Hashing을 이용하여 Data를 분배한다. 또한 Client Lib은 모든 Memcached와 Session을 맺고 있는데, Client Lib은 Session의 상태를 통해서 각 Memcached의 상태를 파악한다. 만약 특정 Memcached가 죽어 Session이 끊긴 경우, Client Lib은 Session이 끊긴 Memcached를 제외하고 Data 분배를 수행한다. 이러한 Data 분배, Memcached의 상태 확인 동작은 각 Client Lib마다 독립적으로 수행된다. 따라서 Client Lib은 다른 Client Lib과 상호작용 하지 않는다.

Memcached는 Caching System이기 때문에 Memcached에 저장된 Data는 언제든지 유실될 수 있다는 가정을 하고 있다. 따라서 대부분의 Client Lib은 Cluster를 위한 Data Replication 기능을 지원하지 않는다.

2. 참조


  https://www.slideshare.net/AmazonWebServices/dat207

]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[Kafka]]></title>
      <link>https://ssup2.github.io/theory_analysis/Kafka/</link>
      <pubDate>Fri, 22 Feb 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[Theory, Analysis]]></category>
      <description>
        <![CDATA[분산 Message Queue인 kafka를 분석한다. 1. Kafka Kafka는 Publish-subscribe 기반의 분산 Message Queue이다. [그림 1]은 Kafka의 구성요소를 나타내고 있다. Kafka Broker는 Message를 수신, 관리, 전송하는 Kafka의 핵심 Server이다. Kafka Broker는 일반적으로 Load Balancing 및 HA (High Availability)를 위해서 다수의 Node 위에서 Cluster를 이루어 동작한다. Zookeeper는 Cluster를 이루는 각 Kafka Broker의...]]>
      </description>
      <content:encoded>
        <![CDATA[분산 Message Queue인 kafka를 분석한다.

1. Kafka



Kafka는 Publish-subscribe 기반의 분산 Message Queue이다. [그림 1]은 Kafka의 구성요소를 나타내고 있다. Kafka Broker는 Message를 수신, 관리, 전송하는 Kafka의 핵심 Server이다. Kafka Broker는 일반적으로 Load Balancing 및 HA (High Availability)를 위해서 다수의 Node 위에서 Cluster를 이루어 동작한다. Zookeeper는 Cluster를 이루는 각 Kafka Broker의 동작 상태를 파악하고 상태 정보를 Producer 및 Consumer에게 전달한다. 또한 Zookeeper는 Message 관리를 위해 필요한 정보를 저장하는 저장소 역활도 수행한다.

Kafka Broker는 Topic이라는 단위로 Message를 관리한다. Topic은 다시 Partition이라는 작은 단위로 쪼개지며, Kafka는 Partiton을 통해서 Message 처리량을 높인다. Producer는 Topic에게 Message를 전송(Publish)하는 App을 의미한다. Consumer는 Topic으로부터 Message를 전달받는 App을 의미한다. 마지막으로 Consumer Group은 의미 그대로 다수의 Consumer 묶는 역활을 수행하며, Kafka는 Consumer Group을 이용하여 Consumer의 가용성 및 Message 처리량 높인다.

[그림 1]은 Kafka에서 Message를 전달하는 과정도 나타내고 있다. Producer가 특정 Topic으로 Message를 전송(Publish)하면, Kafka Cluster는 해당 Topic을 구독(Subscribe)하고 있는 모든 Consumer Group에게 Producer로부터 전달받은 Message를 전송한다. [그림 1]에서 Consumer Group B와 Consumer Group C는 Topic B를 구독하고 있기 때문에 Kafka Broker는 Producer A가 Topic B로 전송한 Message를 Consumer Group B와 Consumer Group C에게 전달한다. Kafka는 Message의 신뢰성보다 높은 Message 처리량에 중점을 둔 Message Queue이다. 따라서 Kafka는 Spark, Storm 같은 빅데이터 처리 Platform의 Data Stream Queue로도 많이 이용되고 있다.

1.1. Partition



Partition은 Topic을 Kafka Cluster를 구성하는 각 Kafka Broker에게 분산하기 위한 단위 및 Message를 순차적으로 저장하는 Queue 역활을 수행한다. Partition은 Message 보존을 위해서 Memory가 아닌 Disk에 존재한다. [그림 2]는 Producer 및 Consumer와 상호작용을 하는 Partition을 자세히 나타내고 있다. Producer가 전송한 Message는 Partition의 끝에 차례대로 저장된다. 이때 Message의 ID는 Array의 Index처럼 순차적으로 증가한다. 이러한 Message의 ID를 Kafka에서는 Offset이라고 한다.

Producer와 별개로 Consumer는 Partition의 앞부분부터 시작하여 Consumer Offset을 증가시키며 차례대로 Message를 읽는다. Consumer Offset은 Consumer가 처리를 완료한 Partition의 가장 마지막 Message의 Offset을 의미한다. 따라서 Consumer Offset은 Kafka Broker가 저장하고 있지만 Consumer의 요청에 의해서 변경된다. Consumer는 Message를 하나씩 처리할때마다 변경된 Consumer Offset을 Kafka Broker에게 전달하는 Sync 방식과, 한꺼번에 여러 Message를 모아서 처리하고 한번에 Consumer Offset을 변경하는 Async 방식이 존재한다. 일반적으로 Message 처리량을 높이기 위해서 Async 방식을 이용한다.

Consumer Offset은 각 Partition, Consumer Group 별로 Kafka Broker에 저장된다. [그림 2]에서 Topic B의 Partition 0의 경우 Consumer Group B의 Consumer Offset은 6, Consumer Group C의 Consumer Offset은 4를 나타내고 있다. Producer는 Topic이 다수의 Partition을 갖고 있을 경우 기본적으로 Round-robin 방식으로 Message를 전달할 Partiton 선택한다. 만약 다른 Partition 선택 알고리즘이 필요하면, Producer 개발자는 Kafka가 제공하는 Interface를 통해 Partition 선택 알고리즘을 직접 개발 및 적용할 수 있다.

Partition의 개수는 Topic마다 다르게 설정할 수 있다. 일반적으로 각 Partition은 서로 다른 Kafka Broker에 배치되어 Message를 병렬처리 한다. [그림 2]에서 Topic C는 3개의 Partiton으로 이루어져 있기 때문에 각 Partiton은 서로 다른 3개의 Kafka Broker에 분산된다. Topic C는 3개의 Kafka Broker를 이용하기 때문에 하나의 Topic을 이용하는 Topic B에 비해서 최대 3배 빠르게 Message를 처리 할 수 있다. 하지만 3개의 Partiton을 이용한다는 의미는 3개의 Queue에 Message를 나누어 저장한다는 의미이기 때문에 Producer 전송한 Message의 순서와 Consumer가 수신하는 Message의 순서는 달라질 수 있다. Topic B는 하나의 Partition만을 이용하기 때문에 Message 순서는 그대로 유지된다.

Partition을 저장하는데 이용하는 Disk는 일반적으로 Memory에 비해서 Read/Write 성능이 떨어진다. 특히 Random Read/Write의 성능은 Disk가 Memory에 비해서 많이 떨어진다. 하지만 Sequential Read/Write의 경우 Disk의 성능이 Memory의 성능에 비해서 크게 떨어지지 않기 때문에, Kafka는 Partition 이용시 최대한 Sequential Read/Write를 많이 이용하도록 설계되어 있다. 또한 Kafka는 Kernel의 Disk Cache (Page Cache)에 있는 Message가 Kafka를 거치지 않고 Kernel의 Socket Buffer로 바로 복사되도록 만들어, Message를 Network를 통해 Consumer로 전달시 발생하는 Copy Overhead를 최소한으로 줄였다. 이처럼 Kafka는 Disk 사용에의한 성능 저하를 다양한 기법을 통해 최소하하고 있다.

Partition은 실제로 하나의 파일로 Disk에 저장되지 않고 Segment 불리는 단위로 쪼개져서 저장된다. Segment의 기본 크기값은 1GB이다. Kafka는 Partition에 저장되어있는 Message를 일정한 기준에 따라서 보존한다. Kafka에서는 Message Retention 정책이라고 표현한다. Message Retention 정책에는 먼져 특정 기간안의 Message만 보존하는 방법이 있다. 기간을 7일로 설정해 준다면 Message는 Kakfka에 도착한뒤 7일까지 보존되며 그 이후에는 보존을 보장하지 않는다. 두번째로는 Partition 사이즈가 특정 용량을 초과하지 않게 보존하는 방법이 있다. Message Write로 인해서 Partition이 설정한 용량보다 커지게 되면 Partition 앞의 Message를 지원 Partition 용량을 유지한다.

1.2. Consumer Group

Consumer Group은 다수의 Consumer를 묶어 하나의 Topic을 다수의 Consumer가 동시에 처리할 수 있도록 만들어준다. 첫 그림에서 Consumer Group C는 Topic C를 구독하고 있다. Consumer Group C는 2개의 Consumer를 갖고 있기 때문에 Topic C의 Message는 2개의 Consumer가 나누어 병렬처리가 가능하다. 다만 Consumer Group의 효율을 높이기 위해서는 Consumer Group이 구독하는 Topic의 Partiton의 개수가 중요하다.



[그림 3]은 같은 Topic에 있는 Partiton의 개수와 같은 Consumer Group에 있는 Consumer의 개수에 따른 관계도를 나타내고 있다. Partition과 Consumer는 N:1의 관계이다. 같은 Consumer Group에 있는 Consumer들은 하나의 Partition을 동시에 같이 이용할 수 없다. 즉 Partition 보다 Consumer의 개수가 많으면 Message를 처리하지 않는 Consume각 생기게 된다. 따라서 Consumer Group을 이용할 경우 Topic의 Partiton 개수도 반드시 같이 고려되야 한다.

각 Consumer Group에는 Consumer Leader가 존재하며 Consumer Group의 Consumer들을 관리하는 역활을 수행한다. 또한 Consumer Leader는 Kafka Broker와 협력하여 Consumer와 Topic을 Mapping하는 작업을 수행한다. Consumer와 Topic을 Mapping 작업은 Consumer Group의 일부 Consumer가 죽었을 경우, Parition이 추가될 경우, Consumer Group에 Consumer가 추가되었을 경우 등 다양한 Event 발생시 수행된다.

1.3. ACK

Kafka는 Producer를 위한 ACK 관련 Option을 제공한다. Producer는 ACK를 이용하여 자신이 전송한 Message가 Broker에게 잘 전달되었는지 확인할 수 있을 뿐만 아니라 Message 유실도 최소화 할 수 있다. 0, 1, all 3가지 Option을 제공한다. Producer마다 각각 다른 ACK Option을 설정할 수 있다.


  0 - Producer는 ACK를 확인하지 않는다.
  1 - Producer는 ACK를 기다린다. 여기서 ACK는 Message가 하나의 Kafka Broker에게만 전달되었다는 것을 의미한다. 따라서 Producer로부터 Message를 전달받은 Kafka Broker가 Replica 설정에 따라서 Message를 다른 Kafka Broker에게 복사하기전에 죽는다면 Message 손실이 발생할 수 있다. 기본 설정값이다.
  all (-1) - Procker는 ACK를 기다린다. 여기서 ACK는 Message가 설정한 Replica만큼 여러 Kafka Broker들에게 복사가 완료되었다는 의미이다. 따라서 Producer로부터 Message를 전달받은 Kafka Broker가 죽어도 복사한 Message를 갖고있는 Kafka Broker가 살아있다면 Message는 유지된다.


Kafka는 Consumer를 위한 별도의 ACK Option을 제공하지 않는다. 위에서 언급한것 처럼 Consumer는 처리가 완료된 Message의 Offset을 Kafka Broker에게 전달한다. 즉 Consumer가 전달하는 Message의 Offset이 Kafka Broker에게 ACK의 역활을 수행한다.

2. 참조


  https://fizalihsan.github.io/technology/bigdata-frameworks.html
  https://en.wikipedia.org/wiki/Apache_Kafka
  https://www.quora.com/What-is-Apache-Kafka
  https://sookocheff.com/post/kafka/kafka-in-a-nutshell/
  https://epicdevs.com/17
  [https://medium.freecodecamp.org/what-makes-apache-kafka-so-fast-a8d4f94ab145]
  https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-producer-acks/


]]>
      </content:encoded>
		</item>
		
		<item>
      <title><![CDATA[etcd]]></title>
      <link>https://ssup2.github.io/theory_analysis/etcd/</link>
      <pubDate>Sun, 17 Feb 2019 12:00:00 +0000</pubDate>
      <category><![CDATA[]]></category>
      <description>
        <![CDATA[etcd를 분석한다.

1. etcd

2. 참조


  https://www.joinc.co.kr/w/man/12/etcd
  https://dbdb.io/db/etcd
  https://loneidealist.wordpress.com/2017/07/12/apache-zookeeper-vs-etcd3/

]]>
      </description>
      <content:encoded>
        <![CDATA[etcd를 분석한다.

1. etcd

2. 참조


  https://www.joinc.co.kr/w/man/12/etcd
  https://dbdb.io/db/etcd
  https://loneidealist.wordpress.com/2017/07/12/apache-zookeeper-vs-etcd3/

]]>
      </content:encoded>
		</item>
		
	</channel>
</rss>
