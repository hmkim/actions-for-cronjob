<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Premist (Minku Lee) on Medium]]></title>
        <description><![CDATA[Stories by Premist (Minku Lee) on Medium]]></description>
        <link>https://medium.com/@premist?source=rss-529345d241d2------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/0*XCzGV9SzpO5mS_tm.png</url>
            <title>Stories by Premist (Minku Lee) on Medium</title>
            <link>https://medium.com/@premist?source=rss-529345d241d2------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Mon, 13 May 2019 13:10:46 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/@premist" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[내 DB에 암호화폐 마이너가?!]]></title>
            <link>https://medium.com/si-mpli-st-blog/%EB%82%B4-db%EC%97%90-%EC%95%94%ED%98%B8%ED%99%94%ED%8F%90-%EB%A7%88%EC%9D%B4%EB%84%88%EA%B0%80-510f8c60a45c?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/510f8c60a45c</guid>
            <category><![CDATA[암호화폐]]></category>
            <category><![CDATA[postgresql]]></category>
            <category><![CDATA[모네로]]></category>
            <category><![CDATA[해킹]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Sun, 15 Apr 2018 12:50:00 GMT</pubDate>
            <atom:updated>2018-05-13T10:04:37.155Z</atom:updated>
            <content:encoded><![CDATA[<p>아이패드 프로를 사면서 원격 서버에서 작업을 하는 일이 많이 늘었다. 메인 컴퓨터인 맥북 프로 15인치는 최신 모델로 바꾸면서 가벼워졌다고는 하지만 그래도 1.8kg 정도 나가는데, 477g 정도 나가는 아이패드 프로와 <a href="http://www.blink.sh/">Blink Shell</a> + Vim의 조합으로 대부분의 작업을 수행할 수 있기 때문에 여행 같이 먼 곳을 갈 때는 아이패드 프로를 챙기게 되었다. LTE를 지원해서 Wi-Fi를 찾아 헤맬 필요도 없고, 지리적으로 가까운 서버를 이용하면 지연 시간도 거의 체감하지 못하기 때문에 본격적인 개발 업무에도 꽤 쓸만하다.</p><p>작년 <a href="http://rubykaigi.org/2017">RubyKaigi 2017</a>에 참가하기 위해 일본 히로시마에 다녀왔을 때에도, 짐을 최대한 줄이고 싶었기 때문에 노트북은 집에 두고 아이패드 프로를 챙겨갔다. 보통 작업을 위해 접속하는 서버는 한국에 있기 때문에, 일본에서 사용하기 위해 VM 서버를 하나 생성하고 PostgreSQL을 비롯한 개발 환경을 구축해 두었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Jmw9WfAs85Dg0-SD.jpg" /><figcaption>10.5인치로 화면이 작은 것을 제외하면 이보다 편리할 수 없다.</figcaption></figure><p>한국으로 돌아오기 전 사용한 데이터베이스는 drop했지만, 서버는 다음에 쓸 일이 있을 것 같아 종료는 하지 않았다. 그리고 시간이 흘러 몇 주 전, 그 때 사용했던 서버를 켜 두었다는 것을 깨닫고 필요한 자료가 있는지 확인하기 위해 서버에 접속하게 되었다.</p><h3>로그에 찍힌 수상한 흔적들</h3><p>몇 달 전 지인의 서버를 점검해주던 도중, 약한 루트 비밀번호를 가진 서버가 해킹이 되어 모네로(Monero) 암호화폐 마이닝에 사용된 것을 발견한 이후로 서버 해킹에 조금 더 경각심이 생겼다. 그 이후로는 원격 접속을 하자마자 <a href="https://en.wikipedia.org/wiki/W_(Unix)">w</a> 커맨드를 입력하여 현재 접속된 다른 사용자가 있는지를 확인하는 버릇이 생겼다.</p><p>이번에 방치해둔 서버에 접속할 때에도 습관적으로 w를 입력했고, 현재 세션을 제외한 다른 사용자는 로그인이 되어 있지 않은 것으로 나와 크게 수상한 점은 없었다.</p><pre>∙ w<br>12:00:00 up xxx days, xx:xx,  1 user,  load average: 0.03, 0.01, 0.00<br>USER     TTY        LOGIN@   IDLE   JCPU   PCPU WHAT<br>premist  pts/0     12:00    0.00s  0.05s  0.00s w</pre><p>그리고는 무슨 바람이 불었는지는 모르겠지만, 서버에서 구동중이던 데몬의 로그를 하나씩 살펴보기 시작했다. PostgreSQL 데몬의 로그를 열고, <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less</a>로 로그 파일을 파이프하고 스크롤을 하던 중…</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*dfJh-3LhpAQbfFaY.jpg" /></figure><p><strong>가슴이 철렁 하는 로그를 발견했다.</strong></p><p>PostgreSQL에서 제공하는 <a href="https://www.postgresql.org/docs/10/static/catalog-pg-largeobject.html">pg_largeobject</a> 기능을 이용하여 데이터베이스에 바이너리 데이터를 로드하는 것 처럼 보이는 SQL 선언문이 로그에 찍혀 있었다. 내가 직접 바이너리 데이터를 Postgres에 넣으려고 시도한 적은 없으니 위 로그는 공격의 흔적으로밖에 설명이 되지 않았다. 불안감이 몰려왔다.</p><p>황급히 로그에서 수상한 다른 부분을 찾기 시작하자, 바이너리 데이터를 넣는 선언문 외에도 다른 수상한 선언문을 여러 개 찾을 수 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2Wz0xQklsR9jlPu6.jpg" /></figure><p>공격자는 원격 코드 실행을 위한 프로시저 함수를 만든 다음, 이 함수를 이용해 바이너리를 생성하고 실행하려는 것 처럼 보였다. 불행 중에 다행으로, 공격자가 시도한 대부분의 명령어는 권한의 문제로 성공하지 않는 것으로 보였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*vgBSYHVCnl1INnGl.jpg" /></figure><p>일부 명령어에서는 현재 접속된 시스템에 그래픽 카드가 장착되어 있는지를 확인하고(lshw -c video), CPU 모델명을 확인하려는 시도(cat /proc/cpuinfo)도 보였다. 이 쯤에서 암호화폐를 마이닝 하기 위한 공격일 것이라는 예상을 하기 시작했다.</p><p>공격이 이루어지고 있다는 사실을 발견하고, 추가적인 공격을 방지하기 위해 Docker Compose를 통해 실행하고 있던 PostgreSQL를 종료했다. 그 다음, 혹여나 공격자가 공격에 성공하여 어떤 작업이 일어나고 있지 않을까 하는 생각에 <a href="https://si.mpli.st/dev/introduction-to-telegraf.html">Telegraf로 수집하고 있던</a> CPU 점유율을 확인하였다.</p><pre>-- InfluxQL</pre><pre>SELECT<br>  mean(&quot;usage_user&quot;) AS &quot;mean_usage_user&quot;, mean(&quot;usage_system&quot;) AS &quot;mean_usage_system&quot;, mean(&quot;usage_idle&quot;) AS &quot;mean_usage_idle&quot;<br>FROM &quot;telegraf&quot;.&quot;autogen&quot;.&quot;cpu&quot;<br>WHERE time &gt; now() - 180d<br>AND &quot;cpu&quot; = &#39;cpu-total&#39;<br>AND &quot;host&quot; = &#39;hostname&#39;<br>GROUP BY time(4d)</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*JqgDWF-GFfYp0cOD.png" /></figure><p>다행히도 CPU 점유율이 비정상적으로 치솟는 현상은 없었다. 누군가가 공격을 시도한 건 맞지만 공격이 성공하지 않아 바이너리가 실행되지는 않은 듯 보였다.</p><p>공격의 흔적이 조금이라도 발견되면 미처 인식하지 못한 백도어가 있을 가능성이 있으므로 서버를 다시 설정하는 것이 현명하겠지만 나의 경우 그럴 필요가 없다고 생각되었다. 이유를 몇 가지 들어보자면:</p><ul><li>PostgreSQL 프로세스는 Unprivileged Docker 컨테이너에서 실행이 되고 있었다.</li><li>호스트 시스템에서 /var/lib/postgresql/data 디렉터리만 별도의 폴더를 마운트하여 사용하고, 호스트의 다른 디렉터리는 마운트하지 않았다.</li><li><a href="https://www.archlinux.org/">Arch Linux</a>를 사용하고 있었기에 취약점이 보고되지 않은 최신 버전의 Linux 커널과 Docker CE를 사용하고 있었다.</li></ul><p>PostgreSQL 컨테이너를 docker kill ID &amp;&amp; docker rm ID 로 제거하고, PostgreSQL 데이터베이스 파일을 모두 삭제하는 것으로 정리를 일단락지었다.</p><h3>실수에 겹친 실수</h3><p>일단 급한 불을 끄고, 도대체 왜 이런 공격이 일어났는지를 조사하기 시작했다. 분명히 필요한 포트만 열고, PostgreSQL이 사용하는 포트인 5432는 로컬에서만 접근할 수 있게 방화벽을 설정했을 텐데, 공격자는 어떻게 데이터베이스에 접속할 수 있었던 것일까?</p><p>답은 허무할 정도로 간단했다. 바로 방화벽이 켜져있지 않았던 것. 며칠동안 쓰고 삭제할 VM이여서 이왕 새로 설치하는 김에, 평소 사용하는 <a href="https://wiki.archlinux.org/index.php/iptables">iptables</a> 대신 보다 간단(다고 주장)한 <a href="https://wiki.archlinux.org/index.php/Uncomplicated_Firewall">ufw</a>를 설치했는데, 사용하는 방법을 충분히 숙지하지 않아서 방화벽이 제대로 설정되지 않았다.</p><p>엎친데 덮친 격으로 PostgreSQL 데이터베이스도 암호가 설정되어 있지 않았다. <a href="https://hub.docker.com/_/postgres/">Docker Inc.가 제공하는 공식 PostgreSQL 이미지</a>의 경우 POSTGRES_PASSWORD 환경 변수를 지정해주지 않으면 <strong>계정의 비밀번호가 설정되지 않은 채로 데이터베이스 서버가 실행된다</strong>. 로컬에서 사용할 데이터베이스였지만 간단한 비밀번호를 환경 변수를 통해 설정했을텐데, systemctl daemon-reload를 해 주지 않아 로컬에서 임의로 생성한 비밀번호가 적용되지 않은 채로 서비스가 실행되었다.</p><p>이런 저런 실수가 겹쳐서 결국 공개 인터넷에 인증 없이 아무나 접근할 수 있는 데이터베이스를 공개한 격이 되어 버렸다. 정말 부끄러운 순간이었다.</p><h3>모네로 깎는 DB</h3><p>어느 정도 수습을 하고 정신을 차린 후 곰곰히 생각해보니, 방금 겪은 상황을 어디선가 접해 본 적이 있었다. Instapaper에 저장한 글을 찬찬히 둘러보던 중, 최근에 읽은 글을 찾을 수 있었다.</p><p><a href="https://www.imperva.com/blog/2018/03/deep-dive-database-attacks-scarlett-johanssons-picture-used-for-crypto-mining-on-postgre-database/"><strong>IMPERVA — A Deep Dive into Database Attacks Part III: Why Scarlett Johansson’s Picture Got My Postgres Database to Start Mining Monero</strong></a></p><p>이 글의 저자는 인터넷에 공개적으로 노출되어 있는 데이터베이스에 어떠한 형태의 공격이 가해지는지를 분석하기 위해 일부러 허니팟을 구축해 두었는데, 이 허니팟을 공격자가 발견하고 내가 당한 것과 같은 공격을 수행하였다.</p><ul><li>pg_largeobject로 바이너리를 저장하고, PostgreSQL의 <a href="https://www.postgresql.org/docs/10/static/lo-funcs.html">Server-side Function</a>인 lo_export를 통해 디스크에 저장한다. 이 때 데이터베이스를 감시하고 있는 보안 솔루션이 있을 것을 대비하여, pg_proc 카탈로그에 간접적으로 lo_export를 실행하는 함수를 저장하고 이를 실행한다.</li><li><a href="https://www.postgresql.org/docs/current/static/xfunc-c.html">C UDF</a>를 이용하여 로컬에 저장된 바이너리를 호출하는 함수를 만든다.</li><li>lshw와 /proc/cpuinfo로 GPU와 CPU 정보를 파악한다.</li><li>바이너리가 숨겨진 사진 파일을 다운받고, 바이너리를 추출한다.</li><li>마이닝 풀 정보와 함께 마이너 바이너리를 실행한다.</li><li>사진 파일을 비롯한 흔적을 지운다.</li></ul><p>암호화폐의 가치가 상승함에 따라 랜섬웨어와 같은 기법으로 암호화폐를 채굴하거나, 브라우저에서 광고 대신 암호화폐를 채굴하는 경우는 보았지만, 취약한 데이터베이스를 이용하여 암호화폐를 채굴하려는 공격이 이루어지고 있다니 정말 상상 초월이었다.</p><h3>교훈</h3><p>공격 시도를 당한 것을 알고 스스로에게 부끄러웠기 때문에 이 에피소드를 글로 옮길까 말까 고민했지만, 나의 실수로 인한 취약점을 제외하더라도 꽤나 흥미로운 공격이었고, 값진 깨달음을 얻었기에 블로그에 글로 옮기게 되었다.</p><ul><li>방화벽을 적용하면 실제로 접속이 되지 않는지 꼭 확인해보자</li><li>데이터베이스 비밀번호를 설정했다면 비밀번호 없이 접속이 되는지 한번 더 확인하자</li><li>올바른 권한을 사용하거나 컨테이너 등으로 다른 프로세스와 격리하여 추가적인 피해를 막자</li><li>시스템의 구성 요소는 최신 버전으로 유지하도록 노력하자</li></ul><p><a href="https://cloud.google.com/sql/">Google Cloud SQL</a>이나 <a href="https://aws.amazon.com/rds/">AWS RDS</a>를 사용한다면 <a href="https://cloud.google.com/sql/docs/postgres/users#default-users">SUPERUSER 권한을 사용자가 취득할 수 없고</a>, 기본적으로 IP 대역을 설정하거나 Security Group을 설정해야 하므로 비교적 안전한 초기 설정으로 데이터베이스를 운영할 수 있다. 프로덕션 서비스를 운영한다면 이러한 매니지드 서비스를 이용하는 것도 좋은 방법이다.</p><h3>더 읽어보기</h3><ul><li><a href="https://www.slideshare.net/inquis/advanced-sql-injection-to-operating-system-full-control-slides">Black Hat Europe — Advanced SQL Injection to operating system full control (2009)</a></li><li><a href="http://bernardodamele.blogspot.kr/2009/01/command-execution-with-postgresql-udf.html">Command execution with a PostgreSQL UDF (2009)</a></li></ul><p><em>Originally published at </em><a href="https://si.mpli.st/dev/cryptominer-inside-postgres.html"><em>si.mpli.st</em></a><em> on April 15, 2018.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=510f8c60a45c" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/%EB%82%B4-db%EC%97%90-%EC%95%94%ED%98%B8%ED%99%94%ED%8F%90-%EB%A7%88%EC%9D%B4%EB%84%88%EA%B0%80-510f8c60a45c">내 DB에 암호화폐 마이너가?!</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NS1와 NGINX를 이용한 홈메이드 CDN]]></title>
            <link>https://medium.com/si-mpli-st-blog/ns1%EC%99%80-nginx%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%99%88%EB%A9%94%EC%9D%B4%EB%93%9C-cdn-e1f1dc2b4826?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/e1f1dc2b4826</guid>
            <category><![CDATA[ns1]]></category>
            <category><![CDATA[cdn]]></category>
            <category><![CDATA[nginx]]></category>
            <category><![CDATA[최적화]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Sun, 08 Apr 2018 08:10:00 GMT</pubDate>
            <atom:updated>2018-04-15T07:56:23.981Z</atom:updated>
            <content:encoded><![CDATA[<p>원문: <a href="https://si.mpli.st/dev/homemade-cdn-with-ns1-and-nginx.html">https://si.mpli.st/dev/homemade-cdn-with-ns1-and-nginx.html</a></p><p><strong>Disclaimer:</strong> 리퍼러 링크가 있는 글입니다. 리퍼러 링크를 통해 서비스에 가입하시면 할인 혜택을 제공하기도 하고, 저도 리퍼럴에 대한 작은 보상을 받음으로써 더 많은 글을 쓸 수 있도록 동기 부여가 됩니다.</p><p>꽤 오래 전부터 <a href="https://www.linode.com/?r=9cc0e9cc373c8c9accddf7fc5ecef153e40f5a56">Linode</a>에 VPS를 만들어서 사용하고 있다. 원격 작업 용도나 다른 용도도 많지만, 주된 용도는 지금 여러분이 보고 있는 사이트인 <a href="https://si.mpli.st/">si.mpli.st</a>부터 <a href="https://xenosium.com/">Xenosium</a>, <a href="https://blog.kudokun.me/">KudoBlog</a>와 같이 여러 사이트를 호스팅 하는 것이다.</p><p>일본 데이터센터를 사용하는만큼 한국에서 접속할 때 <a href="https://m.do.co/c/6aa0891d593f">DigitalOcean</a>이나 다른 VPS 업체보다 반응 속도가 빠르다는 것이 장점이었는데, 최근 한국에서 해외로 접속하는 속도가 느려지면서 덩달아 속도가 느려져서 어떤 날은 이미지를 모두 불러오는 데에 1분이 넘어갈 때도 생겼다. 최근에 자주 속도가 느려져서 예전에 쓴 글을 보기 위해 오랜 시간 동안 기다리는 경우가 점점 잦아지자, 사이트의 속도를 향상시키기 위한 여러 가지 방법을 고민하기 시작하였다.</p><h3>CDN</h3><p>웹 사이트를 접속하는 속도와 웹 사이트가 호스팅된 위치와는 필연적인 상관 관계가 있다. 아무리 효율적으로 최적화를 한다고 해도, 한국에서 한국 서버에 접속하는 것이랑 미국 서버에 접속하는 것과는 속도의 차이가 날 수밖에 없다.</p><p>이를 극복하기 위한 가장 확실한 방법은 서버의 위치를 사용자에 가깝게 옮기는 것이지만, 여러 지역에서 접속하는 사이트의 경우에는 사용자의 위치가 한 곳으로 정해진 것이 아니기 때문에 한 곳을 정하는 것은 불가능하다. 이럴 때는 여러 개의 서버를 통해 각각의 사용자가 자신의 위치와 가장 가까운 서버에 접속하도록 설정할 수 있다. 만약 전 세계의 사용자를 대상으로 사이트를 운영하고 싶다면, 전 세계 구석 구석 서버를 두어 서버와 사용자 간의 거리를 최대한 줄이면 되는 것이다.</p><p>하지만 각 나라의 안정적인 데이터센터를 알아보고, 서버를 설정하고, 전 세계 어디에서든 일관적인 컨텐츠를 보여지게 하기 위해서는 꽤 많은 시간과 노력이 들어가기 마련. 이러한 서버 네트워크를 Akamai나 CloudFlare, Fastly와 같은 CDN 업체들이 제공한다. 상업 사이트를 운영한다면 이러한 CDN 업체는 사이트의 퍼포먼스를 위해 필수적인데, Akamai나 Fastly와 같은 곳은 개인 사이트가 사용하기에는 가격이 비싸서 접근성이 떨어지고, CloudFlare는 무료 플랜이 있지만 한국 POP이 불안정하고 무료 플랜은 아예 라우팅이 되지 않아 CDN을 끼면 오히려 느려지는 기현상도 발생한다.</p><p><a href="https://www.shakr.com/">Shakr.com</a>은 한국에서도 비교적으로 반응 속도가 균일한 <a href="https://cloud.google.com/cdn/">Google Cloud CDN</a>을 사용중인데, 개인적으로 호스팅하는 사이트에 쓰기에는 가격 부담도 있고 Google Cloud에 서버가 호스팅되어 있지도 않다보니 직접 CDN의 역할을 하는 캐시 서버를 만들어서 사용해 보기로 했다.</p><h3>지역 기반 라우팅</h3><p>가장 먼저 지역 기반 라우팅을 어떻게 할 지 고민하기 시작하였다. 개인적으로 관리하고 있는 서버는 한국과 일본에 위치한 총 두 개의 서버에서, 지역에 따라 어떤 서버를 사용해야 할 지를 정할 수 있어야 했다.</p><p>직접 Anycast 라우팅을 구축할 수도 있겠지만, <a href="https://labs.ripe.net/Members/samir_jafferali/build-your-own-anycast-network-in-nine-steps">절차도 복잡하고 비용도 요구 사항도 까다로워서</a> 어느 정도 찾아보다 포기를 하고 서비스 형태로 제공해 주는 곳을 찾아보게 되었다.</p><p>AWS Route 53의 <a href="https://aws.amazon.com/ko/blogs/korea/route53-latency-based-routing/">지연 속도 기반 라우팅(Latency Based Routing)</a>이나 <a href="https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-geo">지리적 라우팅(Geolocation Routing)</a>을 사용하는 방법도 있지만, 두 라우팅 방식 모두 추가적인 비용을 지불해야 하기 때문에 되도록 지양하고 싶었다.</p><p>내가 소유하고 있는 모든 도메인은 <a href="https://dnsimple.com/r/a1ed6fe742efea">DNSimple</a>을 통해 관리하고 있는데, 찾아보니 DNSimple에도 <a href="https://support.dnsimple.com/articles/regional-records/">Regional Records</a>라는 이름으로 특정 요금제에서는 사용자의 접속 지역에 따라 다른 DNS 레코드를 반환해주는 기능이 들어가 있었다. 다만 지역 설정이 아시아의 경우 일본 하나밖에 없어서, 한국의 유저를 구별해낼 수 있는 방법이 없었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*GvPUvX4lNrypJSjc.png" /><figcaption>DNSimple의 Regional Records 기능</figcaption></figure><p>여러 방법을 찾아보던 중 최근 유명세를 타기 시작한 DNS 제공자인 <a href="https://ns1.com/">NS1</a>에 무료 플랜이 있다는 사실을 발견하고, 한번 설정을 해 보았다.</p><h3>NS1의 Filter Chain</h3><p>NS1의 킬러 기능은 Filter Chain인데, 서버의 다운타임이나 사용자의 위치 등 다양한 종류의 지표를 이용하여 DNS 요청에 어떤 레코드를 반환해 줄 지를 설정할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*CIZK7t83BidQ5IAm.png" /><figcaption>NS1에서 지원하는 다양한 필터</figcaption></figure><p>무료 사용자의 경우 Filter Chain을 한 개의 레코드에 사용할 수 있는데, 여러 사이트에 각각 도메인을 배정하기 위해 와일드카드 레코드를 생성하였다. 그런 다음 Filter Chain으로 한국과 한국 외의 레코드 반환값을 다르게 지정하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*34UewQxWCKI3tbHH.png" /><figcaption>와일드카드 레코드를 만들고, KR과 Non-KR 그룹을 각각 설정했다</figcaption></figure><p>설정을 마치고 DNS 레코드를 쿼리해보니, 서울 엣지 서버의 IP가 정상적으로 반환된다!</p><pre>❯ dig simplist.cdn.sapbox.me @8.8.8.8<br><br>; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; simplist.cdn.sapbox.me @8.8.8.8<br>;; global options: +cmd<br>;; Got answer:<br><br>(중략)<br><br>;; ANSWER SECTION:<br>simplist.cdn.sapbox.me. 21599   IN  A   &lt;SEOUL EDGE IP&gt;<br><br>;; Query time: 680 msec<br>;; SERVER: 8.8.8.8#53(8.8.8.8)<br>;; WHEN: Sun Apr 08 16:15:49 KST 2018<br>;; MSG SIZE  rcvd: 67</pre><p>같은 명령어를 일본에 위치한 다른 서버에 접속하여 실행해 보니, 정상적으로 도쿄 오리진 서버의 IP가 반환된다.</p><pre>❯ dig simplist.cdn.sapbox.me @8.8.8.8<br><br>; &lt;&lt;&gt;&gt; DiG 9.12.1 &lt;&lt;&gt;&gt; simplist.cdn.sapbox.me @8.8.8.8<br>;; global options: +cmd<br>;; Got answer:<br><br>(중략)<br><br>;; ANSWER SECTION:<br>simplist.cdn.sapbox.me. 21599   IN  A   &lt;TOKYO ORIGIN IP&gt;<br><br>;; Query time: 133 msec<br>;; SERVER: 8.8.8.8#53(8.8.8.8)<br>;; WHEN: Sun Apr 08 07:18:40 UTC 2018<br>;; MSG SIZE  rcvd: 67</pre><h3>캐시 프록시 설정</h3><p>이제 어떤 서버를 찾아가야 할 지는 설정했으니, 각 서버에서 올바른 리소스를 주도록 설정할 차례였다. 도쿄 오리진 서버의 경우 모든 리소스를 가지고 있으니까 도메인을 추가하고 SSL 인증서를 추가하는 것으로 간단하게 설정을 마칠 수 있지만, 서울 엣지 서버의 경우 도쿄 오리진 서버와 디스크를 공유하지 않으니 파일 호스팅을 설정하는 대신 캐시 프록시를 설정해야 한다. <a href="https://varnish-cache.org/">Varnish</a>와 같은 전용 캐시 서버를 이용할 수도 있지만, 이미 사용하고 있던 웹 서버인 NGINX에도 간단한 캐시 기능이 있어서 그것을 사용하기로 했다.</p><pre># http block<br>proxy_cache_path /mnt/superfast-ssd/nginx-cache levels=1:2 keys_zone=default:500m max_size=5g inactive=30d;<br><br># server block<br>server {<br>  listen 80;<br>  listen 443 ssl http2;<br><br>  ssl_certificate /opt/certs/fullchain.pem;<br>  ssl_certificate_key /opt/certs/privkey.key;<br><br>  server_name simplist.cdn.sapbox.me;<br><br>  proxy_http_version 1.1;<br>  proxy_cache default;<br>  proxy_cache_revalidate on;<br>  proxy_cache_min_uses 3;<br>  proxy_cache_use_stale error timeout updating http_500 http_502<br>                        http_503 http_504;<br>  proxy_cache_valid 200 60d;<br>  proxy_cache_background_update on;<br>  proxy_ssl_server_name on;<br>  proxy_ssl_verify on;<br>  proxy_ssl_session_reuse on;<br>  proxy_ssl_trusted_certificate /opt/certs/cacert.pem;<br><br>  location / {<br>    proxy_set_header Host UPSTREAM_HOST;<br>    proxy_hide_header X-Powered-By;<br>    add_header X-Powered-By &quot;Sapbox-CDN-EDGENAME&quot;;<br>    add_header X-Sapbox-Cache $upstream_cache_status;<br>    proxy_pass https://UPSTREAM_HOST;<br>  }<br>}</pre><p>SSL을 설정할 때는 <a href="https://letsencrypt.org/">Let’s Encrypt</a>의 인증서를 활용했는데, 지역에 따라 반환값이 달라질 수 있으므로 <a href="https://github.com/Neilpang/acme.sh">acme.sh</a>를 이용하여 http-01 챌린지 대신 dns-01 챌린지로 인증서를 발급받았다.</p><h3>결과</h3><p>이미지가 꽤 많이 포함된 글인 <a href="https://si.mpli.st/review/wework-a-year-later.html">WeWork, 1년 후</a>를 브라우저 캐시를 해제한 상태로 로드해 본 결과, 간섭이 심한 Wi-Fi 환경에서 12초 정도 로드가 되던 페이지가 1초대에 로드되었다!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*UzuWr2PLn8uSJ1cL.png" /><figcaption>Before: 12.07s, After: 1.54s</figcaption></figure><p>이렇게 구축한 홈메이드 CDN의 장점은, 자신이 원하는 서버 제공자를 선택한 다음 NGINX를 이용해 원하는 대로 세팅을 할 수 있다는 것이다. 통상적인 CDN에 비해 성능이 조금 떨어질 수 있고 관리의 귀찮음도 있겠지만, 개인적인 용도로 사용할 때, 혹은 일반적인 CDN으로는 해결하기가 힘든 특수한 설정을 하고 싶을 때는 충분히 써볼 만 한 것 같다.</p><p><em>Originally published at </em><a href="https://si.mpli.st/dev/homemade-cdn-with-ns1-and-nginx.html"><em>si.mpli.st</em></a><em> on April 8, 2018.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e1f1dc2b4826" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/ns1%EC%99%80-nginx%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%99%88%EB%A9%94%EC%9D%B4%EB%93%9C-cdn-e1f1dc2b4826">NS1와 NGINX를 이용한 홈메이드 CDN</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[평창 2018]]></title>
            <link>https://medium.com/si-mpli-st-blog/%ED%8F%89%EC%B0%BD-2018-6b5ad935ee7a?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/6b5ad935ee7a</guid>
            <category><![CDATA[올림픽]]></category>
            <category><![CDATA[pyeongchang2018]]></category>
            <category><![CDATA[평창]]></category>
            <category><![CDATA[olympics]]></category>
            <category><![CDATA[pyeongchang]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Sun, 18 Feb 2018 12:00:00 GMT</pubDate>
            <atom:updated>2018-04-15T07:51:50.936Z</atom:updated>
            <content:encoded><![CDATA[<p>원문: <a href="https://si.mpli.st/travel/pyeongchang-2018.html">https://si.mpli.st/travel/pyeongchang-2018.html</a></p><p>2018년 2월 9일부터 25일까지, 평창군, 강릉시, 정선군에서 평창 동계올림픽이 열린다. 한국에서 이런 세계적인 행사가 열린다는 사실이 신기하기도 하고, 평창 동계올림픽이 아니면 올림픽 행사를 방문해 볼 일이 없을 것 같아서 당일치기로 여행을 다녀왔다.</p><h3>티케팅</h3><p>티케팅은 <a href="https://tickets.pyeongchang2018.com/">평창 동계올림픽 입장권 공식 사이트</a>에서 했다. 되도록이면 공휴일에 가고 싶었고, 평창의 숙소 상황이 좋지 않기에 대중교통으로 갈 수 있는 시간에 열리는 경기에 참가해야 했다. 나를 비롯하여 같이 가는 일행 모두 스포츠에 큰 관심이 없어서 큰 돈을 쓰고 싶지는 않아서, 경쟁이 치열한 경기와 입장권 가격이 비싼 경기는 자연스럽게 제외하였다. 여러 경기와 시간을 비교하다 보니, 설 연휴의 마지막 날인 2월 18일 오전 9시에 열리는 컬링 경기를 참관하게 되었다.</p><h3>강릉 코스탈 클러스터로 이동</h3><p>오전 9시의 경기를 보기 위해서는 오전 6시에 경강선 KTX 첫 차를 타야 했다. 지하철도 운행하지 않는 시간이서 서울역 근처의 비즈니스 호텔에서 간단하게 하루를 묵었다. 서울역에서 접근성이 좋은 호텔이라 그런지, 호텔 내부에 마련되어 있는 바에서 시끌벅적하게 올림픽을 보는 외국 투숙객들이 많았다. 그 중 일부는 캐나다 공식 유니폼까지 입고 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*o-qQPummJHKs7BxJ.jpg" /></figure><p>18일 오전 5시, 체크아웃을 하고 서울역으로 이동하여 KTX에 탑승하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*_4FkG5pvDVEXJ_MI.jpg" /></figure><h3>강릉역 도착, 그리고 컬링 관람</h3><p>약 2시간 후에 강릉역에 도착하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ED6aKRiy74OFy-Sd.jpg" /><figcaption>강릉역에 도착하니 비로소 올림픽 분위기가 실감이 났다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zSyRLBQtZoKqknKc.jpg" /><figcaption>역을 나오니 올림픽을 상징하는 오륜기와 올림픽 마스코트 동상이 있었다.</figcaption></figure><p>강릉에 도착하고 경기가 시작할 때 까지 시간이 얼마 없기에 서둘러 움직였다. 강릉역에서 강릉 코스탈 클러스터로 이동하려면 버스를 타거나 도보로 이동해야 했다. 이동 방식의 시간 차이가 크지 않아서 도보로 이동하였는데, 중간에 언덕이 있어서 왜 버스를 마련해 두었는지 알 것 같았다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*K4--1Pt6HZGiWtQo.jpg" /><figcaption>강릉 코스탈 클러스터 입구</figcaption></figure><p>시간에 맞춰 강릉 컬링 센터에 도착하여 컬링 경기를 관람하였다. 우리가 보게 된 경기는 <strong>노르웨이 대 덴마크</strong>, <strong>미국 대 일본</strong>, <strong>스위스 대 캐나다</strong>였는데, 비록 한국의 경기는 아니었지만 유럽의 수준급 국가들이 있어 재미있는 경기를 볼 수 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2UqSvVi8NbgqI1FK.jpg" /><figcaption>강릉 컬링 센터의 모습. 이 날은 한 번에 3개의 경기가 동시에 진행되어 눈을 뗄 새가 없었다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*5yjydQnxEnu4BgB-.jpg" /><figcaption>좌석 한 쪽에는 방송사를 위한 중계석이 마련되어 있다.</figcaption></figure><p>경기가 진행되는 동안 관중을 위해 마련된 인터넷 중계 사이트를 통해 경기 해설을 한국어로 들을 수 있었는데, 중계를 듣는 중간 우연히 이벤트에 당첨되어 익일 메달 플라자의 앞좌석 특별 입장권을 얻었다! 하지만 당일치기로 왔던 터라 직접 사용하지는 못하고, 지인에게 양도하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-fRjj_fjmjxMz5eO.jpg" /><figcaption>예매한 입장권(가장 오른쪽)과 이벤트로 당첨되어 받은 입장권(왼쪽부터 두 개). 파란색 고무공인 패션 볼(Passion Ball)을 가지고 있으면 메달 플라자의 맨 앞 좌석으로 입장이 가능하다고 한다.</figcaption></figure><h3>점심 식사, 강릉 올림픽 플라자 구경</h3><p>경기를 모두 관람하고 식당이 있는 구역으로 향했다. 올림픽 플라자 안에는 관중을 위해 마련된 식당이 있는데, 돈가스가 15,000원, 육개장이 12,000원과 같이 가격대가 전반적으로 높아서 평창 올림픽의 스폰서 중 하나인 맥도날드의 특별 매장에서 식사를 하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*NIA8pQJ9QPLkddvP.jpg" /><figcaption>맥도날드 강릉 올림픽 파크점. 특설 매장이라 빅맥과 같은 대표 메뉴만 주문이 가능했다.</figcaption></figure><p>점심 식사를 간단히 마치고 나와서 근처 구경을 했는데, 삼성전자나 코카콜라와 같은 올림픽 스폰서의 부스, 그리고 올림픽 기념품을 판매하는 슈퍼스토어가 꾸며져 있었다. 하지만 대기줄이 상당히 길기도 하고, 크게 관심이 가는 주제가 없어서 간단하게 구경을 마치고 다음 지역으로 이동하였다.</p><h3>평창 올림픽 플라자</h3><p>올림픽 기간동안은 주요 장소를 연결하는 셔틀버스가 운행되는데, 개막식이 열린 평창 올림픽 플라자로 이동하려면 이 셔틀버스를 타고 이동할 수 있다. 먼저 강릉 올림픽 파크에서 북강릉 주차장으로 이동하여 대관령 주차장으로 가는 버스를 타고, 거기서 한번 더 버스를 갈아타서 평창 올림픽 플라자로 향하는 식. 대부분의 길이 올림픽 지정도로 및 지정차로여서 빠르게 이동할 수 있었지만, 일반 차량과 섞이는 지점에서는 여지없이 심한 정체가 생겼다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Z2hpqg_4ATvljmNF.png" /><figcaption>강릉 올림픽 파크에서 평창 올림픽 플라자로 이동하는 경로. 실제로 1시간 반 정도 걸린 것 같다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*IbobWR4myoqpPf0_.jpg" /><figcaption>평창 올림픽 플라자 입구</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*89V0V_oa1QuFZhjG.jpg" /></figure><p>올림픽에서 가장 인상깊었던 것은 브랜드 아이덴티티의 일관성. 세계 최대의 브랜드 축제라고 할 만큼 올림픽 브랜드는 엄격한 기준을 가지고 있는데, 이러한 기준이 굉장히 많은 종류의 표지판 및 안내에 일관적으로 적용되는 것을 보니 상당히 대단하다는 생각이 들었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zAo_Fi6vJQ9gVYSA.jpg" /><figcaption>개막식 이후로 점화되어있는 개막식장의 성화대.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*gE9uLdfcoqui5h4H.jpg" /></figure><p>길목에 올림픽 스폰서의 다양한 부스가 준비되어 있다. 슈퍼스토어의 경우에는 줄이 매우 길어 한시간 정도는 각오해야 할 것 같았다. 개인적인 감상으로는 평창 올림픽 파크보다 강릉 올림픽 파크의 볼 거리가 다양했다.</p><h3>진부역, 그리고 귀가</h3><p>이동에 생각보다 많은 시간이 소요되어 평창 올림픽 파크를 모두 돌아보았을 때는 열차 시간이 꽤 빠듯했는데, 다행히 진부역으로 출발하는 셔틀버스가 빨리 도착하였다. 한 가지 놀라웠던 점이 있었는데, 진부역으로 향하는 셔틀버스의 모든 경로가 올림픽 전용도로로 지정이 되어 있다는 점이었다. 일반 차량의 경우 출입이 금지되고 올림픽 담당자와 셔틀버스만 출입이 가능해지는데, 덕분에 네비게이션에 따르면 35분 정도 걸리는 길을 15분만에 주파할 수 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DheHSETFJKOaBSUe.jpg" /><figcaption>진부역 입구. 비교적 작은 역사이지만 아담하고 멋진 디자인이 좋았다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Rl1RxplkdC_AyR7a.JPG" /><figcaption>진부역 플랫폼. 회색 톤의 절제된 표지판 색이 주변 풍경과 조화롭게 어울렸다. KTX가 정차하는 다른 역도 이렇게 바꾸면 차분하고 좋을 것 같은데…</figcaption></figure><p>오후 4시 24분에 출발하는 상봉행 열차를 타고 진부역을 떠나서, 당일치기 올림픽 일정을 마무리했다.</p><p><em>Originally published at </em><a href="https://si.mpli.st/travel/pyeongchang-2018.html"><em>si.mpli.st</em></a><em> on February 18, 2018.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=6b5ad935ee7a" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/%ED%8F%89%EC%B0%BD-2018-6b5ad935ee7a">평창 2018</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[멋진 신세계, 컨테이너: 프로덕션에 Docker를 사용하기]]></title>
            <link>https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%ED%94%84%EB%A1%9C%EB%8D%95%EC%85%98%EC%97%90-docker%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-31cae43e4aea?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/31cae43e4aea</guid>
            <category><![CDATA[devops]]></category>
            <category><![CDATA[korean]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[docker]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Mon, 20 Nov 2017 03:28:05 GMT</pubDate>
            <atom:updated>2017-11-20T03:38:09.477Z</atom:updated>
            <content:encoded><![CDATA[<h3>멋진 신세계, 컨테이너: 프로덕션에 Docker사용하기</h3><p><a href="http://www.imaso.co.kr/archives/248">마이크로소프트웨어 390호, &lt;오픈의 꿈&gt;</a>에 투고한 글을 옮겼습니다.</p><ul><li><a href="https://making.shakr.com/25341989e986">Docker를 소개합니다</a></li><li><a href="https://making.shakr.com/f6b5f75c36a2">Google App Engine에 Docker 애플리케이션 배포하기</a></li><li><strong>프로덕션에 Docker 사용하기</strong></li></ul><p>최근에는 인터넷에 게시되어 있는 기술 예제가 많아져서, 어떤 기술을 어떻게 사용하는지 궁금하다면 몇 번의 검색으로 기술을 쉽게 접하는 것이 가능해졌다. 하지만 튜토리얼을 따라 하다 보면 로컬 환경에서 간단한 애플리케이션을 구동할 때는 큰 문제가 없지만, 프로젝트에 참여하는 팀원이 늘어나고 애플리케이션의 규모가 커지면서 튜토리얼에서 다루지 않는 새로운 구조를 이용하여 시스템을 설계해야 할 순간이 찾아온다. 이전 글에서 설명한 예제에서는 아주 간단한 웹 애플리케이션을 Docker와 Google App Engine을 사용하여 애플리케이션을 배포하는 예제를 살펴보았는데, 지금부터는 조금 더 나아가서 보다 지속 가능한 개발을 위해 빌드 파이프라인을 구축하고, 여러 서비스로 구성된 애플리케이션을 배포할 수 있는 몇 가지 솔루션을 소개하려고 한다.</p><h3>컨테이너 이미지 호스팅</h3><p>공개를 하기 원하는 컨테이너 이미지를 제작한 경우에는 <a href="https://hub.docker.com">Docker Hub</a>나 <a href="https://quay.io">Quay</a>와 같은 레지스트리를 사용하여 무료로 공개 이미지를 저장할 수 있지만, 상용 애플리케이션의 경우에는 이미지를 공개할 수 없는 경우가 대부분이기에 어느 레지스트리를 사용할 것인지 고민해 보아야 한다.</p><ul><li><a href="https://hub.docker.com/"><strong>Docker Hub</strong></a><strong> (Docker Inc.)</strong>: Docker의 기본 레지스트리로 지정이 되어 있기 때문에 URL 지정 없이도 바로 사용이 가능하며(docker pull hub.docker.com/shakr/helloworld 대신 간단하게 docker pull shakr/helloworld 를 입력해서 사용 가능하다) 추가적인 인증 설정 없이 docker login 만으로 사용 가능하다는 장점이 있다. 내부적으로는 AWS에 파일을 호스팅하는 것으로 알려져 있어, AWS 사용자에게는 좋은 선택지가 될 수 있다.</li><li><a href="https://quay.io/"><strong>Quay</strong></a><strong> (CoreOS Inc.)</strong>: Container Linux를 개발하는 CoreOS, Inc. 에서 운영 중이다. 자체적으로 개발한 오픈 소스 취약점 분석 도구 <a href="https://coreos.com/clair/"><strong>Clair</strong></a>를 이용하여, 레지스트리에 업로드한 이미지의 취약점을 자동으로 분석하고 발견된 보안 결점의 심각도와 관련된 CVE 정보를 보여주는 기능이 강점이다.</li><li><a href="https://aws.amazon.com/ko/ecr/"><strong>AWS EC2 Container Registry</strong></a><strong> (Amazon Web Services)</strong>: AWS 인프라스트럭쳐 내부에 호스팅 되어 AWS 내 같은 리전에서 사용할 때에는 별도의 트래픽 요금이 발생하지 않고, AWS IAM을 이용해 권한을 관리할 수 있다. US East (N. Virgina)를 포함하여 11개의 AWS 리전을 지원하고, <a href="https://aws.amazon.com/ko/blogs/korea/amazon-ecr-now-available-in-asia-pacific-seoul-region/"><strong>최근 서울 리전 지원이 추가되었다</strong></a>.</li><li><a href="http://cloud.google.com/container-registry"><strong>Google Container Registry</strong></a><strong> (Google Cloud)</strong>: GCP 내부에 호스팅 되어 GCP 내 같은 리전에서 사용할 때는 별도의 트래픽 요금이 발생하지 않고, GCP의 <a href="https://cloudplatform.googleblog.com/2014/04/enter-andromeda-zone-google-cloud-platforms-latest-networking-stack.html">Andromeda 네트워크 스택</a>을 통해 VM에서 이미지를 효율적으로 받아올 수 있다. Google Compute Engine에서 구동되는 VM에서는 생성시 Container Registry의 권한을 허용하면 VM 내부에서는 별도의 인증 절차 없이 사용할 수 있고, GCP 인프라 외에서는 Service Account를 통해 레지스트리에 접근할 수 있다. 미국, 유럽, 아시아 세 곳에 이미지를 호스팅 하는 것을 지원한다.</li><li><strong>직접 호스팅</strong>: 호스팅 서비스를 사용하길 원하지 않는 사용자는 <a href="https://docs.docker.com/registry/">Docker Registry</a> 이미지를 사용하여 직접 레지스트리 서버를 구축할 수 있다. 설정을 통해 이미지를 파일시스템에 저장할 지, S3나 Google Cloud Storage, OpenStack Swift와 같은 원격 객체 저장소에 저장할 지 설정할 수 있다.</li></ul><h3>지속적 통합(CI; Continuous Integration)과 지속적 배포(CD; Continuous Delivery)</h3><p>현대적인 애플리케이션 개발 프로세스에 지속 통합과 지속 배포는 더이상 선택이 아닌 필수이다. 기능 업데이트에 대해 빌드와 유닛 테스트를 자동으로 실행하고, 이러한 결과를 간편하게 받아볼 수 있으므로써 개발 과정의 생산성이 크게 올라가고 여러 개발자 사이에 보다 효율적인 협업을 할 수 있다. 이러한 지속 통합 이후 빠르게 고객에게 새로운 변경점을 선보이기 위해 배포 과정을 자동화 하는 것도 일반적인 애플리케이션에서 갖춰야 할 과정이 되었다.</p><p>Docker를 이미 사용하고 있는 애플리케이션의 경우에는 이미 어느 환경에서나 재현 가능한 상태일 확률이 높은데, Dockerfile 명세에 애플리케이션 단위의 의존성 뿐만이 아니라 서버에서의 라이브러리 의존성 등이 모두 Dockerfile에 포함되어 있기 때문이다. 운영체제 버전이나 사용하고 있는 의존성 라이브러리의 버전만 고정하면, 지속 통합을 하기 위한 준비를 쉽게 끝마칠 수 있다.</p><h4>Travis CI + App Engine</h4><p>앞서 살펴본 예제의 Google App Engine을 이용한 웹 애플리케이션의 경우, 개발자의 로컬 환경에서 gcloud app deploy를 사용하여 수동으로 배포를 하는 방식이었는데, 이러한 애플리케이션에 지속적 배포를 적용하려면 어떤 과정을 거쳐야 할까? 소스 코드 저장소에서 협업할 때 <a href="https://guides.github.com/introduction/flow/">GitHub Flow</a>와 같은 풀 리퀘스트 기반 협업 방식을 사용하고 있다면, master 브랜치에 풀 리퀘스트가 머지되었을 때 <a href="http://travis-ci.org/"><strong>Travis CI</strong></a>와 같은 지속 통합 서비스에서 유닛 테스트를 실행하고, 테스트를 모두 통과하면 Google App Engine으로 자동으로 배포하도록 설정할 수 있다. Google Cloud Platform에서 이와 같은 시나리오를 위한 <a href="https://cloud.google.com/solutions/continuous-delivery-with-travis-ci"><strong>예제 튜토리얼(영문)</strong></a>를 제공하고 있다.</p><h4>클라우드 플랫폼별 지속 통합 및 배포 서비스</h4><p>대부분의 기업에서는 이미 AWS나 Google Cloud 등 하나의 클라우드 서비스를 주력으로 사용하고 있는 경우가 많을텐데, 각 클라우드별로 대표적인 지속 통합 및 지속 배포 솔루션을 지원하고 있어 이를 사용하면 다른 별도의 서비스에 가입할 필요가 없고, 기존에 사용하는 클라우드 서비스와 연동이 용이하며, 네트워크 트래픽 비용을 절감할 수 있다.</p><ul><li><strong>AWS CodePipeline</strong>: Amazon Web Services의 CodePipeline를 사용하면 애플리케이션 빌드부터 유닛 테스트, 그리고 배포에 이르는 과정을 파이프라인으로 정의할 수 있다. GitHub이나 AWS CodeCommit 저장소에 새로운 변경점이 추가되면 이를 받아온 후, AWS CodeBuild나 Jenkins를 통해 빌드 아티팩트를 생성하고 테스트를 실행한다. 유닛 테스트를 통과하고 정상적으로 빌드에 성공했다면, 애플리케이션을 AWS CodeDeploy나 AWS CloudFormation 등을 사용하여 배포할 수 있다. 각 단계를 파이프라인으로 관리하여 현재 지속 통합 과정이 어떻게 이루어지고 있는지를 쉽게 인지할 수 있다는 것이 큰 장점이며, AWS Lambda와 연동하여 파이프라인의 각 단계에 대한 알림을 받아 사용자가 원하는 코드를 실행할 수 있다는 점도 파이프라인을 보다 유연하게 운영할 수 있게 해 준다.</li><li><strong>Google Cloud Container Builder</strong>: Google Cloud Platform의 Container Builder를 사용하면 AWS CodePipeline과 마찬가지로 애플리케이션 빌드부터 유닛 테스트, 그리고 배포에 이르는 과정을 파이프라인으로 정의할 수 있다. Google Cloud Source Repository와 GitHub, Bitbucket에서 코드를 자동으로 받아오는 것을 지원하며, YAML 형태로 된 파이프라인 설정 파일에 빌드와 유닛 테스트, 그리고 배포에 필요한 단계를 정의할 수 있다. 사용자가 지정한 Docker 이미지 내에서 커스텀 스크립트을 실행할 수 있기에, 쉘 스크립트로 자동화가 가능한 모든 작업을 수행할 수 있다. Google Cloud Pub/Sub 으로 빌드의 진행 상황을 이벤트로 받을 수 있으며, Google Cloud KMS를 통해 외부로 유출되면 곤란한 민감한 설정 파일을 저장해 두었다가 배포 과정에서 사용할 수 있다.</li></ul><h3>컨테이너 애플리케이션 호스팅</h3><p>이전 글에서 살펴본 애플리케이션 개발 및 배포 예제에서는 로드 밸런싱이나 로그 저장과 같은 작업을 모두 매니지드 서비스 형태로 제공해주는 App Engine을 사용하였는데, 모든 비즈니스에서 App Engine을 사용하기에는 한계가 있다. 마이크로서비스 형태의 아키텍처로 애플리케이션을 설계한 경우에는 서비스 디스커버리와 같은 기능이 필요할 것이고, GPU나 높은 IO 성능을 가진 스토리지 등 호스트 머신에 특정한 요구 사항이 있는 경우에도 App Engine을 주력으로 사용하기에는 어려움이 있을 것이다. 이럴 때 사용할 수 있는 애플리케이션 호스팅 소프트웨어 중 대표주자인 Kubernetes에 대해서 알아보자.</p><h4>Kubernetes</h4><p>Kubernetes는 컨테이너 기반 애플리케이션을 배포하고, 확장하고, 관리하는 작업을 자동화 해 주는 소프트웨어이다. Kubernetes는 오토 스케일링 그룹이나 로드 밸런서, 디스크 볼륨과 같은 애플리케이션의 각 구성 요소를 이해하기 쉽도록 추상화 해 주고, 사용자가 설정한 구성 요소를 관리해준다. Kubernetes의 초기 개발은 구글이 주도했는데, 구글이 리눅스의 cgroups의 모태가 된 Process Containers, 그리고 내부적으로 컨테이너를 운영할 때 사용한 <a href="http://queue.acm.org/detail.cfm?id=2898444">Borg와 Omega를 개발하고 사용해 본 경험</a>이 녹아들어가 높은 완성도의 소프트웨어가 되었다. 여기서 그치지 않고 Google이 Kubernetes를 Linux Foundation과 함께 <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a>의 첫 번째 프로젝트로 이관하면서, 특정 기업에 종속되지 않고 여러 관련 기업이 함께 만들어나가는 오픈 소스 프로젝트가 되었다.</p><p>현재 Shakr에서는 Kubernetes를 이용하여 컨테이너 애플리케이션을 운영하고 있는데, Kubernetes를 선택한 이유는 다음과 같다.</p><ul><li><strong>Google Cloud Platform에서 쉽게 사용 가능:</strong> 오퍼레이션 팀이 본격적으로 갖춰져 있지 않은 스타트업의 입장에서는 서비스 형태로 인프라를 제공하는 곳이 있는지를 찾아보는 것이 가장 중요한 우선 순위였다. GCP에서 아주 적은 비용(5개의 노드까지는 관리 비용 무과금, us-central-1 리전 기준 한 달에 109.50 미국 달러) 으로 매니지드 형태로 사용이 가능하다는 것은 큰 이점이다.</li><li><strong>유연한 자원 활용:</strong> Shakr에는 앱 스토어나 구글 플레이처럼 디자이너가 비디오 디자인을 입점할 수 있는데, 앱 스토어에 앱 패키지를 업로드하듯이 디자이너도 Shakr에 디자인 패키지를 업로드한다. 이 때 Shakr 시스템에서는 이를 사용자에게 제공해 줄 수 있도록 패키지의 각 구성 요소를 모든 환경에서 사용 가능하게 변환하는데, 이 작업은 컴퓨팅 집약적이지만 일반 사용자의 트래픽처럼 빈번하게 일어나지는 않는다. 이전에는 이러한 작업을 위해 비교적 CPU와 메모리를 많이 할당한 가상 머신을 프로비저닝 해 두었는데, 대부분의 경우 리소스 사용량이 그리 많지 않아 효율적으로 자원을 활용하지 않는 상태였다. Kubernetes의 경우 단일 호스트에도 많은 애플리케이션을 프로비저닝 하면서도 유연하게 리소스 관리를 할 수 있어서, 유휴 자원을 최소화 할 수 있게 되었다.</li><li><strong>Batteries Included:</strong> 애플리케이션의 동작 상태를 확인할 수 있는 웹 대시보드를 쉽게 설치하여 사용할 수 있고(kubernetes-ui), 패턴 매칭이 가능한 로드 밸런싱 기능을 제공하고(Ingress/Service), 구동 중인 컨테이너의 상태를 모니터링할 수 있는 방법(cAdvisor, Heapster)을 제공하는 등 인프라 운영에 필요한 여러 구성 요소를 쉽게 설정할 수 있다.</li><li><strong>적은 벤더 종속성:</strong> 현재는 GCP 위에서 Google Container Engine을 통해 Kubernetes를 사용하고 있지만, Kuberentes 프로젝트는 오픈 소스(Apache License 2.0)로 공개가 되어 있고, Google 직원뿐만 아닌 다양한 기업의 엔지니어가 활발하게 참여하여 공동 개발을 하고 있다. 또한 Google Cloud Platform에서만 사용할 수 있는 것이 아니라 CoreOS, Inc. 와 같은 기업에서 다른 클라우드 서비스나 물리적인 서버 인프라에 Kubernetes를 설치할 수 있는 솔루션을 제공해 주기 때문에 GCP에 종속되지 않고 추후 필요시 다른 벤더로 서비스를 이전하기도 용이하다.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*xS-9OZmPci-_ycKnzPVaXA.png" /><figcaption>Shakr에서는 영상 및 사진 등 미디어 처리 파이프라인과 분산 서비스 운영에 Kubernetes를 활용하고 있다</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*0DzkX1PomX14LdKkSIQIlA.png" /><figcaption>Datadog과 같은 모니터링 솔루션을 사용하면 Kubernetes 클러스터의 상황을 한 눈에 볼 수 있다</figcaption></figure><h4>Kuberentes의 주요 리소스 소개</h4><ul><li><strong>Pod:</strong> Pod은 가장 작은 컴퓨팅 유닛이다. 컨테이너 하나 혹은 여러개로 구성되어 있으며, 일반적인 클라우드 인프라스트럭쳐로 비교하면 VM과 같은 위치에 있는 리소스이다. Pod은 일반적으로 휘발성이기 때문에 Pod이 소멸될 때 내부의 데이터도 같이 삭제되지만, PersistentVolume과 같은 리소스를 사용하여 이를 외부 저장소에 보존할 수 있다.</li><li><strong>Deployment:</strong> Deployment는 여러 개의 Pod을 관리하는 리소스이다. 클라우드 인프라스트럭쳐에서는 오토 스케일링이 켜져 있는 인스턴스 그룹과 비교해 볼 수 있는데, 정해진 replica 갯수에 따라 Pod을 자동으로 생성하고 삭제한다. Horizontal Pod Autoscaling을 이용하여 CPU나 다른 지표에 따라 Pod 갯수를 동적으로 조정하는 것 또한 가능하다.</li><li><strong>Service:</strong> Service를 사용하여 같은 역할을 하는 Pod의 그룹을 어떻게 접근할 지 정의할 수 있다. 가령 마이크로서비스 아키텍쳐에서 서비스 A가 서비스 B로 접근하고자 할때 Deployment에 의해 생성된 Pod의 IP를 사용한다면, 해당 Pod이 어떠한 이유로 소멸되었을 때 같은 Deployment 내 다른 Pod은 정상적으로 구동되고 있음에도 불구하고 서비스 B에 접속을 하지 못하게 된다. Service를 이용하면 조건문으로 어떤 Pod을 선택할지 정의하고, 이 Pod의 어떤 포트가 접근 가능해야 하는지를 설정해 줄 수 있다. Kubernetes 내의 서비스 디스커버리(Service Discovery) 기능과 밀접하게 연결되어, 같은 네임스페이스의 다른 Pod에서 서비스 내 Pod의 IP를 알지 않고도 서비스 이름으로 접속이 가능하다. LoadBalancer 타입으로 Service를 생성하면 외부 트래픽을 수용할 수 있는 간단한 로드 밸런서로도 사용할 수 있다.</li><li><strong>Ingress:</strong> 일반적으로 Service와 Pod은 클러스터 내부에서만 접근 가능한데, Ingress는 외부 트래픽을 이러한 Service로 전달해 주는 역할을 한다. HTTP 요청의 경로에 따라 다른 서비스가 요청을 처리하도록 설정하는 것도 가능한데, 예를 들면 /api/ 경로로 오는 요청은 백엔드 서비스가 처리하도록 설정하고 나머지는 프론트엔드 서비스가 처리하도록 설정할 수 있다. Kubernetes가 설치된 환경에 따라 다르지만, Google Container Engine에서 Ingress를 사용하면 Google Cloud HTTP(S) 로드 밸런서를 자동으로 생성한다.</li><li><strong>Secret/ConfigMap:</strong> 애플리케이션 구동에 필요한 설정 파일이나 민감한 환경 변수를 저장할 때 사용할 수 있다. Pod을 설정할 때 환경 변수를 직접 추가하는 대신 Secret이나 ConfigMap에서 값을 참조하도록 설정할 수 있는데, 이렇게 설정할 경우 여러 서비스에서 공통으로 사용되는 환경 변수를 별도로 저장하지 않아도 되기 때문에 편리하다.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GNEKD15l-Lq8pgm8pu_kLw.png" /><figcaption>2017년 초 공개하여 현재까지 서비스 중인 StoriesAds.com의 시스템 다이어그램. 개발부터 프로덕션 공개까지 Kubernetes를 이용하여 배포를 진행하였다</figcaption></figure><h3>Kubernetes 외 컨테이너 호스팅 솔루션</h3><p><a href="http://aws.amazon.com/ecs"><strong>AWS ECS</strong></a></p><ul><li>Amazon Web Services에서 대표적으로 컨테이너를 관리할 수 있는 서비스이다. 자체적인 Task Definition 파일이나 Docker Compose 파일 형식으로 컨테이너 워크로드를 정의할 수 있고, Application Load Balancer나 CloudTrail과 같은 다른 AWS 서비스와 연동이 가능하다. ECS는 서비스 형태로 제공되기 때문에 소스가 공개되어 있지 않지만, ECS에서 사용할 수 있는 스케쥴러인 Blox(<a href="https://blox.github.io/">https://blox.github.io/</a>)를 최근에 오픈소스로 공개하였다.</li></ul><p><a href="https://mesosphere.github.io/marathon/"><strong>Mesosphere Marathon</strong></a></p><ul><li>Mesosphere, Inc. 가 제작한 Apache Mesos 위에서 컨테이너 기반 애플리케이션을 구동할 수 있는 오픈 소스 작업 스케쥴러이다. Mesosphere, Inc. (<a href="https://mesosphere.com">https://mesosphere.com</a>) 에서 제작한 운영체제인 DC/OS (<a href="https://dcos.io">https://dcos.io</a>)와 DC/OS가 기반을 두고 있는 Apache Mesos에서도 사용 가능하다. Mesos는 트위터나 애플에서도 사용하고 있는만큼 아느 정도의 안정성이 증명된 클러스터 관리 시스템인데, 이 위에서 컨테이너 기반 애플리케이션을 구동할 수 있다.</li><li>라이센스: Apache License 2.0</li></ul><p><a href="https://www.nomadproject.io/"><strong>HashiCorp Nomad</strong></a></p><ul><li>Terraform, Vagrant, Consul 등의 DevOps 소프트웨어로 유명한 HashiCorp이 만든 작업 스케쥴러이다. Docker를 사용하는 작업 뿐만 아니라 rkt, LXC와 같은 다른 컨테이너 런타임, 그리고 Qemu를 이용한 가상 머신이나 컨테이너 없이 프로세스를 실행하는 것과 같은 다양한 작업 형태를 지원한다. 서비스 디스커버리와 같은 핵심 기능에 Consul을 사용하며, 민감한 정보 저장에 Vault를 사용할 수 있다.</li><li>라이센스: Mozilla Public License 2.0</li></ul><h3>마치며</h3><p>몇 년 전 까지만 해도 Docker를 도입하는 것의 위험 부담이 어느 정도 남아 있었지만, 많은 클라우드 서비스에서 Docker 컨테이너 배포를 지원하기 시작하고 Kubernetes와 같이 활발하게 개발되는 오픈 소스 프로젝트가 생기면서 스타트업뿐만 아니라 대기업도 컨테이너를 높은 안정성을 요구하는 워크로드에도 도입하고 있다. Shakr에서 인력 대비로 운영하는 내부 컴포넌트가 많다 보니 겪었던 여러 가지 문제들도 Kubernetes로 대부분의 컴퓨팅 워크로드를 옮긴 이후로 대부분 해결할 수 있었다. 아무런 연구 없이 새로운 기술을 도입하는 것은 바람직하지 않지만, Docker와 같은 컨테이너 기반 인프라 구축에 익숙해진다면 인프라 운영에서 누구나 가지고 있는 큰 짐을 덜 수 있을 것이다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=31cae43e4aea" width="1" height="1"><hr><p><a href="https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%ED%94%84%EB%A1%9C%EB%8D%95%EC%85%98%EC%97%90-docker%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-31cae43e4aea">멋진 신세계, 컨테이너: 프로덕션에 Docker를 사용하기</a> was originally published in <a href="https://making.shakr.com">Making Shakr</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[멋진 신세계, 컨테이너: Google App Engine에 Docker 애플리케이션 배포하기]]></title>
            <link>https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-google-app-engine%EC%97%90-docker-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC%ED%95%98%EA%B8%B0-f6b5f75c36a2?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/f6b5f75c36a2</guid>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[korean]]></category>
            <category><![CDATA[devops]]></category>
            <category><![CDATA[ruby-on-rails]]></category>
            <category><![CDATA[google-app-engine]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Mon, 20 Nov 2017 03:27:42 GMT</pubDate>
            <atom:updated>2017-11-20T03:32:36.753Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="http://www.imaso.co.kr/archives/248">마이크로소프트웨어 390호, &lt;오픈의 꿈&gt;</a>에 투고한 글을 옮겼습니다.</p><ul><li><a href="https://making.shakr.com/25341989e986">Docker를 소개합니다</a></li><li><strong>Google App Engine에 Docker 애플리케이션 배포하기</strong></li><li><a href="https://making.shakr.com/31cae43e4aea">프로덕션에 Docker 사용하기</a></li></ul><p>Docker를 이용하면 어떤 종류의 애플리케이션이라도 컨테이너 형태로 제작하여 구동할 수 있지만, 많은 기업이 웹 애플리케이션을 혹은 마이크로서비스 등의 구성요소를 운영할 때 주로 Docker를 이용하여 프로덕션 환경을 구축하곤 한다. 어떤 기술에 대한 설명을 무작정 듣기보다는 실제로 사용해 보면서 얻는 지식과 경험이 크기 때문에, 실제로 있을만한 상황을 가정하여 Docker 사용 방법에 대해 설명해 보려고 한다. 간단한 웹 애플리케이션을 제작하여 Docker를 활용해 보고, Docker 이미지를 생성하여 컨테이너 레지스트리에 등록하고, Google App Engine에 애플리케이션을 배포해보자.</p><h3>예제 소개</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*eXgFMsPpnjTykms1SASNUA.png" /></figure><p>Docker를 사용하는 애플리케이션을 <a href="https://cloud.google.com/appengine/"><strong>Google App Engine</strong></a>에 배포하는 과정을 설명하기 위해 Translator라는 간단한 웹 애플리케이션을 제작하였다. Translator는 빠르고 간단하게 웹 개발을 할 수 있는 <a href="http://rubyonrails.org/">Ruby on Rails</a> 최신 버전인 5.1을 사용하고 있고, 프론트엔드 구현에는 <a href="https://vuejs.org/">Vue.js</a>와 <a href="https://webpack.js.org/">webpack</a>을 사용하였다. Translator의 소스 코드는 <a href="https://github.com/premist/translator"><strong>GitHub에 공개</strong></a>하여, 누구나 자유롭게 사용할 수 있다.</p><p>예제 배포에 Google App Engine을 선택한 이유는 여러 가지가 있지만, 대표적인 이유를 꼽아보자면 다음과 같다.</p><ul><li>Snapchat, Nintendo, Niantic 등 많은 회사가 이미 프로덕션 환경에서 문제 없이 사용하고 있다.</li><li>작년 초 출시된 Flexible Environment를 사용하면 언어에 관계 없이 모든 Docker 기반 애플리케이션을 구동할 수 있다.</li><li>최소한의 설정으로 로드 밸런싱, 오토 스케일링, 애플리케이션 헬스 체크, 스플릿 테스트, 애플리케이션 성능 모니터링(APM) 등을 모두 제공한다.</li><li>쉬운 배포를 위한 커맨드 라인 도구(Google Cloud SDK)를 제공한다.</li></ul><h3>준비</h3><h4><strong>Git과 Docker가 설치된 컴퓨터</strong></h4><p>Git은 macOS나 Linux에는 기본적으로 설치되어 있는 경우가 많고, 설치되어 있지 않다면 패키지 매니저를 통해 쉽게 설치가 가능하다. Windows 환경에서는 <a href="https://git-scm.com/">Git 웹사이트</a>에서 직접 다운로드하여 설치하자.</p><p>Docker는 Linux(Ubuntu 14.04, Debian 7.7, CentOS 7 이상), macOS(버전 10.11 이상), Windows(10 Pro, 10 Enterprise, 10 Education) 기반의 64비트 컴퓨터에 <a href="https://www.docker.com/community-edition">다음 링크</a>에서 다운로드하여 설치할 수 있다. Linux에서는 네이티브로 동작하고, macOS와 Windows에서는 운영 체제의 가상 환경 프레임워크(macOS의 경우 Hypervisor.framework, Windows의 경우 Hyper-V)를 통해 동작한다.</p><h4><strong>Google Cloud Platform 계정</strong></h4><p>예제 애플리케이션을 Google App Engine으로 배포할 예정이고, 애플리케이션에서 Google API를 사용하기 때문에 Google Cloud Platform계정이 필요하다. Google API나 Google App Engine은 유료 서비스이지만, GCP 가입 시 $300 크레딧을 제공하므로 이를 사용하여 튜토리얼을 충분히 완료할 수 있다.</p><h3>Translator 프로젝트 받기</h3><p>앞서 간단하게 설명한 Translator 프로젝트를 컴퓨터에 준비하자. 쉘에서 Git으로 쉽게 소스 코드를 받아올 수 있다.</p><pre>$ git clone https://github.com/premist/translator.git<br>Cloning into &#39;translator&#39;...<br>remote: Counting objects: 279, done.<br>remote: Compressing objects: 100% (178/178), done.<br>remote: Total 279 (delta 112), reused 228 (delta 78), pack-reused 0<br>Receiving objects: 100% (279/279), 104.74 KiB | 599.00 KiB/s, done.<br>Resolving deltas: 100% (112/112), done.<br>$ cd translator</pre><h3>Dockerfile 톺아보기</h3><p>받아온 소스 코드를 살펴보면 루트 디렉터리에 Dockerfile이라는 파일이 존재하는데, 이 Dockerfile은 Docker가 어떻게 이미지를 어떤 단계를 거쳐 생성해야 할 지 기술한다.</p><pre>FROM ruby:2.4.1<br><br>ENV RAILS_ENV production<br>ENV RAILS_LOG_TO_STDOUT true<br>ENV RAILS_SERVE_STATIC_FILES true<br>ENV PORT 8080<br><br># Install apt-https-transport and lsb-release for Node.js and Yarn<br>RUN apt-get update &amp;&amp; apt-get install -y apt-transport-https &amp;&amp; apt-get clean<br><br># Add Node.js and Yarn source<br>RUN curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | apt-key add -<br>RUN curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -<br>RUN echo &quot;deb https://deb.nodesource.com/node_8.x jessie main\ndeb-src https://deb.nodesource.com/node_8.x jessie main&quot; | tee /etc/apt/sources.list.d/nodesource.list<br>RUN echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | tee /etc/apt/sources.list.d/yarn.list<br><br>ADD . /opt/translator<br>WORKDIR /opt/translator<br><br># Install Ruby dependencies<br>RUN bundle install<br><br># Install Node.js and Yarn, install NPM packages via Yarn,<br># run asset precompilation (which runs webpack), and remove Node.js and Yarn.<br>RUN apt-get update &amp;&amp; apt-get install -y nodejs yarn \<br>  &amp;&amp; yarn install &amp;&amp; rake assets:precompile &amp;&amp; apt-get remove -y yarn nodejs \<br>  &amp;&amp; apt-get clean &amp;&amp; rm -rf node_modules<br><br>EXPOSE 8080<br><br>RUN [&quot;./bin/rails&quot;, &quot;server&quot;]</pre><p>처음 Dockerfile 포맷을 보면 어떤 부분이 어떤 역할을 하는지 감이 오지 않을 수 있는데, 각 단계별로 천천히 살펴보자.</p><pre>FROM ruby:2.4.1</pre><p>모든 Dockerfile은 <strong>FROM</strong> 구문으로 시작한다. 이 이미지의 기반 이미지를 지정하는 것인데, 여기서는 Docker가 제공하는 공식 <a href="https://hub.docker.com/_/ruby/">Ruby 이미지</a>를 사용하였다. 사용하는 언어 런타임을 설치하는 과정부터 직접 수행하고 싶다면, 이 <strong>FROM</strong> 구문에 debian:stretch 나 centos:7 와 같은 OS 이미지를 지정하여 Dockerfile을 작성할 수 있다.</p><pre>ENV RAILS_ENV production</pre><p><strong>ENV</strong> 구문을 사용하면 컨테이너 내에 환경 변수를 할당할 수 있다. 가령 레일즈 애플리케이션의 경우 RAILS_ENV 라는 환경 변수로 현재 애플리케이션의 환경을 정의해줄 수 있는데, 여기서는 프로덕션 환경에서 사용할 이미지이므로 프로덕션으로 지정해주었다. 여기서 지정된 환경 변수이더라도 이미지를 실행할 때 -e MY_ENV_VAR=OVERRIDE_VALUE 와 같이 스위치를 지정해 주는 것으로 오버라이드가 가능하다.</p><pre>RUN apt-get update &amp;&amp; apt-get install -y apt-transport-https &amp;&amp; apt-get clean</pre><p><strong>RUN</strong> 구문을 사용하여 이미지 빌드 단계에서 명령어를 실행할 수 있다. 위의 명령어는 APT 패키지 관리자를 이용하여 apt-transport-https 패키지를 설치하는 명령어이다. apt-get update 와 apt-get install, apt-get clean 명령을 단일 <strong>RUN</strong> 구문으로 실행하여 가독성이 낮게 느껴질 수도 있는데, 그럼에도 불구하고 이렇게 <strong>RUN</strong> 구문을 작성한 이유는 Docker가 이미지를 빌드하는 특성을 감안해서이다. 각 명령어가 독립적인 레이어 형태로 저장이 되므로, 위 명령어를 3개로 나누어 실행하게 되면 apt-get clean 에 의해 삭제될 파일도 모두 저장되기 때문에 단일 명령어로 묶어주면 레이어가 보다 간결해지고 사이즈도 작게 유지할 수 있다. 파일 아래 부분에서도 이와 같은 이유로 Node.js와 Yarn을 설치하고, 패키지를 받아와 webpack 빌드를 실행하는 구문을 단일 명령어를 묶어서 RUN 구문으로 작성하였다.</p><pre>ADD . /opt/translator<br>WORKDIR /opt/translator</pre><p><strong>ADD</strong> 구문을 사용하면 현재 작업 디렉터리 내의 파일이나 폴더를 지정하여 이미지 내에 추가할 수 있고, <strong>WORKDIR</strong> 구문으로 Dockerfile의 각 명령어가 실행되는 작업 디렉터리를 정의할 수 있다.</p><pre>EXPOSE 8080</pre><p><strong>EXPOSE</strong> 구문에 포트를 지정해주면, 컨테이너를 실행할 때 해당 포트에서 연결을 받을 수 있다. 이렇게 지정된 포트는 동일한 Docker 네트워크 내에서 다른 컨테이너가 접근할 수 있다. 다만 <strong>EXPOSE</strong> 구문 만으로는 해당 포트가 호스트에 노출되지는 않으므로, 호스트에 해당 포트를 노출시키고 싶다면 이미지를 실행할 때 -p 컨테이너-포트:호스트-포트 스위치를 지정해 주어야 한다.</p><pre>RUN [&quot;./bin/rails&quot;]</pre><p><strong>RUN</strong> 구문으로 해당 이미지가 기본으로 실행할 명령어를 지정할 수 있다. 이렇게 지정한 명령어는 명령어 지정 없이 docker run를 실행하였을 때 기본적으로 사용되며, 필요한 경우 명령어를 지정해주는 것으로 오버라이드도 가능하다.</p><blockquote><strong>.dockerignore 파일</strong></blockquote><blockquote>Git 버전 관리 소프트웨어를 사용해 본 독자라면 <strong>.gitignore</strong> 파일에 익숙할 것이다. .gitignore 파일에는 Git이 무시할 파일을 지정하는데, 이를 사용하면 중요한 정보를 저장하고 있는 설정 파일이나 크기가 지나치게 방대한 의존성 디렉터리가 Git 저장소에 포함되는 것을 미연에 방지할 수 있다. <strong>.dockerignore</strong> 파일도 이와 비슷한데, 이 파일에 Docker 이미지 빌드 시 무시할 파일과 폴더를 지정해 주면 이미지가 필요 이상으로 커지는 것을 방지할 수 있다.</blockquote><h3>개발 환경에서 이미지 빌드하고 실행하기</h3><p>Docker 이미지 명세를 담고 있는 Dockerfile을 살펴보았으니, 이제 이 Dockerfile을 이용하여 이미지를 빌드해보자. 커맨드 라인에서 다음과 같은 명령어로 이미지를 빌드할 수 있다. 이미지를 빌드할 때는 docker build 명령어를 사용하는데, Dockerfile이 위치한 디렉터리에서 다음과 같은 명령어를 실행하면 된다.</p><pre>$ docker build -t image-name .</pre><p>해당 명령어를 실행하면, Dockerfile에 작성한 순서대로 각 단계를 거쳐 이미지가 완성되는 것을 확인할 수 있다.</p><pre>$ docker build -t translator .<br>Sending build context to Docker daemon  3.723MB<br>Step 1/16 : FROM ruby:2.4.1<br> ---&gt; 3630c02d3d1b<br>Step 2/16 : ENV RAILS_ENV production<br> ---&gt; 2a12ea7c6eef<br>(중략)<br>Step 13/16 : RUN bundle install<br> ---&gt; Running in f2a52936b83d<br>Fetching gem metadata from https://rubygems.org/.........<br>(중략)<br> ---&gt; 1f57192986de<br>Step 16/16 : CMD ./bin/rails server<br> ---&gt; Running in b8b2bab7504c<br> ---&gt; dc51ead245a0<br>Removing intermediate container b8b2bab7504c<br>Successfully built dc51ead245a0<br>Successfully tagged translator:latest</pre><p>이렇게 생성된 이미지를 이용해 컨테이너를 실행하기 위해서는 docker run 명령어를 사용한다.</p><pre>$ docker run -p 8080:8080 -e SECRET_KEY_BASE=XXX translator:latest<br>=&gt; Booting Puma<br>=&gt; Rails 5.1.3 application starting in production on http://0.0.0.0:8080<br>=&gt; Run `rails server -h` for more startup options<br>Puma starting in single mode...</pre><p>앞서 설명한 -p 스위치를 이용하여 컨테이너의 80 포트를 호스트의 8080 포트에 매핑하고, -e 스위치를 이용하여 컨테이너에 환경 변수를 설정해주었다.</p><h3>Google App Engine 배포를 위한 app.yaml 작성</h3><p>이제 Google App Engine에 Translator 애플리케이션을 배포할 차례이다. Google App Engine에 배포를 위해서는 app.yaml을 작성해야 하는데, Translator 애플리케이션의 app.yaml을 보며 어떤 부분을 설정할 수 있는지 살펴보자.</p><pre>runtime: custom<br>env: flex<br><br>skip_files:<br>  - .env<br>  - tmp/<br>  - node_modules<br><br>resources:<br>  cpu: 1<br>  memory_gb: 1<br>  disk_size_gb: 10<br><br>health_check:<br>  enable_health_check: true<br>  check_interval_sec: 10<br>  timeout_sec: 5<br>  unhealthy_threshold: 2<br>  healthy_threshold: 2<br><br>automatic_scaling:<br>  min_num_instances: 1<br>  max_num_instances: 10<br>  cool_down_period_sec: 120<br>  cpu_utilization:<br>    target_utilization: 0.6<br><br>env_variables:<br>  SECRET_KEY_BASE: &#39;XXX&#39;<br>  GOOGLE_CLOUD_KEYFILE_JSON: &#39;{...}&#39;</pre><p>먼저 runtime: custom 과 env: flex 는 이 Google App Engine 애플리케이션은 Flexible Environment 에서 Custom Runtime 을 이용한다는 것을 알려준다. skip_files 의 경우에는 Google App Engine이 이미지를 빌드하기 위해 파일을 업로드할 때 업로드 하지 않아도 되는 파일을 정의할 수 있는데, Docker 이미지에 포함이 될 필요가 없거나 포함되어서는 안 되는 파일을 추가해 줄 수 있다.</p><p>다음은 <strong>resources</strong> 블록인데, 여기서 이 애플리케이션의 리소스 사용량을 정의할 수 있다. CPU 코어 갯수의 경우 1 혹은 2부터 32까지의 짝수 숫자를 사용할 수 있고, 메모리의 경우에는 (CPU 코어 수 x 0.9 - 0.4) 부터 (CPU 코어 수 x 6.5 - 0.4) 기가바이트까지 지정이 가능하다. 이 외에도 베이스 디스크의 크기나 추가적으로 마운트할 디스크의 크기를 지정할 수 있다.</p><p><strong>health_check</strong> 블록에서는 애플리케이션의 헬스 체크 조건을 설정할 수 있다. 헬스 체크를 수행할 간격과 최대 요청 시간, 그리고 애플리케이션이 사용 가능한 상태인지를 판단할 헬스 체크의 최소 갯수를 정의할 수 있다. 헬스 체크의 경우 Google App Engine에서 애플리케이션의 /_ah/health 엔드포인트로 HTTP GET 요청을 보내게 되므로, 이 엔드포인트에서 애플리케이션이 사용 가능한 상태인지를 확인하여 응답을 보내도록 코드를 작성하면 된다.</p><p>Google App Engine은 기본적으로 CPU 사용량에 따라 자동으로 인스턴스의 갯수를 늘이고 줄이는데, 이에 대한 자세한 설정을 automatic_scaling 블록에서 할 수 있다. 위 설정에서는 CPU의 사용량이 60%(0.6)를 초과하였을 때 인스턴스를 최대 10개까지 생성하도록 설정하였다. 필요한 경우 automatic_scaling 대신 manual_scaling 블록을 사용하여 인스턴스 갯수를 정의할 수도 있다.</p><p>애플리케이션 구동에 필요한 환경 변수(Environment Variable)이 있다면 env_variables 블록에 정의해줄 수 있다. 다만 환경 변수의 특성상 민감한 정보를 가지고 있을 수 있는데, 이러한 경우에는 app.yaml 을 .gitignore 파일과 같은 버전 관리 소프트웨어의 예외 목록에 추가하자.</p><h3>Google App Engine에 배포하기</h3><p>먼저 <a href="https://console.cloud.google.com">Google Cloud Platform 콘솔</a>에 접속하여, 새로운 프로젝트를 제작한다. App Engine 애플리케이션의 경우 한 프로젝트당 하나만 생성하고 배포할 수 있기 때문에, 애플리케이션 별로 프로젝트를 생성해 주어야 한다. 이 과정에서 프로젝트의 고유 ID가 할당되는데, 이 ID를 기억해 두자.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*UuREVS0X9g4yuxE7fn2Obw.png" /><figcaption>GCP 프로젝트 생성</figcaption></figure><p>다음으로 <a href="https://cloud.google.com/sdk/"><strong>Google Cloud SDK</strong></a>를 로컬 컴퓨터에 설치한다. 모든 배포 작업을 커맨드라인으로 진행하기 때문에, Google Cloud SDK의 gcloud 명령어를 많이 사용하게 된다. macOS를 사용하고 있고 컴퓨터에 Homebrew가 설치되어 있다면, brew cask install google-cloud-sdk 로도 설치가 가능하다. Google Cloud SDK를 설치한 이후에는 gcloud auth login 명령어로 인증 정보를 저장할 수 있다.</p><p>SDK 설치까지 끝마쳤으면 App Engine 애플리케이션을 생성해 줄 차례이다. 이 단계에서 App Engine 애플리케이션이 어느 리전에 배포될 지를 결정하는데, 한번 결정하면 이 프로젝트에서는 변경이 불가능하니 신중하게 결정해야 한다. 대한민국과 가장 가까운 리전은 일본 도쿄에 위치한 asia-northeast1 이므로, 대부분의 사용자는 이 리전을 사용하면 빠른 반응 속도를 기대할 수 있다. 쉘에서 다음 명령어를 실행하자.</p><pre>$ gcloud app create<br>You are creating an app for project [project-id].<br>WARNING: Creating an App Engine application for a project is irreversible and the region<br>cannot be changed. More information about regions is at<br>https://cloud.google.com/appengine/docs/locations.<br><br>Please choose the region where you want your App Engine application<br>located:<br><br> [1] us-central    (supports standard and flexible)<br> (중략)<br> [6] asia-northeast1 (supports standard and flexible)<br> (중략)<br> [9] cancel<br>Please enter your numeric choice:  6<br><br>Creating App Engine application in project [project-id] and region [asia-northeast1]....done.<br>Success! The app is now created. Please use `gcloud app deploy` to deploy your first app.</pre><p>App Engine 애플리케이션을 생성했다면 이제 Translator 애플리케이션을 배포할 차례이다! 앞서 받아온 Translator 폴더로 이동하여, gcloud app deploy 명령어로 배포를 시작하자. gcloud app deploy를 실행하면 애플리케이션의 소스 코드를 업로드하여 클라우드에서 Docker 이미지 빌드를 수행하고, 빌드된 버전을 레지스트리에 저장하고 실행한 후, 앞서 app.yaml에서 지정해 준 헬스 체크가 통과할 때 활성 버전으로 승격시킨다. 애플리케이션을 처음 배포할 때는 비교적 긴 시간이 걸릴 수 있으니, 여유를 가지고 기다리자.</p><pre>$ gcloud app deploy<br>Services to deploy:<br><br>descriptor:      [/Users/premist/dev/translator/app.yaml]<br>source:          [/Users/premist/dev/translator]<br>target project:  [sample-project-id]<br>target service:  [default]<br>target version:  [20170822t013314]<br>target url:      [https://sample-project-id.appspot.com]<br>Do you want to continue (Y/n)?  y<br>If this is your first deployment, this may take a while...done.<br>Beginning deployment of service [default]...<br>(중략)<br>Updating service [default]...done.<br>Deployed service [default] to [https://sample-project-id.appspot.com]<br><br>You can stream logs from the command line by running:<br>  $ gcloud app logs tail -s default<br><br>To view your application in the web browser run:<br>  $ gcloud app browse</pre><p>모든 과정이 완료되면 Google Cloud Platform 콘솔에서 애플리케이션이 정상적으로 배포된 것을 확인할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*e1CROGhla_FtVTA_jagMKg.png" /><figcaption>Translator 애플리케이션을 무사히 배포했다</figcaption></figure><p>https://프로젝트-ID.appspot.com 에 방문하면, Translator 애플리케이션을 문제 없이 사용할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*djZ46SuqOU3CSGpT8BduxQ.png" /></figure><p><a href="https://making.shakr.com/31cae43e4aea">이어서 읽기: 프로덕션에 Docker 사용하기</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f6b5f75c36a2" width="1" height="1"><hr><p><a href="https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-google-app-engine%EC%97%90-docker-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC%ED%95%98%EA%B8%B0-f6b5f75c36a2">멋진 신세계, 컨테이너: Google App Engine에 Docker 애플리케이션 배포하기</a> was originally published in <a href="https://making.shakr.com">Making Shakr</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[멋진 신세계,  컨테이너: Docker를 소개합니다]]></title>
            <link>https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-docker%EB%A5%BC-%EC%86%8C%EA%B0%9C%ED%95%A9%EB%8B%88%EB%8B%A4-25341989e986?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/25341989e986</guid>
            <category><![CDATA[devops]]></category>
            <category><![CDATA[korean]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[containers]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Mon, 20 Nov 2017 03:27:13 GMT</pubDate>
            <atom:updated>2018-05-13T10:13:42.912Z</atom:updated>
            <content:encoded><![CDATA[<h3>멋진 신세계, 컨테이너: Docker를 소개합니다</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PsecxPuZQn0kVxC04OPU8Q.jpeg" /></figure><p><a href="http://www.imaso.co.kr/archives/248">마이크로소프트웨어 390호, &lt;오픈의 꿈&gt;</a>에 투고한 글을 옮겼습니다.</p><ul><li><strong>Docker를 소개합니다</strong></li><li><a href="https://making.shakr.com/f6b5f75c36a2">Google App Engine에 Docker 애플리케이션 배포하기</a></li><li><a href="https://making.shakr.com/31cae43e4aea">프로덕션에 Docker 사용하기</a></li></ul><p>2008년, Amazon이 가상머신 호스팅 서비스인 Elastic Compute Cloud (EC2)를 정식으로 공개하였다. 절대적인 컴퓨팅 성능으로는 온프레미스 서버보다 비싼 비용을 주어야 하지만, 필요에 따라 즉시 스케일이 가능하고, 서비스를 만들기 위한 서비스들이 준비되어 있고, 이를 API를 통해 서로 연결할 수 있다는 점은 엔지니어를 사로잡기 충분했다. 기존에 서버를 관리하고 웹 애플리케이션을 배포하는 전통적인 방식에서 이러한 IaaS 기반의 인프라 구축 서비스로 이전하는 기업이 빠르게 늘어갔고, 새로 비즈니스를 시작하는 스타트업은 클라우드에서 웹 애플리케이션을 구동하는 것을 전제로 계획을 세우는 방식이 정착하기 시작했다.</p><p>시간이 흘러 2017년 현재, 가상머신을 이어 클라우드 환경에서 새로운 컴퓨팅 단위가 될 기술로 컨테이너가 주목받고 있다. Amazon, Microsoft, Google, IBM 등 주요 클라우드 제공자는 이미 컨테이너를 프로덕션 환경에서 구동할 수 있는 서비스를 제공하고 있고, Docker Swarm이나 Kubernetes, Marathon 등 컨테이너 기반으로 애플리케이션을 배포하고 운영할 수 있는 오픈소스 소프트웨어도 활발하게 개발되고 있다. Right Scale의 조사에 따르면 <a href="https://www.rightscale.com/lp/state-of-the-cloud">DevOps 도구 중 Docker의 사용률이 Chef, Puppet, Ansible을 앞지르고 1위</a>를 차지했는데, 이에서 볼 수 있듯이 컨테이너를 개발 워크플로우에 도입하는 기업이 점점 많아지고 있다.</p><p>‘멋진 신세계, 컨테이너’ 시리즈에서는 이렇게 활발한 생태계 성장과 실제 사용이 이루어지고 있는 컨테이너에 대해서 같이 알아보고, 컨테이너를 개발 프로젝트에서 어떻게 활용할 수 있는지, 그리고 컨테이너 기반 웹 애플리케이션을 프로덕션 환경에 배포할 때 유의해야 할 점을 소개하고자 한다.</p><h4>컨테이너의 역사 그리고 Docker</h4><p>한 컴퓨터 내에서 자원을 효과적이고 안전하게 격리하기 위한 시도는 꽤 오래 전으로 거슬러 올라간다. 1979년, Unix V7에서 처음 등장한 chroot 시스템 호출은 현재 실행 중인 프로세스와 자식 프로세스가 접근할 수 있는 루트 디렉터리를 특정 디렉터리로 변경하고, 해당 디렉터리 상위의 디렉터리는 수정하지 못하도록 하였다. 2000년에는 FreeBSD에 chroot의 개념이 jail이라는 기능으로 추가되었고, jail을 통해 격리된 시스템마다 IP 주소와 설정을 할당할 수 있는 기능을 제공하였다. 2004년에는 오라클이 Solaris Zone을 발표했고, 2005년에는 Linux 커널을 패치하여 리소스 격리를 구현한 OpenVZ 프로젝트가 등장했다.</p><p>2007년, 구글이 내부적인 사용을 위해 <strong>Process Containers</strong>를 발표했고, 이 기능은 Control Groups (<strong>cgroups</strong>) 라는 이름으로 리눅스 커널에 추가되었다. 이 cgroups를 이용하여 만들어진 것이 <strong>LXC(Linux Containers)</strong>인데, 커널에 이미 존재하는 네임스페이스 관련 여러 기능을 활용하여 각 환경을 격리하는 기능을 제공하였다.</p><p>2013년 초, dotCloud가 새로운 컨테이너 엔진 Docker를 오픈 소스로 공개하였다. Docker를 제작한 회사인 dotCloud는 기존에는 Heroku나 Google App Engine과 같은 PaaS를 제작하던 회사였지만, 성장세와 유명세에 힘입어 Docker에 집중하기로 결정하고 사명을 Docker Inc.로 바꾸고 PaaS 비즈니스를 매각하였다.</p><p>Docker의 경우에도 초기 개발 단계에서는 LXC를 이용하여 자원 격리를 구현했지만, 1.0 버전 공개를 하기 전에 Go로 제작된 오픈 소스 컨테이너 라이브러리인 libcontainer를 개발하여 사용하고 있다.</p><p>현재 구동되는 컨테이너 시스템의 대부분은 Docker를 사용하고 있으며, CoreOS사에서 제작한 <a href="https://coreos.com/rkt/">rkt 컨테이너 엔진</a>을 사용하기도 한다.</p><h4>환경 구축의 해결사</h4><p>개발자라면 환경 구축에 대해 고민하던 적이 한두 번 이상은 있을 것이다. 새로 팀에 합류한 팀원에게 개발 환경을 구축해주려고 할 때 생길 수 있는 고민부터, 프로덕션 서버에 특정 패키지가 설치되어 있지 않아 오류가 발생하는 경우까지, 개발할 당시에는 간과하기 쉬운 요소가 나중에 발목을 잡는 경우도 많다.</p><p>개발 단계에서의 환경 구성을 도와주는 툴의 대표적인 예로는 <a href="http://vagrantup.com/">Vagrant</a>가 있는데, 기본적으로는 VM을 사용하여 환경을 관리하기 때문에 VM 내부에서 어떤 것이 바뀌었는지 추적하기 어렵고, 커널을 포함한 운영체제의 구성 요소를 모두 담고 있어 이미지의 용량이 굉장히 크고, Virtualbox와 같은 VM 하이퍼바이저를 설치해야 한다.</p><p>배포 단계에서는 <a href="https://www.chef.io/">Chef</a>, <a href="https://puppetlabs.com/">Puppet</a>, <a href="https://www.ansible.com/">Ansible</a>까지 환경을 구성하기 위핸 단계를 코드로 작성하는 다양한 도구가 나와 있다. 이러한 도구의 경우 환경을 프로비저닝할 때 각각의 단계가 실행되기 때문에 오랜 시간이 지난 후에도 해당 환경을 동일하게 복제해낸다는 보장이 없고, 환경 외부에 제어를 위한 별도의 서버를 두어 관리를 해야 한다. 또한 여러 환경에 대응해야 하기 때문에 운영체제의 기능을 아우를 수 있는 고수준의 추상화를 필요로 해서, 내장되어 있는 모듈을 사용하는 등 간단한 작업시에는 불편함을 느끼지 않을 수는 있어도 복잡한 작업을 하기 시작할수록 서버의 형상 관리에 신경을 많이 써야 한다.</p><p>반면 Docker는 이미지를 생성하기 위한 각 단계를 <strong>Dockerfile</strong>이라는 규격으로 관리한다. Dockerfile 안에 기반 이미지와 애플리케이션과 의존성을 설치하기 위한 단계를 순차적으로 기술할 수 있으며, 이렇게 기술한 단계는 컨테이너 이미지를 빌드할 때 실행되고 단계별 결과는 캐시에 보관되어 추후 동일한 이미지를 빌드할 때 반복된 작업을 줄여준다. 또한 호스트 운영체제의 커널을 공유하면서 각 운영체제의 자원 격리 기술을 이용하는데, Linux의 경우에는 cgroups와 네임스페이스, Windows의 경우에는 Job Objects를 사용하여 낭비되는 리소스를 최대한 줄인다.</p><p>꽤 오래 전 Shakr에서 가상 서버 여러 대를 운영하고 있었을 때, 각 서버의 libcurl 버전에 차이가 있어 애플리케이션 엔드포인트가 동작하는 방식이 서버에 따라 달라져 디버깅에 애를 먹은 적이 있다. 중간에 호스트의 운영체제와 라이브러리 버전에 관련 없이 격리된 환경 안에서 사용자가 지정한 라이브러리와 함께 애플리케이션을 구동함으로써, 미연에 생길 수 있는 호스트간 환경 불일치를 막을 수 있다. 또한 프로덕션 환경과 동일한 환경을 개발 환경에서도 재현할 수 있어, 보다 예외가 적은 디버깅을 할 수 있다.</p><p>초기 Docker가 출시되었을 때는 AUFS와 같은 리눅스 커널에 내장되지 않은 파일시스템 형식을 사용하여 설치하는 과정이 매우 복잡했지만, 이후 btrfs나 overlayfs, devicemapper 등 여러 저장소 드라이버를 지원하게 되어 대부분의 Linux 시스템에 간단하게 설치하고 애플리케이션을 배포할 수 있다.</p><h3>References</h3><ul><li><a href="https://content.pivotal.io/infographics/moments-in-container-history">Pivotal: Moments in Container History</a></li><li><a href="https://www.kernel.org/doc/ols/2007/ols2007v2-pages-45-58.pdf">Google Inc: Adding Generic Process Containers to the Linux Kernel</a></li></ul><p><a href="https://making.shakr.com/f6b5f75c36a2">이어서 읽기: Google App Engine에 Docker 애플리케이션 배포하기</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=25341989e986" width="1" height="1"><hr><p><a href="https://making.shakr.com/%EB%A9%8B%EC%A7%84-%EC%8B%A0%EC%84%B8%EA%B3%84-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-docker%EB%A5%BC-%EC%86%8C%EA%B0%9C%ED%95%A9%EB%8B%88%EB%8B%A4-25341989e986">멋진 신세계,  컨테이너: Docker를 소개합니다</a> was originally published in <a href="https://making.shakr.com">Making Shakr</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WeWork, 1년 후]]></title>
            <link>https://medium.com/si-mpli-st-blog/wework-1%EB%85%84-%ED%9B%84-a1ba9c865a01?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/a1ba9c865a01</guid>
            <category><![CDATA[coworking-space]]></category>
            <category><![CDATA[office]]></category>
            <category><![CDATA[coworking]]></category>
            <category><![CDATA[wework]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Mon, 09 Oct 2017 08:44:00 GMT</pubDate>
            <atom:updated>2017-11-19T07:27:23.718Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://www.shakr.com/">Shakr</a>는 이사를 정말 많이 경험한 회사다. 내가 팀에 합류하기 전에는 지금은 사라진 KT 에코노베이션 센터 모란점에 있다가 내가 합류할 즈음에 강남역 근처의 오피스텔 건물로 이사를 했다. 어느 정도 인원이 많아지고 더이상 입주해 있던 사무실로는 감당하기 어려울 규모가 되었을 때 선정릉역 근처의 사무실로 한번 더 이사를 했는데, 어느 정도 정착되었다고 생각했을 때 임대를 비롯한 여러 가지 사정으로 다시 이사를 하게 되었다. 이사를 많이 한 만큼 다음에 이사가는 곳에는 오래 정착하고 싶어서 어느 곳으로 이사를 할 지에 대한 고민을 많이 했는데, 수도권 각지에서의 접근성과 사무실의 면적 및 편의성 등을 생각하다보니 결정을 내리기가 쉽지 않았다.</p><h3>입주를 결정하다</h3><p>고민을 거듭하던 중 작년 3월경 국내 언론에 미국의 공유 사무실 기업인 <a href="http://biz.chosun.com/site/data/html_dir/2016/01/13/2016011303531.html">WeWork</a>가 들어온다는 <a href="http://biz.chosun.com/site/data/html_dir/2016/01/13/2016011303531.html">기사</a>가 실렸고, 호기심에 연락을 해 보게 되었다. 입주 시기나 사무실의 위치가 아직은 확정되지 않아서 어느 정도 시간이 흐른 후 답장을 받았는데, 8월 1일에 국내 첫 번째 WeWork인 강남역점에 입주할 것을 제안하는 내용이었다. 공유 사무실에 대한 궁금증과 약간의 걱정이 있었기에 여러 번 질문과 답변을 주고받았고, 마침내 WeWork에 입주하기로 결정하였다. 그 당시 있던 건물의 임대 계약이 만료되는 시점과 WeWork 강남역점의 오픈일과 2주 정도의 차이가 있었는데, 이 동안은 <a href="http://www.fastfive.co.kr/seocho/">패스트파이브 서초점</a>을 단기 임대하여 사용하였다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*6_uFZ0bLevA0241v.jpg" /><figcaption>작년 7월, WeWork 강남점의 오픈을 알리는 팻말</figcaption></figure><h3>WeWork</h3><p>WeWork은 뉴욕에서 시작하여 빠르게 확장하고 있는 공유 사무실 업체다. 여러 기업들이 시내 중심가 건물들을 직접 임대하려면 살인적인 임대료를 지불해야 하는데, 이를 WeWork가 지불하고 공간을 나눠 공용 사무실을 제공해주는 방식으로 가격을 낮춰 스타트업과 여러 기업에 공급한다. 모든 지점의 인테리어를 본사에서 관리 감독하기 때문에 WeWork 사무실은 유명 대기업에 견줄 정도로 멋진 인테리어를 가지고 있으며, 단순한 공간 임대에 그치지 않고 사무실에 필요한 각종 비품 및 시설을 제공한다. 같은 내 기업들의 교류를 도와주는 여러 가지 이벤트를 운영한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*63uwCmstj3XLjJak.jpg" /><figcaption>WeWork 삼성점의 라운지</figcaption></figure><p>입주 전 WeWork을 고려하게 된 가장 큰 이유는 바로 기업 입장에서 관리할 것이 적어진다는 점이었다. 이전에 입주해 있던 건물의 경우에는 에이컨에서 물이 새는 문제부터 시작하여 엘리베이터 운영 시간, 임대료 관련 협상까지 신경 써야 할 부분이 정말 많아서, 이따금씩 생기는 문제로 인해 분위기가 산만해지고 일에 집중할 수 없던 적이 종종 있었다. 또한 사무실 외에도 작게는 책상부터 커피와 음료수, 책상까지 필요한 비품의 구입을 직접 해야 했는데, 매달 잊지 않고 커피 캡슐을 주문하는 것도 작아 보이지만 꽤나 귀찮은 일이었다. 당시에 쓰고 있던 기업용 네스프레소 머신용 캡슐을 구입하기 위해서는 Active X를 설치할 수 있는 윈도 가상 머신을 켜야 했다..</p><p>WeWork에서는 커피와 맥주(!)를 무제한 제공하고, 복사기도 각 층마다 설치되어 있어 인터넷으로 문서 프린트가 가능하다. 인터넷의 경우에도 기본적으로 유무선 연결이 가능하며, 공인 IP나 서버 랙이 필요한 경우 CM(Community Management)팀에 요청하면 테크니션의 도움을 받아 구성할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PHQzzhjGd_9_CU_H.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*hmF90zRn8gxoclk6.jpg" /><figcaption>키친에 준비되어 있는 맥주 탭. 각 층마다 맥주 종류가 다른데, 아쉽게도 우리 층은 OB다..</figcaption></figure><h3>WeWork 내부 톺아보기</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*M2ou07Kcx1x-gAW0.jpg" /></figure><p>WeWork에 입주를 하면 키카드를 받게 되는데, 이 키카드로 자신이 소속한 지점에 24시간 출입할 수 있다. 뿐만 아니라 다른 WeWork 지점을 이용할 때도 이 키카드를 사용할 수 있는데, 다른 지점의 일일 사용 예약을 한 후 자신이 가지고 있는 키카드를 사용하면 해당 지점에 자유롭게 출입하여 작업 공간을 사용할 수 있다. 올해 초 Google Cloud 컨퍼런스 참여를 위해 샌프란시스코에 방문했을 때도 잠시 집중해서 일을 할 수 있는 공간이 필요했는데, 근처에 있는 <a href="https://www.wework.com/buildings/soma--sf-bay-area--CA">WeWork SOMA</a>에 방문하여 작업을 할 수 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*FTvVPQOnbMr0KCbF.jpg" /></figure><p>엘리베이터 로비에는 디스플레이가 설치되어 있다. 보통의 건물이라면 입주사의 목록이 나열되어 있는 디렉터리가 있겠지만, WeWork의 경우에는 개인으로 입주하여 있는 경우도 있고, 입주사의 수가 워낙 많을 뿐더러 주기적으로 입주사가 바뀌기 때문에 디스플레이를 설치해 둔 것 같다. WeWork에 입주한 회사와 멤버를 무작위로 보여주며, 이번 주에 예정되어 있는 커뮤니티 이벤트나 WeWork 인스타그램 계정의 사진을 소개해준다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DwptycGnrF_wuG1a.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*SY2-wkm2YonTyMim.jpg" /></figure><p>WeWork에 처음 방문하게 되면 오게 되는 곳은 바로 라운지. 내가 입주해 있는 강남점의 경우에는 WeWork 층 중에서는 가장 높은 18층에 라운지가 있는데, 리셉션 데스크 또한 이 곳에 위치해 있다. 게스트가 방문할 일이 있는 경우에는 스마트폰 앱으로 게스트 등록을 해 두면, 리셉션에서 게스트의 등록을 도와주고 문자 메시지로 도착 여부를 보내준다. 또한 우편 보관함이 있어 리셉션을 통해 택배를 수령할 수 있다.</p><p>공용 공간의 경우 자유롭게 이용할 수 있는데, 다른 WeWork 지점을 방문했을 때 이용하게 되는 공간도 바로 이 라운지 공간이다. 이벤트가 진행되는 날에는 라운지 공간이 여유있는 이벤트 홀로 변신하는데, Shakr도 이 곳에서 여러 번 세미나를 진행했다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*43zzLs5-H5wKQW2c.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*VsLWfp1DBNeiXdxv.jpg" /></figure><p>각 층에도 작은 공용 공간과 더불어 주방이 마련되어 있다. 사무실이 너무 답답하게 느껴진다면 이 공간에서 작업을 하고, 식사를 배달해 먹는 경우에도 이 공간을 주로 이용한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*A3RsTfWiYPyD76gK.jpg" /></figure><p>각 사무실은 사무실 간의 벽을 투명한 유리 소재를 사용하여 개방감이 느껴지는데, 어느 정도의 프라이버시를 보호하기 위해 눈높이까지는 반투명 코팅이 되어 있다. 처음 사무실에 입주했을때는 복도를 지나가는 사람들이 많이 의식되었지만, 지금은 어느정도 적응이 되어 크게 신경쓰이지 않게 되었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*h51iB-JOxE4O_Tpe.jpg" /></figure><p>층마다 있는 작은 방에는 복합기와 파쇄함, 절단기와 같은 인쇄와 관련된 여러 도구가 구비되어 있다. 입주한 기업에게는 매달 사무실 크기에 비례하여 크레딧이 주어지는데, 크레딧을 사용하여 출력이 가능하다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*fYYvVKrvSP5sTP6D.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*5-KNK_M-M2YKwwkY.jpg" /></figure><p>3인부터 10인까지 다양한 인원을 수용할 수 있는 회의실이 각 층마다 있어, 크레딧으로 예약 후 사용이 가능하다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ym8i4RT7XcpSrYri.jpg" /></figure><p>통화를 위해서 회의실을 대여하자니 너무 크고, 혼자만의 조용한 공간이 필요한 경우가 있을 때는 폰부스를 사용한다. 화상 회의가 있을 때나 전화를 받을 일이 있을 때 사용하며, 한 층에 2개밖에 없다보니 사용을 위한 경쟁(?)이 치열한 편이다.</p><h3>1년 후 느낀 점</h3><p>입주한 후 일주일 쯤 지났을 무렵, 저녁을 먹던 중 사무실에 대한 이야기를 한 적이 있다.</p><blockquote><strong><em>Minku:</em></strong><em> 그래서 WeWork에 입주한 지 벌써 일주일 정도가 지났는데, 지금까지의 인상은 다들 어떠신가요? <br> </em><strong><em>Anton:</em></strong><em> 아직까지는 좋은데, 한 일년 정도 지나봐야 제대로 알겠죠?</em></blockquote><p>안톤 말대로 1년 넘게 WeWork에서 지내고 나니, 공용 사무실에서의 생활도 익숙해졌고 WeWork 첫 지점인만큼 정착하면서 생겼던 혼란스러웠던 점도 많이 해결되었다. 그동안 느낀 점 중 몇 가지를 공유해 보려고 하는데, 아쉬웠던 점을 먼저 소개한다.</p><p><strong>냉난방:</strong> WeWork가 거대한 임대인이긴 하지만 건물주의 벽은 높을 수 밖에 없다는 것을 깨닫게 해 준, 유일하게 아쉬웠던 점이다. 3월에서 5월 사이 환절기에는 햇빛이 직접적으로 내리쬐는 사무실에 입주해 있다 보니 실내 온도가 불쾌할 정도로 올라간 적이 있는데, 건물의 정책상 아직 냉방이 가능하지 않을 때라서 굉장히 더운 나날을 보냈다. 약간 죄송스러운 느낌이 들 정도로 고객 지원 시스템을 통해 티켓을 보내고 여러 번 논의해 보았지만, 뾰족한 해결책은 나오지 않았고 결국 에어컨이 나오는 기간까지 몇 개월을 버텨야 했다. 잠깐동안 있었던 패스트파이브 서초점의 경우 모든 사무실에 직접 온도 조절이 가능한 냉난방기가 설치되어 있는 것과는 대조되어 아쉬운데, 강남점 외 다른 지점의 상황은 어떤지 궁금하다.</p><p>하지만 냉난방이 거의 유일한 아쉬운 점이라고 할 정도로 마음에 드는 점이 많다.</p><p><strong>멋진 인테리어:</strong> 이전 사무실에서는 저비용으로 간단한 인테리어만 했던 터라 더욱 멋진 인테리어에 매료되었다. 사무실을 실제로 소유하고 있지 않다면 인테리어에 비용을 쓰기가 아무래도 힘든 것이 사실인데, WeWork의 경우에는 초기 인테리어가 워낙 잘 되어 있고 목재 재질의 책상 등 멋진 소품들이 마련되어 있어 인테리어에 대한 고민을 덜 수 있었다. 사무실에 방문할 일이 있어 찾아온 손님이나 화상 대화로 연결한 파트너가 카메라를 통해 보여지는 멋진 인테리어에 놀라는 것은 덤.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*kuo9f2y3CV68IREx.jpg" /><figcaption>형광등이 아닌 따뜻한 조명이 비치는 복도는 언제 봐도 기분이 좋다.</figcaption></figure><p><strong>배경 음악:</strong> 소소한 점일지도 모르겠지만 전용 사무실을 제외한 여러 공간에서 나오는 취향 저격 배경음악이 정말 마음에 든다. 신기하게도 Spotify에서 추천해주는 나의 <a href="https://www.spotify.com/int/discoverweekly/">Discover Weekly</a> 플레이리스트와 음악 성격이 정말 비슷한데, 덕분에 화장실에 갈 때마다 Shazam 앱을 켜서 지금 재생 중인 음악을 찾아보는 경우가 정말 많다. 배경 음악이 없을 때는 느끼지 못했지만, WeWork에 와서 가장 좋았던 점 중 하나로 꼽을 정도로 분위기에 큰 변화를 가져와 주었다.</p><style>body[data-twttr-rendered="true"] {background-color: transparent;}.twitter-tweet {margin: auto !important;}</style><blockquote class="twitter-tweet" data-conversation="none" data-align="center" data-dnt="true"><p>Does <a href="http://twitter.com/WeWork" target="_blank" title="Twitter profile for @WeWork">@WeWork</a> have a playlist of their loo jams on <a href="http://twitter.com/Spotify" target="_blank" title="Twitter profile for @Spotify">@Spotify</a>? I literally <a href="http://twitter.com/Shazam" target="_blank" title="Twitter profile for @Shazam">@Shazam</a> a song every time I&#39;m in the bathroom at the office.</p><p>&#x200a;&mdash;&#x200a;<a href="https://twitter.com/kundrela/status/579145053467205632">@kundrela</a></p></blockquote><script src="//platform.twitter.com/widgets.js" charset="utf-8"></script><script>function notifyResize(height) {height = height ? height : document.documentElement.offsetHeight; var resized = false; if (window.donkey && donkey.resize) {donkey.resize(height); resized = true;}if (parent && parent._resizeIframe) {var obj = {iframe: window.frameElement, height: height}; parent._resizeIframe(obj); resized = true;}if (window.location && window.location.hash === "#amp=1" && window.parent && window.parent.postMessage) {window.parent.postMessage({sentinel: "amp", type: "embed-size", height: height}, "*");}if (window.webkit && window.webkit.messageHandlers && window.webkit.messageHandlers.resize) {window.webkit.messageHandlers.resize.postMessage(height); resized = true;}return resized;}twttr.events.bind('rendered', function (event) {notifyResize();}); twttr.events.bind('resize', function (event) {notifyResize();});</script><script>if (parent && parent._resizeIframe) {var maxWidth = parseInt(window.frameElement.getAttribute("width")); if ( 500  < maxWidth) {window.frameElement.setAttribute("width", "500");}}</script><p><strong>유연함:</strong> 출장을 갔을 때 다른 WeWork 지점에서 미팅을 하고 근무를 하거나, 필요한 경우 같은 층의 다른 사무실을 빌려 유연하게 확장을 할 수 있다는 점 또한 매력적이다. Shakr의 경우 20인실로 시작하였지만 인원을 충원하면서 8인실을 추가적으로 사용 중인데, 일반적인 사무실을 이용했다면 쉽게 확장이 불가능했을 것이다.</p><p><strong>매주 진행되는 여러 이벤트:</strong> 입주하고 며칠간 라운지에서 진행되는 이벤트를 보면서 얼마 가지 못하겠다는 생각을 했지만, 1년이 지난 지금까지도 매주 활발하게 이벤트가 진행되고 있다. 월요일에 WeWork에서 직접 진행하는 TGIM(Thank God It’s Monday의 약자) 아침 식사 이벤트부터 여러 기업들이 참여하는 리크루팅 이벤트, 그리고 Google 등 외부 기업에서 주최하는 기술이나 디자인 관련 행사까지 다양한 행사가 열리고 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*iODgg6F4SnE8Y7pZ.jpg" /><figcaption>작년 11월에 열린 을지로점 런칭 기념 파티에 마련된 보드카 바</figcaption></figure><p><strong>앱에 내장되어 있는 고객 지원 시스템:</strong> WeWork 앱을 사용하여 CM팀에 고객 지원 메시지를 보낼 수 있는데, 이를 이용하면 리셉션 데스크에 가지 않고도 필요한 사항을 건의하거나 불편한 사항을 제보할 수 있다. Shakr의 경우에는 공인 IP와 VLAN을 설치하여 사용하고 있는데, 이러한 네트워크 관련 설치를 문의할 때도 고객 지원 메시지를 통해 간단하게 요청이 가능하다.</p><h3>링크</h3><ul><li><a href="https://refer.wework.com/i/premist">WeWork에서 일하기 (리퍼러 링크)</a></li><li><a href="https://www.wework.com/buildings/gangnam-station--seoul">WeWork 강남역점</a></li><li><a href="https://www.businessinsider.com/working-in-a-wework-2016-7/">Business Insider — WeWork에서 일한다는 것은 이렇습니다 (영문)</a></li></ul><p><em>본 글은 별도의 금전적 지원 없이 작성한 리뷰입니다. 사진은 모두 직접 촬영하였으며, 외부 사용을 허가하지 않습니다.</em></p><p><em>Originally published at </em><a href="https://si.mpli.st/review/wework-a-year-later.html"><em>si.mpli.st</em></a><em> on October 9, 2017.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a1ba9c865a01" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/wework-1%EB%85%84-%ED%9B%84-a1ba9c865a01">WeWork, 1년 후</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[오픈소스 시스템 모니터링 에이전트, Telegraf]]></title>
            <link>https://medium.com/si-mpli-st-blog/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-telegraf-1b52f1985853?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/1b52f1985853</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[ops]]></category>
            <category><![CDATA[devops]]></category>
            <category><![CDATA[open-source]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Sun, 10 Sep 2017 13:41:00 GMT</pubDate>
            <atom:updated>2017-11-19T07:23:58.666Z</atom:updated>
            <content:encoded><![CDATA[<p>서버의 댓수와 상관 없이 프로덕션 환경에서 구동하고 있는 서버가 있다면 모니터링은 반드시 필요하다. 호스팅 업체를 비롯해 여러 기업들에서도 이러한 이유로 <a href="https://oss.oetiker.ch/rrdtool/">RRDTool</a>이나 <a href="https://www.nagios.org/">Nagios</a>를 이용하여 서버의 리소스 사용량 지표를 수집하고 그래프를 출력하여 시스템의 사용량을 모니터링한다.</p><p>최근에는 애플리케이션을 구성하는 여러 구성 요소(웹 서버, 데이터베이스, 로드 밸런서)에서 유의미한 정보를 수집하기 위해서 시계열 지표(Time series metric)을 <a href="https://github.com/etsy/statsd">StatsD</a>와 같은 데몬을 통해 수집하거나, 아니면 애플리케이션에서 출력하는 로그에서 <a href="https://www.elastic.co/products/logstash">Logstash</a>와 같은 로그 정제 도구를 통해 시계열 지표를 생성한다. 이렇게 만들어진 시계열 지표 자료는 <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a>나 <a href="https://www.influxdata.com/time-series-platform/influxdb/">InfluxDB</a>와 같은 데이터베이스에 저장하고, <a href="https://grafana.com/">Grafana</a>나 <a href="https://www.elastic.co/products/kibana">Kibana</a> 와 같은 도구로 시각화한다.</p><p><a href="https://www.shakr.com/">Shakr</a>에서도 시스템 모니터링과 시계열 지표 수집을 하고 있는데, 시스템의 규모에 비해 운영을 할 수 있는 팀원의 수가 매우 적어서 여러 솔루션을 직접 이어 시스템을 구축하는 것이 아니라 SaaS 솔루션인 <a href="http://datadoghq.com/">Datadog</a>을 이용해 서버를 관리하고 시계열 지표를 수집하고 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*I1hvYqESpjAeH6e5NgI60g.png" /><figcaption>수집, 저장, 시각화 소프트웨어</figcaption></figure><p>이 글에서는 조금 생소할 수도 있는 에이전트, <a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a>를 소개하고자 한다.</p><p><strong>Telegraf</strong>는 InfluxDB의 제작사, InfluxDB에서 제작한 시스템 모니터링 및 지표 수집 에이전트이다. 플러그인 시스템을 기반으로 제작되어 여러 소프트웨어 혹은 서비스를 위한 지원을 간단하게 추가할 수 있고, InfluxDB나 ElasticSearch와 같은 다양한 백엔드로 수집한 데이터를 전송할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*e_AQQh5x-N14g-14mxOfAA.png" /><figcaption>다른 에이전트와의 비교</figcaption></figure><p>개인적으로 보유하고 있는 여러 시스템을 관리할 수 있는 에이전트를 찾고 있었는데, 여러 에이전트 중에서도 Telegraf가 마음에 들었던 점들은 다음과 같다.</p><ul><li><strong>단일 바이너리로 배포 가능:</strong> Go 언어로 제작되었기 때문에 별도의 의존성 설치 없이 단일 바이너리만으로 모든 시스템에 배포 및 실행이 가능하다.</li><li><strong>표준 StatsD 프로토콜 지원:</strong> Telegraf의 지원 여부와 상관 없이 지표를 직접 생성할 수 있기 때문에 직접 제작한 애플리케이션에서도 지표를 수집할 수 있다.</li><li><strong>다양한 연동 기능 내장:</strong> 별도의 플러그인을 설치할 필요 없이 HAProxy, Kubernetes, NGINX, PostgreSQL와 같은 애플리케이션과의 연동을 지원한다.</li><li><strong>시스템 모니터링 지원:</strong> StatsD를 사용하여 시스템 모니터링을 하려면 <a href="https://github.com/statsd/system">StatsD System</a>과 같은 플러그인을 설치해야 하는데, Telegraf를 사용하면 별도의 플러그인 없이 CPU나 메모리 사용량과 같은 시스템 지표를 수집할 수 있다.</li></ul><p>Telegraf의 장점을 알아보았으니 사용을 위해 설치해보도록 하자. <a href="https://docs.influxdata.com/telegraf/v1.4/introduction/installation/">InfluxData 사이트</a>에서 각 운영체제를 위한 설치 방법을 자세하게 설명하고 있고, 원한다면 패키지나 바이너리를 <a href="https://github.com/influxdata/telegraf/releases">릴리즈 페이지</a>에서 직접 다운로드할 수도 있다. 내가 Telegraf를 설치하고자 하는 시스템은 Arch Linux를 구동하고 있어, AUR에 등록되어 있는 <a href="https://aur.archlinux.org/packages/telegraf-bin/">telegraf-bin</a> 패키지를 설치하였다.</p><p><a href="https://asciinema.org/a/Dr9ilYbYuNTEfwlwE42KlFyiW">Installing telegraf on Arch Linux</a></p><p>Telegraf를 설치하였다면 이제 설정 파일을 살펴볼 차례이다.</p><pre>[global_tags]<br>  datacenter = &quot;linode-tyo2&quot;<br>  type = &quot;vm&quot;<br><br>[agent]<br>  interval = &quot;10s&quot;<br>  round_interval = true<br>  metric_batch_size = 1000<br>  metric_buffer_limit = 10000<br>  connection_jitter = &quot;1s&quot;<br>  flush_interval = &quot;10s&quot;<br>  flush_jitter = &quot;1s&quot;<br><br>[[outputs.influxdb]]<br>  urls = [&quot;http://localhost:8086&quot;]<br>  database = &quot;telegraf&quot;<br>  retention_policy = &quot;&quot;<br>  write_consistency = &quot;any&quot;<br>  timeout = &quot;5s&quot;<br><br>[[inputs.cpu]]<br>  percpu = true<br>  totalcpu = true<br>  collect_cpu_time = false<br><br>[[inputs.disk]]<br>  ignore_fs = [&quot;tmpfs&quot;, &quot;devtmpfs&quot;, &quot;devfs&quot;]<br><br>[[inputs.diskio]]<br><br>[[inputs.kernel]]<br><br>[[inputs.mem]]<br><br>[[inputs.processes]]<br><br>[[inputs.swap]]<br><br>[[inputs.system]]<br><br>[[inputs.postgresql]]<br>  address = &quot;postgres://test:pass@localhost/db?sslmode=disable&quot;<br>  databases = [&quot;db&quot;]</pre><p><strong>global_tags</strong> 항목에서는 모든 지표에 추가될 태그를 정의한다. 예제에서는 datacenter와 type 태그를 추가해주어 해당 인스턴스의 위치와 종류를 알 수 있도록 설정했다.</p><p><strong>agent</strong> 항목에서는 에이전트의 기본 동작 방식을 정의한다. 지표를 얼마나 자주 지정된 output으로 전송할지, <a href="https://www.awsarchitectureblog.com/2015/03/backoff.html">jitter</a>는 얼마나 줄 지를 설정한다.</p><p><strong>outputs</strong> 항목을 이용하여 수집된 지표를 어디로 보낼지를 정의한다. 예제에서는 로컬에 존재하는 InfluxDB로 전송하도록 설정하였는데, outputs.datadog이나 outputs.kafka 등 다양한 출력을 정의할 수 있다.</p><p><strong>inputs</strong> 항목을 사용하여 어떤 지표를 수집할지 정의한다. 예제에서는 기본적인 시스템 리소스 사용량과 PostgreSQL 데이터베이스 통계를 수집하도록 설정했다.</p><p>예제에서는 사용하지 않았지만, <strong>aggregator</strong>와 <strong>processor</strong>를 이용하여 수집한 지표를 변환할 수 있다. 자세한 정보는 <a href="https://docs.influxdata.com/telegraf/v1.4/concepts/aggregator_processor_plugins/">관련 문서</a>를 참고하자.</p><p>앞서 살펴본 것처럼 지표를 시각화할 때 여러 가지 소프트웨어를 사용할 수 있는데, InfluxDB에 저장된 지표를 시각화할 수 있는 대표적인 도구로는 <a href="https://grafana.com/">Grafana</a>와 <a href="https://www.influxdata.com/time-series-platform/chronograf/">Chronograf</a>가 있다. Grafana의 경우 초기에는 Elasticsearch와 함께 사용이 가능한 Kibana처럼 Graphite와 같이 사용하도록 제작되었지만, 현재는 InfluxDB 뿐만 아니라 매우 다양한 데이터 소스를 지원한다. Chronograf의 경우 Telegraf와 마찬가지로 InfluxData가 제작하였으며, 커뮤니티는 Grafana에 비해 작지만 간단하게 사용하기에는 큰 문제가 없다.</p><p>Grafana를 시스템에서 간단하게 구동하려면, Docker 이미지를 사용하는 것이 가장 간편하다. 다음과 같은 명령어로 Grafana를 실행하자.</p><pre>docker run -p 3000:3000 -d grafana/grafana</pre><p>실행이 완료되었으면 브라우저로 localhost:3000에 방문하여 Grafana를 사용할 수 있다. 위 Docker 이미지로 생성된 Grafana의 기본 사용자 정보인 admin/admin로 접속하여, InfluxDB 데이터 소스를 추가해준다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*_Pc1UxLj1G2ICqLD.jpg" /><figcaption>Grafana에 InfluxDB를 데이터 소스로 추가하기</figcaption></figure><p>InfluxDB 지표로 직접 대시보드를 제작해도 되지만, Grafana.com에서 <a href="https://grafana.com/dashboards?search=telegraf">다른 사용자가 미리 제작해둔 대시보드</a>를 받아서 사용할 수도 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*f9DHseAtPT5zD11_.jpg" /><figcaption>Grafana로 Telegraf 지표 확인하기</figcaption></figure><p>Chronograf도 Grafana와 사용 방법이 비슷하지만, Telegraf와 마찬가지로 <a href="https://github.com/influxdata/chronograf/releases">릴리즈 페이지</a>에서 단일 바이너리를 다운로드 받아서 설치가 가능하다는 이점이 있다. Docker 이미지로 Chronograf를 실행하려면, 다음 명령어를 사용하자.</p><pre>docker run -p 8888:8888 -d quay.io/influxdb/chronograf:1.3.7.0</pre><p>실행이 완료되었으면 브라우저로 localhost:3000에 방문하여 Chronograf를 사용할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*0_8dwiFV97bEvw8n.jpg" /><figcaption>Chronograf에 InfluxDB를 데이터 소스로 추가하기</figcaption></figure><p>데이터 소스를 추가하면 Telegraf가 전송한 리소스 사용 현황을 확인할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PcYijV_-0uQY8jZx.jpg" /><figcaption>Chronograf로 Telegraf 지표 확인하기</figcaption></figure><p><em>Originally published at </em><a href="https://si.mpli.st/dev/introduction-to-telegraf.html"><em>si.mpli.st</em></a><em> on September 10, 2017.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1b52f1985853" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-telegraf-1b52f1985853">오픈소스 시스템 모니터링 에이전트, Telegraf</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Elixir 정적 코드 분석, Credo와 Dialyzer]]></title>
            <link>https://medium.com/si-mpli-st-blog/elixir-%EC%A0%95%EC%A0%81-%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D-credo%EC%99%80-dialyzer-cf7dc447696d?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/cf7dc447696d</guid>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Sun, 27 Aug 2017 12:10:00 GMT</pubDate>
            <atom:updated>2017-11-19T07:19:15.211Z</atom:updated>
            <content:encoded><![CDATA[<p>코드의 품질을 분석하여 개선이 필요한 코드를 알려주고, 같이 협업을 할 때 코딩 컨벤션을 프로젝트 전반에 걸쳐 강제하기 위해 정적 코드 분석기를 사용한다. 유닛 테스트와 더불어 이러한 정적 코드 분석기를 지속 통합(Continuous Integration) 과정에 추가해 두면, 기능 브랜치가 머지되지 전에 코딩 컨벤션 위반이나 지나치게 복잡한 코드가 머지되는 것을 사전에 방지할 수 있다.</p><p><a href="https://www.shakr.com/">Shakr</a>에서는 Ruby를 주력 언어로 사용하고 있기 때문에 코딩 컨벤션 검사와 복잡한 코드를 찾아주는 <a href="https://github.com/bbatsov/rubocop">Rubocop</a>과 Rails 기반 애플리케이션에서 취약점을 노출할 수 있는 코딩 패턴을 검출해주는 <a href="https://github.com/presidentbeef/brakeman">Brakeman</a> 정적 코드 분석기를 사용하고 있다. 이러한 정적 코드 분석기들은 <a href="https://codeclimate.com/">Code Climate</a>을 이용해 CI 파이프라인에 연동해 두고, GitHub 저장소에서 <a href="https://help.github.com/articles/about-required-status-checks/">필수 상태 검사</a>로 지정해 두어 하나라도 실패하면 머지가 되지 않도록 구성하였다. 이러한 정적 코드 분석기들을 사용하면서 배포 이전에 많은 오류를 발견하고 수정할 수 있었는데, 이러한 경험은 나를 포함한 모든 사람은 언제나 실수를 한다는 생각에 더해져 새로운 언어를 접할 때는 믿을만한 정적 코드 분석기가 있는지의 여부를 먼저 확인하게 되었다.</p><p><a href="http://elixir-lang.org/">Elixir</a> 프로그래밍 언어에 사용 가능한 대표적인 정적 코드 분석기로는 두 가지가 있는데, 바로 <a href="https://github.com/rrrene/credo"><strong>Credo</strong></a>와 <a href="http://erlang.org/doc/man/dialyzer.html"><strong>Dlaiyzer</strong></a>이다.</p><h3>Credo</h3><p>Credo는 Elixir 언어를 위한 정적 코드 분석기이다. 공식 저장소의 설명에 따르면 다음과 같은 항목에 대한 검사를 수행한다.</p><ul><li><strong>일관성:</strong> <a href="https://www.emacswiki.org/emacs/TabsSpacesBoth">Tab과 Spaces를 한 코드베이스에서 섞어서 사용하는 것</a> 등의 실수를 범하지는 않았는지, 코드 전반적으로 일관성 있는 코딩 스타일을 사용하고 있는지 확인한다.</li><li><strong>가독성:</strong> 줄 당 문자열 수, 메소드 당 문자열 수 등을 통해 코드가 읽기 좋도록 구성이 되어 있는지 확인한다.</li><li><strong>리팩토링 필요:</strong> Cyclomatic Complexity나 Assignment Branch Condition Size와 같은 코드의 복잡도를 측정하는 지표들을 통해 리팩토링이 필요한 코드가 있는지 확인한다.</li><li><strong>코드 디자인:</strong> 중복된 코드를 발견하거나 TODO/FIXME와 같은 주석이 존재하는지 확인한다.</li><li><strong>기타 경고:</strong> IEx.pry와 같은 디버그 엔트리포인트를 방치해 두었는지, 변수의 이름을 동일 모듈에 존재하는 메소드와 같게 지정해주었는지 등의 오류를 확인한다.</li></ul><p>Credo를 프로젝트에서 사용하려면 mix.exs의 의존성 목록에 다음과 같이 추가하자.</p><pre>defp deps do<br>  [{:credo, &quot;~&gt; 0.8&quot;, only: [:dev, :test], runtime: false}]<br>end</pre><p>추가 후 mix deps.get으로 의존성 패키지를 모두 받은 다음, mix credo를 실행하면 Credo가 정적 코드 분석을 수행한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*UwIji-1Y7H0sRAXB.jpeg" /></figure><h3>Dialyzer</h3><p>Dialyzer는 Erlang 프로그램을 위한 정적 코드 분석기이다. 왜 Elixir 프로그램을 분석하는데 Erlang용 분석기를 사용하는지 의문을 가질 수 있지만, Elixir는 Erlang 기반으로 제작되어 Erlang이 사용하는 BEAM bytecode로 컴파일이 되기 때문에 Dialyzer를 사용하는 것이 가능하다.</p><p>Elixir는 언어 자체적으로 <a href="http://elixir-lang.org/getting-started/typespecs-and-behaviours.html">typespecs</a>라는 타입 어노테이션(annotation)을 지원하는데, Dialyzer를 이용하면 이렇게 추가한 타입 어노테이션을 통해 정적 분석을 할 수 있다.</p><p>Dialyzer를 직접 실행해도 되지만, Elixir 프로젝트를 사용할때 항상 다르게 되는 Mix를 통해 Dialyzer를 실행하는 것이 아무래도 편리하기 때문에, Dialyzer를 위한 Mix task를 제공해주는 Dialyxir를 사용하였다. 다음과 같이 의존성 목록에 추가할 수 있다.</p><pre>defp deps do<br>  [{:dialyxir, &quot;~&gt; 0.5&quot;, only: [:dev, :test], runtime: false}]<br>end</pre><p>Credo와 마찬가지로 추가 후 mix deps.get을 통해 의존성 패키지를 모두 받은 다음, mix dialyzer를 실행하면 된다. 다만 dialyzer의 경우에는 PLT(Persistent Lookup Table)이라는 파일에 분석 결과를 담아두는데, 기본 라이브러리와 OTP 모듈 또한 함께 분석하므로 초기 실행 시에는 상당히 오랜 시간이 걸릴 수 있다.</p><p>또한, Dlaiyxir는 기본적으로 :erts, :kernel, :stdlib, :crypto 이 네 가지의 Erlang 모듈을 위한 PLT를 생성하는데, 다른 Erlang 모듈을 사용한다면 아래와 같이 mix.exs에 추가해 주어야 한다.</p><pre>def project do<br>  ...<br>  dialyzer: [plt_add_apps: [:public_key]]<br>end</pre><p>이렇게 필요한 설정을 모두 마치고 Dialyzer를 실행하면, 타입 어노테이션이 잘못 지정된 오류를 찾아서 출력해준다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*GXCeJQ3NSempXXSN.jpeg" /></figure><p><em>Originally published at </em><a href="https://si.mpli.st/dev/elixir-credo-and-dialyzer.html"><em>si.mpli.st</em></a><em> on August 27, 2017.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=cf7dc447696d" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/elixir-%EC%A0%95%EC%A0%81-%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D-credo%EC%99%80-dialyzer-cf7dc447696d">Elixir 정적 코드 분석, Credo와 Dialyzer</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[처음 타보는 퍼스트 클래스, ANA NH211 후편]]></title>
            <link>https://medium.com/si-mpli-st-blog/%EC%B2%98%EC%9D%8C-%ED%83%80%EB%B3%B4%EB%8A%94-%ED%8D%BC%EC%8A%A4%ED%8A%B8-%ED%81%B4%EB%9E%98%EC%8A%A4-ana-nh211-%ED%9B%84%ED%8E%B8-bee22c09c770?source=rss-529345d241d2------2</link>
            <guid isPermaLink="false">https://medium.com/p/bee22c09c770</guid>
            <category><![CDATA[travel]]></category>
            <category><![CDATA[first-class]]></category>
            <category><![CDATA[airlines]]></category>
            <dc:creator><![CDATA[Premist (Minku Lee)]]></dc:creator>
            <pubDate>Mon, 03 Oct 2016 14:56:00 GMT</pubDate>
            <atom:updated>2017-11-19T07:13:41.737Z</atom:updated>
            <content:encoded><![CDATA[<p>2016.03.24</p><h3>탑승</h3><p>기내에 들어서자 여러 승무원 분께서 탑승을 환영해 주시고, 내 자리인 1K로 안내해 주셨다. 내 좌석 옆 자리인 1G 좌석에는 신문과 여러 잡지들이 가지런히 정돈되어 있었고, 그 중에 잡지 하나를 가지고 자리에 앉았다.</p><p>탑승 시작 몇 분 후가 되어도 퍼스트 클래스 캐빈으로는 다른 사람들이 들어오지 않았다. 승무원분께 물어보니 오늘은 나 혼자만 퍼스트 클래스에 탑승한다고 하셨다. 예약을 할 때 1A 좌석이 이미 차 있어 1K를 예약한 것이 기억났지만, 그 손님은 아무래도 예약을 취소하신 모양이었다. 덕분에 비행기 앞 부분 전체를 전세낸 기분이었다!</p><p>이륙 전에 승무원 분께서 오셔서 웰컴 드링크로 어떤 음료를 마실 건지 물어보셔서, 샴페인을 주문했다. 점심 식사 직전이라 주스나 차 같은 가벼운 음료를 마실까 하는 생각도 들었지만, 그래도 샴페인을 즐기기로 했다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZctyZm2id-nEA3t5.jpg" /><figcaption>웰컴 드링크</figcaption></figure><p>긴 비행동안 나를 담당해주실 승무원 분은 연륜이 꽤 있어 보이셨다. 아무래도 일등석은 서비스 품질 등을 가장 신경써야 하다 보니, 어떤 상황에도 유연하게 대처할 수 있는 경력이 많은 승무원분을 보통 배정하는 듯. 걱정했던 것과는 달리 영어를 굉장히 능숙하게 잘 하셨는데, 음료수나 기내 서비스 등 무언가 부탁을 할 때 “Certainly” 라고 웃으면서 대답을 해 주시는 모습이 정말 멋졌다.</p><p>샴페인을 어느 정도 마시고 내가 앉은 자리를 둘러보기 시작했다. 자리에 앉을 때 부터 가장 빨리 눈치챈 점은 바로 수납 공간이 엄청나게 많다는 점. 안경 혹은 스마트폰을 넣기 적당한 왼쪽 수납함부터 오른쪽의 다목적 수납함, 좌석 벽 쪽에 위치한 수트 및 코트 보관함, 그리고 좌석 앞 디스플레이 위의 선반과 발이 닿는 곳의 짐 보관함까지. 평소 이코노미 클래스를 타면 헤드폰을 어디에 놓을지 고민하고 스마트폰과 충전기를 좌석 앞 주머니에 넣을 때 늘 앞 사람 눈치를 보곤 했는데, 퍼스트 클래스 좌석의 수납 공간은 많은 수준을 넘어서 내릴 때 조심하지 않으면 소지품을 놓고 내릴 정도로 많았다.</p><p>좌석 오른쪽에는 기내 엔터테인먼트 시스템 리모컨과 더불어 터치스크린으로 된 좌석 조정 리모컨이 달려 있었다. 처음 탑승했을 때는 소파 모양으로 되어 있는 좌석이지만, 착륙 후 수면을 취하고 싶을 때는 이 리모컨을 사용하여 침대로 전환할 수 있는 것. 침대로 완전히 바꾸지 않아도 리클라이너처럼 자신이 원하는 형태로 바꿀 수 있는 미세한 조정도 가능했다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*w2t-0Eem7ZOrgLlf.jpg" /><figcaption>1–2–1 식 좌석 배치. 일부 항공사 좌석과는 다르게 별도의 좌석간 가림막은 설치되어 있지 않아, 프라이버시 보호는 되지 않는다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*P-C5kDvXxVXh7cgA.jpg" /><figcaption>소파식 좌석. 문처럼 생긴 것들은 모두 수납장이다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*T8zktujpN9rfaPye.jpg" /><figcaption>널찍한 모니터와 수납장. 자세히 보면 식탁이 수납되어 있는 것을 볼 수 있다.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*HmRXHwWWwT3iLPuD.jpg" /><figcaption>터치스크린 형태의 좌석 조정 리모컨</figcaption></figure><p>잠시 후 일등석 좌석에 제공되는 노이스 캔슬링 헤드폰을 받았다. 예상했던대로 Bose 헤드폰보다는 떨어지는 노이스 캔슬링 성능이었지만, 이것저것 챙기기 싫은 사람에게는 큰 도움이 될 것 같았다. 비행 시간 대부분동안 휴대폰에 저장해둔 음악을 들을 예정이었기 때문에, 헤드폰 전용 수납함(!)에 넣어 두고 늘 휴대하게 되는 Bose QC25 헤드폰을 착용했다.</p><p>다른 승무원분이 여러 가지 기내용품을 들고 와서 필요한 게 있으면 가져가시라고 보여주셨는데, 마침 입술이 말도 안되게 터졌을 때라 립밤을 받았다.</p><h3>점심식사</h3><p>비행기가 이륙하고 얼마 되지 않아 담당 승무원 분께서 메뉴판 두 개를 가지고 오셨다. 하나에는 이 비행의 메인 식사인 점심 식사 메뉴와 더불어 비행 중간에 언제든지 요청할 수 있는 간단한 식사 메뉴와 스낵이 적혀 있었고, 다른 하나의 메뉴판에는 샴페인과 각종 음료 메뉴가 적혀 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*AiDMvoYGKjKBmXbZ.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ySyZ3qBlByO-hP84.jpg" /><figcaption>일본식과 서양식 두 가지가 준비되어 있다</figcaption></figure><p>점심 식사의 메뉴의 경우에는 크게 일본식 카이세키 요리와 서양식 코스 메뉴가 있었는데, 일본 국적 항공사를 탄 만큼 ANA가 자랑하는 카이세키 요리를 맛보고 싶었다. 하지만 서양식 코스 메뉴의 일부 요리도 맛을 보고 싶어져서 승무원 분께 여쭤보았다.</p><blockquote><strong><em>나</em></strong><em> “혹시 메인 요리를 받을 때 서양식 코스에 있는 스테이크도 같이 받을 수 있을까요?”</em></blockquote><blockquote><strong><em>승무원</em></strong><em> “오늘 퍼스트 클래스에 손님만 타셨는데, 당연히 가능하죠!”</em></blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*iD3mWtDOj_torNh1.jpg" /><figcaption>사키즈케先附 라고 불리우는 에피타이저가 제일 먼저 나왔지만 사진을 찍지 못했다.<br>사진은 두 번째 에피타이저 젠사이前菜.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*znkSWePR_hRqXbjr.jpg" /><figcaption>Krug Grande Cuvée 샴페인</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*VhEIFE3_TKreDVM8.jpg" /><figcaption>녹차와 진저 에일을 추가로 주문했다</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*e-SQJcYBREvGvphh.jpg" /><figcaption>국물 코스인 오완お椀. 조개와 대하가 들어간 어묵으로 깔끔한 맛을 낸 국물 요리.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*74tNS5pYy5CfZHiT.jpg" /><figcaption>다음 코스인 오츠쿠리お造り. 기내에서 서빙된 회가 과연 맛이 있을까 걱정했지만 상상했던 것보다 아주 맛있었다.</figcaption></figure><p>흰살 생선의 경우 일본식 요리에 쓰인 만큼 숙성이 어느 정도 되어 쫄깃하기 보다는 선어회에 가까운 식감이 났다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*96NlZ4o1oobgaTh2.jpg" /><figcaption>타키와세炊き合わせ와 친미珍味, 카이세키식 메인 요리 슈사이主菜, 그리고 서양식 메인 요리</figcaption></figure><p>사실 일본식 메인 요리가 생선 요리라 스테이크를 추가로 주문했는데, 타키와세 요리가 사가규로 나와서 본의 아니게 고기를 원 없이 먹게 되었다. 쿠로게규로 만든 서양식 스테이크는 개인적으로 가장 궁금했던 요리인데, 그릴 등을 자유롭게 사용할 수 없는 비행기의 특성 상 스테이크를 어떻게 조리할 지 궁금했기 때문이다. 예상했던대로 스테이크의 굽기는 선택할 수 없었지만 고기는 매우 부드럽고 연했다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pg0SeXnIjIIAiRyg.jpg" /><figcaption>후식</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PpCCCh3WZzY9nQVC.jpg" /><figcaption>일리 카페라떼</figcaption></figure><p>점심 식사가 끝나고 담당 승무원 분께서 오셔서 잠자리를 준비해 줄지 물어보셨다. 원래대로라면 한숨 돌라고 잠을 청하고 싶었지만, 생각보다 많은 양의 음식을 먹은 것도 있고 지금 잠을 청하면 왠지 아까운 것 같아서 노트북을 펴고 잠깐 작업을 하기로 했다.</p><h3>하늘 위의 침대</h3><p>어느 정도 시간이 지나고 잠을 자고 싶어져서, 리모컨의 호출 버튼을 누러 승무원 분께 잠자리를 준비해달라고 부탁드렸다. 퍼스트 클래스 캐빈 내에 나 혼자밖에 없어서, 원래 내 좌석은 그대로 두고 옆 좌석을 침대로 바꿔줄 수 있냐고 여쭤보았더니 흔쾌히 그렇게 하겠다고 답해주셨다. 승무원 분이 주신 파자마를 들고 화장실로 향했다.</p><p>화장실은 인터넷 상에서 봤던 다른 퍼스트 클래스만큼은 크지 않았지만, 그래도 이코노미 클래스의 그것보다는 훨씬 컸다. 놀랍게도 일반적인 티슈와 더불어 수건이 준비되어 있었다. 세면대 옆에 구비된 칫솔과 세면 도구로 간단하게 잘 준비를 마쳤다.</p><p>화장실에서 나와 자리로 돌아가니 침대가 준비되어 있었고, 캐빈 내의 조명도 잠자리에 알맞게 조절되어 있었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pBbFZj4XOQqfa7IJ.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*C8q8frbJdwoGqS8L.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*b8pmRYntmSD83b1x.jpg" /></figure><p>아주 조금씩 흔들리는 비행기 안에서, 넓은 침대에 누워 비행기의 천장을 바라보고 있다는 사실이 굉장히 비현실적으로 느껴졌다. 평소에 이코노미 석에서는 잠에 금방 들곤 했는데, 훨씬 편안한 이 곳에서는 한 숨도 잠이 오지 않았다.</p><p>몇 번을 뒤척이다 결국 잠을 청하지 못하고, 다시 자리로 돌아와서 미리 준비해온 영화를 봤다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*tlbqv_4nCFHr5DZr.jpg" /><figcaption>〈내부자들: 디 오리지널〉 / 전에 본 영화인데다가 러닝타임이 길어서 중간부터 잠이 왔다.</figcaption></figure><p>영화를 다 보고 난 후, 다시 침대에 누워 잠을 청했다. 눈이 피로해져서 그런지 이번에는 잠에 들 수 있었다.</p><h3>간식</h3><p>약 2시간 정도 잠을 자고 일어났다. 잠자리가 불편한 건 아니었는데, 아마 최대한 덜 자고 퍼스트 클래스에서 느낄 수 있는 경험을 최대한 하고 싶다는 생각을 하느라 잠을 깊게 잘 수 없었던 것 같다.</p><p>간식을 시켜야겠다고 생각하고 메뉴를 보던 중, 아까 하네다 공항 라운지에서 시키지 못했던 카레가 보여 냉큼 주문했다. 음료는 어떻게 하겠냐고 승무원 분께서 물어보셔서, 산토리 히비키 21년산 위스키를 같이 시켰다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*xv8EJ_tozc9nLOm3.jpg" /><figcaption>ANA 오리지널 카레</figcaption></figure><p>어느 정도 잠이 깬 상태였지만, 아직 캐빈 안의 불은 꺼져 있는 상황이었다. 보통 착륙 몇 시간 전이 되었을 때 켜고 식사를 주기 시작할 때 불이 켜지곤 하는데, 무언가를 하려고 해도 조금 어두워서 언제 불이 켜지는지를 승무원 분께 여쭤보았다.</p><blockquote><strong><em>나</em></strong><em> “혹시 언제 불이 켜지는지 알 수 있을까요?”</em></blockquote><blockquote><strong><em>승무원</em></strong><em> “퍼스트 클래스 캐빈에 다른 사람이 아무도 없으니까, 원하시는 대로 언제든지 조정해 드리겠습니다.”</em></blockquote><p>정중히 불을 켜달라고 부탁드렸고, 나 혼자 있는 캐빈에 환하게 불이 켜졌다. 뒤로 보이는 비즈니스 클래스 캐빈은 아직 캄캄했다.</p><p>하늘 위에서 내 맘대로 조명을 껐다 켤 수 있다니, 정말이지 꿈만 같은 순간이었다.</p><h3>마지막 식사, 그리고 착륙 준비</h3><p>어느 덧 마지막 식사를 할 때가 되었다. 착륙 전 식사는 메뉴가 딱히 정해져 있지 않고 비행 도중 언제든지 시킬 수 있는 메뉴 중에서 시키면 되는 방식이었는데, 평소보다 과식을 한 것도 있고 속을 풀기 위해서 잇푸도 미소라멘과 죽을 주문했다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*kJkmoalZwMX9fApU.jpg" /><figcaption>잇푸도 미소라멘</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*uNTQMYQqnAPTzLCE.jpg" /><figcaption>죽과 일본식 반찬들</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-CJSXmLIDCXVwSZs.jpg" /><figcaption>일리 아이스 아메리카노</figcaption></figure><p>착륙 준비를 알리는 안내 방송이 나왔다. 파자마에서 평상복으로 갈아입고, 좌석을 리클라이너에서 소파 형태로 전환하고 있는데, 승무원분께서 다가와서 Fast Track 이용권을 주셨다. 보통 공항에서 내려서 입국 수속을 밟을 때 줄을 길게 서서 기다려야 하는데, 이러한 대기열에서 기다릴 필요 없이 전용 대기열을 이용할 수 있게 해주는 이용권이었다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*K9s7Nj6_cjfJfy8y.jpg" /></figure><p>비행기가 착륙하고 자리에서 일어나자 이륙 전에 맡겼던 겉옷을 수트 보관함에서 꺼내 주셨다. 보통 비행기 착륙이 끝나고 안전 벨트 사인이 꺼지면 먼저 나가려는 사람들로 복도가 줄을 이루는데, 혼자 유유히 출구로 향했다. 출구 앞에서 “다음에도 ANA를 이용해주세요” 라고 이야기해주시는 승무원 분들에게 감사하다는 인사를 하고, 드디어 비행기에서 내렸다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*aHHhzzpRHvMOmyDd.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Tyvpx1suZ6j7CWrO.jpg" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*xMspiYT3ePMGq1nZ.jpg" /><figcaption>히드로 공항 도착.</figcaption></figure><h3>마치며</h3><p>사실 타기 전에는 어느 정도 고민을 많이 했었다. 퍼스트 클래스 편도 항공편을 예약할 때 총 8만 마일리지를 사용했는데, 이 마일리지가 있으면 미주나 유럽을 한 번 왕복할 수 있는 마일리지이기 때문이다. 하지만 일등석 예약을 알아보기 시작하면서 고민은 점점 사라졌는데, 사전 조사 도중에 내가 타게 될 일등석 좌석의 편도 요금이 약 1500만원에 육박한다는 것을 알게 된 것이다. 살면서 이만한 돈을 비행기 표에 쓸 수 있는 사람은 극히 한정이 되어 있을 것이라는 생각이 들면서, 두 번의 평범한 여행보다는 한 번의 특별한 여행을 하고 싶다는 마음을 굳혔다.</p><p>비행기 착륙이 가까워 지면서 내리기 싫다는 생각이 든 비행은 이번이 처음이었다. 그동안 먹어보지 않은 식사, 마셔 보지 않은 음료, 받아보지 않은 대우. 앞으로 일등석을 다시 타는 경험은 거의 없을 것이고, 내 돈으로 탈 수 있을 가능성도 더더욱 없겠지만, 나중에 마일리지가 모여서 다시 선택을 할 날이 온다면 나는 망설이지 않고 다시 일등석을 예약할 것이다.</p><h3>다시 읽기</h3><ul><li><a href="https://si.mpli.st/travel/nh211-first-class-chapter1.html"><strong>생애 처음 퍼스트 클래스, ANA NH211 — 전편</strong></a></li></ul><p><em>Originally published at </em><a href="https://si.mpli.st/travel/nh211-first-class-chapter2.html"><em>si.mpli.st</em></a><em> on October 3, 2016.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=bee22c09c770" width="1" height="1"><hr><p><a href="https://medium.com/si-mpli-st-blog/%EC%B2%98%EC%9D%8C-%ED%83%80%EB%B3%B4%EB%8A%94-%ED%8D%BC%EC%8A%A4%ED%8A%B8-%ED%81%B4%EB%9E%98%EC%8A%A4-ana-nh211-%ED%9B%84%ED%8E%B8-bee22c09c770">처음 타보는 퍼스트 클래스, ANA NH211 후편</a> was originally published in <a href="https://medium.com/si-mpli-st-blog">si.mpli.st</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>