<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>개발하며 Nolsigan</title>
    <description>Nolsigan's personal blog</description>
    <link>http://nolsigan.com/</link>
    <atom:link href="http://nolsigan.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 24 Jan 2018 13:52:07 +0000</pubDate>
    <lastBuildDate>Wed, 24 Jan 2018 13:52:07 +0000</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      
      <item>
        <title>Dynamic Routing Between Capsules</title>
        <description>&lt;p&gt;Introduces new concept called capsule whose output represents the instantiation parameters of a specific type of entity such as an object or object part. Output’s orientation represents its instantiation parameters and length represents its probability.&lt;/p&gt;

&lt;h2 id=&quot;key-points&quot;&gt;Key Points&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Lower level capsule influences higher level capsule if two capsule’s outputs agrees&lt;/li&gt;
  &lt;li&gt;Agreement is caculated by scalar product of outputs&lt;/li&gt;
  &lt;li&gt;Uses shrinking algorithm to make output vector size from 0 to 1&lt;/li&gt;
  &lt;li&gt;Total loss is sum of each class’s loss&lt;/li&gt;
  &lt;li&gt;Because there’s no max pooling, capsule network can capture not only the most significant object but also others&lt;/li&gt;
  &lt;li&gt;Even two digits highly overlapped&lt;/li&gt;
  &lt;li&gt;But also generates drawback that images with high variance background are hard to classify&lt;/li&gt;
  &lt;li&gt;Network depends more on forward propagation through routing-by-agreement&lt;/li&gt;
  &lt;li&gt;Reduce burden for backpropagation to do the whole learning job&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Nice, interesting, novel method&lt;/li&gt;
  &lt;li&gt;Hard to predict if this will substitute CNN completely&lt;/li&gt;
  &lt;li&gt;But giving more responsibility for making prediction to dynamic forward propagation seems like a good direction of progress&lt;/li&gt;
  &lt;li&gt;But takes longer time to train&lt;/li&gt;
&lt;/ul&gt;
</description>
        
          <description>&lt;p&gt;Introduces new concept called capsule whose output represents the instantiation parameters of a specific type of entity such as an object or object part. Output’s orientation represents its instantiation parameters and length represents its probability.&lt;/p&gt;

</description>
        
        <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/capsule-network/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/capsule-network/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>What is variational autoencoder?</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Jaan Altosaar의 블로그 글 &lt;em&gt;What is variational autoencoder&lt;/em&gt; 를 허락하에 번역한 글입니다.
한글로 번역하기 어렵거나 영어로 두는 게 나은 단어들은 그대로 사용하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;variational-autoencodervae-를-두-가지-관점에서-이해하기-딥러닝과-그래프-모델&quot;&gt;Variational Autoencoder(VAE) 를 두 가지 관점에서 이해하기: 딥러닝과 그래프 모델&lt;/h3&gt;

&lt;p&gt;딥러닝 연구자와 확률론적 기계 학습 연구자는 왜 variational autoencoder(VAE) 를 논의할 때 혼란스러워 하는가?
VAE 란 무엇인가? 왜 이 용어를 둘러싼 많은 혼란이 있을까?&lt;/p&gt;

&lt;p&gt;개념과 언어간의 거리가 있기 때문이다. 뉴럴넷의 과학과 확률 모델은 같은 언어를 사용하지 않는다.
나의 목표는 이 거리를 좁히고 두 분야간의 협력과 토의가 활발해질 수 있도록 하고 이를 구현한 코드를 제공하는 것이다. (&lt;a href=&quot;https://github.com/altosaar/vae/blob/master/vae.py&quot;&gt;Github link&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Variational Autoencoder 는 멋지다. 이 모델은 복잡한 generative model 를 설계하고 큰 데이터셋에 적용할 수 있게 해준다. 또한 허구의 연예인 얼굴과 높은 화질의 디지털 작품을 생성할 수도 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/assets/img/variational-autoencoder-faces.jpg&quot; alt=&quot;&quot; /&gt;
    &lt;figcaption&gt;VAE 로 생성된 허구의 연예인 얼굴들 (&lt;a href=&quot;https://www.youtube.com/watch?v=XNZIN7Jh3Sg&quot;&gt;by Alec Radford&lt;/a&gt;)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;이 모델은 또한 image generation 과 reinforcement learning 에서 최고의 결과(state-of-the-art)를 얻는다.
VAE 는 2013년에 &lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;Kingma et al.&lt;/a&gt; 과 &lt;a href=&quot;https://arxiv.org/abs/1401.4082&quot;&gt;Rezende et al.&lt;/a&gt; 에 의해 정의되었다.&lt;/p&gt;

&lt;p&gt;VAE 를 설명하기 위한 언어를 어떻게 만들 수 있을까? 먼저 뉴럴넷의 관점에서 생각해보고, 그래프 모델의 variational inference 를 통해 생각해보자.&lt;/p&gt;

&lt;h4 id=&quot;뉴럴넷-관점&quot;&gt;뉴럴넷 관점&lt;/h4&gt;

&lt;p&gt;뉴럴넷 관점에서 VAE 는 encoder, decoder 그리고 loss function 으로 구성된다.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/assets/img/encoder-decoder.png&quot; width=&quot;70%&quot; alt=&quot;&quot; /&gt;
    &lt;figcaption&gt;Encoder 는 데이터를 잠재된 차원 (z) 로 압축한다. Decoder 는 잠재된 차원 (Z) 로부터 데이터를 재구성한다.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Encoder 는 뉴럴넷이다. 인풋은 datapoint &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 이고, 아웃풋은 잠재된 차원(hidden representation) &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 이며, weight 들과 biase &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; 를 가지고 있다.
구체적으로 설명하기 위해, &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 를 28 x 28 사이즈의 손으로 쓴 숫자 사진이라고 생각하자.
Encoder 는 784 차원 데이터를 훨씬 낮은 차원의 잠재된 차원 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 로 암호화(encode)한다.
이는 흔히 병목 지역이라 불리는데, encoder 가 데이터를 낮은 차원으로 효율적으로 압축하는 것을 배워야하기 때문이다.
Encoder 를 &lt;script type=&quot;math/tex&quot;&gt;q_\theta (z \vert x)&lt;/script&gt; 로 표현하자. 낮은 차원 (&lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;)이 확률론적임을 확인하자: 
encoder 는 Gaussian probability density 인 &lt;script type=&quot;math/tex&quot;&gt;q_\theta (z \vert x)&lt;/script&gt; 에 파라미터를 아웃풋으로 내보낸다.
우리는 이 확률 분포에서 샘플을 뽑음으로써 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 에 잡음이 포함된 값을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;Decoder 는 또 다른 뉴럴넷이다. 인풋은 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 이고 아웃풋은 데이터 확률분포의 파라미터 값들이며 weight 과 biase &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; 를 갖는다.
Decoder 는 &lt;script type=&quot;math/tex&quot;&gt;p_\phi (x \vert z)&lt;/script&gt; 로 표현된다. 손으로 쓴 숫자 사진을 사용한다고 할 때, 사진은 흑백이고 각 픽셀이 0 이나 1 이라 하자.
그러면 픽셀 하나의 확률분포는 Bernoulli distribution 으로 표현할 수 있다.
Decoder 는 숨겨진 차원 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 을 input 으로 받아 784 개의 각각 이미지 픽셀에 대한 Bernoulli 파라미터들을 output 으로 내보낸다.
실수로 된 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 784 개의 0 과 1 사이의 실수로 해독(decode)하는 것이다.
낮은 차원에서 높은 차원으로 가기 때문에 정보의 손실이 발생한다. 얼마나 손실이 발생하는가?
우리는 이 것을 단위가 자연수인 reconstruction log-likelihood &lt;script type=&quot;math/tex&quot;&gt;\log p_\phi (x\vert z)&lt;/script&gt; 를 사용하여 측정한다.
이 측정값이 decoder 가 숨겨진 차원 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 에서 인풋 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 를 얼마나 효율적으로 재생성 했는지를 알려준다.&lt;/p&gt;

&lt;p&gt;VAE 의 loss function 은 regularizer 가 포함된 negative log-likehood 이다.
모든 datapoint 가 공유하는 전역 변수가 없으므로 우리는 loss function 을 하나의 datapoint &lt;script type=&quot;math/tex&quot;&gt;l_i&lt;/script&gt; 에만 의존적이도록 나눌 수 있다.
총 loss 는 총 N 개의 datapoint 에 대해 &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^N l_i&lt;/script&gt; 가 된다.
Datapoint &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; 에 대한 loss function &lt;script type=&quot;math/tex&quot;&gt;l_i&lt;/script&gt; 는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_i(\theta, \phi) = - E_{z\sim q_\theta(z\vert x_i)}[\log p_\phi(x_i\vert z)] + KL(q_\theta(z\vert x_i) \vert\vert p(z))&lt;/script&gt;

&lt;p&gt;앞 부분은 재생성 loss 혹은 i 번째 datapoint 의 negative log-likelihood 기대값이다.
기대값은 encoder 의 분포와 관련 있다. 이 부분이 decoder 를 데이터를 재생성하도록 유도한다.
Decoder 의 output 이 데이터를 잘 재생성하지 못한다면 loss function 이 높은 값을 갖게 된다.&lt;/p&gt;

&lt;p&gt;뒷 부분은 우리가 추가하는 regularizer 이다 (유도하는 법은 나중에 나온다).
이 것은 encoder 의 분포 &lt;script type=&quot;math/tex&quot;&gt;q_\theta(z\vert x)&lt;/script&gt; 와 &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt; 사이의 Kullback-Leibler divergence 이다.
이 divergence 는 &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; 를 사용하여 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; 를 표현할 때 얼마나 정보가 유실 되는지를 측정한다.
&lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; 가 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; 에 얼마나 가까운 지를 측정하는 방법 중 하나이다.&lt;/p&gt;

&lt;p&gt;VAE 에서 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; 는 평균 0 과 분산 1 을 갖는 표준정규분포 &lt;script type=&quot;math/tex&quot;&gt;p(z) = Normal(0, 1)&lt;/script&gt; 이다.
Encoder 가 표준정규분포와 다른 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 output 으로 갖는다면 loss 값에서 손해(penalty)를 본다.
이 regularizer 는 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 의 각 숫자를 충분히 다양하도록 만들라는 뜻이다.
우리가 regularizer 를 포함시키지 않는다면 encoder 는 각 datapoint 에 대해 유클리드 공간상의 다른 영역을 나타내도록 편법을 사용할 수도 있다.
이것은 좋지 않은 현상인데, 똑같은 숫자를 나타내는 두 이미지 (두 명이 쓴 숫자 2, &lt;script type=&quot;math/tex&quot;&gt;2_{alice}&lt;/script&gt; 와 &lt;script type=&quot;math/tex&quot;&gt;2_{bob}&lt;/script&gt;) 가 각각 다른 값 &lt;script type=&quot;math/tex&quot;&gt;z_{alice}&lt;/script&gt; 와 &lt;script type=&quot;math/tex&quot;&gt;z_{bob}&lt;/script&gt; 을 가질 수 있기 때문이다.
우리는 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 값이 의미 있길 원하기 때문에 이 행동을 제한한다.
이를 통해 비슷한 숫자의 표현을 가깝게 유지할 수 있다.
(e.g. 따라서 &lt;script type=&quot;math/tex&quot;&gt;z_{alice}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;z_{bob}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;z_{ali}&lt;/script&gt; 값이 충분히 가깝게 유지된다)&lt;/p&gt;

&lt;h4 id=&quot;확률-모델의-관점&quot;&gt;확률 모델의 관점&lt;/h4&gt;

&lt;p&gt;이제 VAE 를 확률 모델의 관점에서 생각해보자. 딥러닝과 뉴럴넷에 대한 지식을 잠시만 잊어버리자.
뉴럴넷과 분리시켜야 다음 개념들을 좀 더 선명하게 볼 수 있을 것이다.
우리는 마지막에 다시 뉴럴넷을 상기할 것이다.&lt;/p&gt;

&lt;p&gt;확률 모델의 관점에서 VAE 는 어떤 특정한 확률 모델을 갖는 data &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 와 숨겨진 변수(latent variable) &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 갖는다.
우리는 이 모델의 joint probability 를 &lt;script type=&quot;math/tex&quot;&gt;p(x, z) = p(x\vert z)p(z)&lt;/script&gt; 로 표현할 수 있다.
생성 과정은 다음과 같다.&lt;/p&gt;

&lt;p&gt;각 datapoint &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; 에 대해:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;z_i \sim p(z)&lt;/script&gt; 를 그린다.&lt;/li&gt;
  &lt;li&gt;datapoint &lt;script type=&quot;math/tex&quot;&gt;x_i \sim p(x\vert z)&lt;/script&gt; 를 그린다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 것을 그래프 모델로 표현하면:&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/assets/img/graphical-model-variational-autoencoder.png&quot; width=&quot;30%&quot; alt=&quot;&quot; /&gt;
    &lt;figcaption&gt;VAE 의 그래프 모델. 숨겨진 변수 z 는 표준정규분포이며 data 는 P(X|Z) 에서 추출된다. 그림자 진 노드 X 는 관찰된 data 를 의미한다. 손글씨 숫자 이미지에 대해서 이 data likelihood 는 Bernoulli distribution 을 따른다.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;이 모델이 우리가 VAE 를 확률 모델의 관점에서 생각할 때 가장 중요한 부분이다.
숨겨진 변수는 prior &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt; 로부터 얻어진다.
데이터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 는 숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 조건부로 한 likelihood &lt;script type=&quot;math/tex&quot;&gt;p(x\vert z)&lt;/script&gt; 를 갖는다.
모델은 data 와 숨겨진 변수에 대한 joint probability &lt;script type=&quot;math/tex&quot;&gt;p(x, z)&lt;/script&gt; 를 정의한다.
우리는 이를 likelihood 와 prior 로 분해할 수 있다: &lt;script type=&quot;math/tex&quot;&gt;p(x, z) = p(x\vert z)p(z)&lt;/script&gt;
흑백 숫자 이미지의 경우, likelihood 는 Bernoulli distribution 을 따른다.&lt;/p&gt;

&lt;p&gt;이제 우리는 이 모델에서의 inference 에 대해 생각해 볼 수 있다.
목표는 관찰된 데이터로부터 숨겨진 변수를 잘 추론(infer)하는 것이다.
곧, posterior &lt;script type=&quot;math/tex&quot;&gt;p(z\vert x)&lt;/script&gt; 를 계산하는 것과 일치한다.
Bayes 에 따르면:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z\vert x) = \frac{p(x\vert z)p(z)}{p(x)}.&lt;/script&gt;

&lt;p&gt;분모 &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; 를 생각해보자. 우리는 이를 evidence 라 부르고 숨겨진 변수를 제거하여 얻을 수 있다: &lt;script type=&quot;math/tex&quot;&gt;p(x) = \int p(x, z)p(z)dz&lt;/script&gt;.
운이 없게도, 이 적분을 계산하기 위해선 모든 숨겨진 변수의 가능성을 고려해야하기 때문에 지수 시간이 걸린다.
따라서 우리는 이 posterior distribution 을 근사해야한다.&lt;/p&gt;

&lt;p&gt;Variational inference 가 &lt;script type=&quot;math/tex&quot;&gt;q_\lambda(z\vert x)&lt;/script&gt; 계열의 분포를 근사할 수 있다.
Variational parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; 는 분포 계열을 구별할 수 있게 한다.
예를 들어, &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; 가 Gaussian 이라면, 각 datapoint &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; 에 대한 숨겨진 변수의 평균과 분산이 된다. &lt;script type=&quot;math/tex&quot;&gt;\lambda_{x_i} = (\mu_{x_i}, \sigma^2_{x_i})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;우리의 variational posterior &lt;script type=&quot;math/tex&quot;&gt;q(z\vert x)&lt;/script&gt; 가 진짜 posterior &lt;script type=&quot;math/tex&quot;&gt;p(z\vert x)&lt;/script&gt; 를 얼마나 잘 근사하는지 어떻게 알 수 있을까?
우리는 &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; 로 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; 를 근사할 때 정보 손실을 측정하는 Kullback-Leibler divergence 를 사용한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;KL(q_\lambda(z \vert x) \vert \vert p(z \vert x)) =&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{E}_q[\log q_\lambda(z \vert x)]- \mathbf{E}_q[\log p(x, z)] + \log p(x)&lt;/script&gt;

&lt;p&gt;우리의 목표는 divergence 를 최소화하는 &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; 를 찾는 것이다.
따라서 최적의 근사 posterior 는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_\lambda^* (z \vert x) = {\arg\min}_\lambda KL(q_\lambda(z \vert x) \vert \vert p(z \vert x)).&lt;/script&gt;

&lt;p&gt;왜 이 값을 바로 계산하는게 불가능한가? 귀찮은 evidence &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; 가 식에 나타나기 때문이다.
위에서 논의했듯이 이 값은 다루기가 매우 힘들다. 다룰 수 있는 variational inference 를 위해선 하나의 조건이 더 필요하다.
아래의 함수를 봐보자:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ELBO(\lambda) = \mathbf{E}_q[\log p(x, z)] - \mathbf{E}_q[\log q_\lambda(z \vert x)].&lt;/script&gt;

&lt;p&gt;이 식을 Kullback-Leibler divergence 와 합치고 다음과 같이 evidence 를 다시 쓸 수 있음을 확인하자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log p(x) = ELBO(\lambda) + KL(q_\lambda(z \vert x) \vert \vert p(z \vert x))&lt;/script&gt;

&lt;p&gt;Jensen’s inequality 에 의해, Kullback-Leibler divergence 는 항상 0 보다 크거나 같다.
이는 곧 Kullback-Leibler divergence 를 최소화하는 것이 ELBO 를 최대화하는 것과 동치임을 말한다.
요약하자면 Evidence Lower BOund (ELBO) 가 posterior inference 근사를 가능하게 한다.
우리는 더이상 Kullback-Leibler divergence 를 최소화하기 위해 시간을 쓸 필요가 없다.
대신, 우리는 ELBO 를 최대화하므로써 계산 가능한 동치의 일을 수행한다.&lt;/p&gt;

&lt;p&gt;VAE 에선 오직 local latent variable 만이 존재한다 (서로 다른 두 datapoint 가 latent &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 공유하지 않는다).
따라서 우리는 ELBO 를 단일 datapoint 단위의 합으로 계산한다.
이를 통해 우리는 &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; 에 대해 stochastic gradient descent 를 사용할 수 있다.
VAE 에서 단일 datapoint 에 대한 ELBO 는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ELBO_i(\lambda) = E_{q_\lambda(z\vert x_i)}[\log p(x_i\vert z)] - KL(q_\lambda(z\vert x_i) \vert\vert p(z)).&lt;/script&gt;

&lt;p&gt;이 값이 예전 ELBO 의 정의와 같은 것을 보이기 위해선 log joint 값을 prior 와 likelihood 값으로 확장하고
log 의 곱셈 법칙을 사용하면 된다.&lt;/p&gt;

&lt;p&gt;이제 뉴럴넷 관점과 연결해보자.
마지막 과정은 근사 posterior &lt;script type=&quot;math/tex&quot;&gt;q_\theta(z\vert x, \lambda)&lt;/script&gt; 를 데이터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 를 인풋으로 받고 파라미터 &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; 를 아웃풋으로 내보내는 inference network(혹은 encoder) 로 파라미터화 하는 것이다.
또한 likelihood &lt;script type=&quot;math/tex&quot;&gt;p(x\vert z)&lt;/script&gt; 를 latent variables 를 인풋으로 받고 데이터 분포 &lt;script type=&quot;math/tex&quot;&gt;p_\phi(x\vert z)&lt;/script&gt; 의 파라미터를 아웃풋으로 내보내는 generative network(혹은 decoder) 로 파라미터화 한다.
Inference 와 generative network 는 각각 파라미터 &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; 와 &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; 를 갖는다.
파라미터들은 뉴럴넷 상에서 weight 과 biase 가 된다.
우리는 stochastic gradient descent 를 통해 이를 최적화하여 ELBO 를 최대화한다. (global latent variable 이 없기 때문에 데이터를 minibatch 로 다루는 것이 더 정결하다)
ELBO 에 inference 와 generative network 의 파라미터를 더해서 쓰면 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ELBO_i(\theta, \phi) = E_{q_\theta(z\vert x_i)}[\log p_\phi(x_i\vert z)] - KL(q_\theta(z\vert x_i) \vert\vert p(z)).&lt;/script&gt;

&lt;p&gt;이 evidence lower bound 는 VAE 의 loss function 의 역으로써, 우리가 뉴럴넷 관점에서 논의한 내용이다; &lt;script type=&quot;math/tex&quot;&gt;ELBO_i(\theta. \phi) = -l_i(\theta, \phi)&lt;/script&gt;.
우리는 원리를 통해 이 결론에 도달하기 위해 확률 모델과 approximate posterior inference 를 사용하였다.
우리는 여전히 Kullback-Leibler divergence 를 regularizer 관점, 또는 재생성 손실 관점에서 likelihood 기대값으로 생각할 수 있다.
하지만 확률 모델을 통한 설명이 왜 이 부분이 존재하는 지를 분명하게 보여준다: approximate posterior &lt;script type=&quot;math/tex&quot;&gt;q_\lambda(z\vert x)&lt;/script&gt; 와 posterior &lt;script type=&quot;math/tex&quot;&gt;p(z\vert x)&lt;/script&gt; 사이의 Kullback-Leibler divergence 를 최소화하는 일.&lt;/p&gt;

&lt;p&gt;이게 전부다! 우리는 확률 모델, 목표 함수(ELBO), 그리고 inference 알고리즘(ELBO 의 gradient ascent)을 정의하였다.&lt;/p&gt;

&lt;h3 id=&quot;experiments&quot;&gt;Experiments&lt;/h3&gt;

&lt;p&gt;이제 우리는 모델의 샘플들을 볼 준비가 되었다.
진행과정을 측정하는 두 가지 방법으로 prior 혹은 posterior 에서 샘플링하는 방법이 있다.
학습된 숨겨진 차원(latent space)를 더 잘 이해하기 위해 숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;q_\lambda(z\vert x)&lt;/script&gt; 의 posterior distribution 을 시각화 할 수 있다.&lt;/p&gt;

&lt;p&gt;계산적 관점에서, 이 것은 곧 정규분포의 변수를 얻기 위해 인풋 이미지 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 를 inference network 에 넣어주고 숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 에서 샘플을 얻는 것을 의미한다.
Inference network 이 어떻게 더 좋은 approximate posterior distribution 를 찾는 지 확인하기 위해 학습 과정에서 그래프에 기록하고 서로 다른 숫자에 대한 숨겨진 변수를 서로 다른 부분의 숨겨진 차원에 배치한다.
학습을 시작한 시점에는 숨겨진 변수의 분포가 prior 와 비슷함을 확인하자 (0 근처의 둥근 방울).&lt;/p&gt;

&lt;center&gt;
&lt;iframe src=&quot;//giphy.com/embed/26ufoVqZDjHoPrp8k?html5=true&quot; width=&quot;480&quot; height=&quot;413&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;

&lt;figure&gt;
    &lt;figcaption&gt;학습 과정에서 approximate posterior 의 시각화. 학습이 진행됨에 따라 숫자 클래스들이 2차원 숨겨진 차원으로 구별된다.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;우리는 또한 prior predictive distribution 을 시각화할 수 있다. 우리는 숨겨진 변수가 &lt;script type=&quot;math/tex&quot;&gt;-3&lt;/script&gt; 과 &lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt; 사이에 같은 간격으로 놓이도록 값을 수정한다.
그 다음 generative network 에 의해 파라미터화 된 likelihood 에서 샘플을 추출한다.
이 ‘환각을 일으키는’(hallucinated) 이미지들은 각 숨겨진 차원의 부분에 대해 모델이 어떻게 연상하는지를 보여준다.&lt;/p&gt;

&lt;center&gt;
&lt;iframe src=&quot;//giphy.com/embed/26ufgj5LH3YKO1Zlu?html5=true&quot; width=&quot;480&quot; height=&quot;480&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;

&lt;figure&gt;
    &lt;figcaption&gt;likelihood 의 샘플을 통한 prior predictive distribution 의 시각화. X 와 Y 축은 -3 과 3 사이에 같은 간격으로 놓여진 숨겨진 변수이다.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;용어-사전&quot;&gt;용어 사전&lt;/h3&gt;

&lt;p&gt;우리는 명확하고 간결하게 VAE 를 설명하기 위한 언어를 선택해야한다. 다음은 몇 개의 내가 헷갈렸던 내용에 대한 용어사전이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Variational Autoencoder (VAE)&lt;/strong&gt;: 뉴럴넷의 언어에서 VAE 는 encoder, decoder, loss function 으로 구성된다.
확률 모델의 관점에서의 VAE 는 approximate posterior 와 model likelihood 가 뉴럴넷(inference 와 generative networks)에 의해 파라미터화 된 latent Guassian model 에서의 approximate inference 를 의미한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Loss function&lt;/strong&gt;: 뉴럴넷의 언어에서 우리는 loss function 을 생각한다. 학습은 이 loss function 을 최소화하는 일이다.
하지만 variational inference 에선 loss function 이 아닌 &lt;script type=&quot;math/tex&quot;&gt;ELBO&lt;/script&gt; 를 최대화한다.
이는 뉴럴넷 프레임워크들이 최소화만 지원해서 &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.minimize(-elbo)&lt;/code&gt; 와 같은 어색한 방법을 쓰게 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: 뉴럴넷 세계에서 encoder 는 데이터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 에 대한 표현 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 내보내는 뉴럴넷이다.
확률 모델 관점에서 &lt;strong&gt;inference network&lt;/strong&gt; 는 숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 의 approximate posterior 를 파라미터화 한다.
Inference network 은 분포 &lt;script type=&quot;math/tex&quot;&gt;q(z\vert x)&lt;/script&gt; 에 파라미터를 아웃풋으로 내보낸다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: 딥러닝에서 decoder 는 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 가 주어졌을 때 데이터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 를 재생성하는 법을 배우는 뉴럴넷이다.
확률 모델의 관점에선 숨겨진 변수 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 가 주어졌을 때 데이터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 의 likelihood 은 &lt;strong&gt;generative network&lt;/strong&gt; 에 의해 파라미터화 된다.
Generative network 는 likihood distribution &lt;script type=&quot;math/tex&quot;&gt;p(x\vert z)&lt;/script&gt; 에 파라미터를 아웃풋으로 내보낸다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local latent variables (지역 숨겨진 변수)&lt;/strong&gt;: 이것은 각 datapoint &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; 에 대한 &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; 이다.
Global latent variable 은 존재하지 않는다. Local latent variable 만 존재하기 때문에 우리는 쉽게 ELBO 를 단일 datapoint &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; 에만 의존적인 &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_i&lt;/script&gt; 로 분해 가능하다.
이는 곧 stochastic gradient descent 를 가능하게 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mean-field versus amortized inference&lt;/strong&gt;: Mean-field variational inference 에선 각 datapoint &lt;script type=&quot;math/tex&quot;&gt;\lambda_i&lt;/script&gt; 에 대한 파라미터들이 존재한다 (e.g. Gaussian latent variable 의 &lt;script type=&quot;math/tex&quot;&gt;\lambda_i = (\mu_i, \sigma_i)&lt;/script&gt;).
VAE 에선 전역 파라미터들(이 경우엔 inference network 의 파라미터 &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;)이 존재하는 &lt;strong&gt;amortized inference&lt;/strong&gt; 를 사용한다.
이 전역 파라미터들은 모든 datapoint 에서 공유한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inference&lt;/strong&gt;: 뉴럴넷에서 inference 는 보통 한번도 보지 못한 datapoint 에 대한 숨겨진 차원을 추측하는 것을 의미한다.
확률 모델에선 관측된 데이터에 대해 숨겨진 변수 값을 추측하는 것을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sample-implementation&quot;&gt;Sample implementation&lt;/h3&gt;

&lt;p&gt;이 글에 쓰인 결과들을 생성하기 위해 사용한 코드를 공유한다: &lt;a href=&quot;https://github.com/altosaar/vae/blob/master/vae.py&quot;&gt;Github link&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;각주-재파라미터화reparametrization-요령&quot;&gt;각주: 재파라미터화(reparametrization) 요령&lt;/h3&gt;

&lt;p&gt;마지막으로 우리가 VAE 에 구현해야할 것은 어떻게 통계학적 변수로부터 도함수를 구할 것인가이다.
우리가 &lt;script type=&quot;math/tex&quot;&gt;q_\theta(z\vert x)&lt;/script&gt; 로부터 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 를 받았고 &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; 에 대한 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 의 도함수를 알고 싶을때 어떻게 할 것인가?
샘플 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 는 고정값이지만, 우리는 본능적으로 이것의 도함수가 0이 아님을 알 수 있다.&lt;/p&gt;

&lt;p&gt;몇몇 분포에 대해선 샘플을 영리하게 재파라미터화하여 확률성이 파라미터와 독립적으로 만들 수 있다.
우리는 샘플들이 결정론적으로 분포의 파라미터에 의존적이길 원한다.
예를 들어, 평균 &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; 와 분산 &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; 를 가지는 정규분포 변수에 대해 우리는 다음과 같이 샘플을 뽑을 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z = \mu + \sigma \odot \epsilon, (\epsilon \sim Normal(0, 1))&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\sim&lt;/script&gt; 에서 &lt;script type=&quot;math/tex&quot;&gt;=&lt;/script&gt; 로 부호가 바뀌는 것은 매우 중요한 과정이다.
우리는 파라미터에 대해 결정론적으로 의존적인 함수를 정의하였다.
따라서 우리는 &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;f(z)&lt;/script&gt; 를 포함하고 &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; 와 &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; 를 파라미터로 갖는 함수의 도함수를 얻을 수 있다.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;/assets/img/reparametrization.png&quot; /&gt;
    &lt;figcaption&gt;재파라미터화는 정규분포를 따르는 랜덤 변수 z 의 랜덤성을 정규분포에서 샘플로 얻은 epsilon 으로 보낸다. 다이아몬드는 결정론적인 의존관계를 의미하고 원은 랜덤 변수를 의미한다.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;VAE 에서 평균과 분산은 우리가 최적화하는 파라미터 &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; 를 가지는 inference network 의 아웃풋이다.
재파라미터화는 latent variables &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; 의 샘플들의 함수인 &lt;script type=&quot;math/tex&quot;&gt;ELBO&lt;/script&gt; 를 통해 &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; 에 대한 backpropagate 을 가능하게 한다.&lt;/p&gt;

&lt;h3 id=&quot;아이디어와-도표에-대한-레퍼런스&quot;&gt;아이디어와 도표에 대한 레퍼런스&lt;/h3&gt;

&lt;p&gt;많은 아이디어와 도표는 Shakir Mohamed 의 완벽한 블로그 글 &lt;a href=&quot;http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/&quot;&gt;재파라미터화&lt;/a&gt;와 &lt;a href=&quot;http://blog.shakirm.com/2015/03/a-statistical-view-of-deep-learning-ii-auto-encoders-and-free-energy/&quot;&gt;autoencoders&lt;/a&gt;로부터 얻었다.
Durk Kingma 는 &lt;a href=&quot;http://dpkingma.com/?page_id=277&quot;&gt;재파라미터화&lt;/a&gt;에 대한 멋진 시각화를 만들었다.
Variational inference 에 대한 좋은 레퍼런스는 이 &lt;a href=&quot;https://arxiv.org/abs/1601.00670&quot;&gt;튜토리얼&lt;/a&gt;과 David Blei 의 &lt;a href=&quot;https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf&quot;&gt;course notes&lt;/a&gt; 이다.
Dustin Tran 의 &lt;a href=&quot;http://dustintran.com/blog/denoising-criterion-for-variational-auto-encoding-framework/&quot;&gt;variational autoencoder&lt;/a&gt; 에 대한 블로그 글도 도움이 된다.
첫 부분의 MNIST gif 는 &lt;a href=&quot;https://github.com/RuiShu/variational-autoencoder&quot;&gt;Rui Shu&lt;/a&gt; 로부터 얻었다.&lt;/p&gt;

&lt;p&gt;Thanks to Rajesh Ranganath, Ben Poole, Cassandra Xia, and Ryan Sepassi for discussions and many concepts in this article.&lt;/p&gt;

&lt;p&gt;논의는 &lt;a href=&quot;https://news.ycombinator.com/edit?id=12292576&quot;&gt;Hacker News&lt;/a&gt; 와 &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/4xv5b5/explainer_of_variational_autoencoders_from_a/&quot;&gt;Reddit&lt;/a&gt; 에서 찾아볼 수 있다.&lt;/p&gt;
</description>
        
          <description>&lt;blockquote&gt;
  &lt;p&gt;Jaan Altosaar의 블로그 글 &lt;em&gt;What is variational autoencoder&lt;/em&gt; 를 허락하에 번역한 글입니다.
한글로 번역하기 어렵거나 영어로 두는 게 나은 단어들은 그대로 사용하였습니다.&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        
        <pubDate>Sat, 14 Jan 2017 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/what-is-variational-autoencoder/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/what-is-variational-autoencoder/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Natural language processing with RNN</title>
        <description>&lt;h3 id=&quot;nlp-&quot;&gt;NLP ?&lt;/h3&gt;

&lt;p&gt;NLP 란 인간이 발화하는 언어 현상을 기계적으로 분석해서 컴퓨터가 이해할 수 있는 형태로 만드는 자연 언어 이해 혹은 그러한 형태를 다시 인간이 이해할 수 있는 언어로 표현하는 제반 기술을 의미한다. (WIKI)&lt;/p&gt;

&lt;p&gt;언어의 특성을 분석하여 불변 알고리즘으로 처리하는 방법이 있고, 머신 러닝을 사용하되 아웃풋을 정해진 데이터에서 고르는 Statistical NLP 방법이 있고 마지막으로 RNN이나 DNN, 강화학습 등을 통해 아웃풋을 만드는 Generative Model 이 있다. 현재 state of the art 는 대부분 statistical NLP가 차지하고 있지만 기존 인풋들과 다른 형식의 인풋이 들어오면 아웃풋이 전혀 상관없는 값으로 튀게 되는 문제 등이 있다. Generative model은  최근 들어 computing power, deep learning의 발전과 LSTM, GRU 등 알고리즘의 발전이 이루어지면서 state of the art에 매우 근접한 성능을 내고 있으며 많은 주목을 받고 있다.&lt;/p&gt;

&lt;h3 id=&quot;rnn-&quot;&gt;RNN ?&lt;/h3&gt;

&lt;p&gt;Recurrent neural network는 기존 neural net의 고정 인풋 사이즈에 따른 고정 아웃풋 사이즈를 내뱉어야만 하는 한계를 극복하기 위해 만들어졌다. 뉴런들이 인풋 데이터 뿐만 아니라 이전 아웃풋까지 학습에 사용하므로서 단일 단계로 끝나는 것이 아니라 인풋이 끝날 때까지 단계를 반복한다. 가장 간단한 모형이 rnn은 n개의 토큰으로 이루어진 인풋이 들어온다면 n개의 아웃풋 토큰을 가지게 된다. 여러 단계를 거쳐 한 학습이 끝남에도 불구하고 weight과 bias를 공유하므로 기존 dnn 과 computing cost가 별 차이가 없다.&lt;/p&gt;

&lt;p&gt;임의의 n개의 인풋 토큰에 대해 임의의 m개의 아웃풋 토큰을 뱉고 싶을 때를 위해 seq2seq model 등의 알고리즘이 연구되었지만 기본 rnn을 n,m의 최댓값을 정하고 더 짧은 인풋, 아웃풋에 대해 빈칸을 특정 토큰으로 채우는 방식으로도 대처할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;lstm-gru-&quot;&gt;LSTM, GRU, …&lt;/h3&gt;

&lt;p&gt;기존 rnn의 가장 큰 문제 중 하나는 긴 인풋 사이즈에 취약하다는 것이다. 인풋 사이즈가 길어질수록 기억해야할 정보가 많아지는데 간단한 모형으로는 그게 쉽지 않았다. 그에 따라 LSTM, GRU 등의 좀 더 복잡한 형태의 hidden layer를 사용하는 알고리즘들이 개발되었고 좋은 성과를 보이고 있으며 최근 논문에서는 대부분 당연히 사용하는 추세이다.&lt;/p&gt;

&lt;h3 id=&quot;seq2seq-model&quot;&gt;seq2seq Model&lt;/h3&gt;

&lt;p&gt;기존 rnn의 또 다른 문제점 중 하나는 인풋을 끝까지 보지 못하고 각 단계에 아웃풋을 출력해야 했다는 점이다. 이를 극복하고 더 나아가 아예 인풋을 받는 encoder와 아웃풋을 내뱉는 decoder를 분리하여 두개의 rnn 모델을 사용하는 방법이 seq2seq model이다. 구글에 의해 제안되었으며 state of the art에 매우 근접한 성과를 내었다. Encoder, decoder를 나눠 변수가 두배나 많아졌지만 사실 더 좋은 성과를 내기 위해 많은 메모리, computing power를 사용하는 것은 불가피한 일인 것 같다. Decoder는 END 토큰이 나올 때까지 아웃풋을 출력한다.&lt;/p&gt;

&lt;p&gt;seq2seq model의 중요한 특징 중 한가지는 beam search decoder를 사용했다는 점인데 하나의 아웃풋을 출력하는 것이 아니라 각 단계에 Top n개의 아웃풋을 출력하므로서 대략 n^(아웃풋 길이)의 아웃풋에서 가장 확률이 높은 것을 선택하게 된다. 이 방법으로 이미 구글 메일에서 스마트 리플라이 기능을  지원하고 있으니 참 대단하다.&lt;/p&gt;

&lt;p&gt;Beam search decoder를 배우면서 느꼈던 의문점은 짧은 문장이 높은 확률을 가질 수 밖에 없는 구조이지 않은가였는데 인풋 길이가 길면 end 토큰이 나오는 시간도 늦춰지고 beam search length normalization을 통해 길이를 조정하는 것 같다.&lt;/p&gt;

&lt;h3 id=&quot;attention&quot;&gt;attention&lt;/h3&gt;

&lt;p&gt;Attention model은 메모리를 더 활용하여 사람처럼 특정 상황에 어떤 부분에 집중해야하는지를 기억하게 하는 방법이다. 각 인풋 토큰에 대해 attention variable이 존재하여 한 문장에서 어떤 부분에 집중해야 하는지를 각 아웃풋 토큰에 알려준다. 이 방법 또한 제안된 이후로 좋은 성과를 내고 있어 거의 모든 논문에 당연하게 사용되고 있다.&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;nlp-&quot;&gt;NLP ?&lt;/h3&gt;

</description>
        
        <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/nlp-with-rnn/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/nlp-with-rnn/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>daily blog 08/29</title>
        <description>&lt;h3 id=&quot;algorithm---탐욕법&quot;&gt;Algorithm - 탐욕법&lt;/h3&gt;

&lt;p&gt;탐욕법은 가장 직관적인 알고리즘 설계 패러다임이다. 탐욕법을 사용하는 경우는 크게 두 가지로 제한된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;탐욕법을 사용해도 항상 최적해를 구할 수 있는 문제의 경우, 탐욕법이 동적 계획법보다 수행 시간이 훨씬 빠르기 때문에 유용하다.&lt;/li&gt;
  &lt;li&gt;시간이나 공간적 제약으로 인해 다른 방법으로 최적해를 찾기 어렵다면 근사해를 찾는 용도로 쓰인다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;탐욕법의-증명&quot;&gt;탐욕법의 증명&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;탐욕적 선택 속성 (greedy choice property)&lt;/p&gt;

    &lt;p&gt;현 상태에서 답의 모든 부분을 고려하지 않고 탐욕적으로 선택하더라도 항상 최적해를 찾을 수 있음을 증명해야한다. 선택한 방법과 다르게 최적해를 구할 수 있다고 가정하고 우리가 선택한 방법이 최적해에 포함됨을 증명하는 방식을 주로 사용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;최적 부분 구조 (optimal substructure)&lt;/p&gt;

    &lt;p&gt;부분 문제의 최적해에서 전체 문제의 최적해를 만들 수 있음을 보여야 한다. 현 상태에서 다음 상태로 넘어간 후에도 탐욕법을 통해 최적해로 나아갈 수 있어야한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
        
          <description>&lt;h3 id=&quot;algorithm---탐욕법&quot;&gt;Algorithm - 탐욕법&lt;/h3&gt;

</description>
        
        <pubDate>Mon, 29 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/daily-blog-08-29/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/daily-blog-08-29/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>Convolutional Neural Network</title>
        <description>&lt;h3 id=&quot;deep-learning&quot;&gt;Deep learning&lt;/h3&gt;

&lt;p&gt;하나의 뉴런이 어떤 특정 feature를 학습한다고 이해하면 hidden layer의 깊이가 깊어질수록 알고리즘이 더 좋은 결과를 낼 것이라 생각할 수 있다.
대부분 인간이 이해하는 문제들은 복잡하고 여러 단계의 추상화를 거쳐 결론에 도달하므로 deep network가 더 좋은 결과를 내는 것은 상식적이다.&lt;/p&gt;

&lt;p&gt;문제는 신경망이 깊어질수록 학습시키기가 어렵다는 건데 이전에 언급한 unstable gradient 현상이 발생할 확률이 증가하기 때문이다.
따라서 좋은 결과를 얻기 위해선 단순히 fully-connected 된 deep network로는 어렵고 여러 방법들을 사용하게 되는데 image recognition 분야에서
가장 좋은 성과를 내고 있는 것은 바로 Convolutional neural network이다.&lt;/p&gt;

&lt;h3 id=&quot;convolutional-neural-networks&quot;&gt;Convolutional Neural Networks&lt;/h3&gt;

&lt;p&gt;CNN이 문제 해결에 접근하는 방식은 상당히 직관적이고 설득력 있다. Image의 경우 그 주변 pixel과의 관계가 어떤 image인 지 판단하는데 중요하다는 사실에서 착안한다.&lt;/p&gt;

&lt;h4 id=&quot;local-receptive-fields&quot;&gt;Local receptive fields&lt;/h4&gt;

&lt;p&gt;Pixel을 부분별로 나눠 판단하는 것에서부터 시작한다. 예로 5x5 크기의 정사각형 모양의 pixel 값들이 하나의 뉴런을 학습시킨다. 이 때, 이 pixel들은 공통의 weight을 사용하므로써
하나의 feature를 뉴런이 학습할 수 있도록 한다. 정사각형 단위를 옆으로 정해진 만큼 슬라이딩 시켜 그 다음 뉴런에 연결한다. 정사각형 변의 길이가 5, 슬라이딩 단위가 1라면 28x28 크기의
input layer는 24x24의 first hidden layer를 갖게 된다. 이를 하나의 feature를 얻는다고도 하며 적게는 3개, 많게는 20개가 넘게 feature를 얻기도 한다.&lt;/p&gt;

&lt;h4 id=&quot;max-pooling&quot;&gt;Max pooling&lt;/h4&gt;

&lt;p&gt;Local receptive fields를 통해 얻어진 layer에서 상대적으로 영향력이 쎈 뉴런들만 선택하여 learning saturation을 방지하는 방법이 max pooling이다. 2x2 단위로 적용하면
24x24의 layer는 12x12가 된다.&lt;/p&gt;

&lt;h4 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h4&gt;

&lt;p&gt;위 두 과정을 n번 (보통 &amp;lt;=3) 반복한 layer를 fully-connected 된 hidden layer에 연결하여 알고리즘을 완성시킨다. 뒤의 fully-connected된 부분이 이전과 모양이 같음을 생각하면
결국 앞의 처리 부분이 saturation을 줄이기 위한 input 사이즈 줄이기라고도 볼 수 있겠다. 다만 이 과정에도 학습과정이 포함 되므로 인간의 판단에 의한 feature를 설정하는게 아니라
학습된 feature를 설정하므로 보편성이 유지 된다.&lt;/p&gt;

&lt;h3 id=&quot;recent-progress-in-image-recognition&quot;&gt;Recent progress in image recognition&lt;/h3&gt;

&lt;p&gt;2016년 기준, MNIST 데이터에 대한 알고리즘의 정확도는 99.79까지 상승하였다. 틀린 답들의 경우, 인간도 구별하기 힘들 정도의 케이스라는 것을 생각하면 MNIST는 완전히 정복했다고 할 수 있겠다.&lt;/p&gt;

&lt;p&gt;더 복잡한 문제로는 ImageNet의 데이터를 classification 하는 것인데, 이 분야는 아직 완벽하지 않아서 가장 근접한 5개로 구별하기와 같은 방법을 쓰더라도 80% 정도의 정확도가 나온다. 연구마다
차이점은 있지만 대부분 공통적으로 back propagation, regularization, dropout, sgd 등의 방법을 쓴다.&lt;/p&gt;

&lt;h3 id=&quot;아직-갈-길이-멀다&quot;&gt;아직 갈 길이 멀다&lt;/h3&gt;

&lt;p&gt;처음 인공 신경망이란 아이디어가 나왔을 땐, 이를 통해 인간의 뇌를 이해하게 되는 것을 기대하였지만 현실은 인공 신경망조차 이해하지 못하고 있다. 연구가 발전하는 과정 또한
어떤 수학적 이론을 바탕으로한 결과물이 아니라 실제로 해 봤을 때 결과가 잘 나오는 것을 다들 택하는 식이다. 예를 들어, 많은 최근 연구들이 ReLu를 activation function으로 사용하는데,
다른 함수에 비해 속도가 빠름은 자명하지만 왜 좋은 퍼포먼스를 내는지는 이해하지 못하고 있다.&lt;/p&gt;

&lt;p&gt;결과 중심적인 연구 흐름은 긍정적일 순 없지만, 좋은 결과를 낸 방법을 바탕으로 새로운 중요한 근본적인 문제를 발견하고 이를 해결하는 방식으로 흐르고 있기 때문에 부정적일 것도 없다고 생각된다.
중요한 것은 neural net이 아직 그 한계가 발견되지 않았다는 것이며, 이를 통해 해결할 수 있는 문제가 너무나 많이 남았다는 것이다.&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;deep-learning&quot;&gt;Deep learning&lt;/h3&gt;

</description>
        
        <pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/cnn/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/cnn/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>daily blog 08/17</title>
        <description>&lt;h3 id=&quot;neural-network&quot;&gt;Neural Network&lt;/h3&gt;

&lt;h4 id=&quot;visual-proof-that-neural-net-can-solve-any-function&quot;&gt;Visual proof that neural net can solve any function&lt;/h4&gt;

&lt;p&gt;Neural net이 모든 함수를 풀 수 있음을 증명하는 것은 수학식을 통해서도 가능하지만 그래프를 통한 설명도 가능하다.
Hidden layer의 두 뉴런을 하나의 쌍으로 이용하면 2차원 그래프 상에 step function을 만들 수 있다.
뉴런을 쌍으로 늘려가며 그래프를 근사하면 원하는 오차값 이하로 그래프를 따라 그릴 수 있다.
더 고차원의 그래프 또한 2차원 그래프를 근사하는 것의 확장된 방법으로 가능하다.&lt;/p&gt;

&lt;p&gt;정확히 말하면 완벽히 똑같은 함수를 만들기는 불가능하지만 원하는 오차 아래로 모든 함수를 만들 수 있음은 충분히 강력한 특성이다. 
어떤 함수 f가 주어지면 이 값은 0~1 사이의 값을 갖지만 이를 sigmoid 함수의 역함수를 곱해 근사 함수를 만듬을 증명 가능하다.&lt;/p&gt;

&lt;h4 id=&quot;deep-neural-network는-왜-학습하기-어려운가&quot;&gt;Deep neural network는 왜 학습하기 어려운가&lt;/h4&gt;

&lt;p&gt;deep circuit이 어떤 함수를 더 잘 설명할 수 있다는 것은 증명 되어있다. 어려운 점은 깊이가 깊어질수록 학습시키기가 어렵다.
문제 중 하나는 unstable gradients 인데, 크게 두 가지 경우가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;vanishing gradient&lt;/li&gt;
  &lt;li&gt;exploding gradient&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Exploding gradient는 안 일어난다고 가정할 수는 없지만 일어날 확률이 vanishing gradient에 비해 현저히 낮다.
Vanishing gradient는 앞 쪽 layer가 학습이 잘 안되는 현상으로, 앞 쪽 layer의 뉴런들의 학습 기울기가 이전 weight, sigmoid 기울기에 비례하는데
이 값이 1 이하일 확률이 높아 앞 쪽으로 갈 수록 점점 값이 작아져서 일어난다.&lt;/p&gt;

&lt;p&gt;이 문제를 해결하기 위해 sigmoid 함수 대신 다른 activation function을 쓰거나, weight initialization을 적절히 잘하는 방법을 쓰거나
등등의 방법을 사용한다.&lt;/p&gt;

&lt;p&gt;unstable gradient만이 deep neural network의 문제는 아니고 여러 다른 문제들이 존재하는데 다음 챕터에서 이를 해결하고 작동하는 neural net을 만들어 볼 것이다.&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;neural-network&quot;&gt;Neural Network&lt;/h3&gt;

</description>
        
        <pubDate>Wed, 17 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/daily-blog-08-17/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/daily-blog-08-17/</guid>
        
        <category>daily blog</category>
        
        <category>neural network</category>
        
        
      </item>
      
    
      
      <item>
        <title>Mac에서 python 환경설정하기</title>
        <description>&lt;p&gt;Mac에서 Python 환경설정 할 때마다 까먹어서 암걸린다..&lt;/p&gt;

&lt;p&gt;적어놔서 다음부턴 보고서 해야지 ㅠㅠ&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;pip-2.7 or python2.7 install pip 이용하기&lt;/li&gt;
  &lt;li&gt;Mac의 default python을 사용하면 안된다. 경로는 /usr/local/lib&lt;/li&gt;
  &lt;li&gt;easy_install, pip를 바로 가져다쓰면 default 경로에 다운된다.&lt;/li&gt;
  &lt;li&gt;MacPorts를 쓰고 있으므로 pip-2.7, python2.7 써서 /opt/local/Library에 설치되도록 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;끝!&lt;/p&gt;
</description>
        
          <description>&lt;p&gt;Mac에서 Python 환경설정 할 때마다 까먹어서 암걸린다..&lt;/p&gt;

</description>
        
        <pubDate>Mon, 08 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/mac-python-configuration/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/mac-python-configuration/</guid>
        
        <category>python</category>
        
        
      </item>
      
    
      
      <item>
        <title>Retrofit2 + RxJava proguard 설정하기</title>
        <description>&lt;p&gt;이음소시어스 개발팀 블로그에 retrofit을 적용하면서 겪은 문제와 해결과정을 공유하였습니다 ㅎ&lt;/p&gt;

&lt;p&gt;개인 블로그에도 링크를 남깁니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://bigmatch.i-um.net/2016/08/retrofit2-rxjava-proguard-settings/&quot;&gt;Retrofit2 + RxJava proguard 설정하기&lt;/a&gt;&lt;/p&gt;

</description>
        
          <description>&lt;p&gt;이음소시어스 개발팀 블로그에 retrofit을 적용하면서 겪은 문제와 해결과정을 공유하였습니다 ㅎ&lt;/p&gt;

</description>
        
        <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/ium-post/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/ium-post/</guid>
        
        <category>ium</category>
        
        <category>android</category>
        
        
      </item>
      
    
      
      <item>
        <title>daily blog 08/02</title>
        <description>&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;

&lt;p&gt;Algorithm 의 내용은 대부분 ‘알고리즘 해결 전략’을 요약한 것입니다.&lt;/p&gt;

&lt;h3 id=&quot;동적-계획법&quot;&gt;동적 계획법&lt;/h3&gt;

&lt;p&gt;동적 계획법은 큰 의미에서 분할 정복과 같은 접근 방식을 의미한다.&lt;br /&gt;
이 문제의 답을 여러 번 계산하는 대신 한 번만 계산하고 계산 결과를 재활용함으로써 속도의 향상을 꾀할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;값을 저장해 두는 메모리의 장소를 캐시(cache)&lt;/li&gt;
  &lt;li&gt;중복되는 부분 문제(overlapping subproblems)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이와 같이 함수의 결과를 저장하는 장소를 마련해 두고, 한 번 계산한 값을 저장해 뒀다 재활용하는 최적화 기법을 메모이제이션(memoization)이라 부른다.&lt;/p&gt;

&lt;h4 id=&quot;참조적-투명성-referential-transparency&quot;&gt;참조적 투명성 (referential transparency)&lt;/h4&gt;

&lt;p&gt;함수의 반환 값이 그 입력 값만으로 결정되는지의 여부를 참조적 투명성이라 한다.&lt;/p&gt;

&lt;h4 id=&quot;구현-패턴&quot;&gt;구현 패턴&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;항상 기저 사례를 제일 먼저 처리&lt;/li&gt;
  &lt;li&gt;함수의 반환 값이 항상 0 이상이면 초기값을 -1로 설정&lt;/li&gt;
  &lt;li&gt;reference (&amp;amp;)의 사용으로 값의 변환과 저장을 한번에 함&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;시간-복잡도&quot;&gt;시간 복잡도&lt;/h4&gt;

&lt;p&gt;(존재하는 부분 문제의 수) X (한 부분 문제를 풀 때 필요한 반복문의 수행 횟수)&lt;/p&gt;

&lt;h4 id=&quot;완전-탐색과의-관계&quot;&gt;완전 탐색과의 관계&lt;/h4&gt;

&lt;p&gt;완전 탐색으로 답을 구할 때 흔히 가장 문제가 되는 것은, 원하는 답은 없는데 전체 답의 개수는 무지막지하게 많은 경우다.&lt;br /&gt;
동적 계획법을 사용하면 완전 탐색이 만드는 경로의 수가 매우 커도 불리는 함수의 경우의 수가 제한적이므로 비둘기집의 원리에 의해 중복으로 해결되는 문제가 항상 존재한다.&lt;/p&gt;

&lt;h4 id=&quot;최적-부분-구조&quot;&gt;최적 부분 구조&lt;/h4&gt;

&lt;p&gt;탐색 과정에서 지금까지의 경로와 무관하게 현재 부분 문제를 해결할 수 있으면 이를 최적 부분 구조를 갖는다고 한다.&lt;br /&gt;
대부분 직관적이라 따로 증명이 필요하지 않지만 그렇지 않은 경우 귀류법, 대우로 증명하게 된다.&lt;/p&gt;

&lt;p&gt;=&amp;gt; 최적 부분 구조를 만족하는 부분 문제로 잘 나누는 능력이 동적 계획법을 잘하는 방법이다!&lt;/p&gt;
</description>
        
          <description>&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;

</description>
        
        <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/daily-blog-08-02/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/daily-blog-08-02/</guid>
        
        
      </item>
      
    
      
      <item>
        <title>daily blog 07/28</title>
        <description>&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;

&lt;h4 id=&quot;분할-정복&quot;&gt;분할 정복&lt;/h4&gt;

&lt;p&gt;가장 유명한 알고리즘 디자인 패러다임, 한 마디로 설명하면 각개 격파!&lt;/p&gt;

&lt;p&gt;총 3단계로 알고리즘을 정의할 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;문제를 더 작은 문제로 분할하는 과정 (divide)&lt;/li&gt;
  &lt;li&gt;각 문제에 대해 구한 답을 원래 문제에 대한 답으로 병합 (merge)&lt;/li&gt;
  &lt;li&gt;더이상 답을 분할하지 않고 곧장 풀 수 있는 매우 작은 문제 (base case)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;시간복잡도는 divide, merge에 지배적이다.&lt;/p&gt;

&lt;p&gt;ex ) merge sort, quick sort, 카라츠바의 빠른 곱셈 알고리즘&lt;/p&gt;

&lt;h4 id=&quot;문제-풀이-팁&quot;&gt;문제 풀이 팁&lt;/h4&gt;

&lt;p&gt;string이나 배열을 다루며 재귀 호출을 통해 문제를 해결하려 할 때, 함수에 필요한 범위만큼 잘라 인자로 넣는 방법도 있지만&lt;br /&gt;
그보다 iterator를 사용해 필요한 만큼 가져다 쓰면 깔끔하게 코드를 작성할 수 있다.&lt;/p&gt;

&lt;p&gt;Thread나 process 기반 concurrency issue가 없기 때문에 재귀 호출을 하더라도 iterator는 하나씩 전진한다는 사실을 기억하자.&lt;/p&gt;

&lt;h3 id=&quot;tdd&quot;&gt;TDD&lt;/h3&gt;

&lt;h4 id=&quot;tdd-란&quot;&gt;TDD 란?&lt;/h4&gt;

&lt;p&gt;Test-Driven Development 의 약자.&lt;br /&gt;
테스트 작성 - 코드 작성 - 리팩토링 의 사이클을 매우 짧게 반복하여 개발하는 프로세스.&lt;br /&gt;
‘테스트를 어떻게 할 것인가?’ 를 생각하므로서 코드 구조에 대해 고민하고 버그 발생 확률을 낮춘다.&lt;/p&gt;

&lt;p&gt;TDD가 쓸데없는 오버헤드가 아니라 실용적이려면 단순히 테스트를 작성하는게 아니라 사고방식을 테스트로부터 시작하는 법을 익혀야겠다는 생각이 든다.&lt;br /&gt;
여러 방식을 직접 적용해보면서 점점 발전시켜 나갈 계획이다.&lt;/p&gt;

&lt;h4 id=&quot;android-app-에서의-tdd&quot;&gt;Android App 에서의 TDD&lt;/h4&gt;

&lt;p&gt;Android App 처럼 UI 중심의 프로젝트는 TDD를 적용시키기가 까다로운 듯 하다.&lt;br /&gt;
특히 지금 작업 중인 앱의 경우 비즈니스 로직이 서버에서 거의 다 이루어지고 있어 UI Testing 외에는 할 수 있는 테스트가 적다.&lt;/p&gt;

&lt;p&gt;하지만 B2C 서비스의 경우, UI가 자주 바뀌기 때문에 테스트의 재활용성이 너무 낮을 뿐더러 오버헤드가 너무 크다고 느꼈다.&lt;br /&gt;
그러면 유일하게 테스트가 필요한 곳은 ‘API 통신 후 데이터에 반영이 잘 됐는가’, ‘데이터에 의한 process decision’이 남는다.&lt;/p&gt;

&lt;p&gt;이 두 영역에 대한 TDD 실험을 진행하려 한다. TDD를 실제로 진행해보는게 처음이라 여러가지 실험을 해보면서 어떤 방법이 효율적인지 배우는 시간이 필요하다.&lt;/p&gt;

&lt;p&gt;다음과 같은 Testing Tool을 쓰려한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JUnit&lt;/li&gt;
  &lt;li&gt;Mockito&lt;/li&gt;
  &lt;li&gt;Robolectric&lt;/li&gt;
  &lt;li&gt;Mock Web Server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;기본적으로 JUnit을 통해 테스트를 작성하고 서버사이드는 Mocking하고 Robolectric을 통해 View와의 interaction을 확인하려한다.&lt;/p&gt;

</description>
        
          <description>&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;

</description>
        
        <pubDate>Thu, 28 Jul 2016 00:00:00 +0000</pubDate>
        <link>http://nolsigan.com/blog/daily-blog-07-28/</link>
        <guid isPermaLink="true">http://nolsigan.com/blog/daily-blog-07-28/</guid>
        
        
      </item>
      
    
  </channel>
</rss>
