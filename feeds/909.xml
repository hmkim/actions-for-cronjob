<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Storyteller</title>
    <description>Dreamgonfly's blog
</description>
    <link>https://dreamgonfly.github.io/</link>
    <atom:link href="https://dreamgonfly.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 28 Dec 2018 02:11:16 +0000</pubDate>
    <lastBuildDate>Fri, 28 Dec 2018 02:11:16 +0000</lastBuildDate>
    <generator>Jekyll v3.7.4</generator>
    
      <item>
        <title>쉽게 씌어진 GAN</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;이 글은 &lt;a href=&quot;https://www.imaso.co.kr/archives/1301&quot;&gt;마이크로소프트웨어 391호 인공지능의 체크포인트(THE CHECKPOINT OF AI)&lt;/a&gt;에 ‘쉽게 쓰이는 GAN’이라는 제목으로 기고된 글입니다. 블로그에는 이 글의 원제이자 윤동주 시인의 &lt;a href=&quot;https://namu.wiki/w/%EC%89%BD%EA%B2%8C%20%EC%94%8C%EC%96%B4%EC%A7%84%20%EC%8B%9C&quot;&gt;‘쉽게 씌어진 시’&lt;/a&gt;를 따라 지어진 제목인 ‘쉽게 씌어진 GAN’으로 포스팅합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;페이스북 인공지능 연구팀의 리더이자 딥러닝의 아버지라 불리는 얀 르쿤(Yann LeCun) 교수는 GAN(Generative Adversarial Network)을 가리켜 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어라고 말했다. 요즘 가장 주목받는 기술인 딥러닝 중에서도 GAN은 가장 많은 관심을 받고 있는 기술이다. 그만큼 GAN은 새로운 연구가 활발히 이루어지고 혁신이 빠르게 일어나고 있는 기술이기도 하다. GAN을 활용해 이전에 없었던 서비스나 제품이 출시되고 우리 삶에 깊숙이 자리 잡을 날도 얼마 남지 않은 듯이 보인다. 이 글에서 GAN이란 무엇인지 소개하고 간단한 튜토리얼을 통해 작동 원리를 이해해보자. 또한, GAN에 어떤 종류가 있는지 살펴보고 그 가능성과 한계에 대해서 알아보자.&lt;/p&gt;

&lt;h1 id=&quot;gan이란&quot;&gt;GAN이란?&lt;/h1&gt;

&lt;p&gt;GAN은 ‘Generative Adversarial Network’의 약자다. 이 세 글자의 뜻을 풀어보는 것만으로도 GAN에 대한 전반적으로 이해할 수 있다. 첫 단어인 ‘Generative’는 GAN이 생성(Generation) 모델이라는 것을 뜻한다. 생성 모델이란 ‘그럴듯한 가짜’를 만들어내는 모델이다. 언뜻 보면 진짜 같은 가짜 사람 얼굴 사진을 만들어내거나 실제로 있을 법한 고양이 사진을 만들어내는 것이 생성 모델의 예다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RKVJ9TP/_______________1.png?pub_secret=4674d81e77&quot; alt=&quot;그림1: GAN으로 생성한 가짜 사람 얼굴 이미지&quot; /&gt;&lt;/p&gt;

&lt;p&gt;‘그럴듯하다’라는 것을 어떻게 정의할 수 있을까? 수학적으로는 실제 데이터의 분포와 비슷한 분포에서 나온 데이터를 실제와 비슷하다고 말할 수 있다. 예를 들어, 어떤 사람이 키는 172cm이고 몸무게는 68kg이라고 하면 그럴듯하지만, 키는 190cm이고 몸무게는 40kg이라고 하면 현실적으로 그럴듯하지 않을 것이다. 190cm와 40kg이라는 키와 몸무게의 조합은 실제 데이터 분포에서는 거의 나오지 않는 조합이기 때문이다. 그럴듯한 키와 몸무게 조합을 만들어 내려면 실제 키와 몸무게의 분포를 최대한 비슷하게 따라야 한다. 이처럼 수학적으로 생성 모델의 목적은 실제 데이터 분포와 근사한 것이라고 말할 수 있다.&lt;/p&gt;

&lt;p&gt;키와 몸무게의 생성 모델을 만드는 것은 비교적 쉬운 문제다. 사람 얼굴이나 고양이 사진의 생성
모델을 만드는 것은 더 어려운 문제다. 이미지는 변수의 수가 훨씬 더 많기 때문이다. 이미지의 크기가 256 x 256 픽셀이라면 RGB 컬러값까지 총 256 x 256 x 3개의 변수가 생긴다. 그 변수들의 어떤 조합은 사람 얼굴처럼 보이지만, 어떤 조합은 그렇지 않다. 얼굴 이미지의 생성 모델을 만들겠다는 것은 사람 얼굴처럼 보이는 픽셀값 조합의 분포를 찾아내겠다는 것이다. 물론 이는 키와 몸무게 두가지 변수의 조합보다 어려운 문제다. 하지만 딥러닝의 발전으로 이런 생성 문제들이 점점 더 도전해 볼만한 주제들이 되고 있다.&lt;/p&gt;

&lt;p&gt;GAN의 두번째 단어인 ‘Adversarial’은 GAN이 두 개의 모델을 적대적(Adversarial)으로 경쟁시키며 발전시킨다는 것을 뜻한다. 위조지폐범과 경찰을 생각해보자. 이 둘은 적대적인 경쟁 관계다. 위조지폐범은 경찰을 속이기 위해 점점 지폐 위조 제조 기술을 발전시키고, 경찰은 위조지폐범을 잡기 위해 점점 위폐를 찾는 기술을 발전시킨다. 시간이 흐르면 위조지폐범의 위폐 제조 기술은 완벽에 가깝게 발전할 것이다.&lt;/p&gt;

&lt;p&gt;이처럼 GAN은 위조지폐범에 해당하는 생성자(Generator)와 경찰에 해당하는 구분자(Discriminator)를 경쟁적으로 학습시킨다. 생성자의 목적은 그럴듯한 가짜 데이터를 만들어서 구분자를 속이는 것이며, 구분자의 목적은 생성자가 만든 가짜 데이터와 진짜 데이터를 구분하는 것이다. 이 둘을 함께 학습시키면서 진짜와 구분할 수 없는 가짜를 만들어내는 생성자를 얻을 수 있다. 이것이 GAN의 핵심적인 아이디어인 적대적 학습(Adversarial Training)이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9SHTP6F9/picture2.png?pub_secret=6821873e68&quot; alt=&quot;그림2: 생성자 – 구분자 도식&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GAN의 마지막 단어 ‘네트워크(Network)’는 이 모델이 인공신경망(Artificial Neural Network) 또는 딥러닝(Deep Learning)으로 만들어졌기 때문에 붙었다. 이 글에서는 ‘인공신경망’과 ‘딥러닝’을 구분 없이 사용하겠다. 사실 적대적 학습이라는 개념을 구현하기 위해 반드시 딥러닝을 써야 하는 것은 아니다. 하지만 알파고 등 여러 사례에서 볼 수 있듯이 딥러닝은 강력한 머신러닝 모델을 가능하게 만드는 기술이다. 딥러닝이 이런 힘을 갖게 된 비결을 비선형 활성 함수(non-Linear Activation Function)와 계층(Hierarchy) 구조, 그리고 역전파(Backpropagation)의 원리를 통해 간단하게 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RGC95AN/picture3.png?pub_secret=8804cfbf83&quot; alt=&quot;그림3: 인공신경망 도식&quot; /&gt;&lt;/p&gt;

&lt;p&gt;널리 알려져 있다시피 인공신경망 알고리즘은 인간 뇌 속 뉴런의 행동 방식에 영감을 받아 만들어졌다. 이전 층(Layer)의 뉴런의 출력값에 가중치(Weights)나 매개 변수(Parameters)를 곱해 합한 것이 다음 층 뉴런의 입력값이 된다. 이 입력값에 활성 함수(Activation Function)라 불리는 비선형 함수를 적용시키면 선형 함수로 표현할 수 없는 복잡한 관계를 표현할 수 있게 된다. 딥러닝의 강력함은 이런 층들이 매우 깊게 쌓을 수 있다는 점에서 나온다. 층을 많이 쌓을수록 더욱 복잡한 함수를 표현할 수 있는 힘(Representation Power)을 얻게 된다.&lt;/p&gt;

&lt;p&gt;딥러닝을 학습시킨다는 것은 최적의 가중치를 찾아간다는 것을 의미한다. 가중치는 처음에 랜덤으로 초기화되지만, 모델의 손실 함수(Loss Function)을 최소화시키는 방향으로 조금씩 업데이트된다. 이때 손실 함수 값이 역전파를 통해 각 층의 가중치에 전달되며 업데이트 방향과 크기를 결정한다. 이런 방식으로 가중치를 최적화하는 방식을 경사하강법(Gradient Descent)이라고 부른다.&lt;/p&gt;

&lt;p&gt;딥러닝은 이론적으로 어떤 함수도 근사할 수 있는 함수(Global Function Approximator)라는 것이 알려져 있다. 이것이 딥러닝이 개와 고양이 사진을 분류하는 문제에서부터 영어를 한국어로 번역하고, 이세돌 9단을 이기는 바둑 알고리즘을 만드는 데까지 널리 쓰이는 이유다. GAN은 실제 데이터 분포를 근사하는 함수를 만들기 위해 이러한 딥러닝 구조를 활용한다.&lt;/p&gt;

&lt;p&gt;요약하자면 GAN은 생성이라는 문제를 풀기 위해 딥러닝으로 만들어진 모델을 적대적 학습이라는 독특한 방식으로 학습시키는 알고리즘이다. 이처럼 ‘Generative Adversarial Network’라는 이름 속에는 모델의 목적부터 학습 방법까지 GAN의 전반적인 개념이 모두 들어있다.&lt;/p&gt;

&lt;h1 id=&quot;gan-직접-만들어보기&quot;&gt;GAN 직접 만들어보기&lt;/h1&gt;

&lt;p&gt;이제 앞서 설명한 개념들이 코드를 통해 어떻게 구현되는지 살펴보자. 구현에는 딥러닝 프레임워크인 파이토치(PyTorch)를 이용한다. 파이토치는 페이스북이 주도해서 개발하는 딥러닝 프레임워크로 파이썬스럽게(Pythonic) 설계됐기 때문에 다른 프레임워크에 비해 비교적 코드가 간결하고, 디버깅이 쉬워서 연구용으로 인기가 높다. 물론 각 프레임워크마다 장단점이 있지만 여기에서는 직관적인 설명과 이해를 위해 파이토치로 GAN을 구현해보자.&lt;/p&gt;

&lt;p&gt;GAN으로 풀어볼 문제는 0부터 9까지 숫자 모양의 손글씨 이미지를 생성하는 문제다. MNIST(Mixed National Institute of Standards and Technology)라 불리는 숫자 손글씨 데이터셋은 딥러닝 계의 ‘Hello World’라고 불릴 정도로 널리 쓰이는 데이터셋이다. 비교적 간단한 문제지만 여기에서 쓰인 GAN의 원리는 어떤 문제에도 동일하게 적용되기 때문에 유용한 예제가 될 것이다. 파이토치에서는 MNIST 데이터셋을 쉽게 불러와 사용할 수 있는 방법을 제공한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;전체 코드는 github.com/dreamgonfly/GAN-tutorial 에서 볼 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드1&amp;gt; 라이브러리 및 데이터 불러오기&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.autograd&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#데이터 전처리 방식을 지정한다.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 데이터를 파이토치의 Tensor 형식으로바꾼다.&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 픽셀값 0 ~ 1 -&amp;gt; -1 ~ 1&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#MNIST 데이터셋을 불러온다. 지정한 폴더에 없을 경우 자동으로 다운로드한다.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#데이터를 한번에 batch_size만큼만 가져오는 dataloader를 만든다.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;GAN의 2가지 요소인 생성자와 구분자 중 생성자(Generator)를 먼저 만들어보자. 생성자는
랜덤 벡터 ‘z’를 입력으로 받아 가짜 이미지를 출력하는 함수다. 여기서 ‘z’는 단순하게 균등 분포(Uniform Distribution)나 정규 분포(Normal Distribution)에서 무작위로 추출된 값이다. 생성자는 이렇게 단순한 분포를 사람 얼굴 이미지와 같은 복잡한 분포로 매핑(Mapping)하는 함수라고 볼 수 있다. 생성자 모델에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다는 것이 알려져 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RFJ3VDJ/picture4.png?pub_secret=da0323f283&quot; alt=&quot;그림4: 생성자는 단순한 분포를 복잡한 분포로 매핑하는 함수다.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;‘z’ 벡터가 존재하는 공간을 잠재 공간(Latent Space)이라고도 부른다. 여기서는 잠재
공간의 크기를 임의로 100차원으로 뒀다. 잠재 공간의 크기에는 제한이 없으나 나타내려고 하는 대상의 정보를 충분히 담을 수 있을 만큼은 커야 한다. GAN은 우리가 이해할 수는 없는 방식이지만 ‘z’ 벡터의 값을 이미지의 속성에 매핑시키기 때문이다. 뒤에 살펴볼 GAN의 파생 모델에서
잠재 공간의 의미를 더욱 자세히 이해할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;생성자에 충분한 수의 매개 변수를 확보하기 위해, 이 구현에서는 4개의 선형 레이어(Linear
Layer, Fully Connected Layer, Linear Transformation)를 쌓아서 생성자를 만들었다. 선형 레이어는 속해있는 모든 뉴런이 이전 레이어의 모든 뉴런과 연결되는 가장 단순한 구조의 레이어다. 이 모델에서는 100차원의 랜덤 벡터를 받아 이를 256개의 뉴런을 가진 레이어로 보내고, 다시 레이어의 크기를 512, 1024로 점점 증가시켰다. 마지막에는 출력을 MNIST 이미지의 크기로 맞추기 위해 레이어 크기를 28x28로 줄였다.&lt;/p&gt;

&lt;p&gt;각 레이어마다 활성 함수로는 LeakyReLU를 이용했다. LeakyReLU는 각 뉴런의 출력값이
0보다 높으면 그대로 놔두고, 0보다 낮으면 정해진 작은 숫자를 곱하는 간단한 함수다. 여기서는 0.2를 곱했다. 이밖에도 활성 함수로는 ReLU, Elu, Tanh, Sigmoid 등이 자주 쓰인다. 생성자의 마지막 레이어에서는 출력값을 픽셀값의 범위인 -1과 1 사이로 만들어주기 위해 Tanh를 사용했다.&lt;/p&gt;

&lt;p&gt;이렇게 여러 개의 레이어와 활성 함수를 쌓은 덕분에 MNIST의 데이터 분포를 근사할 수 있는
충분한 표현력(Representation Power)을 얻을 수 있었다. MNIST는 비교적 간단한 문제에 속하므로 더욱 복잡한 문제를 풀기 위해서는 더 깊은 레이어 구조와 더 많은 양의 매개 변수가 필요할 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드2&amp;gt; GAN의 생성자(Generator)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 생성자는 랜덤 벡터 z를 입력으로 받아 가짜 이미지를 출력한다.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# 네트워크 구조&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
  &lt;span class=&quot;c&quot;&gt;# (batch_size x 100) 크기의 랜덤 벡터를 받아 &lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# 이미지를 (batch_size x 1 x 28 x 28) 크기로 출력한다.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;구분자는 이미지를 입력으로 받고 그 이미지가 진짜일 확률을 0과 1 사이의 숫자 하나로 출력하는 함수다. 구분자의 구현은 생성자와 마찬가지로 4개의 선형 레이어를 쌓았으며 레이어마다 활성 함수로 LeakyReLU를 넣어줬다. 입력값으로 이미지 크기인 28x28개의 변수를 받은 뒤 레이어의 크기가 28x28에서 1024로, 512로, 256으로 점차 줄어들다. 마지막에는 확률값을 나타내는 숫자 하나를 출력한다.&lt;/p&gt;

&lt;p&gt;레이어마다 들어간 드롭아웃(Dropout)은 학습 시에 무작위로 절반의 뉴런을 사용하지 않도록
한다. 이를 통해 모델이 과적합(Overfitting, 오버피팅)되는 것을 방지할 수 있고, 또한 구분자가 생성자보다 지나치게 빨리 학습되는 것도 막을 수 있다. 구분자의 마지막 레이어에서는 출력값을 0과 1 사이로 만들기 위해 활성 함수로 Sigmoid를 넣었다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드3&amp;gt; GAN의 구분자(Discriminator)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 구분자는 이미지를 입력으로 받아 이미지가 진짜인지 가짜인지 출력한다.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
&lt;span class=&quot;c&quot;&gt;# 네트워크 구조&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
  &lt;span class=&quot;c&quot;&gt;# (batch_size x 1 x 28 x 28) 크기의 이미지를 받아&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# 이미지가 진짜일 확률을 0~1 사이로 출력한다.&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드4&amp;gt; 생성자와 구분자 객체 만들기&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제부터는 이렇게 만들어진 네트워크 구조를 학습하는 방법에 대해 알아보자. 학습하기 위해서는 모델을 평가할 수 있어야 한다. 모델의 평가 지표가 좋아지는 방향으로 매개 변수를 업데이트할 것이기 때문이다. 구분자의 출력값은 이미지가 진짜일 확률이고, 이 확률이 얼마나 정답과 가까운지를 측정하기 위해 바이너리 크로스 엔트로피(Binary cross entropy) 손실 함수(loss
function)를 사용한다. 이 함수는 구분자가 출력한 확률값이 정답에 가까우면 낮아지고 정답에서 멀면 높아진다. 이 손실 함수의 값을 낮추는 것이 모델 학습의 목표가 된다.&lt;/p&gt;

&lt;p&gt;이제 생성자와 구분자의 매개 변수를 업데이트하는 최적화 함수가 각각 하나씩 필요하다. 최적화
기법에는 여러 종류가 있지만 여기서는 가장 널리 쓰이는 기법인 아담(Adam)을 사용했다. 아담은 매개 변수마다 업데이트 속도를 최적으로 조절하는 효율적인 최적화 기법이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드5&amp;gt; 손실 함수와 최적화 기법 지정하기&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Binary Cross Entropy loss&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 생성자의 매개 변수를 최적화하는 Adam optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 구분자의 매개 변수를 최적화하는 Adam optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모델 학습을 위해서 전체 데이터셋을 여러 번 돌며 매개 변수를 조금씩 업데이트한다. 데이터셋을 한 번 도는 것을 1 에폭(Epoch)이라고 부르는데, 여기서는 100 에폭 동안 학습할 것이다. 각 에폭마다 배치 사이즈(Batch Size)인 60개만큼 데이터를 가져와서 모델을 학습시킨다. MNIST 학습 데이터의 개수가 6만개이니 1에폭마다 1000번씩 학습이 이루어지는 셈이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드6&amp;gt; 모델 학습을 위한 반복문&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 데이터셋을 100번 돌며 학습한다.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# 한번에 batch_size만큼 데이터를 가져온다.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
  &lt;span class=&quot;c&quot;&gt;# 데이터를 파이토치의 변수로 변환한다.&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;real_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# ...(중략)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;먼저 구분자를 학습시켜보자. 구분자는 진짜 이미지를 입력하면 1에 가까운 확률값을 출력하고, 가짜 데이터를 입력하면 0에 가까운 확률값을 출력해야 한다. 따라서 구분자의 손실 함수는 두 가지의 합으로 이루어진다. 진짜 이미지를 입력했을 때의 출력값과 1과의 차이, 그리고 가짜 이미지를 입력했을 때의 출력값과 0과의 차이, 두 경우의 합이 구분자의 손실 함수다. 이 손실 함수의 값을 최소화하는 방향으로 구분자의 매개 변수가 업데이트된다.&lt;/p&gt;

&lt;p&gt;파이토치에서는 간단한 방법으로 역전파를 통해 계산된 각 변수의 미분 값을 구할 수 있다. 그 상태에서 최적화 함수를 실행시키면 매개 변수가 한번 업데이트된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드7&amp;gt; 구분자 학습시키기&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 이미지가 진짜일 때 정답 값은 1이고 가짜일 때는 0이다.&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 정답지에 해당하는 변수를 만든다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 진짜 이미지를 구분자에 넣는다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_result_from_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_loss_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_result_from_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자로 가짜 이미지를 생성한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fake_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자가 만든 가짜 이미지를 구분자에 넣는다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_result_from_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 구분자의 출력값이 정답지인 0에서 멀수록 loss가 높아진다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_loss_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_result_from_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 구분자의 loss는 두 문제에서 계산된 loss의 합이다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_loss_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_loss_fake&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 구분자의 매개 변수의 미분값을 0으로 초기화한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 역전파를 통해 매개 변수의 loss에 대한 미분값을 계산한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 최적화 기법을 이용해 구분자의 매개 변수를 업데이트한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로 생성자를 학습할 차례다. 생성자의 목적은 구분자를 속이는 것이다. 다시 말해 생성자가 만들어낸 가짜 이미지를 구분자에 넣었을 때 출력값이 1에 가깝게 나오도록 해야 한다. 이 값이 1에서 떨어진 정도가 생성자의 손실 함수가 되고, 이를 최소화 시키도록 생성자를 학습시키게 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드8&amp;gt; 생성자 학습시키기&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자로 가짜 이미지를 생성한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fake_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자가 만든 가짜 이미지를 구분자에 넣는다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;D_result_from_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자의 입장에서 구분자의 출력값이 1에서 멀수록 loss가 높아진다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_result_from_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 생성자의 매개 변수의 미분값을 0으로 초기화한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 역전파를 통해 매개 변수의 loss에 대한 미분값을 계산한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 최적화 기법을 이용해 생성자의 매개 변수를 업데이트한다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RGFUHBL/picture5.png?pub_secret=b83bb25199&quot; alt=&quot;그림5: 실제 MNIST 이미지&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RL0A4N9/picture6.png?pub_secret=3ae8b223da&quot; alt=&quot;그림6: GAN으로 생성한 MNIST 이미지&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지금까지 코드를 통해 GAN의 원리를 이해해봤다. 이제부터는 GAN이 발표된 이후로 나온 수많은 발전과 응용 중 가장 중요했던 모델들을 살펴보고 GAN으로 할 수 있는 여러 가지 일에 대해 알아보자.&lt;/p&gt;

&lt;h1 id=&quot;gan의-전성시대를-연-dcgandeep-convolutional-gan&quot;&gt;GAN의 전성시대를 연 DCGAN(Deep Convolutional GAN)&lt;/h1&gt;

&lt;p&gt;GAN은 학습이 불안정하기로 악명이 높다. 학습이 어렵다는 점은 GAN 모델이 다양한 곳에 응용되는 것을 가로막는 큰 장애물이었다. 이런 상황에서 수많은 실험 끝에 안정적인 학습이 가능한 GAN 모델의 구조를 찾아낸 것이 DCGAN이다.&lt;/p&gt;

&lt;p&gt;DCGAN의 특징은 몇 가지로 요약할 수 있다. 먼저, 선형 레이어와 풀링 레이어(Pooling
Layer)를 최대한 배제하고 합성곱(Convolution)과 ‘Transposed Convolution(Fractional-Strided Convolution)’으로 네트워크 구조를 만들었다. 풀링 레이어는 여러 딥러닝 모델에서 불필요한 매개변수의 수를 줄이고 중요한 특징만을 골라내는
역할을 하는 레이어지만 이미지의 위치 정보를 잃어버린다는 단점이 있다. 이미지를 생성하기 위해서는 위치 정보가 중요하기 때문에 DCGAN은 풀링 레이어를 배제했다. 선형 레이어 역시 마찬가지로 위치 정보를 잃어버리므로 모델의 깊은 레이어에서는 선형 레이어를 사용하지 않았다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9SHY37JT/picture7.png?pub_secret=a4ad9b1733&quot; alt=&quot;그림7: DCGAN의 생성자 네트워크 구조&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DCGAN의 또 다른 특징은 배치 정규화(Batch Normalization)를 사용했다는 점이다.
배치 정규화는 레이어의 입력 데이터 분포가 치우쳐져 있을 때 평균과 분산을 조정해주는 역할을 한다. 이는 역전파가 각 레이어에 쉽게 전달되도록 해 학습이 안정적으로 이뤄지도록 돕는 데 중요한 역할을 한다.&lt;/p&gt;

&lt;p&gt;이외에도 DCGAN은 수많은 실험을 통해 GAN을 학습시키는 가장 좋은 조건들을 찾아냈다.
DCGAN은 마지막 레이어를 제외하고 생성자의 모든 레이어에 ReLU를 사용했고, 구분자의 모든 레이어에 LeakyReLU를 사용했다. 또한, 가장 좋은 최적화 기법과 적절한 학습 속도(Learning Rate) 등을 찾아내기도 했다.&lt;/p&gt;

&lt;p&gt;DCGAN의 성공은 GAN 모델이 유명해지는 데 결정적인 역할을 했다. DCGAN에서 사용한
모델 구조는 아직도 새로운 GAN 모델을 설계할 때 베이스 모델이 되고 있다.&lt;/p&gt;

&lt;p&gt;DCGAN의 네트워크 구조는 기존 GAN에서 생성자와 구분자만 교체하는 것만으로 간단히 구현할 수 있다. DCGAN의 생성자는 GAN과 마찬가지로 랜덤 벡터 z를 받고 가짜 이미지를 생성하는 함수다. 다만 그 구현에서 ‘Transposed Convolution’과 배치 정규화 등을 사용한다는 점이 다르다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드9&amp;gt; DCGAN의 생성자&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
  &lt;span class=&quot;c&quot;&gt;# 네트워크 구조&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
  &lt;span class=&quot;c&quot;&gt;# (batch_size x 100) 크기의 랜덤 벡터를 받아 &lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# 이미지를 (batch_size x 1 x 28 x 28) 크기로 출력한다.&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DCGAN의 구분자도 GAN의 구분자와 입력과 출력이 동일하다. 단지 convolution 레이어와
배치 정규화 등을 사용한다는 차이점만 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# &amp;lt;코드10&amp;gt; DCGAN의 구분자&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
  &lt;span class=&quot;c&quot;&gt;# 네트워크 구조&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
  &lt;span class=&quot;c&quot;&gt;# (batch_size x 1 x 28 x 28) 크기의 이미지를 받아&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# 이미지가 진짜일 확률을 0~1 사이로 출력한다.&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DCGAN의 또 다른 혁신은 학습이 잘 이뤄졌는지 확인하기 위한 여러 가지 검증 방법을 도입했다는 점이다. 그 중 하나가 잠재 공간에 실제 데이터의 특성이 투영됐는지 살펴보는 것이다. 예를 들어 사람 얼굴을 생성하는 모델이 잘 학습되면 단순히 사람 얼굴을 잘 만들어내는 것뿐만 아니라 성별, 머리 색깔, 얼굴방향, 선글라스를 썼는지 여부 등 의미 있는 단위들이 잠재 공간에 드러나게 된다. 즉 생성자의 입력인 100차원짜리 ‘z’ 벡터의 값을 바꿔보는것으로 생성자의 출력인 이미지의 속성을 바꿔볼 수 있다는 것이다.&lt;/p&gt;

&lt;p&gt;예를 들어 잠재공간에서 얼굴 방향에 해당하는 특성을 찾아낼 수 있고, ‘z’ 벡터에서 이에 해당하는 값을 바꿈으로써 이미지에서 얼굴이 바라보고 있는 방향을 바꿔볼수 있다. 이것이 가능하다는 것은 생성자가 얼굴의 의미적인 속성을 학습했다는 것을 뜻한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9R06368H/picture8.png?pub_secret=f19a88da19&quot; alt=&quot;그림8: DCGAN에서 생성한 얼굴의 방향을 바꿔보기&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;이미지를-새로운-이미지로-변형하는-cgan&quot;&gt;이미지를 새로운 이미지로 변형하는 cGAN&lt;/h1&gt;

&lt;p&gt;때때로 이미지를 처음부터 생성하기보다 이미 있는 이미지를 다른 영역의 이미지로 변형하고 싶은 경우가 많다. 예를 들어, 스케치에 채색하거나, 흑백 사진을 컬러로 만들거나, 낮 사진을 밤 사진으로 바꾸고 싶을 때 등이다. ‘cGAN(Conditional GAN)’은 이를 가능케 해주는 모델이다.&lt;/p&gt;

&lt;p&gt;기존의 GAN의 생성자가 랜덤 벡터를 입력으로 받는 것에 비해 cGAN의 생성자는 변형할 이미지를 입력으로 받는다. 그 뒤 생성자는 입력 이미지에 맞는 변형된 이미지를 출력한다. 예를 들어 스케치 사진을 받은 생성자는 그 스케치에 맞는 색을 칠한 뒤 채색된 이미지를 출력하는 것이다. 구분자는 스케치와 채색된 이미지를 모두 보고 그 채색된 이미지가 과연 스케치에 어울리는지 판단한다. 구분자를 속이기 위해서 생성자는 첫째, 진짜 같은 이미지를 만들어야 하고 둘째, 스케치에 맞는 이미지를 만들어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9SBYT06A/picture9.png?pub_secret=fa4da6cab2&quot; alt=&quot;그림9: cGAN의 생성자와 구분자&quot; /&gt;&lt;/p&gt;

&lt;p&gt;cGAN의 혁신은 주어진 이미지를 새로운 이미지로 변형하는 수많은 문제를 하나의 간단한 네트워크 구조로 모두 풀었다는 점이다. 모든 문제는 이미지에서 의미적인 정보를 찾아내어 다른 이미지로 바꾸는 문제로 볼 수 있기 때문이다. 이렇게 한 영역의 이미지를 다른 영역의 이미지로 변형하는 문제의 경우 cGAN이 유용하게 쓰일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RFM1UKW/picture10.png?pub_secret=eb61f533e7&quot; alt=&quot;그림10: cGAN으로 가능한 이미지 처리 예시&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;다양한-종류의-gan&quot;&gt;다양한 종류의 GAN&lt;/h1&gt;

&lt;p&gt;앞서 소개한 모델 외에도 GAN의 성능을 높이고 새로운 분야에 응용하려는 다양한 종류의
GAN 모델이 있다. ‘WGAN(Wasserstein GAN)’은 GAN에서 실제 데이터 분포와 근사하는 분포가 얼마나 다른지 측정하는 거리 개념을 바꿔 안정적인 학습을 가능하게 만들었다. ‘EBGAN(Energy-based GAN)’은 GAN을 에너지 관점에서 바라봄으로써 역시 더 안정적인
학습을 추구했다. ‘BEGAN(Boundary Equilibrium GAN)’은 WGAN과 EBGAN을 발전시켜 생성하는 이미지의 퀄리티를 획기적으로 높이고 이미지의 퀄리티와 다양성을 컨트롤 할 수 있게 했다. 이 글의 처음에 있는 &lt;그림1&gt;의 실제 같은 사람 얼굴 이미지들이 BEGAN의 결과물이다.&lt;/그림1&gt;&lt;/p&gt;

&lt;p&gt;cGAN은 강력한 모델이지만 입력 이미지와 출력 이미지가 매칭된 데이터를 필요로 한다.
‘CycleGAN’과 ‘DiscoGAN’은 두 영역의 이미지 데이터셋이 매칭돼 있지 않아도 이미지 변형을 가능하게 하는 모델이다. 예를 들어 핸드백과 신발의 이미지 데이터셋이 있으면 이 두 영역 사이의 연결을 스스로 찾아내어 주어진 핸드백 이미지와 같은 스타일의 신발 이미지를 생성한다(CycleGAN과 DiscoGAN은 거의 동일한 구조를 갖고 있다). ‘StarGAN’은 이 아이디어를 확장시켜 세 개 이상의 영역 사이의 이미지 변형을 시도했다.&lt;/p&gt;

&lt;p&gt;GAN을 다양한 분야에 응용하려는 시도도 활발하다. 사진의 해상도를 높이는 ‘SRGAN(Super-Resolution GAN)’이나, 음성 녹음에서 노이즈를 줄여주는 ‘SEGAN(Speech Enhancement GAN)’을 예로 들 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F9RL21UGM/picture11.png?pub_secret=a59d54d636&quot; alt=&quot;그림11: 핸드백과 같은 스타일의 신발 이미지를 생성하는 DiscoGAN&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;gan의-한계점&quot;&gt;GAN의 한계점&lt;/h1&gt;

&lt;p&gt;GAN은 많은 기대를 받고 있는 모델이지만 아직 여러 가지 한계점도 존재한다. 앞서 소개한 많은 모델이 GAN의 학습을 안정화시키기 위해 노력했지만, 아직도 GAN을 실제로 적용하려 할 때 가장 큰 걸림돌은 학습이 어렵다는 점이다. GAN 학습이 잘 되기 위해서는 서로 비슷한 수준의 생성자와 구분자가 함께 조금씩 발전해야 한다. 그런데 한쪽이 너무 급격하게 강력해지면 이 관계가 깨져버려서 GAN의 학습이 이루어지지 않는다. 경찰이 너무 강력하면 위조지폐범의 씨가 말라버리는 것이다.&lt;/p&gt;

&lt;p&gt;GAN이 제대로 학습을 하지 못하고 있을 때 나타나는 모드붕괴(Mode Collapse)라는 현상이 있다. 이는 생성자가 다양한 이미지를 만들어내지 못하고 비슷한 이미지만 계속해서 생성하는 경우를 뜻한다. GAN을 학습시킬 때는 이런 모드 붕괴 현상이 벌어지지 않는지, 생성자와 구분자 중 한 쪽이 너무 강해지지 않는지 유의해야 한다.&lt;/p&gt;

&lt;p&gt;GAN의 학습이 너무 어려울 때는 ‘VAE(Variational Auto-Encoder)’라는 모델을 쓰는 것도 고려해 볼 수 있다. VAE는 생성 모델이라는 목적은 GAN과 같지만, GAN과는 다른 방식으로 동작한다. VAE는 GAN보다 학습이 좀 더 안정적이라는 점이 장점이지만, 흐릿한 이미지가 생성되는 블러(Blur) 현상이 있다고 알려져 있다.&lt;/p&gt;

&lt;p&gt;GAN의 또 다른 한계점은 아직 텍스트를 생성하는 데는 적용하기 어렵다는 점이다. 이미지나 음성 분야에서는 GAN의 성공 사례가 많이 있지만, 영어나 한국어 같은 자연어를 생성하는 문제에는 GAN의 성공 사례를 찾아보기 어렵다. 이는 텍스트가 이미지와 달리 불연속적이기 때문이다. 이미지는 실수값인 픽셀로 이루어져 있기 때문에 미분을 통해 조금씩 값을 바꿔보며 개선해 나갈 수 있다. 하지만 텍스트는 단어로 이뤄져 있기 때문에 이런 방식이 불가능하다. 물론 GAN으로 텍스트를 생성하려는 시도가 없었던 것은 아니지만, 아직 뚜렷한 성과는 내지 못하고 있다.&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;

&lt;p&gt;이안 굿펠로우(Ian Goodfellow)가 GAN을 처음 발표한 것은 2014년이다. 그 후 4년에 가까운 시간이 지나는 동안 GAN에는 수많은 발전이 있었다. 이제 GAN으로 사람 눈으로도 진짜와 구분하기 힘든 얼굴 이미지를 생성하고, 스케치에 채색을 입히고, 핸드백과 같은 스타일의 신발을 만들어낼 수 있다. 그러나 여전히 GAN은 태어난지 얼마 되지 않은 모델이고 앞으로 더욱 놀라운 결과물을 내는 모델들과 서비스들이 발표될 것이다. 이 글이 GAN이라는 혁신적인 모델을 이해하는 데 도움이 되고 인공 지능의 물결에 올라타는 발판이 됐으면 하는 바람이다.&lt;/p&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;GAN: https://arxiv.org/abs/1406.2661&lt;/p&gt;

  &lt;p&gt;DCGAN:https://arxiv.org/abs/1511.06434&lt;/p&gt;

  &lt;p&gt;cGAN:https://arxiv.org/abs/1611.07004&lt;/p&gt;

  &lt;p&gt;WGAN: https://arxiv.org/abs/1701.07875&lt;/p&gt;

  &lt;p&gt;EBGAN:https://arxiv.org/abs/1609.03126&lt;/p&gt;

  &lt;p&gt;BEGAN:https://arxiv.org/abs/1703.10717&lt;/p&gt;

  &lt;p&gt;CycleGAN:https://arxiv.org/abs/1703.10593&lt;/p&gt;

  &lt;p&gt;DiscoGAN:https://arxiv.org/abs/1703.05192&lt;/p&gt;

  &lt;p&gt;StarGAN:https://arxiv.org/abs/1711.09020&lt;/p&gt;

  &lt;p&gt;SRGAN:https://arxiv.org/abs/1609.04802&lt;/p&gt;

  &lt;p&gt;SEGAN: https://arxiv.org/abs/1703.09452&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2018/03/17/gan-explained.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2018/03/17/gan-explained.html</guid>
        
        <category>featured</category>
        
        
      </item>
    
      <item>
        <title>Conda 가상 환경으로 PyTorch 설치하기</title>
        <description>&lt;p&gt;PyTorch 설치가 어려울 때, conda 가상 환경 안에 PyTorch를 설치하면 깔끔하게 설치될 때가 많습니다. 이 글은 conda 가상 환경으로 PyTorch를 설치하고 Jupyter의 kernel로 등록하는 방법을 소개합니다. TensorFlow도 같은 방법으로 설치할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;windows&quot;&gt;Windows&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;새 가상 환경 만들기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; pytorch ipykernel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pytorch&lt;/code&gt; 대신 자신이 원하는 이름을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;가상 환경 안으로 들어가기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;activate pytorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;PyTorch 설치하기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; peterjc123 pytorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Jupyter에 새 kernel 등록하기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; ipykernel install &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; pytorch &lt;span class=&quot;nt&quot;&gt;--display-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;PyTorch&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--display-name&lt;/code&gt;은 Jupyter Notebook 위에서 표시될 kernel의 이름으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;PyTorch&quot;&lt;/code&gt; 대신 자신이 원하는 이름을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;가상 환경 빠져나오기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;macos--linux&quot;&gt;MacOS / Linux&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;새 가상 환경 만들기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; pytorch ipykernel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pytorch&lt;/code&gt; 대신 자신이 원하는 이름을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;가상 환경 안으로 들어가기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;activate pytorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;PyTorch 설치하기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; pytorch torchvision &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; pytorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Jupyter에 새 kernel 등록하기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; ipykernel install &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; pytorch &lt;span class=&quot;nt&quot;&gt;--display-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;PyTorch&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--display-name&lt;/code&gt;은 Jupyter Notebook 위에서 표시될 kernel의 이름으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;PyTorch&quot;&lt;/code&gt; 대신 자신이 원하는 이름을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;가상 환경 빠져나오기&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;jupyter에-등록된-kernel-확인하기&quot;&gt;Jupyter에 등록된 kernel 확인하기&lt;/h1&gt;

&lt;p&gt;이제 Jupyter Notebook에서 새 노트북을 만들 때 PyTorch kernel을 선택할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F901YJLAV/_______________.png?pub_secret=0974008d7a&quot; alt=&quot;Jupyter Notebook에 등록된 PyTorch kernel&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;해설&quot;&gt;해설&lt;/h1&gt;

&lt;h4 id=&quot;새-가상-환경-만들기에-대해서&quot;&gt;새 가상 환경 만들기에 대해서&lt;/h4&gt;

&lt;p&gt;Conda는 패키지 관리 프로그램인 동시에 가상 환경 관리 프로그램입니다. Conda로 기존 환경과 충돌이 없는 가상 환경을 만들고 관리할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; pytorch ipykernel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;conda create&lt;/code&gt; : 새 conda 환경을 만듭니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-y&lt;/code&gt; : &lt;code class=&quot;highlighter-rouge&quot;&gt;--yes&lt;/code&gt;의 줄임말입니다. 설치 승인을 생략하고 바로 설치합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-n pytorch&lt;/code&gt; : &lt;code class=&quot;highlighter-rouge&quot;&gt;--name pytorch&lt;/code&gt;의 줄임말입니다. 환경 이름을 pytorch로 짓습니다. 환경 이름은 필수입니다. 이름은 원하는 대로 지을 수 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ipykernel&lt;/code&gt; : ipykernel이 설치되어 있는 가상 환경을 만듭니다. ipykernel 외에 다른 패키지 이름을 쓸 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;jupyter에-새-kernel-등록하기에-대해서&quot;&gt;Jupyter에 새 kernel 등록하기에 대해서&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;pytorch&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; ipykernel install &lt;span class=&quot;nt&quot;&gt;--user&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; pytorch &lt;span class=&quot;nt&quot;&gt;--display-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;PyTorch&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python -m ipykernel&lt;/code&gt; : ipykernel &lt;a href=&quot;https://www.python.org/dev/peps/pep-0338/&quot;&gt;모듈을 파이썬 스크립트로 실행&lt;/a&gt;합니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;—name pytorch&lt;/code&gt; : Jupyter 내부적으로 쓰이는 kernel의 이름을 지정합니다. 같은 이름을 쓰면 덮어쓰기가 됩니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--display-name &quot;PyTorch&quot;&lt;/code&gt; : Jupyter Notebook 위에서 사용자에게 보이는 kernel의 이름을 정합니다. 내부적으로 쓰이는 이름과 상관없이 띄어쓰기 등 특수문자도 포함하여 자유롭게 지을 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;유용한-conda-명령어&quot;&gt;유용한 Conda 명령어&lt;/h1&gt;

&lt;p&gt;conda를 사용할 때 자주 사용하는 명령어들을 모아보았습니다.&lt;/p&gt;

&lt;h2 id=&quot;가상-환경-만들기-옵션&quot;&gt;가상 환경 만들기 옵션&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;파이썬만 있는 최소한의 환경을 원할 때&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; myenv python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;파이썬과 pip 등의 최소한의 패키지만 설치되어 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;myenv&lt;/code&gt;라는 이름의 새 가상 환경을 만듭니다. ipykernel, numpy 등이 모두 없는 환경입니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;myenv&lt;/code&gt; 대신 원하는 이름을 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;파이썬 버전을 지정하고 싶을 때&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; myenv &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python2.7의 가상 환경을 만듭니다. 이처럼 원하는 파이썬 버전을 지정하여 가상 환경을 만들 수 있습니다. 위와 마찬가지로 최소한의 환경만 설치합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;아나콘다 환경을 만들고 싶을 때&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; myenv anaconda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아나콘다 환경에는 numpy, pandas 등 수학/과학 관련 패키지들이 포함됩니다. ipykernel 역시 설치되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;파이썬 버전을 지정하고 아나콘다 환경을 만들고 싶을 때&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; myenv &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2.7 anaconda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;가상-환경-목록-보기&quot;&gt;가상 환경 목록 보기&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda env list

pytorch
myenv
myenv2
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;가상-환경-삭제하기&quot;&gt;가상 환경 삭제하기&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;conda env remove &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; myenv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ipython.readthedocs.io/en/stable/install/kernel_install.html&quot;&gt;Installing the IPython kernel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://conda.io/docs/user-guide/tasks/manage-environments.html&quot;&gt;Managing environments in Conda&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/peterjc123/pytorch-scripts&quot;&gt;Installing Pytorch on WIndows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2018/01/30/conda-pytorch.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2018/01/30/conda-pytorch.html</guid>
        
        
      </item>
    
      <item>
        <title>쉽고 빠르게 수준 급의 GitHub 블로그 만들기 - jekyll remote theme으로</title>
        <description>&lt;p&gt;.github.io라는 url로 익숙한 GitHub Pages는 개인 블로그, 특히 개발 블로그 용으로 인기가 높습니다. 이 글에서는 가장 간단하게 수준 급의 GitHub Pages로 static 페이지를 호스팅하는 방법을 소개해 보겠습니다.&lt;/p&gt;

&lt;p&gt;이미 많은 글들이 GitHub Pages를 사용하는 방법을 설명하고 있지만, 이 글에서 소개하는 방법은 다음과 같은 특징이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;쉽고 빠르다 : 프로그램 설치가 없습니다. 이 글에서 소개하는 방법으로는 로컬 컴퓨터에 Ruby, Jekyll 등의 프로그램을 설치하지 않고도 블로그를 만들 수 있습니다. 그렇기 때문에 누구나 쉽게 10분 만에 따라할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;수준 급이다 : 수백 개가 넘는 Jekyll theme이 이미 공개되어 있습니다. 이 글의 방법은 그 중 직접 마음에 드는 theme을 선택하고 그대로 내 블로그에 쓸 수 있게 해줍니다. 덕분에 프론트에 대한 고민 없이도 수준 급의 멋있는 블로그를 가질 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 시작해 볼까요?&lt;/p&gt;

&lt;h1 id=&quot;1-새-저장소repository-만들기&quot;&gt;1. 새 저장소(repository) 만들기&lt;/h1&gt;

&lt;p&gt;GitHub에서 새 저장소(repository)를 만듭니다. 이 때 저장소의 이름을 자신의 username 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;.github.io&lt;/code&gt;가 붙은 이름으로 짓습니다. 이렇게 해야 &lt;code class=&quot;highlighter-rouge&quot;&gt;yourname.github.io&lt;/code&gt;의 도메인으로 접속할 수 있는 블로그가 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8YCAF664/screenshot_2018-01-26_16.02.44.png?pub_secret=615fd6f28e&quot; alt=&quot;새 프로젝트 만들기&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;프로젝트 별 페이지 만들기&lt;/p&gt;

  &lt;p&gt;프로젝트 별로 페이지를 만들 수도 있습니다. 이 때는 프로젝트 이름이 &lt;code class=&quot;highlighter-rouge&quot;&gt;yourname.github.io&lt;/code&gt;가 아니어도 상관 없으며 이미 존재하는 프로젝트에 페이지를 만들 수도 있습니다. 다만 이렇게 만든 페이지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;yourname.github.io/projectname&lt;/code&gt;의 url로 접속하게 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;2-마음에-드는-jekyll-테마-찾기&quot;&gt;2. 마음에 드는 Jekyll 테마 찾기&lt;/h1&gt;

&lt;p&gt;GitHub에는 이미 &lt;a href=&quot;https://github.com/topics/jekyll-theme&quot;&gt;수백 개의 Jekyll 테마&lt;/a&gt;가 공개되어 있습니다. jekyll-theme이라는 topic을 갖고 있는 repository는 모두 공개된 jekyll 테마인데요. 이 중 어떤 테마든 내 블로그에 적용하고 싶은 테마를 선택해 보세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8Z1NP17W/screenshot_2018-01-26_16.18.35.png?pub_secret=66a1198973&quot; alt=&quot;공개된 Jekyll 테마들&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 글에서는 테마 리스트에서 가장 위에 보이는 minimal-mistakes라는 테마를 사용해 보겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;3-_configyml-파일-가져오기&quot;&gt;3. &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 파일 가져오기&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F91H9F9K9/2018-01-29_23_01_37.gif?pub_secret=7c0ba1db24&quot; alt=&quot;`_config.yml` 파일 가져오기&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;선택한 테마 저장소(repository)에 들어가서 &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;라는 파일의 내용을 복사합니다. 이때 &lt;strong&gt;Raw&lt;/strong&gt;를 누르면 군더더기 없이 파일의 내용만 볼 수 있습니다. 이 파일은 모든 Jekyll 사이트가 갖고 있는 설정 파일입니다.&lt;/li&gt;
  &lt;li&gt;자신이 방금 만든 저장소(repository)에 똑같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;이라는 이름의 파일을 만들고 복사한 내용을 붙여넣기 합니다.&lt;/li&gt;
  &lt;li&gt;이 파일에서 다음과 같이 한 줄을 추가하고 두 줄을 변경해야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음과 같은 한 줄을 추가합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;remote_theme &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mmistakes/minimal-mistakes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이는 remote_theme을 지정하는 설정이며 GitHub의 &lt;code class=&quot;highlighter-rouge&quot;&gt;OWNER/REPOSITORY&lt;/code&gt; 의 형식으로 이루어집니다. 아래는 mmistakes라는 owner의 minimal-mistakes라는 저장소의 Jekyll 테마를 가져오겠다는 뜻입니다.&lt;/p&gt;

&lt;p&gt;다음과 같이 설정 중에 url과 baseurl 두 줄을 수정합니다. url은 &lt;code class=&quot;highlighter-rouge&quot;&gt;yourname&lt;/code&gt;을 자신의 username으로 바꾸어야 하며, baseurl은 빈 문자열로 두어야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;url                      &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://yourname.github.io&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the base hostname &amp;amp; protocol for your site e.g. &quot;https://mmistakes.github.io&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;baseurl                  &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the subpath of your site, e.g. &quot;/blog&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;프로젝트 별 페이지 만들기&lt;/p&gt;

  &lt;p&gt;프로젝트 별 페이지를 만들 때 baseurl은 &lt;code class=&quot;highlighter-rouge&quot;&gt;/projectname&lt;/code&gt;처럼 써야 합니다. 이렇게 두어야 &lt;code class=&quot;highlighter-rouge&quot;&gt;https://yourname.github.io/projectname&lt;/code&gt;의 url로 접속할 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;제가 선택한 minimal-mistakes의 원본 &lt;code class=&quot;highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 중 일부분을 가져와 보았습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Welcome to Jekyll!&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# This config file is meant for settings that affect your entire site, values&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# which you are expected to set up once and rarely need to edit after that.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# For technical reasons, this file is *NOT* reloaded automatically when you use&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# `jekyll serve`. If you change this file, please restart the server process.&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;minimal_mistakes_skin    &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;default&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &quot;air&quot;, &quot;aqua&quot;, &quot;contrast&quot;, &quot;dark&quot;, &quot;dirt&quot;, &quot;neon&quot;, &quot;mint&quot;, &quot;plum&quot;, &quot;sunrise&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Site Settings&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;locale                   &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;en-US&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title                    &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Site&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Title&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title_separator          &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;name                     &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Your&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Name&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description              &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;An&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;amazing&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;website.&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;url                      &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the base hostname &amp;amp; protocol for your site e.g. &quot;https://mmistakes.github.io&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;baseurl                  &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the subpath of your site, e.g. &quot;/blog&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;repository               &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# GitHub username/repo-name e.g. &quot;mmistakes/minimal-mistakes&quot;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;(뒷부분 생략)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;수정된 설정 파일은 다음과 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Welcome to Jekyll!&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# This config file is meant for settings that affect your entire site, values&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# which you are expected to set up once and rarely need to edit after that.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# For technical reasons, this file is *NOT* reloaded automatically when you use&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# `jekyll serve`. If you change this file, please restart the server process.&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;remote_theme &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mmistakes/minimal-mistakes&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;minimal_mistakes_skin    &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;default&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# &quot;air&quot;, &quot;aqua&quot;, &quot;contrast&quot;, &quot;dark&quot;, &quot;dirt&quot;, &quot;neon&quot;, &quot;mint&quot;, &quot;plum&quot;, &quot;sunrise&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Site Settings&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;locale                   &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;en-US&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title                    &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Site&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Title&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title_separator          &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;name                     &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Your&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Name&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description              &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;An&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;amazing&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;website.&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;url                      &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://yourname.github.io&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the base hostname &amp;amp; protocol for your site e.g. &quot;https://mmistakes.github.io&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;baseurl                  &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the subpath of your site, e.g. &quot;/blog&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;repository               &lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# GitHub username/repo-name e.g. &quot;mmistakes/minimal-mistakes&quot;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;(뒷부분 생략)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;설정 파일에서 이외에도 제목, 저자, 설명, 페이스북 설정 등 원하는 대로 설정을 바꾸셔도 됩니다.&lt;/p&gt;

&lt;h1 id=&quot;4-index-파일-가져오기&quot;&gt;4. index 파일 가져오기&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;선택한 테마 저장소(repository)에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;index.md&lt;/code&gt; 등의 파일을 찾습니다. 이 예시에서 사용하는 테마는 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt;이라는 이름의 파일로 있습니다. 이 파일이 Jekyll이 사이트를 생성할 때 가장 처음 보여주는 페이지입니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;index&lt;/code&gt; 파일과 동일한 이름과 동일한 내용의 파일을 자신의 저장소(repository)에서도 만듭니다. 이 예시에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt;의 내용은 다음과 같이 몇 줄 되지 않습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;home&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;author_profile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F90EHDNK0/screenshot_2018-01-27_14.52.30.png?pub_secret=93cc25e567&quot; alt=&quot;index.html 파일 생성하기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;테마에 따라서 추가로 가져와야 하는 파일이 있을 수도 있습니다. 예를 들어 어떤 테마에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;posts.md&lt;/code&gt;라는 파일이 있어야 합니다. 페이지가 제대로 작동하지 않는다면 테마에 따라서 필요한 파일을 확인해 주세요.&lt;/p&gt;

&lt;h1 id=&quot;5-_posts에-새-글-쓰기&quot;&gt;5. &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt;에 새 글 쓰기&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;자신의 GitHub 저장소에서 &lt;strong&gt;Create new file&lt;/strong&gt;을 눌러 새 파일을 생성합니다.&lt;/li&gt;
  &lt;li&gt;파일 이름에 &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts/2018-01-26-first-post.md&lt;/code&gt;을 입력합니다. 이 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt; 앞의 &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt;는 폴더 이름으로 인식되며 GitHub에서 자동으로 폴더를 생성합니다. Jekyll은 &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; 아래의 markdown 글들을 블로그 포스트로 인식하고 블로그에서 보여주는데요. 파일 이름은 일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.md&lt;/code&gt; 형식으로 짓습니다.&lt;/li&gt;
  &lt;li&gt;파일 내용 맨 처음에는 다음과 같이 글의 제목과 날짜 등을 적어줍니다. 이 형식은 &lt;a href=&quot;https://jekyllrb.com/docs/frontmatter/&quot;&gt;Front matter&lt;/a&gt;라고 불리며, Jekyll에서 글의 메타 데이터를 확인하는 방법입니다. 테마에 따라서 여기에 들어가는 정보가 조금씩 다를 수 있으니 각 테마 별로 예시를 확인해 주세요.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Welcome&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll!&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;2017-10-20 08:26:28 -0400&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll update&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;이 뒤의 내용은 무엇을 쓰셔도 좋습니다. 다음은 제가 사용한 예시 파일의 전문입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Welcome&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Jekyll!&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;2017-10-20 08:26:28 -0400&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll update&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
You’ll find this post in your &lt;span class=&quot;sb&quot;&gt;`_posts`&lt;/span&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;span class=&quot;sb&quot;&gt;`jekyll serve`&lt;/span&gt;, which launches a web server and auto-regenerates your site when a file is updated.

To add new posts, simply add a file in the &lt;span class=&quot;sb&quot;&gt;`_posts`&lt;/span&gt; directory that follows the convention &lt;span class=&quot;sb&quot;&gt;`YYYY-MM-DD-name-of-post.ext`&lt;/span&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.

Jekyll also offers powerful support for code snippets:

​&lt;span class=&quot;sb&quot;&gt;```python
def print_hi(name):
  print(&quot;hello&quot;, name)
print_hi('Tom')
​```&lt;/span&gt;

Check out the &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Jekyll docs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-docs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Jekyll’s GitHub repo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-gh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;. If you have questions, you can ask them on &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Jekyll Talk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-talk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;.

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-docs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://jekyllrb.com/docs/home&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-gh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;   &lt;span class=&quot;sx&quot;&gt;https://github.com/jekyll/jekyll&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;jekyll-talk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;sx&quot;&gt;https://talk.jekyllrb.com/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8Z2HJ9PC/screenshot_2018-01-26_17.06.25.png?pub_secret=c19592b80f&quot; alt=&quot;새 포스트 만들기&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;확인하기&quot;&gt;확인하기&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;yourname.github.io&lt;/code&gt;로 접속하여 GitHub Pages가 잘 만들어졌는지 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8YCMJQHW/screenshot_2018-01-26_16.52.30.png?pub_secret=04ae040a08&quot; alt=&quot;만들어진 minimal-mistakes 테마의 GitHub Pages 블로그&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;프로젝트 별 페이지 만들기&lt;/p&gt;

  &lt;p&gt;프로젝트 별 페이지를 만들 때는 한가지 과정이 더 필요합니다. 바로 GitHub 설정에서 Gihub Pages를 활성화하는 것입니다. (&lt;code class=&quot;highlighter-rouge&quot;&gt;yourname.github.io&lt;/code&gt;라는 이름의 저장소는 이 설정이 자동으로 활성화되어 있습니다.)&lt;/p&gt;

  &lt;p&gt;GitHub 저장소 메뉴 중에 &lt;strong&gt;Settings&lt;/strong&gt;에 들어간 뒤 스크롤을 내리면 GitHub Pages 설정을 볼 수 있습니다. 여기에서 &lt;strong&gt;Source&lt;/strong&gt;를 &lt;strong&gt;master branch&lt;/strong&gt;로 설정한 뒤 Save를 누르면 GitHub Pages 설정이 완료되고, 접속할 수 있는 url이 나타납니다. 이 url로 들어가 GitHub Pages가 제대로 작동하는지 확인할 수 있습니다. url은 &lt;code class=&quot;highlighter-rouge&quot;&gt;https://yourname.github.io/projectname&lt;/code&gt;의 형식으로 보이게 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8ZJAPDD2/screenshot_2018-01-27_15.02.43.png?pub_secret=b0da820a8c&quot; alt=&quot;GitHub Pages 활성화하기&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;

&lt;p&gt;이 글에서 소개드린 방법의 핵심은 &lt;a href=&quot;https://github.com/benbalter/jekyll-remote-theme&quot;&gt;jekyll remote theme&lt;/a&gt;이었습니다. Jekyll remote theme은 GitHub에 공개되어 있는 어떤 Jekyll 테마든지 가져와서 쓸 수 있도록 하는 Jekyll의 플러그인입니다. &lt;a href=&quot;https://github.com/blog/2464-use-any-theme-with-github-pages&quot;&gt;Jekyll remote theme이 GitHub Pages에 내장&lt;/a&gt;되어 있었기 때문에 이 글에서 소개한 방법이 가능했던 것입니다.&lt;/p&gt;

&lt;p&gt;물론 이 방법으로는 블로그의 css 등을 커스터마이징하는 것은 불가능합니다. 커스터마이징을 하기 위해서는 자신만의 &lt;code class=&quot;highlighter-rouge&quot;&gt;_layouts&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;_includes&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;_sass&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;assets&lt;/code&gt; 등의 폴더들을 만들어야 합니다. (다른 말로 하면, jekyll remote theme은 이 폴더들의 내용을 지정한 테마에서 가져옵니다.) 또한 자신의 로컬 컴퓨터에 Jekyll 환경을 설치하고 빌드해 보아야 합니다. 자세한 내용은 &lt;a href=&quot;https://jekyllrb.com&quot;&gt;Jekyll의 공식 웹사이트&lt;/a&gt;를 참고해야 합니다.&lt;/p&gt;

&lt;p&gt;커스터마이징을 하지 않고 이미 공개된 테마를 그대로 쓰고 싶다면 remote theme은 최소한의 설정으로 원하는 Jekyll 테마를 사용할 수 있는 쉽고 빠른 방법입니다.&lt;/p&gt;
</description>
        <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2018/01/27/jekyll-remote-theme.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2018/01/27/jekyll-remote-theme.html</guid>
        
        
      </item>
    
      <item>
        <title>AWS Lambda로 PyTorch 모델 서빙하기</title>
        <description>&lt;h1 id=&quot;aws-lambda로-pytorch-모델-서빙하기&quot;&gt;AWS Lambda로 PyTorch 모델 서빙하기&lt;/h1&gt;

&lt;p&gt;AWS Lambda는 서버 관리의 부담을 없애주는 서버 리스 컴퓨팅(Serverless computing) 서비스입니다. Lambda를 한마디로 설명하면 이벤트가 발생했을 때만 서버가 떠서 코드를 실행하는 이벤트 기반 클라우드 플랫폼입니다. Lambda는 코드가 실행된 시간에 대해서만 비용을 내는 효율성과, 이벤트가 갑자기 많이 발생해도 병렬처리가 가능한 확장성 덕분에 각광받고 있습니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 Lambda 위에 PyTorch 모델을 업로드하여 API로 서비스하는 방법을 공유하겠습니다. 이 글은 step-by-step으로 구성되어 있습니다. 배포 준비를 위해 Docker를 설치하고 PyTorch 라이브러리와 모델을 압축파일로 만들고 Lambda 위에 올린 뒤 API를 배포하는 것까지 차근차근 따라가 보겠습니다.&lt;/p&gt;

&lt;p&gt;이 글에서 쓰이는 모든 코드는 github에 모아놓았습니다 : &lt;a href=&quot;https://github.com/dreamgonfly/pytorch-lambdapack&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8VCWU8GM/screenshot_2018-01-19_11.29.38.png?pub_secret=b61a06eeb7&quot; alt=&quot;예제 파일 구성&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;샘플-모델-만들기&quot;&gt;샘플 모델 만들기&lt;/h1&gt;

&lt;p&gt;이 글에서 예제로 사용할 모델은 PyTorch Tutorial에서 제공하는 &lt;a href=&quot;http://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html&quot;&gt;Generating Names with a Character-Level RNN&lt;/a&gt; 모델입니다. 텍스트로 인풋을 받고 텍스트로 아웃풋을 내기 때문에 API 설계가 간단해지는 장점이 있어 선택했습니다. 튜토리얼의 코드를 그대로 쓰되, 마지막에 학습된 모델을 저장하는 코드만 추가해서 사용하겠습니다. 아래는 맨 아래에 추가되는 코드입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# char_rnn_generation_tutorial.py&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 튜토리얼 코드 생략&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Save the model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'model.pth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;to_pickle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'all_categories'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'n_categories'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'all_letters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'n_letters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_letters&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_pickle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;PyTorch 모델을 저장할 때는 모델 전체가 아니라 모델의 state dict만 저장합니다. 이것은 모델을 다른 환경 위에서도 문제 없이 load하기 위해서입니다. PyTorch 모델을 저장하고 불러오는 방법은 공식 문서인 &lt;a href=&quot;https://github.com/pytorch/pytorch/blob/761d6799beb3afa03657a71776412a2171ee7533/docs/source/notes/serialization.rst&quot;&gt;Recommended approach for saving a model&lt;/a&gt;을 따랐습니다.&lt;/p&gt;

&lt;p&gt;코드를 실행하면 저장된 모델 파일인 &lt;code class=&quot;highlighter-rouge&quot;&gt;model.pth&lt;/code&gt;과 전처리를 위한 파라미터 파일인 &lt;code class=&quot;highlighter-rouge&quot;&gt;params.pkl&lt;/code&gt;을 얻을 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;docker-설치하기&quot;&gt;Docker 설치하기&lt;/h1&gt;

&lt;p&gt;Lambda에서 코드를 실행하는 환경과 동일한 환경을 로컬에 쉽게 구성하기 위해서는 Docker가 필요합니다. Lambda에 올린 코드를 디버깅할 때도 Docker에서 코드를 테스트해보는 것은 유용하죠.&lt;/p&gt;

&lt;p&gt;Docker가 이미 설치되어 있으신 분은 이 부분을 생략하고 바로 다음으로 넘어가셔도 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;macos--windows&quot;&gt;MacOS &amp;amp; Windows&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://store.docker.com/search?type=edition&amp;amp;offering=community&quot;&gt;Docker Community Edition 다운로드 페이지&lt;/a&gt;에서 원하는 환경의 설치 파일을 다운로드받으면 GUI 방식으로 쉽게 설치할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8TKZE5E3/screenshot_2018-01-14_17.31.30.png?pub_secret=a3d1253e1f&quot; alt=&quot;MacOS에서 Docker 설치 화면&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ubuntu&quot;&gt;Ubuntu&lt;/h2&gt;

&lt;p&gt;간편하게 만들어진 스크립트를 실행함으로써 Docker를 설치할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;이미 Docker가 설치되어 있다면 아래 스크립트를 실행하지 마세요. 아래 스크립트에 대한 자세한 설명은 &lt;a href=&quot;https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#upgrade-docker-ce-1&quot;&gt;설치 페이지&lt;/a&gt;에서 읽을 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; get.docker.com &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; get-docker.sh
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;sh get-docker.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 후 Docker를 사용할 유저에게 권한을 주기 위해 유저를 Docker 그룹에 추가합니다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;usermod &lt;span class=&quot;nt&quot;&gt;-aG&lt;/span&gt; docker &amp;lt;your-user&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 제가 실험해보았을 때는, 이 글의 뒤에 나오는대로 PyTorch를 설치하고 불필요한 파일을 삭제했을 때 Linux (Ubuntu 14.04)에서는 AWS Lambda에 올릴 수 있는 크기가 나왔지만 MacOS (Sierra)에서는 그보다 큰 용량이 나왔습니다. 여러가지 환경에 따라 결과는 달라질 수 있으니 직접 실험해보는 것을 권장합니다.&lt;/p&gt;

&lt;h1 id=&quot;amazon-linux-docker-이미지-다운받기&quot;&gt;Amazon Linux Docker 이미지 다운받기&lt;/h1&gt;

&lt;p&gt;Lambda에서 코드를 실행할 때 사용하는 환경은 Amazon Linux입니다. 따라서 Lambda의 배포 환경과 동일한 환경을 구축하기 위해서는 Docker를 이용해 Amazon Linux 이미지를 다운받아야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ docker pull amazonlinux:latest&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;다운로드가 끝나면 다음 명령어로 설치된 이미지를 확인할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ docker images

REPOSITORY     TAG        IMAGE ID       CREATED         SIZE
amazonlinux    latest     6133b2c7d7c2   2 hours ago     165MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;배포-패키지-압축-파일-만들기&quot;&gt;배포 패키지 압축 파일 만들기&lt;/h1&gt;

&lt;p&gt;이제 Lambda에 업로드할 압축 파일(.zip)을 만들어야 합니다. 이를 위해서 Amazon Linux 환경 위에 필요한 패키지들을 모두 설치하고 설치된 파일을 압축하는 과정이 필요합니다.&lt;/p&gt;

&lt;p&gt;다음 코드는 그 과정을 모두 담고 있습니다. 코드에 대한 설명은 아래에 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# build_pack_script.sh&lt;/span&gt;

dev_install &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    yum &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; update
    yum &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; upgrade
    yum &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; groupinstall &lt;span class=&quot;s2&quot;&gt;&quot;Development Tools&quot;&lt;/span&gt;
    yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; findutils zip
    yum install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; python36-devel python36-virtualenv
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

make_virtualenv &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home
    rm &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; env
    python3 &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; virtualenv env &lt;span class=&quot;nt&quot;&gt;--python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;python3
    &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;env/bin/activate
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install_pytorch &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    pip install http://download.pytorch.org/whl/cpu/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl
    pip install torchvision
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

install_packages &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    pip install &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /host/requirements.txt
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

gather_pack &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /home
    rm &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; lambdapack
    mkdir lambdapack
    &lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;lambdapack

    &lt;span class=&quot;c&quot;&gt;# Copy python pakages from virtual environment&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; /home/env/lib/python3.6/site-packages/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
    cp &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; /home/env/lib64/python3.6/site-packages/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
    
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Original size &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;du &lt;span class=&quot;nt&quot;&gt;-sh&lt;/span&gt; /home/lambdapack | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# Clean pakages&lt;/span&gt;
    find &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-type&lt;/span&gt; d &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;tests&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-exec&lt;/span&gt; rm &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt; +
    find &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;*.so&quot;&lt;/span&gt; | xargs strip
    find &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;*.so.*&quot;&lt;/span&gt; | xargs strip
    rm &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; pip
    rm &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; pip-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
    rm &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; wheel
    rm &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; wheel-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
    rm easy_install.py
    find &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\*&lt;/span&gt;.pyc &lt;span class=&quot;nt&quot;&gt;-delete&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Stripped size &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;du &lt;span class=&quot;nt&quot;&gt;-sh&lt;/span&gt; /home/lambdapack | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# Compress&lt;/span&gt;
    zip &lt;span class=&quot;nt&quot;&gt;-FS&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r1&lt;/span&gt; /host/pack.zip &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; /dev/null
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Compressed size &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;du &lt;span class=&quot;nt&quot;&gt;-sh&lt;/span&gt; /host/pack.zip | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

add_pack &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /host
    zip &lt;span class=&quot;nt&quot;&gt;-9&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; pack.zip lambda_function.py
    zip &lt;span class=&quot;nt&quot;&gt;-9&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; pack.zip model.py
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

main &lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    dev_install
    make_virtualenv
    install_pytorch
    install_packages
    gather_pack
    add_pack
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 코드를 다음과 같이 실행할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; lambdapack &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;:/host amazonlinux:latest
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; lambdapack bash /host/build_pack_script.sh

...
Successfully installed numpy-1.14.0
Successfully installed pyyaml-3.12 torch-0.3.0.post4
Successfully installed pillow-5.0.0 six-1.11.0 torchvision-0.2.0
...
Original size 310M
Stripped size 249M
Compressed size 71M
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 후 이 코드를 실행한 디렉토리에 &lt;code class=&quot;highlighter-rouge&quot;&gt;pack.zip&lt;/code&gt;이라는 압축파일이 생성된 것을 볼 수 있습니다. 이 압축파일 안에 우리가 실행할 코드와 라이브러리가 모두 들어 있습니다.&lt;/p&gt;

&lt;p&gt;이 압축파일을 Lambda에 올리고 API로 만드는 방법으로 넘어가기 전에, 위의 코드에서 중요한 부분을 몇가지 설명드리겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;pytorch-설치하기&quot;&gt;PyTorch 설치하기&lt;/h2&gt;

&lt;p&gt;PyTorch를 CPU 버전으로 설치합니다. 참고로 CUDA 버전은 용량이 800MB에 달해서 Lambda에 올릴 수 있는 코드와 라이브러리 크기 제한인 250MB를 훨씬 뛰어넘습니다. Lambda에서는 CPU로 코드를 실행하기 때문에 CUDA 버전은 필요 없습니다.&lt;/p&gt;

&lt;p&gt;참고로 Lambda의 코드와 라이브러리 크기 제한은 압축 해제 시를 기준으로 합니다.&lt;/p&gt;

&lt;h2 id=&quot;lambda_functionpy&quot;&gt;lambda_function.py&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;build_pack_script.sh&lt;/code&gt; 코드 중 &lt;code class=&quot;highlighter-rouge&quot;&gt;add_pack&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_function.py&lt;/code&gt;이란 파일을 압축 파일에 추가하는 부분이 있습니다. Lambda가 실제로 실행하는 코드는 바로 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_function.py&lt;/code&gt; 파일 안의 &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_handler&lt;/code&gt;라는 함수입니다. 이 파일 역시 다른 라이브러리들과 함께 압축 파일 안에 포함되어 Lambda에 업로드되어야 합니다. 실행하는 파일과 함수의 이름을 Lambda 설정에서 변경할 수는 있지만 여기서는 디폴트 대로 파일과 함수 이름을 지었습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_function.py&lt;/code&gt;의 내용을 하나씩 살펴보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;boto3&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RNN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;필요한 패키지를 불러오는 부분입니다. 모든 패키지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;build_pack.sh&lt;/code&gt;을 실행할 때 pack.zip 안에 함께 들어가야 합니다. 단, boto3는 Lambda에 이미 설치되어 있으니 따로 설치할 필요는 없습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ACCESS_KEY'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SECRET_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'SECRET_KEY'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BUCKET_NAME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;max_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'max_length'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 20&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lambda에서는 설정으로 환경 변수를 지정할 수 있습니다. 이 환경 변수는 코드 내에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;os.environ.get&lt;/code&gt; 함수를 통해 가져올 수 있습니다. 참고로 모든 환경변수는 문자열 타입입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;s3_client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boto3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'s3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;aws_access_key_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ACCESS_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;aws_secret_access_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SECRET_KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lambda 내에서 S3에 접근하기 위해 위와 같이 s3 client를 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Load preprocessing parameters&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/tmp/params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s3_client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'/tmp/params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/tmp/params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pkl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pickle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pkl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;all_categories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'all_categories'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_categories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n_categories'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;all_letters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'all_letters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_letters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n_letters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Check if models are available&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Download model from S3 if model is not already present&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/tmp/model.pth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s3_client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'model.pth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'/tmp/model.pth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_categories&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/tmp/model.pth&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;샘플 모델을 학습한 뒤 저장한 &lt;code class=&quot;highlighter-rouge&quot;&gt;model.pth&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;params.pkl&lt;/code&gt;은 AWS S3에 올린 뒤 Lambda가 실행될 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;/tmp/&lt;/code&gt; 디렉토리 안으로 다운로드합니다. 이 예제에서는 모델의 크기가 매우 작기 때문에 이럴 필요는 없지만, 일반적인 경우에도 적용 가능하도록 예제를 만들었습니다. 이렇게 모델 파라미터를 S3에서 다운받는 것의 또 하나의 장점은 모델을 새로 학습시켜서 파라미터가 바뀌었을 때, 처음부터 다시 패키지 압축을 하지 않고 S3에 올려져 있는 모델 파라미터 파일을 교체하는 것만으로도 배포된 모델을 업데이트할 수 있다는 점입니다. 참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;/tmp/&lt;/code&gt; 디렉토리 안에는 500MB까지 저장이 가능합니다.&lt;/p&gt;

&lt;p&gt;모델 파일을 S3에서 가져오면 lambda 함수가 실행될 때마다 네트워크 비용을 감수해야 하는 단점은 있습니다. 그러나 람다가 병렬 처리로 동작하고 S3 위의 파일은 읽기에 lock이 걸리지 않아 여러명이 동시에 읽을 수 있습니다. S3와 lambda 함수가 같은 region에 있다면 속도 저하를 거의 느낄 수 없는 수준입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# samples 함수 실행을 위해 튜토리얼에서 그대로 가져온 기타 함수들은 생략&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Get multiple samples from one category and multiple starting letters&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_letters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ABC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_letter&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_letter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lambda_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Create dummy input for model&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LEAVE_LOG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'event:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;output_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Russian'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'RUS'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;# return results formatted for AWS API Gateway&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;statusCode&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; \
            &lt;span class=&quot;s&quot;&gt;&quot;headers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; \
             &lt;span class=&quot;s&quot;&gt;&quot;body&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dumps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;AWS Lambda가 실제로 실행하는 것은 &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_handler&lt;/code&gt;입니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_handler&lt;/code&gt; 함수가 실행될 때 event와 context 안에 lambda를 호출한 이벤트의 정보가 담깁니다. event 변수의 구체적인 형태는 이벤트 종류마다 다르지만, 이 예제의 경우 다음과 같은 정보가 event 객체가 담기게 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'category'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Russian'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'start_letters'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'RUS'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;modelpy와-requirementstxt&quot;&gt;model.py와 requirements.txt&lt;/h2&gt;

&lt;p&gt;github에는 위에 설명드린 파일 외에도 몇가지 파일들이 더 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;model.py&lt;/code&gt;는 모델 정의가 그대로 담겨 있는 파일입니다. PyTorch 모델을 불러올 때는 모델 &lt;code class=&quot;highlighter-rouge&quot;&gt;class&lt;/code&gt; 정의가 필요하기 때문입니다. 샘플 모델 대신 자신의 모델을 쓰고 싶다면 이 파일을 수정해주어야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;requirements.txt&lt;/code&gt;는 추가적으로 필요한 파이썬 패키지들을 명시하는 곳입니다. Pandas 등 필요한 패키지를 이곳에 적어놓으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;build_pack_script.sh&lt;/code&gt;가 실행되어 압축 파일을 만들면서 명시된 패키지가 함께 들어갑니다. 이 때 Stripped size가 250MB를 넘어서는 안된다는 점을 명심해주세요. 참고로 예시에는 로컬에서 테스트를 위해 boto3가 포함되어 있지만, 실제 Lambda에는 boto3가 이미 설치되어 있으므로 생략하는 것이 좋습니다.&lt;/p&gt;

&lt;h1 id=&quot;aws-lambda로-배포하기&quot;&gt;AWS Lambda로 배포하기&lt;/h1&gt;

&lt;h2 id=&quot;압축-파일-및-모델-파일-업로드&quot;&gt;압축 파일 및 모델 파일 업로드&lt;/h2&gt;

&lt;p&gt;AWS Lambda에 코드를 올리는 방법은 세 가지가 있습니다. 이 중 압축된 파일의 크기가 50MB를 넘는다면 압축 파일을 S3에 업로드한 뒤 Lambda에 압축 파일의 주소를 입력하는 방법을 사용해야 합니다. 이를 위해서 S3에 압축 파일을 업로드합니다. 또한 모델 파라미터와 전처리 파라미터 파일도 같이 S3에 업로드합니다.&lt;/p&gt;

&lt;p&gt;이 글에서는 새로운 S3 bucket을 만들고 그곳에 필요한 모든 파일을 업로드하겠습니다. 하지만 실제로는 이미 있는 bucket을 사용해도 되며 모든 파일이 같은 곳에 위치할 필요는 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8SGERG0K/bucket-create.png?pub_secret=60e96730c4&quot; alt=&quot;새 bucket 만들기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8TM6NMUP/screenshot_2018-01-14_23.14.28.png?pub_secret=74984ee530&quot; alt=&quot;S3에 업로드된 압축 파일과 모델 및 전처리 파라미터 파일&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;iam-user-만들기&quot;&gt;IAM User 만들기&lt;/h2&gt;

&lt;p&gt;lambda 함수는 모델과 전처리 파라미터를 S3에서 가져오기 때문에 S3에 접근 권한이 필요합니다. root 권한을 줄 수도 있지만 보안에 취약해진다는 단점이 있습니다. 안전한 권한 관리를 위해서 S3 읽기 권한만 갖고 있는 새 IAM User를 만들어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8VNST9SB/create_iam_user.gif?pub_secret=be05c04c7b&quot; alt=&quot;새 IAM User 만들기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;만들어진 유저의 Access key와 Secret access key는 안전한 곳에 잘 저장해놓아야 합니다. 한번 창을 닫으면 Access key와 Secret access key를 다시 볼 수 있는 방법은 없습니다.&lt;/p&gt;

&lt;h2 id=&quot;lambda-함수-만들기&quot;&gt;lambda 함수 만들기&lt;/h2&gt;

&lt;p&gt;이제 새 lambda 함수를 만들어보겠습니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;pytorch-lambda&lt;/code&gt;라는 이름의 lambda 함수를 만듭니다. 이 때, 코드 및 라이브러리는 S3에 올려둔 압축 파일의 주소를 입력합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8U4XD8F3/create_lambda.gif?pub_secret=50e33769f4&quot; alt=&quot;새 lambda 함수 만들기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서는 lambda 함수의 메모리와 시간 제한을 최대인 3GB와 5분으로 정했습니다. 이 제한은 필요한 만큼 설정하시면 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;api-gateway로-api-만들기&quot;&gt;API Gateway로 API 만들기&lt;/h2&gt;

&lt;p&gt;이렇게 설정한 lambda를 API로 만들어서 서비스할 차례입니다. API Gateway에서 새 API를 만들며 이미 있는 lambda 함수에 연결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 예제에서는 도메인이 다른 리소스에 접속할 수 있게 CORS 설정을 하는 부분까지 담았습니다.&lt;/p&gt;

&lt;p&gt;AWS의 API Gateway에서는 Deployment stage를 설정할 수 있습니다. 이를 통해서 개발 버전과 서비스 버전을 분리할 수 있습니다. 버전의 이름은 보통 &lt;code class=&quot;highlighter-rouge&quot;&gt;prob&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;live&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;dev&lt;/code&gt; 등으로 짓습니다.&lt;/p&gt;

&lt;p&gt;API를 설정하고 나면 마지막으로 API를 호출할 수 있는 URL을 얻게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8U4W55RP/create_api.gif?pub_secret=4a20b5a250&quot; alt=&quot;새 API 만들기&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;테스트하기&quot;&gt;테스트하기&lt;/h2&gt;

&lt;p&gt;만들어진 API는 POST method로 호출해야 합니다. 커멘드 라인에서 url을 호출할 수 있게 해주는 curl로 간단하게 테스트 해볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;{&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Russian&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;start_letters&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;RUS&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt; POST https://tcodv2ela9.execute-api.ap-northeast-2.amazonaws.com/v1

&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;statusCode&quot;&lt;/span&gt;: 200, &lt;span class=&quot;s2&quot;&gt;&quot;headers&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Content-Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;application/json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;body&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Rovantov&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Uarthin&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Shantov&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;]&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;lambda의 로그 확인은 AWS CloudWatch에서 합니다. &lt;strong&gt;CloudWatch&lt;/strong&gt; &amp;gt; &lt;strong&gt;Logs&lt;/strong&gt; &amp;gt; Log Group 선택 &amp;gt; Log Stream 선택으로 로그를 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;빠른-개발을-위해서&quot;&gt;빠른 개발을 위해서&lt;/h2&gt;

&lt;p&gt;lambda 함수를 개발하고 테스트하는 한 사이클에는 상당한 시간이 걸립니다. 코딩을 하고, docker에 환경을 구축한 뒤 압축해서 zip 파일로 만들고, 이를 S3에 업로드하고 다시 lambda에 넣은 뒤 url을 호출해 보아야 코드에 버그가 있는지 없는지 알 수 있습니다. 버그를 확인한 후 코드를 수정하고 나면 다시 위의 과정을 반복해야 하죠.&lt;/p&gt;

&lt;p&gt;코딩을 하고 테스트로 피드백을 받는 간격이 짧으면 짧을 수록 개발 속도는 빨라지게 됩니다. 빠른 개발을 위해서 &lt;a href=&quot;https://github.com/dreamgonfly/pytorch-lambdapack&quot;&gt;github&lt;/a&gt;에는 위에 설명드린 파일 외에 몇가지 파일들이 더 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;add_pack_script.sh&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;build_pack_script.sh&lt;/code&gt;의 간소화된 버전이라고 할 수 있습니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;add_pack_script.sh&lt;/code&gt;는 Amazon Linux 환경을 다시 구축하는 과정을 생략하고 이미 만들어진 container 위에 파이썬 패키지 압축만 다시 합니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_function.py&lt;/code&gt; 등 몇가지 파일만 수정한 뒤 압축 파일을 다시 만들어야 할 때 유용하게 쓸 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;local_test.py&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;local_test_script.sh&lt;/code&gt;는 로컬에서 테스트를 할 수 있게 해주는 스크립트입니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;local_test.py&lt;/code&gt;를 수정하여 필요한 환경 변수와 event를 지정한 뒤 사용할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;

&lt;p&gt;이것으로 PyTorch 모델을 AWS Lambda로 서빙하는 과정을 마쳤습니다. PyTorch와 AWS Lambda의 조합은 간단한 딥러닝 모델을 서빙하는 데 최적의 조합입니다. 요청이 없을 때는 과금이 없으며, 요청이 갑자기 많아지더라도 서버가 죽을 걱정이 없이 서비스할 수 있기 때문이죠.&lt;/p&gt;

&lt;p&gt;이제 여러분도 딥러닝 모델을 만드는 것에서 끝나는 것이 아니라 언제 어디서나 사용할 수 있도록 서비스화할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://machinelearnings.co/serving-pytorch-models-on-aws-lambda-with-caffe2-onnx-7b096806cfac&quot;&gt;Serving PyTorch Models on AWS Lambda with Caffe2 &amp;amp; ONNX&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://beomi.github.io/2017/12/07/Deploy-Tensorflow-Keras-on-AWS-Lambda/&quot;&gt;AWS Lambda에 Tensorflow/Keras 배포하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.networkworld.com/article/3053111/cloud-computing/what-is-amazon-cloud-s-lambda-and-why-is-it-a-big-deal.html&quot;&gt;What is Amazon cloud’s Lambda and why is it a big deal?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2018/01/19/pytorch-on-aws-lambda.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2018/01/19/pytorch-on-aws-lambda.html</guid>
        
        <category>featured</category>
        
        
      </item>
    
      <item>
        <title>딥러닝용 서버 설치기</title>
        <description>&lt;p&gt;어제 딥러닝용 1080 Ti GPU 서버의 개발 환경 세팅을 마쳤습니다. 이 글에서는 서버 구매부터 Ubuntu 설치, NVIDIA driver, CUDA 및 cuDNN 설치, 그리고 Tensorflow와 PyTorch 설치까지 제가 개발 환경을 세팅한 방법을 정리했습니다.&lt;/p&gt;

&lt;h1 id=&quot;하드웨어-구성&quot;&gt;하드웨어 구성&lt;/h1&gt;

&lt;p&gt;참고를 위해 제가 구성한 서버 하드웨어도 보여드리겠습니다.&lt;/p&gt;

&lt;p&gt;괄호 안의 가격은 실제 구매한 가격이 아니라 참고를 위해 적어놓은 현금 최저가입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU : 인텔 코어X-시리즈 i7-6850K (브로드웰-E) (587,870원)&lt;/li&gt;
  &lt;li&gt;메인보드 : ASUS X99-A II STCOM (432,490원)&lt;/li&gt;
  &lt;li&gt;메모리 : 삼성전자 DDR4 16G PC4-19200 X 4 (185,850원)&lt;/li&gt;
  &lt;li&gt;그래픽카드 : GIGABYTE 지포스 GTX1080 Ti AORUS D5X 11GB (1,061,700원)&lt;/li&gt;
  &lt;li&gt;하드디스크 : WD 4TB BLUE WD40EZRZ (SATA3/5400/64M)  (135,450원)&lt;/li&gt;
  &lt;li&gt;케이스 : BRAVOTEC 스텔스 TX 블랙 파노라마 윈도우 (58,000원)&lt;/li&gt;
  &lt;li&gt;파워 : 써멀테이크 터프파워 그랜드 RGB 850W 골드 풀 모듈러 (177,450원)&lt;/li&gt;
  &lt;li&gt;쿨러/튜닝 : CORSAIR HYDRO SERIES H80i v2  (148,540원)&lt;/li&gt;
  &lt;li&gt;외장HDD : Toshiba CANVIO BASIC 2 1TB  (69,830원)&lt;/li&gt;
  &lt;li&gt;조립비 : 컴퓨터 프리미엄 조립 + 1년 전국 무상 방문출장AS (1대분) (35,000원)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;총 상품 금액 : 3,604,000원 (배송비 9,000원 제외)&lt;/p&gt;

&lt;p&gt;가격 비교는 다나와(http://www.danawa.com) &amp;gt; &lt;strong&gt;온라인 견적&lt;/strong&gt;을 이용했습니다. 다나와에서 견적을 만든 후 &lt;strong&gt;호환성 체크&lt;/strong&gt;를 한 뒤 &lt;strong&gt;구매신청 등록&lt;/strong&gt;을 클릭하면 구매를 진행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8FUBADFF/screenshot.png?pub_secret=4f69dcc170&quot; alt=&quot;다나와(www.danawa.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8F6LG064/danawa.png?pub_secret=3ac2f607cb&quot; alt=&quot;다나와 호환성 체크와 구매신청&quot; /&gt;&lt;/p&gt;

&lt;p&gt;주문을 완료한 뒤 배송이 오면 이제 개발 환경을 세팅할 차례입니다.&lt;/p&gt;

&lt;h1 id=&quot;ubuntu-설치하기&quot;&gt;Ubuntu 설치하기&lt;/h1&gt;

&lt;p&gt;Ubuntu 14.04를 설치합니다. 최신 LTS인 16.04는 GTX1080 Ti GPU가 달린 서버에서 바로 부팅 시 검은 화면만 뜨는 문제가 있습니다. 설정을 바꿔 이 문제를 우회할 수는 있지만 설치 과정에서 복잡성을 최소화하기 위해 14.04를 설치하는 방법을 택했습니다. 14.04는 언제든지 16.04로 업그레이드할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;ubuntu-다운받기&quot;&gt;Ubuntu 다운받기&lt;/h3&gt;

&lt;p&gt;Ubuntu 14.04로 검색한 뒤 나오는 페이지(http://releases.ubuntu.com/14.04/)에서 &lt;a href=&quot;http://releases.ubuntu.com/14.04/ubuntu-14.04.5-desktop-amd64.iso&quot;&gt;64-bit PC (AMD64) desktop image&lt;/a&gt;를 다운받습니다.&lt;/p&gt;

&lt;h3 id=&quot;부팅-디스크-만들기&quot;&gt;부팅 디스크 만들기&lt;/h3&gt;

&lt;p&gt;USB 하나를 부팅 디스크로 만들어야 합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;다음 과정은 Mac 기준이며 윈도우의 경우 다른 방식이 필요합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;먼저, Disk Utility를 이용해서 USB를 포맷합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Applications&lt;/strong&gt; &amp;gt; &lt;strong&gt;Disk Utility&lt;/strong&gt;를 실행합니다.&lt;/li&gt;
  &lt;li&gt;USB를 선택한 뒤 &lt;strong&gt;Erase&lt;/strong&gt;를 클릭합니다.&lt;/li&gt;
  &lt;li&gt;Format은 &lt;strong&gt;MS-DOS (FAT)&lt;/strong&gt;으로 지정하고 Scheme은 디폴트 상태로 둔 뒤 &lt;strong&gt;Erase&lt;/strong&gt;를 눌러 포맷을 진행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8FR4GM0V/screenshot.png?pub_secret=d1d065ce2b&quot; alt=&quot;Disk Utility에서 USB 포맷하기&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;UNetbootin(https://unetbootin.github.io/)를 설치합니다.&lt;/li&gt;
  &lt;li&gt;설치한 UNetbootin에 다운받은 Ubuntu 14.04 파일(.iso)을 넣고 USB를 지정해주면 부팅 디스크를 만들어줍니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8GGX7F0W/screenshot.png?pub_secret=32447bd174&quot; alt=&quot;UNetbootin으로 부팅 디스크 만들기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 부팅 디스크가 만들어졌습니다. 이 USB를 서버에 꽂은 뒤 BIOS에서 부팅을 할 때 &lt;strong&gt;Boot Menu&lt;/strong&gt;에서 USB에 해당하는 항목을 클릭한 뒤 &lt;strong&gt;Install Ubuntu&lt;/strong&gt;를 선택한 뒤 나오는 안내에 따라 설정을 입력하면 Ubuntu 설치가 완료됩니다.&lt;/p&gt;

&lt;h5 id=&quot;트러블-슈팅&quot;&gt;트러블 슈팅&lt;/h5&gt;

&lt;p&gt;서버의 전원을 켰을 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;CPU Fan speed error detected&lt;/code&gt;라는 문구가 계속해서 떴습니다. 이는 제가 수냉식 쿨러를 사용했고 ASUS 메인보드에서 이슈가 있었기 때문이었습니다. BIOS 상에서 Fan 설정을 바꾸어서 해결했습니다. (참고 : &lt;a href=&quot;http://rgy0409.tistory.com/1165&quot;&gt;아수스 CPU Fan speed errer detected 해결하기&lt;/a&gt;)&lt;/p&gt;

&lt;h1 id=&quot;nvidia-driver-설치하기&quot;&gt;NVIDIA driver 설치하기&lt;/h1&gt;

&lt;p&gt;Ubuntu에서 NVIDIA driver를 설치하는 가장 간단하고 권장되는 방법은 운영체제가 제공하는 설정 메뉴에서 GUI 그래픽 드라이버 설치 방법를 따르는 것입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu에서 &lt;strong&gt;System Settings&lt;/strong&gt; &amp;gt; &lt;strong&gt;Software &amp;amp; Updates&lt;/strong&gt; &amp;gt; &lt;strong&gt;Additional Drivers&lt;/strong&gt;를 클릭합니다.&lt;/li&gt;
  &lt;li&gt;잠시 기다린 뒤 표시되는 선택지 중에 &lt;strong&gt;using NVIDIA binary driver&lt;/strong&gt;를 선택합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8GU1GBQF/driver.png?pub_secret=a6137dc6e3&quot; alt=&quot;System Settings에서 NVIDIA driver 다운로드 하기&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;설치-확인하기&quot;&gt;설치 확인하기&lt;/h3&gt;

&lt;p&gt;다음 명령어를 터미널 창(단축키 : ctrl + alt + t)에서 입력합니다. 이 때 GPU 정보가 올바르게 표시되면 설치가 정상적으로 완료된 것입니다. 첫번째 명령어는 텍스트로, 두번째 명령어는 그래픽으로 GPU 정보를 표시합니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-settings&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8F6NLDEC/smi.png?pub_secret=7ecd36a66c&quot; alt=&quot;driver 설치 후 nvidia-smi가 정상적으로 표시된 화면&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h5&gt;

&lt;p&gt;CLI를 이용해 NVIDIA driver를 설치하고 싶다면 다음 자료를 참고합니다. 다만 두번째 링크에서도 밝히고 있듯이 이는 권장되는 방식은 아닙니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://pythonkim.tistory.com/48&quot;&gt;[우분투] nvidia 드라이버 설치&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://askubuntu.com/questions/481414/install-nvidia-driver-instead-of-nouveau&quot;&gt;Install Nvidia driver instead of nouveau&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cuda-설치하기&quot;&gt;CUDA 설치하기&lt;/h1&gt;

&lt;p&gt;현재 CUDA 최신 버전은 9.1이지만 TensorFlow는 CUDA 8.0 설치를 요구하고 있습니다. 따라서 여기에서도 CUDA 8.0을 설치하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CUDA 8.0 다운로드 페이지 (https://developer.nvidia.com/cuda-80-ga2-download-archive)에 들어갑니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linux &amp;gt; x86_64 &amp;gt; Ubuntu &amp;gt; 14.04 &amp;gt; deb (local)&lt;/strong&gt;을 선택하고 &lt;a href=&quot;https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1404-8-0-local-ga2_8.0.61-1_amd64-deb&quot;&gt;다운로드&lt;/a&gt;합니다.&lt;/li&gt;
  &lt;li&gt;다운로드 페이지에서 안내되는 것처럼 다음 명령어를 입력합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;dpkg &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; cuda-repo-ubuntu1404-8-0-local-ga2_8.0.61-1_amd64.deb
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get install cuda
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;reboot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;bashrc 파일을 열고 맨 아래에 다음 환경변수를 추가합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gedit ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CUDA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/local/cuda-8.0
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/local/cuda-8.0/bin&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;:+:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/local/cuda-8.0/lib64&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;:+:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8F5HGB3J/cuda.png?pub_secret=88515d4aa2&quot; alt=&quot;CUDA 다운로드 페이지&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;참고-자료-1&quot;&gt;참고 자료&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://haanjack.github.io/cuda/2016-02-29-cuda-linux/&quot;&gt;Ubuntu에 CUDA 설치&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://seojmediview.com/2017/08/09/ubuntu-16-04-lts%ec%97%90-tensorflow-gpu%eb%b2%84%ec%a0%84-%ec%84%a4%ec%b9%98%ed%95%98%ea%b8%b0/&quot;&gt;Ubuntu 16.04 LTS에 tensorflow gpu버전 설치하기&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cudnn-설치하기&quot;&gt;cuDNN 설치하기&lt;/h1&gt;

&lt;p&gt;TensorFlow가 cuDNN 6.0을 요구하므로 최신 버전인 7.0이 아닌 6.0 버전을 설치해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;cuDNN 다운로드 페이지(https://developer.nvidia.com/cudnn)에 들어갑니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Download&lt;/strong&gt; 버튼을 클릭하면 회원 가입을 하라는 문구가 뜹니다. NVIDIA 회원 가입을 진행합니다.&lt;/li&gt;
  &lt;li&gt;로그인 후 다시 &lt;strong&gt;Download&lt;/strong&gt; 버튼을 클릭하고 몇가지 질문에 답한 후 이용 약관에 동의하면 다운로드 가능한 버전들을 볼 수 있습니다.&lt;/li&gt;
  &lt;li&gt;이 중에서 &lt;strong&gt;Download cuDNN v6.0 (April 27, 2017), for CUDA 8.0&lt;/strong&gt; 를 클릭하면 다운로드 리스트가 뜹니다.&lt;/li&gt;
  &lt;li&gt;Linux용 버전인 &lt;a href=&quot;https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v6/prod/8.0_20170307/cudnn-8.0-linux-x64-v6.0-tgz&quot;&gt;cuDNN v6.0 Library for Linux&lt;/a&gt; 링크를 클릭하면 다운로드가 진행됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8FQY896W/cdnn-annotated.png?pub_secret=f996fb45cc&quot; alt=&quot;cuDNN 다운로드 페이지&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다음 명령어를 입력해서 다운받은 cuDNN 파일의 압축을 풀고 cuda 라이브러리에 복사합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;Downloads/

&lt;span class=&quot;nb&quot;&gt;tar &lt;/span&gt;xvzf cudnn-8.0-linux-x64-v5.1.tgz
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;cp cuda/include/cudnn.h /usr/local/cuda-8.0/include
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;cp cuda/lib64/libcudnn&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/local/cuda-8.0/lib64
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;chmod a+r /usr/local/cuda-8.0/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;참고-자료-2&quot;&gt;참고 자료&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://seojmediview.com/2017/08/09/ubuntu-16-04-lts%ec%97%90-tensorflow-gpu%eb%b2%84%ec%a0%84-%ec%84%a4%ec%b9%98%ed%95%98%ea%b8%b0/&quot;&gt;Ubuntu 16.04 LTS에 tensorflow gpu버전 설치하기&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;anaconda-설치하기&quot;&gt;Anaconda 설치하기&lt;/h1&gt;

&lt;p&gt;Anaconda는 Python과 여러 라이브러리들을 설치하는 가장 편리하고 빠른 방법입니다. 현재 Anaconda를 다운받으면 Python 3.6으로 설치되지만, &lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/14182&quot;&gt;TensorFlow 1.4 GPU 버전이 아직 Python 3.6을 지원하지 않기 때문에&lt;/a&gt; Python 3.5 환경으로 맞춰줄 필요가 있습니다. 여기에서는 Python 3.5를 지원하는 Anaconda의 이전 버전을 설치하겠습니다.&lt;/p&gt;

&lt;p&gt;또한, 설치된 Python을 모든 사용자가 사용할 수 있게 하기 위해 아래 과정부터 CLI 명령어는 root 계정에서 실행하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;su
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Anaconda 아카이브 페이지(https://repo.continuum.io/archive/index.html)에 접속합니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://repo.continuum.io/archive/Anaconda3-4.2.0-Linux-x86_64.sh&quot;&gt;Anaconda3-4.2.0-Linux-x86_64.sh&lt;/a&gt; 버전을 선택하여 다운로드합니다. Anaconda3 4.2 버전은 Python 3.5가 디폴트인 버전입니다.&lt;/li&gt;
  &lt;li&gt;다운로드 받은 파일이 담긴 폴더로 이동하여 bash로 해당 파일을 실행합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bash Anaconda3-4.2.0-Linux-x86_64.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;(Optional) 모든 사용자가 설치된 Python에 접근할 수 있게 하기 위해 Anaconda 설치 중 설치 경로 설정에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/conda&lt;/code&gt;를 입력하였습니다. 이 과정을 생략하면 사용자의 home 디렉토리 아래에 Anaconda가 설치됩니다.&lt;/li&gt;
  &lt;li&gt;PATH를 추가하겠느냐는 질문에 yes를 입력합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;설치-확인하기-1&quot;&gt;설치 확인하기&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt;을 실행했을 때 Anaconda 4.2의 Python 3.5가 실행되면 정상적으로 설치된 것입니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python

Python 3.5.2 |Anaconda 4.2.0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;64-bit&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;| &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;default, Jul  2 2016, 17:53:06&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;GCC 4.4.7 20120313 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Red Hat 4.4.7-1&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; on linux
Type &lt;span class=&quot;s2&quot;&gt;&quot;help&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;copyright&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;credits&quot;&lt;/span&gt; or &lt;span class=&quot;s2&quot;&gt;&quot;license&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;more information.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;tensorflow-설치하기&quot;&gt;Tensorflow 설치하기&lt;/h1&gt;

&lt;p&gt;이 글을 작성하는 때에 TensorFlow의 최신 버전은 1.4입니다. 최신 버전인 TensorFlow 1.4 버전을 설치해 보겠습니다. TensorFlow에서는 가상 환경 위에 설치를 권장하고 있지만 여기에서는 사용의 편리함을 위해 디폴트 Python 위에 pip으로 바로 설치합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다음 명령어로 libcupti-dev 라이브러리를 설치합니다. 이는 TensorFlow &lt;a href=&quot;https://www.tensorflow.org/install/install_linux&quot;&gt;공식 설치 가이드&lt;/a&gt;의 요구사항을 따른 것입니다. CUDA와 cuDNN은 이미 설치했으니 마지막 단계인 libcupti-dev 라이브러리만 남았습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get install libcupti-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;pip으로 TensorFlow GPU 버전을 설치합니다. pip으로 설치하는 가이드는 &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#InstallingNativePip&quot;&gt;Installinng with native pip&lt;/a&gt;에서 찾을 수 있고 설치 URL은 &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package&quot;&gt;URL of the TensorFlow Python package&lt;/a&gt;에서 Python 3.5 버전을 선택했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install &lt;span class=&quot;nt&quot;&gt;--ignore-installed&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--upgrade&lt;/span&gt; https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp35-cp35m-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;설치-확인하기-2&quot;&gt;설치 확인하기&lt;/h3&gt;

&lt;p&gt;Python을 실행한 뒤 TensorFlow를 import하고, Session을 열 때 GPU 정보가 표시되면 TensorFlow GPU 버전이 정상적으로 설치된 것입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2017&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;09.494588&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common_runtime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu_device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1030&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Found&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GeForce&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GTX&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1080&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ti&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;major&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memoryClockRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GHz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.683&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pciBusID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;0000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;00.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;totalMemory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.91&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GiB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freeMemory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.49&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GiB&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2017&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;09.494619&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common_runtime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu_device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Creating&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TensorFlow&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GPU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GeForce&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GTX&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1080&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ti&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pci&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bus&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;0000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;00.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;capability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;6.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x7f9c04d43668&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pytorch-설치하기&quot;&gt;PyTorch 설치하기&lt;/h3&gt;

&lt;p&gt;PyTorch 설치는 공식 사이트(www.pytorch.org)를 그대로 따르면 됩니다. conda로 Python 3.5, CUDA 8.0 버전을 설치하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install pytorch torchvision &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; pytorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;네트워크-연결하기&quot;&gt;네트워크 연결하기&lt;/h1&gt;

&lt;p&gt;이제 서버 개발 환경 세팅은 완료되었으니, 이 서버를 다른 컴퓨터에서도 접속할 수 있게 만들어야 합니다. 이를 위해서 외부 포트를 내부 포트로 연결하는 포트 포워딩을 설정하고, Ubuntu 내에서 SSH를 외부에서 접근 가능하도록 설정합니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;다음 과정은 iptime을 사용한다고 가정합니다. 다른 제품을 쓰는 경우 과정이 약간 다를 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;포트포워딩&quot;&gt;포트포워딩&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;192.168.0.1&lt;/strong&gt; 주소로 접속하여 iptime 관리 페이지로 이동합니다. 관리 페이지를 모를 때는 Ubuntu 내 Terminal에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;ifconfig&lt;/code&gt;를 입력하여 내부 IP 주소(inet addr)를 알아낸 뒤 마지막 자리를 1로 치환한 주소가 관리 페이지 주소일 가능성이 높습니다.&lt;/li&gt;
  &lt;li&gt;로그인 후 &lt;strong&gt;관리 도구 &amp;gt; 고급 설정 &amp;gt; NAT/라우터 관리 &amp;gt; 포트포워드 설정&lt;/strong&gt;로 이동합니다.&lt;/li&gt;
  &lt;li&gt;새 규칙을 추가합니다. &lt;strong&gt;규칙 이름&lt;/strong&gt;과 &lt;strong&gt;외부 포트&lt;/strong&gt;, &lt;strong&gt;내부 포트&lt;/strong&gt;, 그리고 &lt;strong&gt;내부 IP주소&lt;/strong&gt;를 설정해주면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F8FSAKX0U/iptime.png?pub_secret=6b0d0ea838&quot; alt=&quot;iptime 포트포워딩 설정&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ssh-외부-접속-설정하기&quot;&gt;SSH 외부 접속 설정하기&lt;/h3&gt;

&lt;p&gt;SSH 설정 방법은 &lt;a href=&quot;https://thishosting.rocks/how-to-enable-ssh-on-ubuntu/&quot;&gt;How to Enable SSH on Ubuntu&lt;/a&gt;를 따랐습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OpenSSH를 설치합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get install openssh-server &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;다음 명령어로 SSH 설정 파일을 엽니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;nano /etc/ssh/sshd_config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Port 설정을 수정합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음과 같은 라인을&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Port 22&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 변경합니다. 이 때 Port 번호는 포트포워드에서 외부 포트에 연결한 내부 포트 번호와 일치해야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Port 1337
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;SSH를 재시작합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;service ssh restart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;공인-ip-알아내기&quot;&gt;공인 IP 알아내기&lt;/h3&gt;

&lt;p&gt;외부에서 접근하려면 공인 IP(public IP)를 알아야 합니다. 이는 간단하게 구글에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;my ip&lt;/code&gt; 등으로 검색해서 나오는 사이트에서 알아낼 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;설정-확인하기&quot;&gt;설정 확인하기&lt;/h3&gt;

&lt;p&gt;외부 컴퓨터에서 SSH로 접속에 성공하면 설정이 완료된 것입니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;다음 명령어는 Mac이나 Linux에서 바로 실행 가능하지만, 일반적인 Windows에서 동작하지 않습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &amp;lt;공인 IP&amp;gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; &amp;lt;username&amp;gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &amp;lt;포트 번호&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Sun, 17 Dec 2017 18:10:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2017/12/17/deeplearning-server-setting.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2017/12/17/deeplearning-server-setting.html</guid>
        
        
      </item>
    
      <item>
        <title>머신러닝 모델의 블랙박스 속을 들여다보기 : LIME</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7V7K1V6H/dog_explained_3.png?pub_secret=d51a563d02&quot; alt=&quot;LIME으로 개와 고양이 이미지 분류 모델의 예측 결과 설명하기&quot; /&gt;&lt;/p&gt;

&lt;p&gt;머신 러닝 모델에 대해서 예측의 이유를 설명하는 것은 어렵습니다. 모델이 복잡해질수록 예측의 정확도는 올라가지만, 결과의 해석은 어려워지죠. 그렇기 때문에 많은 머신 러닝 모델들이 블랙박스라고 불립니다.&lt;/p&gt;

&lt;p&gt;하지만 모델이 ‘왜’ 그렇게 작동하는지 아는 것은 중요합니다. 의사가 “인공 지능이 이렇게 하래요”라고 말하면서 환자를 수술하지는 않겠죠. 은행에서 의심스러운 거래를 차단하는 경우에도 차단당한 이용자는 설명을 요구할 것입니다. 하물며 Netflix에서 볼 영화를 선택할 때도, 추천 영화에 시간을 투자하기 전에 어느 정도의 모델에 대한 신뢰감은 필요합니다.&lt;/p&gt;

&lt;p&gt;모델의 예측의 근거를 이해하는 것은 언제 모델을 신뢰할지 또는 신뢰하지 않을지 결정하는 데도 중요합니다. 아래 그림을 예를 들어볼까요. 아래 그림은 머신 러닝 모델이 특정 환자가 독감에 걸렸다고 예측하는 예입니다. 만약 예측을 하는 것만으로 끝나지 않고, ‘Explainer’가 있어서 이 예측을 내릴 때 모델에서 가장 중요했던 증상을 강조해주며 모델을 설명한다면, 아마 의사는 모델을 신뢰하거나 또는 신뢰하지 않기로 결정하기가 좀 더 쉬울 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d3ansictanv2wj.cloudfront.net/figure1-a9533a3fb9bb9ace6ee96b4cdc9b6bcb.jpg&quot; alt=&quot;사람에게 모델의 예측을 설명하기. 출처: Marco Tulio Ribeiro.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모델의 예측을 얼마나 믿을 수 있는지는 보통 평가용 데이터셋에서 구한 정확도 등으로 검증합니다. 하지만, 머신 러닝 해보신 분들이라면 다 아시듯이 현실에서 이런 수치들은 흔히 믿을 수 없을 때가 많습니다. 때로는 평가용과 학습용 데이터셋을 잘못 나누어서 평가용 데이터셋의 정보가 학습용 데이터셋에 섞여 있기도 하죠. 때로는 평가용 데이터셋이 현실을 정확하게 반영하지 않을 때도 있습니다. 이럴 때 모델의 작동 방식을 이해하는 것은 모델의 성능을 평가하는 데 유용합니다. 사람은 보통 모델이 어떻게 행동해야 한다는 직관을 갖고 있습니다. 모델의 예측의 근거를 보여주고 사람의 직관을 이용하면 정확도 등의 지표로 잡아내기 어려운 모델의 신뢰도를 평가할 수 있죠.&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 어떤 예측 모델이든 그 모델이 ‘왜’ 그렇게 예측했는지 설명해주는 모델, LIME (Local Interpretable Model-agnostic Explanations)에 대해서 알아보겠습니다. 그리고 Python과 Jupyter Notebook에서 쉽게 LIME을 사용하는 방법을 소개해드리겠습니다.&lt;/p&gt;

&lt;h1 id=&quot;무엇을-할-수-있나요&quot;&gt;무엇을 할 수 있나요?&lt;/h1&gt;

&lt;p&gt;LIME은 뉴럴 네트워크, 랜덤 포레스트, SVM 등 어떤 머신 러닝 예측 모델에도 적용할 수 있습니다. 데이터 형식도 이미지, 텍스트, 수치형 데이터를 가리지 않습니다. 텍스트와 이미지 분류 문제에 LIME을 이용하는 예시를 통해 LIME이 어떤 알고리즘인지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;먼저, 텍스트 예시입니다. 20 newsgroups 데이터셋은 텍스트 분류 문제에서 유명한 데이터셋입니다. 여기서는 ‘기독교’ 카테고리와 ‘무신론’ 카테고리를 분류하는 모델을 살펴봅니다. 이 두 카테고리는 서로 많은 단어들을 공유하기 때문에 분류하기 어려운 문제로 알려져 있습니다.&lt;/p&gt;

&lt;p&gt;랜덤 포레스트를 의사 결정 나무 500개로 돌리면 92.4%의 평가용 데이터셋 정확도를 얻습니다. 굉장히 높은 수치죠. 만약 정확도가 유일한 신뢰의 지표였다면 분명 이 분류기를 믿었을 겁니다. 하지만, 무작위로 뽑은 데이터에 대한 LIME의 설명을 들여다보면 그 결과는 사뭇 다릅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d3ansictanv2wj.cloudfront.net/figure5-cd7d3c5128549df1e957bf8f9f93bb2b.jpg&quot; alt=&quot;20 newsgroups 데이터셋 중 한 예측에 대한 설명.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이것은 모델이 예측은 정확하게 했지만 그 이유는 틀린 경우입니다. 이메일 상단에 있는 ‘posting’이란 단어는 학습 데이터셋에서는 21.6%의 데이터에서 나타나지만 ‘기독교’ 카테고리에서는 두번밖에 나타나지 않습니다. 테스트셋에서도 마찬가지로 데이터 중 20%의 경우에 ‘posting’이 나오지만 ‘기독교’에는 두번밖에 나오지 않습니다. 하지만 실제 현실에서 이런 패턴이 나타날 것이라고 예상하기는 어렵습니다. 이처럼 모델이 대체 뭘 하는지 이해하고 있다면 모델이 얼마나 일반화 가능한지 인사이트를 얻기가 훨씬 쉽습니다.&lt;/p&gt;

&lt;p&gt;두번째 예로, 구글의 inception 네트워크의 이미지 분류 결과를 설명해봅시다. 이 경우에는, 아래 그림에서 볼 수 있듯이 분류기는 주어진 이미지가 개구리일 확률이 가장 높다고 예측했습니다. 그 다음으로는 당구대랑 풍선을 좀 더 낮은 확률로 예측했네요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d3ansictanv2wj.cloudfront.net/Figure-6-c8db425eefec7cff5a3cf035a40d8841.jpg&quot; alt=&quot;LIME으로 오답의 이유 이해하기. 출처: Marco Tulio Ribeiro.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;LIME은 inception 모델이 주어진 이미지를 개구리라고 예측한 데에는 개구리의 얼굴이 가장 중요한 역할을 했다고 설명합니다. 그런데 당구대와 풍선은 왜 나온 것일까요? 개구리의 손과 눈은 당구공을 닮았습니다. 초록색 배경에 당구공 같이 생긴 것들이 있으니 모델이 당구대라고 생각한 것입니다. 개구리가 들고 있는 하트는 빨간색 풍선을 닮았습니다. 이것이 모델이 풍선이라고 예측한 이유입니다. 이렇듯 LIME을 통해 왜 모델이 이런 예측들을 했는지 이해할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;어떻게-사용하나요&quot;&gt;어떻게 사용하나요?&lt;/h1&gt;

&lt;p&gt;LIME은 파이썬 패키지로 공개되어 있습니다. 이제 LIME을 설치하고 사용하는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;설치하기&quot;&gt;설치하기&lt;/h2&gt;

&lt;p&gt;pip으로 쉽게 설치할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lime&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# for python3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lime&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;예측-함수-모양-맞춰주기&quot;&gt;예측 함수 모양 맞춰주기&lt;/h2&gt;

&lt;p&gt;LIME에 예측 모델을 넣어주기 위해서 예측 모델을 함수 형태로 만들어주어야 합니다. 예측 모델을 scikit-learn로 만들었다면 모델의 &lt;code class=&quot;highlighter-rouge&quot;&gt;predict_proba&lt;/code&gt; 함수를 쓰는 것으로 충분합니다. 만약 예측 모델이 TensorFlow 모델이라면 다음과 같이 함수로 만들어줄 수 있습니다. 이 함수의 입력은 원본 데이터이고 출력은 각 카테고리의 확률입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probabilities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processed_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;explainer-만들기&quot;&gt;Explainer 만들기&lt;/h2&gt;

&lt;p&gt;데이터의 형식에 따라 만들어줘야 하는 Explainer가 다릅니다. 각 경우를 나눠서 설명드리겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;이미지의-경우&quot;&gt;이미지의 경우&lt;/h3&gt;

&lt;p&gt;다음과 같은 이미지에 대한 이미지 분류 모델의 예측값을 설명해봅시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7UHLG85P/dog_and_cat.png?pub_secret=0b718fa371&quot; alt=&quot;개와 고양이 사진&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 예측 결과
286 Egyptian cat 0.000892741
242 EntleBucher 0.0163564
239 Greater Swiss Mountain dog 0.0171362
241 Appenzeller 0.0393639
240 Bernese mountain dog 0.829222
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;먼저, lime 패키지에서 이미지 모듈을 불러옵니다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-pyrhon&quot;&gt;from lime.lime_image import LimeImageExplainer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이미지 모듈에서 Explainer를 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;explainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LimeImageExplainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;특정 이미지에 대한 설명을 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# image : 설명하고자 하는 이미지입니다.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# predict_fn : 위에서 만든 예측 모델 함수입니다.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# hide_color=0 : superpixel을 회색으로 가리겠다는 뜻입니다. 이 인자가 없을 경우 픽셀들 색깔의 평균으로 가려집니다.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 아래 코드를 실행시킬 때 시간이 다소 걸릴 수 있습니다.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explain_instance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hide_color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 만들어진 설명을 이미지로 나타내봅시다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;skimage.segmentation&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mark_boundaries&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_image_and_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positive_only&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hide_rest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_boundaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7UHLL2CR/dog_explained_1.png?pub_secret=d32467efb4&quot; alt=&quot;모델이 사진을 개로 분류하는 데 가장 중요했던 요소만 뽑아볼 수 있습니다.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이미지의 나머지 부분도 같이 보고 싶다면 다음과 같이 할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_image_and_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positive_only&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hide_rest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_boundaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7V15RCJX/dog_explained_2.png?pub_secret=bcac1a942a&quot; alt=&quot;사진에서 노란색 선으로 표시된 영역이 개로 예측하는 데 가장 중요했던 부분입니다.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;어떤 부분이 개로 예측할 확률을 높이는 부분이었고 어떤 부분이 확률을 낮추는 부분이었는지 보기 위해서는 다음 코드를 씁니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_image_and_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;240&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positive_only&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hide_rest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_boundaries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7V7K1V6H/dog_explained_3.png?pub_secret=d51a563d02&quot; alt=&quot;사진을 개로 예측하는 확률을 높인 부분(초록색)과 낮춘 부분(빨간색)을 각각 볼 수 있습니다.&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;설명을 위해서 코드의 많은 부분을 생략했습니다. Tensorflow에서 slim의 inception v3 모델을 LIME으로 설명하는 전체 코드는 &lt;a href=&quot;https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20images.html&quot;&gt;여기&lt;/a&gt;에서 볼 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;텍스트의-경우&quot;&gt;텍스트의 경우&lt;/h3&gt;

&lt;p&gt;lime 패키지에서 텍스트 모듈을 불러옵니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lime.lime_text&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LimeTextExplainer&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;텍스트 모듈에서 Explainer를 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# class_names : 각 카테고리들의 이름을 줄 수 있습니다. (없는 경우 0, 1 같은 index로 보여집니다.)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;explainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LimeTextExplainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;특정 텍스트에 대한 설명을 생성합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# text : 설명하고자 하는 텍스트입니다.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# predict_fn : 예측 모델 함수입니다.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;explainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;explain_instance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 만들어진 설명을 확인해봅시다. LIME은 시각적으로 한 눈에 들어오도록 설명을 html로 생성하는 기능도 갖고 있습니다. 그리고 이 설명을 Jupyter Notebook에서 보기도 쉽게 되어 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;explanation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_in_notebook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7V4WD8P6/screenshot.png?pub_secret=afa0fc19b1&quot; alt=&quot;텍스트에 대한 예측을 LIME으로 설명할 수 있습니다.&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;전체 코드는 &lt;a href=&quot;https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html&quot;&gt;여기&lt;/a&gt;에서 볼 수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이밖에도 &lt;a href=&quot;https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html&quot;&gt;수치형 테이블 데이터에 대해서&lt;/a&gt;, 또는 &lt;a href=&quot;https://marcotcr.github.io/lime/tutorials/Using%2Blime%2Bfor%2Bregression.html&quot;&gt;회귀 문제에 대해서&lt;/a&gt;도 LIME을 적용할 수 있습니다.&lt;/p&gt;

&lt;h1 id=&quot;어떻게-작동하나요&quot;&gt;어떻게 작동하나요?&lt;/h1&gt;

&lt;p&gt;LIME의 핵심 아이디어는 이것입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;입력값을 조금 바꿨을 때 모델의 예측값이 크게 바뀌면, 그 변수는 중요한 변수이다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이미지 분류 문제에 LIME을 적용하는 예시를 들어보겠습니다. 먼저 그림을 superpixel이라고 불리는 해석 가능한 요소로 쪼개는 전처리 과정을 거칩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d3ansictanv2wj.cloudfront.net/figure3-2cea505fe733a4713eeff3b90f696507.jpg&quot; alt=&quot;이미지를 해석 가능한 요소로 쪼개기. 출처: Marco Tulio Ribeiro, Pixabay.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 나서 변수에 약간의 변화(perturbation)를 줍니다. 이미지의 경우에는 superpixel 몇개를 찝어서 회색으로 가립니다. 그리고 모델에 넣고 예측값을 구합니다. 만약 예측값이 많이 변하면 가렸던 부분이 중요했다는 것을 알 수 있겠죠. 반대로 예측값이 많이 달라지지 않았으면 가렸던 부분이 별로 중요하지 않았나보다, 라고 알게 되겠죠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d3ansictanv2wj.cloudfront.net/figure4-99d9ea184dd35876e0dbae81f6fce038.jpg&quot; alt=&quot;LIME으로 예측 설명하기. 출처: Marco Tulio Ribeiro.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 예시에서 원본 사진은 0.54 확률로 개구리로 예측됩니다. 이 사진을 첫번째 변형(perturbed instance)처럼 가렸더니 개구리일 확률이 0.85로 높아졌습니다. 사진에서 남은 부분이 개구리라고 예측하는 데 중요한 요소라는 것을 알 수 있죠. 두번째 변형처럼 가렸더니 개구리일 확률이 0.00001로 매우 낮아졌습니다. 그러면 방금 가린 부분이 개구리라고 판단하는 데 중요한 요소였다는 것을 알 수 있겠죠. 세번째 변형처럼 가리면 개구리일 확률이 별로 변하지 않습니다. 이때 가린 부분은 개구리라고 판단하는 데 별로 중요하지 않았다는 것을 알 수 있죠. 이렇게 여러번의 과정을 거친 뒤 결국 어떤 superpixel이 개구리라고 판단하는 데 가장 중요했는지 찾는 것이 LIME의 핵심입니다.&lt;/p&gt;

&lt;p&gt;이 방법은 두가지 점에서 장점이 있습니다. 첫째, 이 방법은 어떤 모델이든 상관 없이(model-agnostic) 적용할 수 있는 방법입니다. 둘째, 이 방법은 해석가능성의 측면에서 굉장한 이점을 갖고 있는데요, 입력은 모델 내부의 변수보다 인간이 이해하기 훨씬 쉽기 때문입니다. 예를 들어 모델이 내부적으로는 word embedding 같이 복잡한 속성을 쓰고 있더라도, 모델의 입력인 단어는 인간이 이해할 수 있는 방식으로 살짝 바꿔보기가 훨씬 쉽죠.&lt;/p&gt;

&lt;p&gt;LIME은 한번에 하나의 데이터에 대해서만 모델의 예측 결과를 설명합니다. 그리고 그 데이터를 예측하는 데 중요했던 변수만을 뽑아줍니다. 예를 들어, 어떤 환자가 독감이 걸렸다고 진단할 때 중요했던 증상들은 아마도 위염을 가진 환자를 진단할 때 중요하지 않을 수도 있겠죠.&lt;/p&gt;

&lt;p&gt;수학적으로 LIME이 블랙 박스 모델을 설명하는 방법은 모델을 해석 가능한 간단한 선형 모델로 근사하는 것입니다. 복잡한 모델 전체를 근사하는 것은 어렵지만, 우리가 설명하고 싶은 예측 주변에 대해서만 간단한 모델로 근사하는 것은 매우 쉽습니다.&lt;/p&gt;

&lt;p&gt;이해를 돕기 위해서 아래 그림처럼 어떤 모델의 변수가 두 개만 있고 데이터를 두 변수를 이용해 파란색과 붉은색 두 클래스로 분류한다고 생각해 봅시다. 모델의 decision boundary(빨간색과 파란색이 나뉘는 경계)는 매우 복잡합니다. 하지만 아래 그림처럼 우리가 설명하려는 데이터(굵은 빨간 십자가)의 살짝 옆에만 본다면, 그 주변만 근사한 선형 함수를 만들어낼 수 있습니다. 이 선형 함수는 전체적으로 보면 원래 모델과는 전혀 다르지만, 특정 예시 주위에서는 원래 모델과 비슷하게 행동합니다. 이렇게 만든 간단한 선형 함수를 보면 이 예시에서 어떤 변수가 중요한 역할을 하는지 알 수 있죠. 이것이 LIME에 Local이라는 말이 붙는 이유입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6ENRVASX/lime.png?pub_secret=197fda2c73&quot; alt=&quot;LIME이 선형 근사 함수를 만드는 방법. 출처: Marco Tulio Ribeiro.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;좀 더 구체적으로 들어가면 선형 함수로의 근사는 다음과 같은 방법으로 구현됩니다. 먼저 원본 데이터를 살짝 변형시켜서(이미지의 일부를 가리거나 단어를 제거해서) 데이터셋을 만듭니다. 각각의 변형된 데이터를 모델에 넣어서 예측값을 구합니다. 그 다음 이 데이터셋에 간단한 선형 모델을 학습시키는데, 이 때 변형된 데이터와 원본 데이터 간의 유사성만큼 가중치를 줍니다. 이렇게 하면 주로 원본 데이터와 가까운 영역에서 블랙 박스 모델과 비슷하게 행동하는 선형 모델을 만들 수 있습니다. 이 방식으로 LIME은 원본 데이터에 대한 예측의 설명을 만들어냅니다.&lt;/p&gt;

&lt;h1 id=&quot;마치며&quot;&gt;마치며&lt;/h1&gt;

&lt;p&gt;블랙 박스 모델을 열어 그 속을 들여다볼 수 있다는 것은 큰 이점이죠. 이 점에서 LIME은 머신 러닝을 사용하는 사람들에게 매우 유용한 도구입니다.&lt;/p&gt;

&lt;p&gt;저는 LIME을 사용하다가 한글이 깨지는 문제를 발견하고 이를 해결하는 pull request로 LIME의 contributor가 되었습니다. 이처럼 LIME은 빠르게 발전하는 모델이고 지금도 기능 추가와 개선이 꾸준히 일어나는 프로젝트입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F7W5Y815M/screenshot.png?pub_secret=f2823100e3&quot; alt=&quot;pull request가 merge된 모습.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지금까지 거의 모든 머신 러닝 프로젝트는 “데이터 수집 -&amp;gt; 전처리 -&amp;gt; 모델링 -&amp;gt; 결론”으로 끝났습니다. 앞으로는 여기에서 끝나지 않고 LIME과 같은 도구를 이용해 모델을 설명하는 단계가 필수적이 될 것이라고 생각합니다.&lt;/p&gt;

&lt;p&gt;LIME을 요약하는 3분짜리 짧은 동영상으로 이 글을 마치겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=hUnRCxnydCc&quot; title=&quot;'Why Should I Trust You?': Explaining the Predictions of Any Classifier&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/hUnRCxnydCc/0.jpg&quot; alt=&quot;LIME&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;p&gt;이 글은 다음 자료들을 바탕으로 쓰여졌습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;논문 : &lt;a href=&quot;https://arxiv.org/abs/1602.04938&quot;&gt;“Why Should I Trust You?”: Explaining the Predictions of Any Classifier&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Article : &lt;a href=&quot;https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime&quot;&gt;Introduction to Local Interpretable Model-Agnostic Explanations (LIME)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/marcotcr/lime&quot;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 05 Nov 2017 21:07:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2017/11/05/LIME.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2017/11/05/LIME.html</guid>
        
        <category>featured</category>
        
        
      </item>
    
      <item>
        <title>Recurrent Neural Network (RNN) 이해하기</title>
        <description>&lt;h1 id=&quot;recurrent-neural-network-rnn-이해하기&quot;&gt;Recurrent Neural Network (RNN) 이해하기&lt;/h1&gt;

&lt;p&gt;음악, 동영상, 에세이, 시, 소스 코드, 주가 차트. 이것들의 공통점은 무엇일까요? 바로 시퀀스라는 점입니다. 음악은 음계들의 시퀀스, 동영상은 이미지의 시퀀스, 에세이는 단어들의 시퀀스로 볼 수 있습니다. 시퀀스의 길이는 가변적입니다. 소설에는 한 페이지짜리 단편소설도 있고 열권짜리 장편소설도 있죠. 기존의 뉴럴 네트워크 알고리즘은 이미지처럼 고정된 크기의 입력을 다루는 데는 탁월하지만, 가변적인 크기의 데이터를 모델링하기에는 적합하지 않습니다.&lt;/p&gt;

&lt;p&gt;RNN(Recurrent Neural Network, 순환신경망)은 시퀀스 데이터를 모델링 하기 위해 등장했습니다. RNN이 기존의 뉴럴 네트워크와 다른 점은 ‘기억’(다른 말로 hidden state)을 갖고 있다는 점입니다. 네트워크의 기억은 지금까지의 입력 데이터를 요약한 정보라고 볼 수 있습니다. 새로운 입력이 들어올때마다 네트워크는 자신의 기억을 조금씩 수정합니다. 결국 입력을 모두 처리하고 난 후 네트워크에게 남겨진 기억은 시퀀스 전체를 요약하는 정보가 됩니다. 이는 사람이 시퀀스를 처리하는 방식과 비슷합니다. 이 글을 읽을 때도 우리는 이전까지의 단어에 대한 기억을 바탕으로 새로운 단어를 이해합니다. 이 과정은 새로운 단어마다 계속해서 반복되기 때문에 RNN에는 Recurrent, 즉 순환적이라는 이름이 붙습니다. RNN은 이런 반복을 통해 아무리 긴 시퀀스라도 처리할 수 있는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6YUKQKCP/rnn-diagram.png?pub_secret=9e9b7d3f1e&quot; alt=&quot;RNN 다이어그램&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 다이어그램에서 빨간색 사각형은 입력, 노란색 사각형은 기억, 파란색 사각형은 출력을 나타냅니다. 첫번째 입력이 들어오면 첫번째 기억이 만들어집니다. 두번째 입력이 들어오면 기존의 기억과 새로운 입력을 참고하여 새 기억을 만듭니다. 입력의 길이만큼 이 과정을 얼마든지 반복할 수 있습니다. 각각의 기억은 그때까지의 입력을 요약해서 갖고 있는 정보입니다. RNN은 이 요약된 정보를 바탕으로 출력을 만들어 냅니다.&lt;/p&gt;

&lt;h1 id=&quot;what-can-rnns-do&quot;&gt;What can RNNs do?&lt;/h1&gt;

&lt;p&gt;RNN의 입력과 출력은 우리가 네트워크에게 시키고 싶은 것이 무엇이냐에 따라 얼마든지 달라질 수 있습니다. 아래는 몇가지 예시입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6XAEQH7T/rnn-examples.png?pub_secret=0eb724d01b&quot; alt=&quot;RNN의 구조 예시&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;고정크기 입력 &amp;amp; 고정크기 출력. 순환적인 부분이 없기 때문에 RNN이 아닙니다.&lt;/li&gt;
  &lt;li&gt;고정크기 입력 &amp;amp; 시퀀스 출력. 예) 이미지를 입력해서 이미지에 대한 설명을 문장으로 출력하는 이미지 캡션 생성&lt;/li&gt;
  &lt;li&gt;시퀀스 입력 &amp;amp; 고정크기 출력. 예) 문장을 입력해서 긍부정 정도를 출력하는 감성 분석기&lt;/li&gt;
  &lt;li&gt;시퀀스 입력 &amp;amp; 시퀀스 출력. 예) 영어를 한국으로 번역하는 자동 번역기&lt;/li&gt;
  &lt;li&gt;동기화된 시퀀스 입력 &amp;amp; 시퀀스 출력. 예) 문장에서 다음에 나올 단어를 예측하는 언어 모델&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;이미지-캡션-생성&quot;&gt;이미지 캡션 생성&lt;/h2&gt;

&lt;p&gt;이미지를 처리하는 CNN(Convolutional Neural Network)과 RNN을 결합하여 이미지를 텍스트로 설명해주는 모델을 만드는 것이 가능합니다. 이 모델은 위의 구조들 중 두번째, 고정크기 입력 &amp;amp; 시퀀스 출력에 해당합니다. 이미지라는 고정된 크기의 입력을 받아서 몇 단어로 표현될지 모를 가변적인 길이의 문장을 만들어내기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6XPSQ4NP/show-and-tell.png?pub_secret=1e78ced420&quot; alt=&quot;이미지 캡션 생성&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.4555&quot;&gt;Show and Tell: A Neural Image Caption Generator&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;자동-번역&quot;&gt;자동 번역&lt;/h2&gt;

&lt;p&gt;구글의 번역기와 네이버의 파파고는 RNN을 응용한 모델로 만들어졌습니다. RNN 기반 모델은 기존 통계 기반 모델의 비해 우수한 성능을 낸다고 알려져 있습니다. 이 모델은 시퀀스 입력 &amp;amp; 시퀀스 출력 구조를 갖고 있습니다. 이 구조의 모델을 다른 말로 encoder-decoder 모델이라고도 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6X6W5UTA/machine-translator.png?pub_secret=c4b0c11754&quot; alt=&quot;자동 번역&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.08144&quot;&gt;Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;show-me-the-code&quot;&gt;Show me the code&lt;/h1&gt;

&lt;h2 id=&quot;problem-definition&quot;&gt;Problem definition&lt;/h2&gt;

&lt;p&gt;지금까지는 RNN에 대한 개념적인 설명이었습니다. 이제부터 수식과 코드를 통해서 RNN에 대해 구체적으로 살펴보겠습니다. 이해를 위해서 간단한 RNN 모델을 직접 구현해 보겠습니다. 뉴럴 네트워크 분야에서는 고전적인 문제인 MNIST 숫자 손글씨 맞추기를 RNN으로도 풀 수 있습니다. 물론 이미지 그 자체는 고정된 크기의 데이터지만, 약간의 트릭을 써서 시퀀스 데이터로 만들 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 모델에서는 MNIST의 28 * 28 크기의 이미지를 28차원 벡터로 이루어진 28개의 시퀀스로 보고 RNN에 입력합니다. 출력은 0부터 9까지의 숫자입니다. 이렇게 모델의 입력과 출력을 구성하고 과연 RNN이 숫자 분류기로서 어느 정도의 성능을 낼 수 있을지 실험해 보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;variable-definition&quot;&gt;Variable definition&lt;/h2&gt;

&lt;p&gt;가장 먼저 할 일은 변수를 정의하는 것입니다. 아래 다이어그램은 만들려고 하는 모델을 변수 기호와 함께 나타낸 것입니다. $x_t$는 t 시간 스텝에서의 입력 벡터, $s_t$는 t 시간 스텝에서 RNN의 기억을 담당하는 hidden state, $o$는 출력 벡터입니다. U, W, V는 모델의 파라미터입니다. 첫 다이어그램에 없던 $s_{init}$은 hidden state의 초기값으로, 구현을 위해 필요한 부분입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6YNRNSTY/rnn-diagram-variables.png?pub_secret=fd7a7351a5&quot; alt=&quot;변수가 정의된 RNN 다이어그램&quot; /&gt;&lt;/p&gt;

&lt;p&gt;변수들의 차원을 써보면 이해하는 데 많은 도움이 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x_t \in \mathcal{R}^{28}$&lt;/li&gt;
  &lt;li&gt;$o \in \mathcal{R}^{10}$&lt;/li&gt;
  &lt;li&gt;$s_t \in \mathcal{R}^{100}$&lt;/li&gt;
  &lt;li&gt;$U \in \mathcal{R}^{28 \times 100}$&lt;/li&gt;
  &lt;li&gt;$W \in \mathcal{R}^{100 \times 100}$&lt;/li&gt;
  &lt;li&gt;$V \in \mathcal{R}^{100 \times 10}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;텐서플로어를 이용해 변수를 정의해 보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;MNIST 이미지를 변형하여 벡터의 시퀀스로 만드는 부분입니다. &lt;code class=&quot;highlighter-rouge&quot;&gt;x_raw&lt;/code&gt;는 28x28 크기의 MNIST 이미지이고, 이를 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.split&lt;/code&gt;을 이용해서 28조각으로 자르면 28차원 벡터가 28개 나열되어 있는 시퀀스로 만들 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x_raw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# [100, 28, 28, 1] &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# [100, 28, 28, 1] -&amp;gt; list of [100, 1, 28, 1]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우리가 맞춰야 하는 0부터 9까지의 label을 &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;로 두겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 모델 정의에 필요한 변수들인 &lt;code class=&quot;highlighter-rouge&quot;&gt;U&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt; 및 hidden state &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;를 정의합니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# always square&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;s_init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s_init&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 변수 정의를 마쳤습니다. 이제 이 변수들을 이용해서 RNN 모델을 만들어봅시다.&lt;/p&gt;

&lt;h2 id=&quot;model-specification&quot;&gt;Model specification&lt;/h2&gt;

&lt;p&gt;네트워크의 기억에 해당하는 hidden state $s_t$는 입력 x와 과거의 기억 $s_{t-1}$을 조합하여 만들어집니다. 조합하는 방식은 파라미터 U와 W에 의해 결정됩니다. U는 새로운 입력이 새로운 기억에 영향을 미치는 정도를, W는 과거의 기억이 새로운 기억에 영향을 미치는 정도를 결정한다고 볼 수 있습니다. 비선형함수로는 tanh나 ReLU가 주로 사용됩니다. 여기에서는 tanh를 쓰겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_t = tanh(x_tU + s_{t−1}W)&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_split&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# [100, 1, 28, 1] -&amp;gt; [100, 28]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력, 즉 예측값은 마지막 hidden state $s_t$로부터 계산됩니다. $s_t$와 V를 곱하는데, 여기서 V는 hidden state와 출력을 연결시켜주며 출력 벡터의 크기를 맞춰주는 역할을 합니다. 마지막으로 출력을 확률값으로 변환하기 위해 softmax 함수를 적용합니다. softmax 함수는 모든 출력값을 0 ~ 1 사이로 변환하고, 출력값의 합이 1이 되도록 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;o = softmax(s_tV)&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모델의 비용함수는 맞춰야 하는 숫자 y와 모델의 출력인 o 사이의 cross entropy로 정해집니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;training&quot;&gt;Training&lt;/h2&gt;

&lt;p&gt;아래 코드는 일반적인 뉴럴 네트워크를 학습시키는 방법과 동일합니다.&lt;/p&gt;

&lt;p&gt;최적화 알고리즘으로는 Gradient Descent를 쓰고, 학습 속도는 0.1로 정하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;TensorFlow에서 실제 계산을 수행하기 위해서는 세션을 열어야 합니다. 여기서는 결과를 즉각적으로 확인하기 위해 interactive session을 열겠습니다. 세션을 연 후에는 모든 변수를 초기화시켜 줍니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;InteractiveSession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우리가 데이터셋으로 쓸 MNIST 데이터를 가져오는 코드입니다. 데이터가 컴퓨터에 있다면 가져오고, 만약 없다면 자동으로 인터넷에서 다운로드를 받습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.examples.tutorials.mnist.input_data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_data_sets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trainimgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainlabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testimgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testlabels&lt;/span&gt; \
 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;ntrain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ntest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nclasses&lt;/span&gt; \
 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainimgs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testimgs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainimgs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainlabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모델을 평가하기 위해 평가용 데이터셋을 따로 떼놓겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;test_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testimgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testlabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모델의 정확도를 계산하기 위한 함수입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;t_predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t_actual&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제로 학습이 수행되는 부분입니다. 여기서는 간단하게 20번만 학습을 시켜보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainlabels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainimgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainlabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;feed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 모델의 정확도를 평가해봅시다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_raw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;mf&quot;&gt;0.92000002&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정확도 92%가 나왔습니다. 나쁘지 않은 성적입니다!&lt;/p&gt;

&lt;p&gt;이 글에서는 이해가 목적이었기 때문에 가장 간단한 모델을 설계했지만, 모델의 입력과 출력에 Affine layer를 붙이는 등 모델을 변형하면 훨씬 더 높은 정확도를 얻을 수 있습니다. 직접 시도해보면 RNN에 대한 이해도를 더욱 높일 수 있을 것입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;이 글에서 우리는 RNN의 개념과 응용 사례를 살펴보고 간단한 문제를 RNN을 구현하여 풀어보았습니다.&lt;/p&gt;

&lt;p&gt;글을 마치기 전에 RNN의 변형 모델에 대해서 간단하게 언급하려고 합니다. RNN은 강력한 모델이지만 물론 단점도 존재합니다. 가장 큰 단점은 시퀀스 중 중요한 입력과 출력 단계 사이의 거리가 멀어질 수록 그 관계를 학습하기 어려워진다는 점입니다. 이는 RNN이 가장 최근의 입력을 가장 강하게 기억하기 때문입니다. 이 점을 극복하기 위해 RNN의 여러 변형 모델들이 제안되고 연구되고 있습니다. 대표적인 변형 모델로는 LSTM이 있습니다. 또한 주의(attention) 기반 모델도 RNN의 단점을 극복하고 놀라운 성과를 내고 있습니다. RNN을 이해했다면 이러한 변형 모델들을 알아보는 것도 흥미로울 것입니다.&lt;/p&gt;

&lt;h1 id=&quot;further-reading&quot;&gt;Further reading&lt;/h1&gt;

&lt;p&gt;이 글과 같이 읽으면 좋은 RNN에 관련된 글들입니다.&lt;/p&gt;

&lt;p&gt;아래 두 글은 같은 영어 블로그 글을 번역한 글입니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.whydsp.org/280&quot;&gt;엘에스티엠 네트워크 이해하기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://brunch.co.kr/@chris-song/9&quot;&gt;LSTM(RNN) 소개&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://aikorea.org/blog/rnn-tutorial-1/&quot;&gt;Recurrent Neural Network (RNN) Tutorial&lt;/a&gt;  : Python과 Theano를 이용해서 RNN을 구현합니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;  : 다양한 RNN 모델들의 결과를 보여줍니다.&lt;/p&gt;
</description>
        <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/rnn/2017/09/04/understanding-rnn.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/rnn/2017/09/04/understanding-rnn.html</guid>
        
        
        <category>rnn</category>
        
      </item>
    
      <item>
        <title>쉽게 씌어진 word2vec</title>
        <description>&lt;p&gt;텍스트 기반의 모델 만들기는 텍스트를 숫자로 바꾸려는 노력의 연속이다. 텍스트를 숫자로 바꾸어야만 알고리즘에 넣고 계산을 한 후 결과값을 낼 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;텍스트를 숫자로 바꾸는 일 중의 하나로 단어를 벡터로 바꾸는 일을 생각할 수 있다. 단어를 벡터로 바꾸는 가장 단순한 방법은 단어에 번호를 매기고, 그 번호에 해당하는 요소만 1이고 나머지는 0을 갖는 벡터로 바꾸는 것이다. 예를 들어 총 5개의 단어가 있는데 ‘강아지’라는 단어에 2번을 매겼다고 하자. 그러면 ‘강아지’는 2번째 요소만 1이고 나머지는 모두 0인 5차원의 벡터로 표현이 된다. 이렇게 단어를 벡터로 바꾸는 방식을 one-hot encoding이라고 부른다. N개의 단어가 있다면 각 단어는 한 개의 요소만 1인 N차원의 벡터로 표현된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6NNEPE01/one-hot.png?pub_secret=1e9eec95ff&quot; alt=&quot;one-hot encoding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One-hot encoding의 단점은 벡터 표현에 단어와 단어 간의 관계가 전혀 드러나지 않는다는 점이다. ‘강아지’와 ‘멍멍이’라는 두 단어가 있을 때 이 두 단어는 의미가 비슷한데도 불구하고 전혀 다른 벡터로 표현이 된다. ‘강아지’와 ‘멍멍이’의 관계가 ‘강아지’와 ‘자유주의’ 간의 관계와 차이가 없는 것이다. One-hot encoding은 어떤 단어가 유사한 의미를 갖고 어떤 단어가 반대의 의미를 갖는지 등 단어 간의 관계는 전혀 반영하지 못한다.&lt;/p&gt;

&lt;p&gt;단어를 벡터로 바꿀 때, 좀 더 똑똑하게 바꿔서 벡터에 단어의 의미를 담을 수 있다면 어떨까? 비슷한 의미의 단어들은 비슷한 벡터로 표현이 된다면? 더 나아가 단어와 단어 간의 관계가 벡터를 통해서 드러날 수 있다면? 예를 들면 ‘왕’과 ‘여왕’의 관계가 ‘남자’와 ‘여자’의 관계라는 것을 벡터를 통해 알아낼 수 있다면, 유용하게 쓸 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 단어를 벡터로 바꾸는 모델을 단어 임베딩 모델(word embedding model)이라고 부른다. word2vec은 단어 임베딩 모델들 중 대표적인 모델이다. 이 글에서는 단어 임베딩 모델의 기본 아이디어와 word2vec의 작동 원리에 대해 알아본다.&lt;/p&gt;

&lt;h1 id=&quot;단어-임베딩word-embedding-맛보기&quot;&gt;단어 임베딩(Word Embedding) 맛보기&lt;/h1&gt;

&lt;p&gt;아래 웹사이트는 Word2Vec 알고리즘을 우리말에 적용해 본 사이트이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://w.elnn.kr/&quot;&gt;한국어 Word2Vec&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;위의 웹사이트에 들어가 “한국 - 서울 + 도쿄”를 해보자. 무엇이 나올까? “한국 - 제주도 + 대마도”는 어떨까? 용기 있는 사람은 “김정은 - 북한 + 한국”도 해보자.&lt;/p&gt;

&lt;p&gt;벡터 간에는 덧셈 뺄셈을 할 수 있다. 위의 예시는 벡터 간의 덧셈 뺄셈이 해당하는 단어 간의 의미의 합과 의미의 차로 반영이 된다는 것을 보여준다. 즉, 단어를 벡터로 바꿀 때 단어의 의미가 벡터에 잘 담긴 것이다.&lt;/p&gt;

&lt;p&gt;단어의 의미를 최대한 담는 벡터를 만들려는 알고리즘이 단어 임베딩 모델이다. 현대적인 자연어 처리 기법들은 대부분 이 임베딩 모델에 기반을 두고 있다. 그렇다면 어떻게 벡터에 단어의 의미를 담을 수 있을까?&lt;/p&gt;

&lt;h1 id=&quot;sparse-vs-dense-representations&quot;&gt;Sparse vs. Dense Representations&lt;/h1&gt;

&lt;p&gt;잠시 데이터가 무엇인지에 대해 다시 생각해보자. 데이터는 대상의 속성을 표현해놓은 자료이다. 우리는 어떤 대상이든 대상의 속성들을 표현하고, 그것을 바탕으로 모델을 만든다. 예를 들어 버섯을 조사해 놓은 데이터가 있다면 이것은 버섯이라는 ‘대상’을 색깔, 크기 같은 ‘속성’들로 표현한 것이고, 이 정보를 바탕으로 그 버섯이 독버섯인지 아닌지 판별하는 모델을 만들 수 있다. 자연히 대상을 어떤 속성으로 표현하는지는 모델의 성능에 매우 중요하다. 이렇게 대상의 속성을 표현하는 방식을 feature representation이라고 부른다.&lt;/p&gt;

&lt;p&gt;자연어 처리의 경우 대상은 텍스트이고, 이 텍스트의 속성을 표현해놓은 것이 데이터가 된다. 대상을 단어로 좁혀보면, 단어에는 어떤 속성이 있을까? 일단 단어 그 자체가 있다. 예를 들어 해당 단어가 ‘강아지’라면 그 단어가 ‘강아지’라는 것 자체가 이 대상의 속성이 된다. 또한 이 단어의 품사가 중요한 속성일 수도 있다. 앞 단어가 무엇인지 또는 문장에서 몇번째 단어인지가 중요할 수도 있다. 풀려는 문제에 따라서는 단어 자체가 긴지 짧은지가 중요할 수도 있다. 이런 언어적 정보(linguistic information)를 추출해서 표현하는 것이 언어의 feature representation이다.&lt;/p&gt;

&lt;p&gt;이런 속성들을 어떻게 표현할까? 언어의 속성을 표현하는 방법으로 크게 sparse representation과 dense representation이라는 두가지 방식이 있다. sparse representation은 위에서 언급했던 one-hot encoding을 뜻하고, dense representation은 word2vec의 방법을 뜻한다. 이 두개를 비교함으로써 word2vec의 특징을 좀 더 잘 이해할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;sparse-representation&quot;&gt;Sparse representation&lt;/h2&gt;

&lt;p&gt;Sparse representation, 즉 one-hot encoding은 해당 속성이 가질 수 있는 모든 경우의 수를 각각의 독립적인 차원으로 표현한다. 예를 들어, 해당 단어가 ‘강아지’라는 속성을 표현해보자. 우리가 가진 단어가 총 N개라면 이 속성이 가질 수 있는 경우의 수는 총 N개이다. One-hot encoding에서는 이 속성을 표현하기 위해 N차원의 벡터를 만든다. 그리고 ‘강아지’에 해당하는 요소만 1이고 나머지는 모두 0으로 둔다. 이런 식으로 단어가 가질 수 있는 N개의 모든 경우의 수를 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;마찬가지 방식으로 품사가 ‘명사’라는 속성을 표현하고 싶다면 품사의 개수만큼의 차원을 갖는 벡터를 만들고, ‘명사’에 해당하는 요소만 1로 두고 나머지는 모두 0으로 둔다. 다른 속성들도 모두 이런 방식으로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6QBLQH55/general_one-hot.png?pub_secret=67b335a806&quot; alt=&quot;sparse representation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 one-hot encoding으로 만들어진 표현을 sparse representation이라고도 부른다. 벡터나 행렬이 sparse하다는 것은 벡터나 행렬의 값 중 대부분이 0이고 몇몇 개만 값을 갖고 있다는 것을 뜻한다. one-hot encoding으로 만들어진 벡터는 0이 대부분이기 때문에, sparse한 벡터가 되는 것이다.&lt;/p&gt;

&lt;p&gt;Sparse representation은 가장 단순하고 전통적으로 자주 쓰이던 표현 방식이다.&lt;/p&gt;

&lt;h2 id=&quot;dense-representation&quot;&gt;Dense representation&lt;/h2&gt;

&lt;p&gt;Dense representation은 각각의 속성을 독립적인 차원으로 나타내지 않는다. 대신, 우리가 정한 개수의 차원으로 대상을 대응시켜서 표현한다. 예컨대 해당 속성을 5차원으로 표현할 것이라고 정하면 그 속성을 5차원 벡터에 대응시키는 것이다. 이 대응을 임베딩(embedding)이라고 하며, 임베딩하는 방식은 머신 러닝을 통해 학습하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6P915890/dense.png?pub_secret=3f6e3ccd28&quot; alt=&quot;dense representation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;임베딩된 벡터는 더이상 sparse하지 않다. One-hot encoding처럼 대부분이 0인 벡터가 아니라, 모든 차원이 값을 갖고 있는 벡터로 표현이 된다. 그래서 sparse의 반대말인 dense를 써서 dense representation 표현이라고 부른다.&lt;/p&gt;

&lt;p&gt;Dense representation은 또다른 말로 distributed representation이라고도 불린다. ‘Distributed’라는 말이 붙는 이유는 하나의 정보가 여러 차원에 분산되어 표현되기 때문이다. Sparse representation에서는 각각의 차원이 각각의 독립적인 정보를 갖고 있지만, Dense representation에서는 하나의 차원이 여러 속성들이 버무려진 정보를 들고 있다. 즉, 하나의 차원이 하나의 속성을 명시적으로 표현하는 것이 아니라 여러 차원들이 조합되어 나타내고자 하는 속성들을 표현하는 것이다.&lt;/p&gt;

&lt;p&gt;위 그림에서 ‘강아지’란 단어는 [0.16, -0.50, 0.20. -0.11, 0.15]라는 5차원 벡터로 표현된다. 이 때 각각의 차원이 어떤 의미를 갖는지는 알 수 없다. 여러 속성이 버무러져서 표현되었기 때문이다. 다만 ‘강아지’를 표현하는 벡터가 ‘멍멍이’를 표현하는 벡터와 얼마나 비슷한지, 또는 ‘의자’를 표현하는 벡터와는 얼마나 다른지는 벡터 간의 거리를 통해 알 수 있다. 이러한 관계에서 단어 벡터의 의미가 드러난다.&lt;/p&gt;

&lt;p&gt;단어 벡터의 값들은 머신 러닝을 통해 학습된다. 뒤에 나올 word2vec은 이 값들을 학습하는 방법론 중의 하나이다.&lt;/p&gt;

&lt;h2 id=&quot;dense-representation의-장점&quot;&gt;Dense Representation의 장점&lt;/h2&gt;

&lt;p&gt;이제 dense representation이라는 방식으로 대상을 표현할 수 있다는 것을 알았다. 그렇다면 sparse representation에 비해 dense representation의 장점은 무엇일까?&lt;/p&gt;

&lt;p&gt;첫번째, dense representation은 적은 차원으로 대상을 표현할 수 있다는 장점이 있다. sparse representation으로 대상을 표현하면 보통 차원 수가 엄청나게 높아진다. 일상적인 텍스트에서 쓰이는 단어의 개수는 몇 천개에 이른다. 이 단어들을 sparse representation으로 표현하려면 몇 천 차원이 필요하다. 게다가 이렇게 만들어진 벡터들은 대부분의 값이 0을 갖는다.&lt;/p&gt;

&lt;p&gt;입력 데이터의 차원이 높으면 차원의 저주(curse of dimensionality)라는 문제가 생긴다. 입력 데이터에 0이 너무 많으면 데이터에서 정보를 뽑아내기 어려워진다. 따라서 sparse representation을 쓰면 모델의 학습이 어렵고 성능이 떨어지기 쉽다.&lt;/p&gt;

&lt;p&gt;Dense representation으로 단어를 표현할 때는 보통 20 ~ 200차원 정도를 사용한다. Sparse representation에서 몇 천 차원이 필요했던 것에 비해 훨씬 적은 차원이다. 게다가 0이 거의 없고 각각의 차원들이 모두 정보를 들고 있으므로 모델이 더 작동하기 쉬워지는 것이다.&lt;/p&gt;

&lt;p&gt;두번째, dense representation은 더 큰 일반화 능력(generalization power)을 갖고 있다. 예를 들어 ‘강아지’라는 단어가 우리가 가진 학습 데이터셋에 자주 나왔고 ‘멍멍이’라는 단어는 별로 나오지 않았다고 생각해보자. sparse representation에는 ‘강아지’와 ‘멍멍이’ 간의 관계가 전혀 표현되지 않는다. 그 때문에 모델이 ‘강아지’에 대해 잘 알게 되더라도 ‘멍멍이’에 대해 더 잘 알게 되는 것은 아니다. 모델이 ‘강아지’가 ‘개’의 아기 상태라는 것을 알게 되었더라도, ‘멍멍이’가 ‘개’와 어떤 관계인지는 여전히 모르는 것이다.&lt;/p&gt;

&lt;p&gt;그러나 dense representation에서 ‘강아지’와 ‘멍멍이’가 서로 비슷한 벡터로 표현이 된다면, ‘강아지’에 대한 정보가 ‘멍멍이’에도 일반화될 수 있다. 예컨대 ‘강아지’라는 단어를 입력으로 받고 ‘애완동물’이라는 출력을 하도록 모델이 학습이 된다면, ‘멍멍이’도 비슷한 입력이기 때문에 비슷한 출력이 나올 가능성이 높다. 즉, ‘강아지’라는 단어에 대해 배운 지식을 ‘멍멍이’라는 단어에도 적용할 수 있는 것이다.&lt;/p&gt;

&lt;h1 id=&quot;word2vec&quot;&gt;word2vec&lt;/h1&gt;

&lt;p&gt;물론 지금까지 언급한 dense representation의 장점들은 모두 단어 임베딩(word embedding)이 잘 학습되었다는 전제 하에서 성립한다. 그렇다면 단어 임베딩을 어떻게 학습할 수 있을까?&lt;/p&gt;

&lt;p&gt;단어 임베딩을 학습하는 알고리즘에는 여러가지가 있다. 그 중 가장 자주 쓰이고 가장 유명한 방식은 word2vec이다. 또다른 방식으로는 GloVe, FastText 등이 있다. 여기서는 word2vec이라는 모델에 대해서만 알아본다.&lt;/p&gt;

&lt;h2 id=&quot;아이디어&quot;&gt;아이디어&lt;/h2&gt;

&lt;p&gt;word2vec은 단어를 표현하는 방법을 어떻게 학습하는 것일까? word2vec의 핵심적인 아이디어는 이것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;친구를 보면 그 사람을 안다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;또는&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;단어의 주변을 보면 그 단어를 안다. You shall know a word by the company it keeps. - 언어학자 J.R. Firth (1957)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;잠시 퀴즈를 하나 풀어보자. 다음 빈칸에 들어갈 수 있는 단어는 무엇이 있을까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/a43674f3c2fc5a93841c2753b812c2215a34006d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f736b69706772616d2d696d616765732f776f7264327665632d312e706e67&quot; alt=&quot;빈칸에 어떤 단어가 들어갈 수 있을까?&quot; /&gt;&lt;/p&gt;

&lt;p&gt;italian, mexican 등의 단어를 떠올릴 수 있다. 하지만 chair, parking 이런 말들은 들어가기 어려울 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/30d4fe1ae96e11d679de6e65632cc708c1237ba7/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f736b69706772616d2d696d616765732f776f7264327665632d322e706e67&quot; alt=&quot;빈칸에 들어가기 적합한 단어들과 부적합한 단어들&quot; /&gt;&lt;/p&gt;

&lt;p&gt;단어의 주위만 보았는데도 어떤 단어가 적합하고 어떤 단어가 부적합한지가 어느정도 드러난다. 이 빈칸에 들어갈 수 있는 단어들은 서로 비슷한 맥락을 갖는 단어들, 즉 서로 비슷한 단어들이다. 단어의 주변을 보면 그 단어를 알 수 있기 때문에, 단어의 주변이 비슷하면 비슷한 단어라는 말이 된다.&lt;/p&gt;

&lt;p&gt;비슷한 맥락을 갖는 단어에 비슷한 벡터를 주고 싶다면 어떻게 할 수 있을까? 여러 방법이 있지만 그중에 word2vec은 predictive method라는 방식에 속한다. predictive method란 맥락으로 단어를 예측하거나 단어로 맥락을 예측하는 문제를 마치 지도 학습(supervised learning)처럼 푸는 것이다. 이 예측 모델을 학습하면서 단어를 어떻게 표현해야 할지를 배우게 되고, 이 과정에서 비슷한 단어가 비슷한 벡터로 표현된다.&lt;/p&gt;

&lt;p&gt;word2vec의 알고리즘은 지도 학습을 닮았지만 사실은 비지도 학습(unsupervised learning) 알고리즘이다. 어떤 단어와 어떤 단어가 비슷한지 사람이 알려주지 않아도 word2vec은 비슷한 단어들을 찾아낼 수 있다. 비지도 학습의 장점은 정답지가 필요 없다는 것이다. 세상에 텍스트는 널려 있다. word2vec은 그 텍스트를 모두 학습 데이터로 쓸 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;p&gt;word2vec 안에도 두가지 방식이 있다. 하나는 맥락으로 단어를 예측하는 CBOW(continuous bag of words) 모델이다. 또다른 하나는 단어로 맥락을 예측하는 skip-gram 모델이다. 그 중에서 여기서는 CBOW 하나만 살펴보자. CBOW 모델을 반대로 뒤집으면 skip-gram 모델이 되므로, 하나만 이해하면 다른 하나는 쉽다.&lt;/p&gt;

&lt;p&gt;CBOW 모델은 주변 단어, 다른 말로 맥락(context)으로 타겟 단어(target word)를 예측하는 문제를 푼다. 주변 단어란 보통 타겟 단어의 직전 몇 단어와 직후 몇 단어를 뜻한다. 타겟 단어의 앞 뒤에 있는 단어들을 타겟 단어의 &lt;em&gt;친구들&lt;/em&gt;이라고 보는 것이다. 이 주변 단어의 범위를 window라고 부른다.&lt;/p&gt;

&lt;p&gt;예를 들어 “Colorless green ideas sleep furiously”라는 문장이 있다고 해보자. 주변 단어는 타겟 단어의 앞 단어와 뒷 단어 하나씩이라고 정의하자. “green”이 타겟 단어라면 “Colorless”부터 “ideas”까지 창문이 놓여있다고 생각하고 이 단어들만 보는 것이 window 접근법이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6P9HHYHG/window.png?pub_secret=27e48ec120&quot; alt=&quot;window&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞과 뒤에서 몇 단어까지 볼지는 지정해줄 수 있다. 이를 window size라고 한다.&lt;/p&gt;

&lt;p&gt;데이터셋을 만들 때 word2vec은 sliding window라는 방법을 쓴다. green을 타겟 단어로 놓고 Colorless부터 ideas까지 한번 본 다음에 window를 밀어서 이번에는 ideas를 중심에 놓는다. 그 다음은 sleep을 중심에 놓고 본다. 이렇게 window를 점차 옆으로 밀면서 타겟 단어를 계속 바꾸는 방식을 sliding window라고 부른다. 만들어진 window 하나 하나가 우리의 학습 데이터가 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6P9HGPGS/sliding_window.png?pub_secret=2f5ff24df3&quot; alt=&quot;sliding window&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CBOW는 맥락으로 단어를 예측하는 문제를 푼다. 즉, 주위에 있는 단어가 입력이 되고 타겟 단어가 우리가 예측해야 하는 출력값이 되는 문제를 푸는 것이다. 그 과정에서 모델의 파라미터를 학습하고, 이렇게 학습된 파라미터가 단어들의 벡터 표현이 된다.&lt;/p&gt;

&lt;p&gt;파라미터가 학습되는 방식은 일반적인 머신 러닝, 딥 러닝 모델이 학습되는 방식과 같다. 처음 파라미터는 랜덤으로 초기화된 상태(random initialization)로 시작한다. 이 파라미터로 예측을 하고, 실제 값과 차이가 생기면 틀린 만큼 파라미터들을 조금씩 조정한다. 이 과정을 학습 데이터셋을 돌아가며 반복한다. 뉴럴 네트워크 용어로는 이를 backpropagation이라고 부르며, 그 원리는 gradient descent와 같다. 즉 cost function이 최소화되는 쪽으로 파라미터들을 업데이트해 가는 것이다.&lt;/p&gt;

&lt;p&gt;CBOW에서 모델의 입력은 주변 단어이다. 그런데 입력이 비슷하면 어떻게 될까? 출력도 비슷해질 것이다. 즉 주위에 있는 단어가 비슷하면 그 단어의 벡터 표현 역시 비슷해진다. 벡터가 비슷하다는 말은 벡터 간의 거리가 짧다는 말이다. word2vec은 이러한 방식으로 비슷한 맥락의 단어에 비슷한 벡터를 준다.&lt;/p&gt;

&lt;h2 id=&quot;수학적으로-이해하기&quot;&gt;수학적으로 이해하기&lt;/h2&gt;

&lt;p&gt;글로 된 설명을 모호하게 느끼는 사람들을 위해 수학적으로 word2vec을 풀어보자. 여기서는 가장 간단한 형태의 CBOW, 즉 문맥에서 한 단어만 보고 타겟 단어를 예측하는 문제를 생각해보자. 한 단어가 앞 단어인지 뒷 단어인지는 중요하지 않지만, 편의상 앞 단어라고 하자. 입력으로 타겟 단어의 앞 단어가 들어가고 출력으로 타겟 단어가 나와야 하는 문제이다.&lt;/p&gt;

&lt;p&gt;아래 그림은 이 단순화된 문제의 뉴럴 네트워크 모델이다. V는 사전의 크기(vocabulary size), N은 히든 레이어의 크기(hidden layer size)을 뜻한다. 사전의 크기란 다른 말로 단어의 개수이다. 히든 레이어의 크기는 우리가 단어를 몇 차원으로 임베딩할지를 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6CPDPKHP/screenshot.png?pub_secret=8ce6c11e3b&quot; alt=&quot;CBOW&quot; /&gt;&lt;/p&gt;

&lt;p&gt;입력은 one-hot encoding된 벡터이다. 입력 단어, 즉 타겟 단어의 앞 단어는 V개의 요소 중 하나만 1이고 나머지는 모두 0인 벡터로 표현된다. 이렇게 단어의 개수만큼의 차원을 갖는 입력 레이어(input layer)가 히든 레이어(hidden layer)에서 임베딩 크기만큼의 차원의 벡터로 대응된다. 마지막으로 출력 레이어(output layer)는 다시 단어의 개수만큼의 차원을 갖는다. 출력은 타겟 단어이므로 단어의 개수만큼의 경우의 수가 있기 때문이다.&lt;/p&gt;

&lt;p&gt;레이어들 사이의 뉴런들은 서로 모두 연결되어(fully connected) 있다. 입력 레이어(input layer)와 히든 레이어(hidden layer) 사이를 연결하는 파라미터들은 V X N의 행렬 W로 나타낼 수 있고, 입력 레이어에서 히든 레이어로 넘어가는 것은 단순히 행렬 W를 곱하는 것과 같다. x가 입력 벡터라고 하면, 히든 레이어 h는 &lt;span&gt;$W^Tx$&lt;/span&gt; 로 계산된다. 이 벡터는 V차원, 즉 임베딩 차원의 벡터가 된다.&lt;/p&gt;

&lt;p&gt;입력 벡터 x는 one-hot encoding된 벡터이다. x의 요소 중 k번째 요소만 1이라고 하자. x의 나머지 요소가 모두 0이기 때문에 다른 부분은 모두 무시되고 &lt;span&gt;$W^Tx$&lt;/span&gt; 의 결과는 $W^T$ 의 k번째 열, 즉 W의 k번째 행만 남는다. 이 벡터가 해당 단어의 N차원 벡터 표현이 된다. W의 각 행들은 각각 해당하는 단어의 N차원의 벡터 표현인 것이다. W의 i번째 행을 &lt;span&gt;$v^T_{w_I}$&lt;/span&gt; 라고 부르면, 히든 레이어 h는 &lt;span&gt;$v^T_{w_I}$&lt;/span&gt;와 결국 같다는 것을 알 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h = W^Tx = W^T_{(k, )} := v^T_{w_I}&lt;/script&gt;

&lt;p&gt;입력 레이어에서 히든 레이어로 넘어가면서 우리는 히든 레이어 h를 얻었다. 히든 레이어에서 출력 레이어로 넘어가기 위해, 우리는 또다른 행렬 $W’$ 가 필요하다. $W’$ 는 N X V의 행렬이다. 이 파라미터 행렬을 이용해서, 우리는 모든 단어에 대해 출력 레이어의 점수 $u_j$를 계산할 수 있다. 아래 식에서 $v’_{w_j}$는 $W’$의 j번쩨 열을 뜻한다. 즉 &lt;span&gt;$u_j$&lt;/span&gt; 는 j번째 단어에 대한 예측 점수이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_j = {v'_{w_j}}^T h&lt;/script&gt;

&lt;p&gt;마지막으로 예측 점수를 각 단어의 확률값으로 바꿔주기 위해 softmax를 쓴다. 이는 각 단어의 점수에 비례하여 점수를 확률로 만들어주는 방법이다. 이 방식을 통해 각 단어의 예측 점수가 모두 0 이상이고 모두 더하면 1이 되는 확률값으로 변한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(w_j|w_I) = y_j = \frac{exp(u_j)}{\sum^V_{j' = 1}exp(u_{j'})}&lt;/script&gt;

&lt;p&gt;여기에서 &lt;span&gt;$y_j$&lt;/span&gt; 는 출력 레이어의 j번째 출력값이다. 위 식들을 조합하면 최종적으로 아래와 같은 식을 얻는다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(w_j|w_I) = \frac{\exp({v'_{w_j}}^Tv_{w_I})}{\sum^V_{j' = 1}\exp({v'_{w_{j'}}}^Tv_{w_I})}&lt;/script&gt;

&lt;p&gt;결과적으로 단어 w는 두가지 벡터로 표현된다. 바로 $v_w$ 와 $v’_w$ 이다. $v’_w$는 입력 레이어에서 히든 레이어로 넘어가는 행렬 W에서 나오며, $v’_w$는 히든 레이어에서 출력 레이어로 넘어가는 행렬 $W’$ 에서 나온다. $v_w$를 단어 w의 입력 벡터(input vector), $v’_w$를 단어 w의 출력 벡터(output vector)라고도 부른다.&lt;/p&gt;

&lt;p&gt;입력 벡터(input vector)와 출력 벡터(output vector) 모두 각각 단어의 의미를 담고 있지만, 이 둘을 조합하면 단어의 의미를 더욱 잘 표현할 수 있다고 알려져 있다.&lt;/p&gt;

&lt;p&gt;여기에서는 word2vec의 가장 기본적인 알고리즘만을 알아보았다. 이 파라미터들이 어떻게 학습되는지, 맥락이 여러 단어일 경우에는 어떻게 일반화되는지, skip-gram은 어떻게 작동하는지, 알고리즘의 계산 속도를 높이기 위해 어떤 방법들이 쓰이는지를 알고 싶다면 &lt;a href=&quot;https://arxiv.org/abs/1411.2738&quot;&gt;word2vec Parameter Learning Explained&lt;/a&gt;를 참고하기 바란다.&lt;/p&gt;

&lt;h2 id=&quot;시각화해서-이해하기&quot;&gt;시각화해서 이해하기&lt;/h2&gt;

&lt;p&gt;word2vec의 원리를 시각화해서 이해해보자. 아래는 word2vec을 이해하기 쉽게 직접 학습시켜보며 시각적으로 볼 수 있는 웹페이지다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ronxin.github.io/wevi/&quot;&gt;wevi&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6V57JD0W/screenshot.png?pub_secret=309c6d1eb9&quot; alt=&quot;wevi 시작 화면&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;왼쪽 위는 이 모델의 설정과 학습 데이터셋을 보여준다. 학습 데이터셋에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;eat|apple&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;eat&lt;/code&gt;이 들어왔을 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;apple&lt;/code&gt;을 예측하도록 학습하겠다는 뜻이다.&lt;/li&gt;
  &lt;li&gt;오른쪽 위에는 word2vec 모델이 있다. 왼쪽 단어들이 입력 레이어(input layer)이고 오른쪽 단어들이 출력 레이어(output layer)이다. 왼쪽 단어들 중 하나가 들어왔을 때 오른쪽 단어가 어떻게 예측되는지를 보여준다.&lt;/li&gt;
  &lt;li&gt;왼쪽 아래는 단어 벡터의 값을 색깔로 보여준다. 정확한 숫자는 보여지지 않지만 빨간색일수록 숫자가 크다는 뜻이고 파란색일수록 숫자가 작다는 뜻이다. 이 색깔의 의미는 오른쪽 위 Neurons에도 동일하게 적용된다.&lt;/li&gt;
  &lt;li&gt;오른쪽 아래는 PCA를 이용해 단어 벡터를 2차원으로 표현한 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next를 누르면 학습이 한번 진행된다. 첫번째로 &lt;code class=&quot;highlighter-rouge&quot;&gt;eat&lt;/code&gt;이 들어가서 &lt;code class=&quot;highlighter-rouge&quot;&gt;apple&lt;/code&gt;을 예측해야 한다. 처음에는 무작위값으로 초기화된 weights가 곱해지기 때문에 &lt;code class=&quot;highlighter-rouge&quot;&gt;eat&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;apple&lt;/code&gt;을 예측할 확률이나 &lt;code class=&quot;highlighter-rouge&quot;&gt;water&lt;/code&gt; 예측할 확률이나 차이가 없다. 하지만 점차 학습이 진행되면서 같이 나올만한 단어와 나오지 않을 단어들의 차이가 뚜렷해진다. 점점 좋은 벡터를 학습하게 되며 오른쪽 아래 PCA 화면에서 비슷한 단어끼리는 뭉치고, 다른 단어끼리는 떨어진다. 이렇게 학습이 되는 과정을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6UA6M1KN/screenshot.png?pub_secret=ff640bfd0b&quot; alt=&quot;word2vec 학습 후 화면&quot; /&gt;&lt;/p&gt;

&lt;p&gt;학습이 된 결과를 보면 오른쪽 아래 그래프에서 apple, orange, rice가 뭉쳤고 milk, juice, water가 뭉쳤다. 먹는 것과 마시는 것이 나눠진 것을 알 수 있다. 오른쪽 위 그래프에서는 drink라는 입력이 들어오자 juice, milk, water에 붉은색으로 높은 가중치가 부여되는 것을 알 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;실제-데이터로-만든-단어-벡터-시각화&quot;&gt;실제 데이터로 만든 단어 벡터 시각화&lt;/h1&gt;

&lt;p&gt;다음은 아마존에서 스마트폰 구매자들이 남긴 리뷰 텍스트를 바탕으로 word2vec을 이용해 만든 단어 벡터를 t-SNE라는 기법을 이용해 2차원으로 차원 축소한 뒤 인터렉티브 시각화를 해본 것이다. 아래 링크에서 그래프의 아무 점이나 점에 마우스를 올리면 어떤 단어들끼리 뭉쳤는지 직접 눈으로 확인할 수 있다. 더불어 실제 텍스트 데이터를 어떻게 가공해서 word2vec 알고리즘을 적용하는지 실습 코드까지 볼 수 있다. 아래 링크에 들어가 직접 마우스를 대보길 바란다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://nbviewer.jupyter.org/github/dreamgonfly/phone-review-nlp/blob/master/phone_reviews_nlp.ipynb#Visualizing-word-vectors-with-t-SNE&quot;&gt;t-SNE를 이용한 단어 벡터 시각화&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6U8ENC7L/word2vec_t-sne.png?pub_secret=71267565ce&quot; alt=&quot;word2vec t-sne&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;p&gt;다음은 이 글을 쓰며 참고했던 자료 및 이 글과 함께 읽으면 좋은 글들이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.2738&quot;&gt;word2vec Parameter Learning Explained&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ronxin.github.io/wevi/&quot;&gt;wevi&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb&quot;&gt;Modern NLP in Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/&quot;&gt;Word2Vec Tutorial - The Skip-Gram Model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mccormickml.com/2016/04/27/word2vec-resources/&quot;&gt;Word2Vec Resources&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.lucypark.kr/slides/2015-pyconkr/#1&quot;&gt;한국어와 NLTK, Gensim의 만남&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@goodvc78/7&quot;&gt;브런치 작가 추천과 Word2Vec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://u.cs.biu.ac.il/~yogo/nnlp.pdf&quot;&gt;A Primer on Neural Network Models for Natural Language Processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 16 Aug 2017 21:07:00 +0000</pubDate>
        <link>https://dreamgonfly.github.io/machine/learning,/natural/language/processing/2017/08/16/word2vec_explained.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/machine/learning,/natural/language/processing/2017/08/16/word2vec_explained.html</guid>
        
        <category>featured</category>
        
        
        <category>machine</category>
        
        <category>learning,</category>
        
        <category>natural</category>
        
        <category>language</category>
        
        <category>processing</category>
        
      </item>
    
      <item>
        <title>머신 러닝 소개 (Introduction to Machine Learning)</title>
        <description>&lt;p&gt;&lt;em&gt;이 글은 머신 러닝에 관심은 있지만 머신 러닝이 무엇인지는 아직 잘 모르는 사람들을 위한 글입니다. 이 글에서는 머신 러닝의 개념과 일반적인 머신 러닝 프로젝트의 진행 과정(workflow)에 대해 알아봅니다.&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;머신 러닝은 이제 일상에서 뗄레야 뗄 수 없는 존재가 되었다. 한가지 예로, 네이버의 검색 페이지에는 머신 러닝 기술이 들어가지 않은 곳을 찾아보기 힘들 정도다. 자동 완성, 음성 인식, 연관검색어, 이미지 검색, 문장 요약 등의 영역에서 수많은 머신 러닝 기술들이 쓰이고 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.slideshare.net/deview/2-72528625&quot;&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F5SK4HAMA/2-3-638.jpg?pub_secret=383a0e5524&quot; alt=&quot;네이버 검색 기술&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그러나 머신 러닝이란 말이 사람들 사이에서 점점 더 널리 쓰이면서, 머신 러닝이 정확히 무엇인지 알지 못하고 엉뚱한 데에 머신 러닝이란 말을 남용하는 경우가 늘어나고 있다. 머신 러닝의 개념을 명확하게 알고 사용하기 위해 머신 러닝이 무엇인지 정확히 알아보자.&lt;/p&gt;

&lt;h1 id=&quot;머신-러닝이란&quot;&gt;머신 러닝이란&lt;/h1&gt;

&lt;p&gt;어떤 컴퓨터 프로그램이 경험을 쌓을 수록 성능이 좋아질 때, 우리는 그 프로그램이 ‘학습’한다고 말한다. 배를 누르면 소리를 내는 인형을 생각해보자. 인형은 배가 몇번 눌리든 정해진 소리만을 낼 수 있다. 이것이 전통적인 프로그램의 예이다. 전통적인 컴퓨터 프로그램은 정해진 규칙만을 따르기 때문에 경험을 많이 한다고 성능이 더 좋아지거나 나빠지지 않는다. 반대로 페이스북은 쓰면 쓸수록 점점 더 자신의 취향에 맞는 글들을 상단에 보여준다. 이는 페이스북이 머신 러닝 기법들을 적용하고 있기 때문이다.&lt;/p&gt;

&lt;p&gt;머신 러닝의 일반적인 정의는 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at task in T, as meausred by P, improves with experience E.&lt;/p&gt;

  &lt;p&gt;Tom Mitchell (1998)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;정의만 읽어서는 머신 러닝이 정확히 무엇인지 와닿기 쉽지 않다. 머신 러닝의 개념을 좀 더 이해하기 위해서, 머신 러닝과 헷갈릴 수 있는 다른 개념들과 머신 러닝을 비교해보자.&lt;/p&gt;

&lt;h2 id=&quot;vs-인공-지능&quot;&gt;vs. 인공 지능&lt;/h2&gt;

&lt;p&gt;머신 러닝은 인공 지능과 어떤 관계일까? 인공지능이란 “지능적인 행위를 할 수 있는 컴퓨터 프로그램”으로 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Artifical intelligence : Computers and computer software that are capable of intelligent behavior.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;인공 지능의 정의는 추상적이다. ‘지능적인 행위’가 무엇을 말하는지는 명확하지 않다. 덧셈과 뺄셈은 지능적인 행위일까? 그렇다면 계산기는 인공 지능일까? 지능이 무엇인가 하는 것은 철학적인 주제이다. 길을 찾아가고, 언어를 이해하고, 감정을 표현하고, 사물을 인식하는 행위들이 모두 지능적인 행위가 될 수 있다.&lt;/p&gt;

&lt;p&gt;인공 지능은 특정한 기술이라기보다 하나의 거대한 목표라고 보아야 한다. 머신 러닝은 그 목표를 이루기 위한 하나의 방법론이다.&lt;/p&gt;

&lt;p&gt;머신 러닝이 인공 지능으로 가는 유일한 방법론은 아니다. 규칙 기반(rule-based) 접근법도 존재한다. 규칙 기반이란 사람이 일일이 프로그램에게 어떻게 하라고 지정해주는 것을 말한다. 머신 러닝 기법이 나오기 전에는 프로그램의 규칙을 정교하게 만드는 것이 인공 지능을 구현하는 유일한 방법이었다. 충분히 정교하게 설계한다면 규칙 기반 프로그램도 유용한 인공 지능 프로그램이 될 수 있다. 예컨대, 한국어 맞춤법 검사기 중에 가장 유명한 &lt;a href=&quot;http://164.125.7.61/speller/&quot;&gt;부산대 맞춤법 검사기&lt;/a&gt;는 규칙 기반으로 되어 있다.&lt;/p&gt;

&lt;p&gt;그러나 규칙 기반 프로그램은 인공 지능을 구현하는 데 여러가지 한계점을 드러냈다. 규칙 기반 프로그램은 구현하는 데 너무 큰 노력이 들고, 새로운 변화에 적응하기도 어렵다. 미묘한 차이를 모두 규칙으로 만든다는 것도 불가능한 일에 가까웠다. 이에 비해 머신 러닝은 여러 분야에서 인간과 비슷하거나 인간을 뛰어넘는 성능을 내며 지능적인 프로그램을 만들 수 있음을 입증했다. 물론 아직 완전한 인공 지능을 위해서는 갈 길이 멀지만, 머신 러닝은 인공 지능이라는 꿈에 가장 가까이 다가가 있는 방법론이다.&lt;/p&gt;

&lt;h2 id=&quot;vs-딥-러닝&quot;&gt;vs. 딥 러닝&lt;/h2&gt;

&lt;p&gt;딥 러닝이 최근에 핫하다. 사실 딥 러닝은 머신 러닝의 한 분야다. 딥 러닝과 머신 러닝, 인공 지능의 관계를 도식화하면 인공 지능이 머신 러닝을, 머신 러닝이 딥 러닝을 포함하고 있는 모습이 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F5WEJH13L/diagram.png?pub_secret=74c6fb0b61&quot; alt=&quot;딥 러닝. 머신 러닝, 인공지능 다이어그램&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다만, 머신 러닝의 한 분야에 불과했던 딥 러닝이 최근에 너무나 급속도로 성장하면서, 이제는 때때로 ‘머신 러닝’이라는 말이 딥 러닝 이전의 전통적인 기술들을 통칭하는 말로 쓰이기도 한다. 하지만 학술적으로 머신 러닝은 딥 러닝을 포함하는 개념이다.&lt;/p&gt;

&lt;p&gt;딥 러닝이 각광받는 데에는 몇가지 이유가 있다. 첫째로 모델의 성능이 뛰어나다. 딥 러닝은 여러 분야에서 기존의 기법들이 꿈도 꾸지 못했던 놀라운 정확도를 보여준다. 이것이 딥 러닝이 주목받는 가장 강력한 이유이다. 둘째, feature engineering이 필요 없다. 기존 머신러닝 기법들은 필수적으로 사람이 개입하여 모델에 입력할 변수를 생각해내야 했다. 하지만 딥 러닝은 모델 뿐만 아니라 모델에 들어갈 변수까지 스스로 학습하는 특징이 있다. 이를 representation learning이라고 부른다. 마지막으로 딥 러닝은 transfer learning이 용이하다. 딥 러닝에서는 하나의 문제를 잘 푸는 모델이 종종 다른 문제 역시 잘 푼다는 것이 알려져 있다. 덕분에 딥 러닝에서는 모델을 자유롭게 변형하거나 갖다 붙이기가 쉽다.&lt;/p&gt;

&lt;p&gt;그래도 딥러닝이 아닌 기존 머신 러닝 기법들을 써야 하는 경우는 언제일까? 첫째, 모델이 ‘왜’ 그렇게 작동하는지 알아야 하는 때이다. 딥 러닝을 쓰면 많은 경우 결과는 잘 나오지만 모델이 어떻게 그 결과를 내는지는 알기 어렵다. 이런 모델을 black box 모델이라고 부른다. 딥 러닝은 속을 들여다 볼 수 없기 때문에 결과에 대한 설명이 필요한 경우에는 적합하지 않다. 예컨대, 환자의 데이터를 보고 이 환자에게 어떤 처방이 필요한지 예측했더라도 왜 그런 처방을 내렸는지 설명하지 못한다면 의사와 환자는 받아들이지 못할 것이다.&lt;/p&gt;

&lt;p&gt;둘째, 데이터가 너무 적은 경우에는 딥 러닝을 적용하기 어렵다. 딥 러닝 모델을 학습시키기 위해서는 수많은 데이터가 필요하다. 필요한 데이터의 양은 물론 문제에 따라 다르지만, 딥 러닝 모델이 처음 유명해진 ImageNet 대회의 경우 이미지를 인식하기 위해 1000만 개가 넘는 사진 데이터가 주어진다.&lt;/p&gt;

&lt;p&gt;셋째, 딥 러닝은 느리다. 가벼운 모델이 필요한 경우 딥 러닝은 적합하지 않다. 딥 러닝을 학습시키기 위해서 흔히 GPU(Graphical Processing Unit)를 쓰는 이유도 엄청난 계산량을 감당하기 위해서이다. 웬만한 크기의 딥 러닝 모델을 학습하기 위해서는 웬만한 GPU로 보통 1~3일이 필요하다고 한다. 빠르게 학습하고 동작하는 모델이 필요하다면 딥 러닝과는 거리가 멀다.&lt;/p&gt;

&lt;p&gt;그밖에 딥 러닝을 쓰지 않는 경우는 기존에 충분히 검증된 모델이 있거나, 문제가 쉬워서 기존 머신 러닝 기법만으로 충분한 성능을 낼 수 있는 경우 등이 있다.&lt;/p&gt;

&lt;p&gt;딥 러닝을 굳이 쓰지 않는 분야의 예로 한국어 형태소 분석기를 들 수 있다. 한국어 형태소 분석기는 아직까지도 대부분 전통적인 머신 러닝과 규칙 기반에 의존하고 있다. 딥 러닝을 적용한 형태소 분석기가 기존 모델에 비해 성능 향상은 미미한 수준이고 모델이 너무 느려지는 단점이 있었기 때문이다.&lt;/p&gt;

&lt;p&gt;그러나 딥 러닝은 계속 발전 중이다. 현재 딥 러닝이 갖고 있는 문제점들이 시간이 지나면서 해결될 가능성도 배제할 수 없다. 계속해서 기술의 변화에 예의주시하는 태도가 필요하다.&lt;/p&gt;

&lt;h2 id=&quot;vs-통계학&quot;&gt;vs. 통계학&lt;/h2&gt;

&lt;p&gt;머신 러닝과 통계학은 많은 면에서 비슷하다. 통계도 데이터가 많아짐에 따라 예측의 정확도가 올라간다는 점에서 머신 러닝과 같다. 또한 머신 러닝의 많은 기법들은 통계학의 기법들과 상당히 유사하다. 예컨대, 선형 회귀는 통계학의 기법이면서 동시에 머신 러닝의 한 모델이다. 머신 러닝과 통계학은 서로 다른 영역에서 발전해왔고, 그래서 같은 개념이더라도 서로 용어가 다른 경우가 많다.&lt;/p&gt;

&lt;p&gt;머신 러닝과 통계학의 차이는 미묘하다. 그 차이는 주로 연구의 초점과 관심사에서 나온다. 통계학은 좀 더 수학적이고 연역적이다. 이에 비해 머신 러닝 연구자들은 증명이 없더라도 새로운 접근 방식을 더 많이 시도하는 경향이 있다.&lt;/p&gt;

&lt;p&gt;또한, 통계학은 전형적으로 작은 데이터셋을 다룬다. 하지만 머신 러닝은 빅 데이터에 더 적합하다. 통계학과 머신 러닝의 차이를 이해하는 방법 중 하나는 두 분야가 어떤 문제를 풀려고 하는지 이해하는 것이다. 통계학의 고민은 데이터가 너무 적은 것이다. 그래서 통계학은 적은 데이터에서도 의미를 끌어내기 위해 수학적으로 점점 더 정교한 방법론을 추구한다. 반대로 머신 러닝의 고민은 데이터가 너무 많은 것이다. 데이터가 너무 많으면 데이터를 저장하고 분석하는 것이 힘들어진다. 이를 분산 처리 등의 엔지니어링적인 방법으로 해결할 수도 있지만, 알고리즘 측면에서도 단순하지만 효과적인 알고리즘을 추구하게 된다.&lt;/p&gt;

&lt;p&gt;컴퓨터 과학에서의 머신 러닝과 통계학에서의 통계적 학습 이론(statistical learning)은 각자 독자적으로 발전하면서 또 서로 영향을 주고 받는 관계에 있다. 머신 러닝에서 풀리지 않던 문제를 통계학의 이론을 가져와서 풀거나, 통계학에서 어려웠던 문제를 머신 러닝의 기법을 이용해서 해결하는 경우도 있다. 머신 러닝과 통계학의 차이는 마치 같은 의자를 옆에서 볼 때와 위에서 볼 때 모양이 다른 것과 비슷하다. 같은 개념을 다른 각도로 바라보기 때문에, 머신 러닝과 통계학 모두 공부하면 하나의 모델이라도 다각도로 이해할 수 있을 것이다.&lt;/p&gt;

&lt;h1 id=&quot;머신-러닝-프로젝트-진행-과정-workflow&quot;&gt;머신 러닝 프로젝트 진행 과정 (Workflow)&lt;/h1&gt;

&lt;p&gt;이제 머신 러닝이 무엇인지는 알았으니, 머신 러닝 프로젝트가 어떻게 진행되는지 알아보자. 물론 프로젝트에 따라 진행 과정은 조금씩 다르지만, 일반적인 예측 모델링 프로젝트(predictive modeling)는 다음과 같은 프로세스를 따른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.slack.com/files-pri/T25783BPY-F6MV2KGQL/wordflow-v2.png?pub_secret=d55e9c900e&quot; alt=&quot;머신 러닝 프로젝트 진행 과정 (Workflow)&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;데이터-수집-data-collection&quot;&gt;데이터 수집 (Data Collection)&lt;/h2&gt;

&lt;p&gt;요리를 하기 위해 식재료가 필요하듯이, 데이터 프로젝트를 하기 위해서는 데이터가 필요하다. 데이터를 수집하는 방법은 여러 가지다. 웹 사이트에 있는 자료들을 긁어오기 위해서는 웹 크롤링(web crawling)을 할 수도 있고. 자신이 운영하는 서비스에서 유저들의 행동 데이터를 수집하기 위해서는 로그를 남길 수도 있다. 또는 이미 데이터베이스에 데이터가 쌓여 있는 경우에 데이터 수집 과정은 간단하게 데이터베이스나 데이터 파일에서 데이터를 불러오는 것으로 충분할 수도 있다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-전처리-data-preprocessing&quot;&gt;데이터 전처리 (Data Preprocessing)&lt;/h2&gt;

&lt;p&gt;수집된 날 것 그대로의 데이터는 많은 경우에 &lt;em&gt;더럽다&lt;/em&gt;. 데이터가 더럽다는 것은, 데이터에 빠진 부분(결측값)이 있거나, 중복으로 들어간 데이터 있거나, 이상한 값이 들어가 있는 경우 등등을 뜻한다. 이렇게 더러운 데이터를 정제해서 머신 러닝 모델의 입력에 적합한 형태로 바꿔주는 단계를 데이터 정제(data cleaning)이라고 부른다.&lt;/p&gt;

&lt;p&gt;또한, 데이터에서 기존 속성(feature)을 조합해서 새로운 속성을 만들어내기 위해 데이터 전처리가 필요한 경우도 있다. 예컨대, 집의 가격을 예측하는 모델을 만든다고 하자. 주어진 데이터는 집의 가로 길이와 세로 길이이다. 하지만 집의 가격을 예측할 때는 집의 가로나 세로 길이가 아니라 면적이 더 중요한 변수일 것이다. 이 때 집의 가로 길이와 세로 길이를 곱해서 집의 면적이란 새로운 속성을 만드는 것이 필요하다. 이렇게 데이터를 가공해서 새로운 속성을 만들어내는 일을 속성 엔지니어링(feature engineering)이라고 부른다.&lt;/p&gt;

&lt;p&gt;데이터를 정제하고 가공하는 일 외에 데이터의 스케일을 맞춰주고(feature scaling), 더미화하고(dummification), 차원을 줄이는 일(dimensionality reduction) 등을 모두 데이터 전처리라고 부르기도 한다.&lt;/p&gt;

&lt;h2 id=&quot;탐색적-데이터-분석-eda-exploratory-data-analysis&quot;&gt;탐색적 데이터 분석 (EDA: Exploratory Data Analysis)&lt;/h2&gt;

&lt;p&gt;데이터 프로젝트의 성공 여부는 데이터 분석가가 얼마나 데이터를 이해하고 있느냐에 좌우된다. 손에 주어진 데이터를 이해하기 위해 데이터의 특징을 찾고, 숨겨진 패턴을 발견하는 과정을 탐색적 데이터 분석이라고 부른다. 구체적으로 탐색적 데이터 분석은 데이터의 히스토그램을 그려보고, 두 변수 사이의 산포도를 그려보고, 변수들의 상관관계를 보는 일 등을 포함한다.&lt;/p&gt;

&lt;h3 id=&quot;탐색적-데이터-분석-데이터-전처리-모델-선택&quot;&gt;탐색적 데이터 분석, 데이터 전처리, 모델 선택&lt;/h3&gt;

&lt;p&gt;탐색적 데이터 분석과 데이터 전처리, 모델 선택 과정은 순차적이라기 보다 반복적인 관계이다. 탐색적 데이터 분석을 통해 어떤 전처리가 필요한지 알 수 있고, 전처리를 한 후에 데이터를 더욱 잘 이해할 수도 있다. 예컨대, 데이터를 탐색하던 중에 예전에 몰랐던 이상치(outlier)을 발견할 수 있고, 이상치를 제거하는 전처리를 한 후에 데이터 탐샛을 더욱 원활하게 할 수 있다. 모델 선택 과정 역시 데이터 탐색과 밀접한 관계가 있다. 데이터를 이해하고 나서 데이터에 적합한 모델을 선택할 수 있고, 원하는 만큼 모델의 정확도가 나오지 않을 경우 그 이유를 찾기 위해 데이터 탐색 과정으로 돌아올 수도 있는 것이다.&lt;/p&gt;

&lt;h2 id=&quot;모델-선택-model-selection&quot;&gt;모델 선택 (Model Selection)&lt;/h2&gt;

&lt;p&gt;예측 모델링 프로젝트에서 모델(Model)이란 새로운 입력 데이터를 받았을 때 예측값을 계산하는 방법이다. 집값 예측 문제를 예로 들면, 집의 면적, 방의 갯수, 층수 등을 갖고 그 집의 집값을 계산하는 알고리즘이 집값 예측 모델이 된다. 세상에는 수많은 종류의 모델이 있고, 주어진 문제와 데이터에 맞는 적절한 모델을 선택하는 것은 데이터 분석가의 몫이다.&lt;/p&gt;

&lt;h3 id=&quot;무엇을-선택할-것인가&quot;&gt;무엇을 선택할 것인가&lt;/h3&gt;

&lt;p&gt;모델을 선택한다는 것은 무엇을 선택한다는 것일까? 첫째, 말그대로 예측값을 계산하는 알고리즘을 선택한다는 것이다. 버섯의 속성들로 그 버섯이 독버섯인지 먹을 수 있는 버섯인지 분류하는 문제를 풀 때에도 로지스틱 회귀(logistic regression)부터 KNN(K-Nearest Neighbors), SVM(Support Vector Machine), 딥 러닝(deep learning)까지 수많은 방법이 있다.&lt;/p&gt;

&lt;p&gt;둘째, 모델이 사용할 속성들(features)을 선택한다는 것이다. 때때로 의미 없는 속성이 모델에 들어갈 때 모델의 성능이 더 떨어지는 경우가 있다. 모델에 중요한 속성들을 골라내는 일도 모델 선택 과정에서 필요한 일이다.&lt;/p&gt;

&lt;p&gt;셋째, 모델에는 일종의 모델을 조절하는 버튼인 하이퍼파라미터(hyperparameter)가 있다. 같은 모델이더라도 하이퍼파라미터에 따라서 성능이 천차만별이다. 적절한 하이퍼파라미터를 선택하는 것도 분석가의 몫이다.&lt;/p&gt;

&lt;h2 id=&quot;평가-및-적용-evaluation--application&quot;&gt;평가 및 적용 (Evaluation &amp;amp; Application)&lt;/h2&gt;

&lt;p&gt;평가 및 적용 단계는 만들어진 머신 러닝 모델의 성능을 평가하고, 모델을 활용하여 새로운 데이터에 대한 예측을 하는 단계이다.&lt;/p&gt;

&lt;p&gt;머신 러닝 프로젝트에서 가장 중요하지만 가장 실수가 자주 일어나는 과정이 바로 이 평가 과정이다. 모델 평가에서 반드시 지켜야 하는 점은 평가용 데이터셋은 모델 선택과 모델 학습 과정에서 쓰이지 않아야 한다는 점이다. 즉, 프로젝트를 시작하기 전에 학습용 데이터셋과 평가용 데이터셋을 나누어놓고, 평가용 데이터셋은 모델 선택 과정이 끝나기 전까지 보지 말아야 한다는 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 하는 이유는 평가 과정의 목적이 모델이 새로운 데이터에 대해 얼마나 일반화 (generalization) 가능한지 측정하는 것이기 때문이다. 모델이 아직 보지 못한 새로운 데이터에 얼마나 잘 작동하는지 제대로 측정하기 위해서는, 평가용 데이터셋은 모델이 ‘아직 보지 못한 새로운 데이터’이어야 한다. 그렇기 때문에 평가용 데이터셋을 미리 떼어놓고 일부러 모델을 만드는 과정에서 제외하는 것이다.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;데이터 과학은 흥미로운 분야이고, 그 중에서 머신 러닝은 데이터 과학의 핵심적인 부분이다. 나무 하나하나를 보기 전에 숲을 보는 것이 중요하듯이, 이 글에서는 머신 러닝이란 무엇이고 전체적인 데이터 분석 과정이 어떻게 이루어지는지 데이터 과학의 숲을 한번 훑어보았다. 이 글이 데이터 과학을 처음 시작하는 사람 뿐만 아니라, 데이터 과학에 익숙한 사람들에게도 숲을 보는 것을 잊지 않게 함으로써 도움이 되었으면 하는 바람이다.&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Aug 2017 17:32:30 +0000</pubDate>
        <link>https://dreamgonfly.github.io/2017/08/13/introduction_to_machine_learning.html</link>
        <guid isPermaLink="true">https://dreamgonfly.github.io/2017/08/13/introduction_to_machine_learning.html</guid>
        
        
      </item>
    
  </channel>
</rss>
