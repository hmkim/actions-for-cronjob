<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="http://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-5201956450461596914</id><updated>2019-05-09T22:35:53.356-07:00</updated><category term="IoT"/><category term="교육"/><category term="머신러닝"/><category term="메이커"/><category term="미디어 아트"/><category term="로봇"/><category term="딥러닝"/><category term="비전"/><category term="사물인터넷"/><category term="그래픽스"/><category term="드론"/><category term="블록체인"/><category term="스마트시티"/><category term="가상현실"/><category term="리눅스"/><category term="항공"/><category term="공간정보"/><category term="도심재생"/><title type='text'>Daddy Makers</title><subtitle type='html'>SW, HW, CG, ART, 건설, 건축 메이크 과정을 정리, 공유하는 블로그입니다 - 대디 메이커</subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link rel='next' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default?start-index=26&amp;max-results=25'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><generator version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>177</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6020017188089731325</id><published>2019-04-20T09:48:00.001-07:00</published><updated>2019-04-20T09:48:39.813-07:00</updated><title type='text'>IFTTT와 NodeMCU 연결</title><content type='html'>IFTTT와 NodeMCU 연결하는 방법을 설명한 영상을 링크한다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe width=&quot;320&quot; height=&quot;266&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/-Iw8kzkeL9E/0.jpg&quot; src=&quot;https://www.youtube.com/embed/-Iw8kzkeL9E?feature=player_embedded&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe width=&quot;320&quot; height=&quot;266&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/5SvRolROPxA/0.jpg&quot; src=&quot;https://www.youtube.com/embed/5SvRolROPxA?feature=player_embedded&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6020017188089731325/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/ifttt-nodemcu.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6020017188089731325'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6020017188089731325'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/ifttt-nodemcu.html' title='IFTTT와 NodeMCU 연결'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/-Iw8kzkeL9E/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6168944866074185265</id><published>2019-04-17T18:52:00.000-07:00</published><updated>2019-04-19T21:32:42.102-07:00</updated><title type='text'>Docker 윈도우 방화벽 문제</title><content type='html'>Docker 윈도우 방화벽 문제 해결과 관련된 몇몇 검색한 링크 남긴다. 이 경우 이미지가 다운로드 되지 않는다.&lt;br /&gt;보통 이런 문제는 방화벽이 철저한 회사나 기관에서 도커 사용할 때 발생한다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://yahwang.github.io/posts/23&quot;&gt;Docker For Windows 설치할 때 생기는 오류 대처하기&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://web-front-end.tistory.com/79&quot;&gt;Docker for Windows 를 이용하여 Docker 사용시 이슈정리&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;참고로 좋은 도커 설치 영상이 있어 링크를 남긴다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/appkr/myshop/blob/master/docs/DOCKER-WINDOWS-HOT-TO.md&quot;&gt;Windows 머신에서 도커 개발 환경 사용하기&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://steemit.com/kr/@mystarlight/docker&quot;&gt;도커 처음 사용자를 위한 윈도우 도커 설치 및 실행하기&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/YeblPnscuc8/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/YeblPnscuc8?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/UUZD7PCBbHg/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/UUZD7PCBbHg?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;도커 설치&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6168944866074185265/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/docker.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6168944866074185265'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6168944866074185265'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/docker.html' title='Docker 윈도우 방화벽 문제'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/YeblPnscuc8/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-8684313235580251723</id><published>2019-04-02T00:10:00.000-07:00</published><updated>2019-04-19T20:57:52.832-07:00</updated><title type='text'>ABB 로봇 제어하기 </title><content type='html'>이 글은&amp;nbsp;ABB 로봇 제어하는 기본 명령어와 기능을 간략히 정리한다.&lt;br /&gt;&lt;br /&gt;ABB는 산업용 로봇으로 C언어와 유사한 개발언어로 로봇을 제어할 수 있다.&lt;br /&gt;개발은 로봇 스튜디오 프로그램이나 비쥬얼 스튜디오 같은 개발 도구로 코딩할 수 있다.&lt;br /&gt;로봇 스튜디오는 특히 시뮬레이션이 가능해서, 코딩된 프로그램을 미리 3차원 공간에서 테스트할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-tSqZY-obMbA/XKMJdWCezFI/AAAAAAAAUec/npKM_m-15I8bJ9kDdxQw3nKLNoI2usHmACLcBGAs/s1600/123.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;858&quot; data-original-width=&quot;1600&quot; height=&quot;213&quot; src=&quot;https://4.bp.blogspot.com/-tSqZY-obMbA/XKMJdWCezFI/AAAAAAAAUec/npKM_m-15I8bJ9kDdxQw3nKLNoI2usHmACLcBGAs/s400/123.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;로봇 스튜디오 클랩프 시뮬레이션 모습(Clamp Claw Vacuum)&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: left;&quot;&gt;코드를 직접 다음 처럼 생긴 펜던트로 터치해서 입력하는 방법도 있으나 매우 불편하다. 보통, 코딩된 프로그램을 USB로 담아서 ABB 로봇암을 제어하는 컴퓨터에 전송한 후에 로봇을 동작시킨다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe width=&quot;320&quot; height=&quot;266&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/OmGts9ZTP-I/0.jpg&quot; src=&quot;https://www.youtube.com/embed/OmGts9ZTP-I?feature=player_embedded&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;로봇암 제어 모습&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: left;&quot;&gt;다음 사이트에서 다양한 개발 예제와 SDK(Software Development Kit)를 다운로드할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-bHETP2B1CVA/XLqUlNje-II/AAAAAAAAVbk/44lHfkJwcv0QJqgfiTF02z5wMS2uwMU6QCLcBGAs/s1600/SDK.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;922&quot; data-original-width=&quot;1038&quot; height=&quot;355&quot; src=&quot;https://1.bp.blogspot.com/-bHETP2B1CVA/XLqUlNje-II/AAAAAAAAVbk/44lHfkJwcv0QJqgfiTF02z5wMS2uwMU6QCLcBGAs/s400/SDK.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://developercenter.robotstudio.com/pcsdk&quot;&gt;ABB SDK 다운로드 홈페이지&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left;&quot;&gt;프로그래밍을 하지 않고 로봇암을 제어하기 위해서는 라이노에서 실행되는 그래스호퍼 애드인이 필요하다. 여기에 다음과 같은 HAL 을 설치하면, 라이노에 그려진 툴패스를 따라서 로봇암이 제어된다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-bCldsWaIN0o/XLqVBaPqWeI/AAAAAAAAVbs/fhfGwWcVlwkugGi_Bu9j_Z_sLUGeQGKAgCLcBGAs/s1600/SDK2.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;936&quot; data-original-width=&quot;913&quot; height=&quot;400&quot; src=&quot;https://1.bp.blogspot.com/-bCldsWaIN0o/XLqVBaPqWeI/AAAAAAAAVbs/fhfGwWcVlwkugGi_Bu9j_Z_sLUGeQGKAgCLcBGAs/s400/SDK2.PNG&quot; width=&quot;390&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://www.robotsinarchitecture.org/778/hal-a-grasshopper-plugin-for-abb-robots&quot;&gt;ABB 로봇암 제어용 그래스호퍼 HAL 애드인&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/8684313235580251723/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/abb.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/8684313235580251723'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/8684313235580251723'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/04/abb.html' title='ABB 로봇 제어하기 '/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-tSqZY-obMbA/XKMJdWCezFI/AAAAAAAAUec/npKM_m-15I8bJ9kDdxQw3nKLNoI2usHmACLcBGAs/s72-c/123.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6309128264192458458</id><published>2019-02-09T20:24:00.001-08:00</published><updated>2019-04-21T19:36:41.649-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="딥러닝"/><title type='text'>간단한 도커 기반 케라스 LSTM 딥러닝 모델 학습 및 데이터 예측</title><content type='html'>이 글은 도커를 기반으로 케라스를 이용한 LSTM 학습 및 예측 방법을 간단히 따라해 보고, 사용방법과 코드를 익힙니다. 작년 가을부터 쌓여있던 연구행정일 어느 정도 정리되어, 쌓아 둔 글들 중 케라스 기반 LSTM과 관련 내용들을 하나씩 정리하도록 하겠습니다. 딥러닝 모델에 대한 내용은 아래 링크 참고 바랍니다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/02/blog-post_24.html&quot;&gt;머신러닝 딥러닝 신경망 개념, 종류 및 개발&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;머리말&lt;/span&gt;&lt;br /&gt;텐서플로우, 케라스를 사용하는 방법은 크게 다음과 같습니다.&lt;br /&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/windows-10-tensorflow.html&quot;&gt;텐서플로우 및 케라스 직접 설치, 사용&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/windows-10-tensorflow.html&quot;&gt;아나콘다 설치 후 텐서플로우 및 케라스 설치, 사용&lt;/a&gt;&lt;/li&gt;&lt;li&gt;AWS와 같은 클라우드 기반 미리 설치된 텐서플로우, 케라스 설치 및 사용&lt;/li&gt;&lt;/ol&gt;각각이 장단점 있죠.&lt;br /&gt;&lt;br /&gt;우선, 1, 2번 같은 경우, 직접 본인 컴퓨터에서 설치부터 시작해 사용까지 경험해 본다는 측면에서 공부하기 좋으나, 수많은 관련 라이브러리 버전 의존성을 맞춰주고, 하나가 업데이트되면 다른 라이브러리 의존성이 깨져 재설치해야 하는 등 번거로움이 많은 방법입니다.&lt;br /&gt;&lt;br /&gt;3번 같은 경우, 클라우드 제공 사이트에 회원 가입 후 몇몇 설정 클릭질만 해 주면 쉽게 사용할 수 있으나, 왠지 내공있어야 하는 일들은 남이 대신 해 주는 것 같고, 사용량이 많아지면, 업체에서 과금을 할 것이기 때문에 번거로운 점이 있습니다.&lt;br /&gt;&lt;br /&gt;딥러닝 라이브러리 사용 편의성과 과금을 피해가는 방법 중 하나가 이 글에서 제안하는 도커를 이용한 딥러닝 라이브러리 사용 방법입니다.&lt;br /&gt;&lt;br /&gt;도커는 사전 설치된 이미지가 있으면 다운로드 받아 컨테이너에 실행하면 되므로, 라이브러리 종속성 문제나 과금에 자유롭죠. 다만, 수많은 이미지 중 안정적인 버전을 찾기가 쉽지 않은 문제가 있습니다.&lt;br /&gt;&lt;br /&gt;이 글에서는 Kitematic 을 사용해 딥러닝 라이브러리 설치된 이미지를 검색하고, 이를 사용해 LSTM을 실행해 보도록 하겠습니다. 도커에 대한 설명은 아래 링크 참고 바랍니다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/docker.html&quot;&gt;도커 기반 우분투, 텐서플로우 설치 및 명령 정리&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/docker.html&quot;&gt;Docker 기반 우분투, 텐서플로우, PyTorch 설치 및 관련 명령 정리&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;Kitematic 이용한 도커 딥러닝 라이브러리 이미지 설치&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;Kitematic은 도커 이미지 원클릭 설치를 제공한다. 그래픽 사용자 인터페이스 (GUI)에서 앱 컨테이너를 제어할 수 있어 매우 편리하다. Kitematic은 다음 링크에서 다운로드 받을 수 있다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-56PzaYhj7DA/XJiOAE10n2I/AAAAAAAAUcQ/xN5oKwygFmksCzAKTd80m5yH8-GVfU1uACLcBGAs/s1600/8.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;924&quot; data-original-width=&quot;920&quot; height=&quot;320&quot; src=&quot;https://3.bp.blogspot.com/-56PzaYhj7DA/XJiOAE10n2I/AAAAAAAAUcQ/xN5oKwygFmksCzAKTd80m5yH8-GVfU1uACLcBGAs/s320/8.PNG&quot; width=&quot;318&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://kitematic.com/&quot;&gt;Kitematic&lt;/a&gt;&amp;nbsp;(2019년 4월 도커 버전과 Kitematic 버전이 서로 문제를 일으켜서, 도커 이미지 다운로드 안되는 현상있음. 이 경우,&amp;nbsp;&lt;a href=&quot;https://github.com/docker/kitematic/releases&quot;&gt;https://github.com/docker/kitematic/releases&lt;/a&gt;&amp;nbsp;에서 Kitematic 0.17.3 버전을 다운로드 받아 실행해 볼것)&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;Kitematic 사이트에서 프로그램을 다운로드 설치한 후 실행하면 다음과 같이 도커 이미지를 검색할 수 있다. 본인은 keras로 검색하였다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-9dZ4_vV8kjI/XJhYBFIrj-I/AAAAAAAAUbk/Ovp5wcJV3k46EynUfn-iAkt7ee8UFmaXgCLcBGAs/s1600/5.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;637&quot; data-original-width=&quot;926&quot; height=&quot;275&quot; src=&quot;https://3.bp.blogspot.com/-9dZ4_vV8kjI/XJhYBFIrj-I/AAAAAAAAUbk/Ovp5wcJV3k46EynUfn-iAkt7ee8UFmaXgCLcBGAs/s400/5.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;keras 검색 결과(Kitematic)&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;이 글에서는 keras-full 이미지를 설치해 사용한다. 참고로, 다른 이미지들은 jupyter notebook이 안되거나, 몇몇 keras 관련 라이브러리가 설치되어 있지 않아, 이 글의 LSTM 예제를 따라하기 어렵다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;keras-full 이미지 설치는 매우 간단해, &#39;CREATE&#39;버튼을 클릭하면 된다. 이후, 이미지를 다운로드하고, 도커 컨테이너에 설치하는 과정은 자동적으로 진행된다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;설치 후 keras-full 이미지는 왼쪽 컬럼에 표시된다. 해당 이미지를 선택하고, 상단의 start 툴바 버튼을 클릭하면 실행된다. 웹이 지원되는 이미지는 WEB PREVIEW 탭이 다음 그림과 같이 보여진다. 이 탭의 문서 툴바 버튼을 클릭하면 쥬피터 노트북이 실행될 것이다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-YLLkxX2U4ik/XJhYs-D9M2I/AAAAAAAAUb8/RAhZPgC6MvE5miXEmnpDl9h-Ya6DdRjkACLcBGAs/s1600/7.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;637&quot; data-original-width=&quot;924&quot; height=&quot;275&quot; src=&quot;https://1.bp.blogspot.com/-YLLkxX2U4ik/XJhYs-D9M2I/AAAAAAAAUb8/RAhZPgC6MvE5miXEmnpDl9h-Ya6DdRjkACLcBGAs/s400/7.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;케라스 기반 LSTM 사용하기&amp;nbsp;&lt;/span&gt;&lt;br /&gt;쥬피터 노트북 실행되면, 암호를 묻는다. 이 이미지의 노트북 암호는 &#39;keras&#39;이다.&lt;br /&gt;&lt;br /&gt;입력 후 로긴하면 다음과 같은 창을 볼 수 있다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-g5MHeRgDQFA/XJhYBbgf11I/AAAAAAAAUbo/swSRnJ6AwHoAp8wIL1oN9FkEityIrmDFACLcBGAs/s1600/6.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em; text-align: center;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;443&quot; data-original-width=&quot;746&quot; height=&quot;237&quot; src=&quot;https://1.bp.blogspot.com/-g5MHeRgDQFA/XJhYBbgf11I/AAAAAAAAUbo/swSRnJ6AwHoAp8wIL1oN9FkEityIrmDFACLcBGAs/s400/6.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;여기서, New 버튼을 이용해 python3 소스 파일을 하나 만들어 본다.&lt;br /&gt;&lt;br /&gt;실습할 LSTM 소스코드는 keras에서 실행된다. 이 코드는 여객기 탑승자 수를 날짜별로 저장한 스프레드시트 파일을 읽어, 딥러닝 모델 학습한 후 예측 모델을 만든다. 그리고, 예측 모델과 실제 값을 비교한 결과를 그래프로 출력한다.&lt;br /&gt;&lt;br /&gt;다음 LSTM 소스코드를 복사해 붙여넣기를 한다. 참고로, 이 소스코드 내용은&amp;nbsp;&lt;a href=&quot;https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/&quot;&gt;Machine Learning Mastery LSTM 링크&lt;/a&gt;를 방문하면 좀 더 상세한 설명을 확인할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt; 1&lt;br /&gt; 2&lt;br /&gt; 3&lt;br /&gt; 4&lt;br /&gt; 5&lt;br /&gt; 6&lt;br /&gt; 7&lt;br /&gt; 8&lt;br /&gt; 9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;26&lt;br /&gt;27&lt;br /&gt;28&lt;br /&gt;29&lt;br /&gt;30&lt;br /&gt;31&lt;br /&gt;32&lt;br /&gt;33&lt;br /&gt;34&lt;br /&gt;35&lt;br /&gt;36&lt;br /&gt;37&lt;br /&gt;38&lt;br /&gt;39&lt;br /&gt;40&lt;br /&gt;41&lt;br /&gt;42&lt;br /&gt;43&lt;br /&gt;44&lt;br /&gt;45&lt;br /&gt;46&lt;br /&gt;47&lt;br /&gt;48&lt;br /&gt;49&lt;br /&gt;50&lt;br /&gt;51&lt;br /&gt;52&lt;br /&gt;53&lt;br /&gt;54&lt;br /&gt;55&lt;br /&gt;56&lt;br /&gt;57&lt;br /&gt;58&lt;br /&gt;59&lt;br /&gt;60&lt;br /&gt;61&lt;br /&gt;62&lt;br /&gt;63&lt;br /&gt;64&lt;br /&gt;65&lt;br /&gt;66&lt;br /&gt;67&lt;br /&gt;68&lt;br /&gt;69&lt;br /&gt;70&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: green;&quot;&gt;# LSTM for international airline passengers problem with regression framing&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; numpy&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&quot;color: blue;&quot;&gt;as&lt;/span&gt; plt&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; pandas &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; read_csv&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; math&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; keras.models &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; Sequential&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; keras.layers &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; Dense&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; keras.layers &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; LSTM&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; MinMaxScaler&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;from&lt;/span&gt; sklearn.metrics &lt;span style=&quot;color: blue;&quot;&gt;import&lt;/span&gt; mean_squared_error&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# convert an array of values into a dataset matrix&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;def&lt;/span&gt; create_dataset(dataset, look_back=1):&lt;br /&gt; dataX, dataY = [], []&lt;br /&gt; &lt;span style=&quot;color: blue;&quot;&gt;for&lt;/span&gt; i &lt;span style=&quot;color: blue;&quot;&gt;in&lt;/span&gt; range(len(dataset)-look_back-1):&lt;br /&gt;  a = dataset[i:(i+look_back), 0]&lt;br /&gt;  dataX.append(a)&lt;br /&gt;  dataY.append(dataset[i + look_back, 0])&lt;br /&gt; &lt;span style=&quot;color: blue;&quot;&gt;return&lt;/span&gt; numpy.array(dataX), numpy.array(dataY)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# fix random seed for reproducibility&lt;/span&gt;&lt;br /&gt;numpy.random.seed(7)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# load the dataset&lt;/span&gt;&lt;br /&gt;dataframe = read_csv(&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;international-airline-passengers.csv&#39;&lt;/span&gt;, usecols=[1], engine=&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;python&#39;&lt;/span&gt;, skipfooter=3)&lt;br /&gt;dataset = dataframe.values&lt;br /&gt;dataset = dataset.astype(&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;float32&#39;&lt;/span&gt;)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# normalize the dataset&lt;/span&gt;&lt;br /&gt;scaler = MinMaxScaler(feature_range=(0, 1))&lt;br /&gt;dataset = scaler.fit_transform(dataset)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# split into train and test sets&lt;/span&gt;&lt;br /&gt;train_size = int(len(dataset) * 0.67)&lt;br /&gt;test_size = len(dataset) - train_size&lt;br /&gt;train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# reshape into X=t and Y=t+1&lt;/span&gt;&lt;br /&gt;look_back = 1&lt;br /&gt;trainX, trainY = create_dataset(train, look_back)&lt;br /&gt;testX, testY = create_dataset(test, look_back)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# reshape input to be [samples, time steps, features]&lt;/span&gt;&lt;br /&gt;trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))&lt;br /&gt;testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# create and fit the LSTM network&lt;/span&gt;&lt;br /&gt;model = Sequential()&lt;br /&gt;model.add(LSTM(4, input_shape=(1, look_back)))&lt;br /&gt;model.add(Dense(1))&lt;br /&gt;model.compile(loss=&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;mean_squared_error&#39;&lt;/span&gt;, optimizer=&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;adam&#39;&lt;/span&gt;)&lt;br /&gt;model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# make predictions&lt;/span&gt;&lt;br /&gt;trainPredict = model.predict(trainX)&lt;br /&gt;testPredict = model.predict(testX)&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# invert predictions&lt;/span&gt;&lt;br /&gt;trainPredict = scaler.inverse_transform(trainPredict)&lt;br /&gt;trainY = scaler.inverse_transform([trainY])&lt;br /&gt;testPredict = scaler.inverse_transform(testPredict)&lt;br /&gt;testY = scaler.inverse_transform([testY])&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# calculate root mean squared error&lt;/span&gt;&lt;br /&gt;trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;print&lt;/span&gt;(&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;Train Score: %.2f RMSE&#39;&lt;/span&gt; % (trainScore))&lt;br /&gt;testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))&lt;br /&gt;&lt;span style=&quot;color: blue;&quot;&gt;print&lt;/span&gt;(&lt;span style=&quot;color: #a31515;&quot;&gt;&#39;Test Score: %.2f RMSE&#39;&lt;/span&gt; % (testScore))&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# shift train predictions for plotting&lt;/span&gt;&lt;br /&gt;trainPredictPlot = numpy.empty_like(dataset)&lt;br /&gt;trainPredictPlot[:, :] = numpy.nan&lt;br /&gt;trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# shift test predictions for plotting&lt;/span&gt;&lt;br /&gt;testPredictPlot = numpy.empty_like(dataset)&lt;br /&gt;testPredictPlot[:, :] = numpy.nan&lt;br /&gt;testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict&lt;br /&gt;&lt;span style=&quot;color: green;&quot;&gt;# plot baseline and predictions&lt;/span&gt;&lt;br /&gt;plt.plot(scaler.inverse_transform(dataset))&lt;br /&gt;plt.plot(trainPredictPlot)&lt;br /&gt;plt.plot(testPredictPlot)&lt;br /&gt;plt.show()&lt;br /&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br /&gt;이 코드를 실행하기 위해서는 아래 링크에서 비행기 탑승자 수 CSV(,) 데이터파일을 미리 소스코드 폴더에 다운로드해 넣어야 한다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;amp;display=line&quot;&gt;International airline passengers (DataMarket)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-6G03hQBTPKY/XJiWPr7vqtI/AAAAAAAAUc8/_kR97A4KbHoNC9ZGESpZmZdDHJyMyX9yACLcBGAs/s1600/13.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;781&quot; data-original-width=&quot;1236&quot; height=&quot;252&quot; src=&quot;https://3.bp.blogspot.com/-6G03hQBTPKY/XJiWPr7vqtI/AAAAAAAAUc8/_kR97A4KbHoNC9ZGESpZmZdDHJyMyX9yACLcBGAs/s400/13.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;amp;display=line&quot;&gt;International airline passengers dataset&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;이 데이터셋에서 67%는 훈련용, 나머지 33%는 테스트 검증용으로 사용한다.&lt;br /&gt;LSTM 소스코드를 쥬피터 노트북에서 실행한 결과는 다음과 같다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-F4RPOm-3gNM/XJiTiUIzOTI/AAAAAAAAUcc/Ag8ZxCwvjhYeVjL-k_L18F6XWHAd90F0ACLcBGAs/s1600/9.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;790&quot; data-original-width=&quot;782&quot; height=&quot;400&quot; src=&quot;https://2.bp.blogspot.com/-F4RPOm-3gNM/XJiTiUIzOTI/AAAAAAAAUcc/Ag8ZxCwvjhYeVjL-k_L18F6XWHAd90F0ACLcBGAs/s400/9.PNG&quot; width=&quot;395&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;...&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-I6IlkOvl_Ok/XJiUYnQme3I/AAAAAAAAUcw/NiC9LBszD1Iqc5L7sJ7Erj18ft915JdhQCLcBGAs/s1600/12.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;252&quot; data-original-width=&quot;378&quot; height=&quot;266&quot; src=&quot;https://1.bp.blogspot.com/-I6IlkOvl_Ok/XJiUYnQme3I/AAAAAAAAUcw/NiC9LBszD1Iqc5L7sJ7Erj18ft915JdhQCLcBGAs/s400/12.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;LSTM 학습 및 테스트 결과 그래프(청색: 원본 데이터, 적색: 훈련 데이터, 녹색: 테스트 예측 데이터)&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;결과 그래프에서 보여지는 것처럼, LSTM은 원본 데이터와 유사한 패턴으로, 향후 데이터를 예측해 내는 것을 확인할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;소스코드 설명&lt;/span&gt;&lt;br /&gt;이 코드는 LSTM 모델을 이용해 시퀀스로 배열된 시계열 데이터를 예측하는 것이다. 이런 기법은 다양한 분야에 사용될 수 있다. 주요 코드만 확인해 본다.&lt;br /&gt;&lt;br /&gt;다음은 데이터셋을 로딩하는 코드이다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# load the dataset&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;dataframe = pandas.read_csv(&#39;international-airline-passengers.csv&#39;, usecols=[1], engine=&#39;python&#39;, skipfooter=3)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;dataset = dataframe.values&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;dataset = dataset.astype(&#39;float32&#39;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;이후 0에서 1 값으로 데이터를 정규화한다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# normalize the dataset&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;scaler = MinMaxScaler(feature_range=(0, 1))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;dataset = scaler.fit_transform(dataset)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;데이터세트에서 67%는 훈련용, 33%는 테스트용으로 분리한다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# split into train and test sets&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;train_size = int(len(dataset) * 0.67)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;test_size = len(dataset) - train_size&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;print(len(train), len(test))&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;LSTM 모델 입력은 현재 주어진 시간(T) 승객수이며, 출력 Y는 다음 시간(T + 1)의 승객수가 되도록 한다. 이 배열을 numpy.array 형 dataX, dataY로 리턴하는 함수를 만든다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# convert an array of values into a dataset matrix&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;def create_dataset(dataset, look_back=1):&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt; &lt;/span&gt;dataX, dataY = [], []&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt; &lt;/span&gt;for i in range(len(dataset)-look_back-1):&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;a = dataset[i:(i+look_back), 0]&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;dataX.append(a)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;dataY.append(dataset[i + look_back, 0])&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;span style=&quot;white-space: pre;&quot;&gt; &lt;/span&gt;return numpy.array(dataX), numpy.array(dataY)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;참고로, 이 함수를 호출하면 다음과 같이, 첫번째 데이터의 Y는 두번째 데이터의 X가 된다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;X&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;Y&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;112&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;118&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;118&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;132&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;132&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;129&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;129&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;121&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;121&lt;span style=&quot;white-space: pre;&quot;&gt;  &lt;/span&gt;135&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;이제, 입력 데이터셋을 LSTM 모델 학습에 맞게 행렬 모양으로 변환하고, LSTM 시퀀스 모델을 생성해, trainX, trainY 데이터를 입력한다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# create and fit the LSTM network&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;model = Sequential()&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;model.add(LSTM(4, input_shape=(1, look_back)))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;model.add(Dense(1))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;model.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;adam&#39;)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;다음 코드를 이용해 학습된 모델을 예측한 출력값을 얻는다. 그리고, 원본 데이터 trainY와 훈련용 데이터셋 예측값 trainPredict, 테스트용 데이터 예측값 testPredict 편차를 RMSE로 확인한다. 참고로, 본인 컴퓨터에서는 각각 RMSE가 22.92, 47.53 이었다.&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# make predictions&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;trainPredict = model.predict(trainX)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;testPredict = model.predict(testX)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# invert predictions&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;trainPredict = scaler.inverse_transform(trainPredict)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;trainY = scaler.inverse_transform([trainY])&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;testPredict = scaler.inverse_transform(testPredict)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;testY = scaler.inverse_transform([testY])&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;# calculate root mean squared error&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;print(&#39;Train Score: %.2f RMSE&#39; % (trainScore))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;print(&#39;Test Score: %.2f RMSE&#39; % (testScore))&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;나머지 코드는 원본 데이터, 학습 데이터, 테스트 데이터를 그래프로 출력하는 코드이다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;-webkit-text-stroke-width: 0px; color: black; font-family: &amp;quot;Malgun Gothic&amp;quot;; font-size: medium; font-style: normal; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 400; letter-spacing: normal; margin: 0px; orphans: 2; text-align: start; text-decoration-color: initial; text-decoration-style: initial; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;&quot;&gt;&lt;span style=&quot;font-size: large;&quot;&gt;마무리&lt;/span&gt;&lt;/div&gt;이 글은 좀 더 간편한 방식으로 딥러닝 모델을 학습하고 테스트할 수 있는 도커 이미지를 이용해, 간단한 LSTM 모델을 케라스 기반으로 실행해 보았다. 도커를 이용하면, 라이브러리 종속성 문제로 삽질할 필요 없이, 딥러닝 모델 개발 본연의 목적에만 집중할 수 있고, 사용량이 많아지면 과금되는 클라우드 플랫폼을 사용할 필요도 없다.&lt;br /&gt;&lt;br /&gt;참고로 설명한 LSTM코드는 매우 일반적인 패턴 학습 모델이므로, 약간만 수정하면, 다양한 예측 모델에 사용할 수 있다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;강태욱,&amp;nbsp;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/docker.html&quot;&gt;도커 기반 우분투, 텐서플로우 설치 및 명령 정리&lt;/a&gt;&lt;/li&gt;&lt;li&gt;강태욱,&amp;nbsp;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/02/blog-post_24.html&quot;&gt;머신러닝 딥러닝 신경망 개념, 종류 및 개발&lt;/a&gt;&lt;/li&gt;&lt;li&gt;강태욱,&amp;nbsp;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/windows-10-tensorflow.html&quot;&gt;텐서플로우 및 케라스 직접 설치, 사&lt;/a&gt;용&lt;/li&gt;&lt;li&gt;강태욱,&amp;nbsp;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2017/05/windows-10-tensorflow.html&quot;&gt;아나콘다 설치 후 텐서플로우 및 케라스 설치, 사용&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://docs.likejazz.com/lstm/&quot;&gt;LSTM원리와 수식계산&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;RNN과 LSTM을 이해해보자&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Kaggle, &lt;a href=&quot;https://www.kaggle.com/amirrezaeian/time-series-data-analysis-using-lstm-tutorial&quot;&gt;Time-series data analysis using LSTM&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://paperswithcode.com/task/time-series&quot;&gt;Time series, papers with code&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://paperswithcode.com/paper/lstm-based-encoder-decoder-for-multi-sensor&quot;&gt;LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.ibm.com/tutorials/iot-deep-learning-anomaly-detection-5/&quot;&gt;Using Keras and TensorFlow for anomaly detection&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&amp;amp;display=line&quot;&gt;International airline passengers (DataMarket)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Jason Brownlee, 2016, &lt;a href=&quot;https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/&quot;&gt;Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras&lt;/a&gt;,&amp;nbsp;machinelearningmastery.com&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6309128264192458458/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/02/lstm-keras.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6309128264192458458'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6309128264192458458'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/02/lstm-keras.html' title='간단한 도커 기반 케라스 LSTM 딥러닝 모델 학습 및 데이터 예측'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-56PzaYhj7DA/XJiOAE10n2I/AAAAAAAAUcQ/xN5oKwygFmksCzAKTd80m5yH8-GVfU1uACLcBGAs/s72-c/8.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-5482929794299432119</id><published>2019-02-02T23:03:00.000-08:00</published><updated>2019-02-02T23:03:15.861-08:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="미디어 아트"/><title type='text'>인공지능 기반 미디어아트</title><content type='html'>이 글은&amp;nbsp;인공지능 기반 미디어아트 기술, 동향 및 사례에 대해 정리한 슬라이드를 공유합니다.&lt;br /&gt;&lt;br /&gt;이 슬라이드는 딥러닝부터 시작해, 관련 다양한 오픈소스 도구를 보여줍니다. 아울러, 딥러닝을 몰라도 간단히 사용할 수 있는 서비스 제공 웹사이트를 나열하고, 해외 최신 인공지능 기반 미디어아트 사례들을 공유합니다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://drive.google.com/open?id=1dGUpLB_Mpm0Ysvjq6sQOT9l7hNuvK-hB&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;808&quot; data-original-width=&quot;1091&quot; height=&quot;295&quot; src=&quot;https://2.bp.blogspot.com/-V-7VVghgH80/XFaQ7ELrD6I/AAAAAAAARAo/yTRAEW1cC30_Ry0ZY5Dfeml5nEdMxFLJgCLcBGAs/s400/art.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/laputa999/ai-media-art&quot;&gt;Slideshare 링크&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/5482929794299432119/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/02/blog-post.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5482929794299432119'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5482929794299432119'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/02/blog-post.html' title='인공지능 기반 미디어아트'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-V-7VVghgH80/XFaQ7ELrD6I/AAAAAAAARAo/yTRAEW1cC30_Ry0ZY5Dfeml5nEdMxFLJgCLcBGAs/s72-c/art.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-3481365542832576238</id><published>2019-01-06T20:23:00.006-08:00</published><updated>2019-01-16T05:48:37.099-08:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="딥러닝"/><title type='text'>라즈베리파이 기반 딥러닝 객체 인식 개발 방법</title><content type='html'>이 글은 어느 분이 블로그로 문의한 내용도 정리할 겸 라즈베리파이 기반 딥러닝 객체 인식 개발 방법에 대한 내용을 간단히 요약해 공유한다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/1000/1*YJbdykJRHFlzlIXWwn0nIA.gif&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;450&quot; data-original-width=&quot;800&quot; height=&quot;180&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*YJbdykJRHFlzlIXWwn0nIA.gif&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;사실, 이와 관련된 자료는 구글링을 하면 꽤 많이 검색된다. 참고로, OpenCV를 이용해 파이썬 기반에서 객체를 인식하는 방법도 유용하다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;머리말&lt;/span&gt;&lt;br /&gt;비전에서 객체 인식이란 다음과 같이 특정 이미지에서 원하는 객체 종류, 위치와 크기를 얻는 것이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*4tPwx3wG720gOmIOaONOEQ.jpeg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;771&quot; data-original-width=&quot;700&quot; height=&quot;400&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*4tPwx3wG720gOmIOaONOEQ.jpeg&quot; width=&quot;362&quot; /&gt;&lt;/a&gt;&lt;/div&gt;객체 인식은 다음과 같이 다양한 분야에서 사용된다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*ZUGVScHbBgmmzO82bALIZQ.jpeg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;544&quot; data-original-width=&quot;700&quot; height=&quot;310&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*ZUGVScHbBgmmzO82bALIZQ.jpeg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;객체 인식에서 유명한 방법인 YOLO는 매우 빠른 방식으로 객체 탐색을 할 수 있다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*I4vKwR9X33DoNz36I1IooQ.jpeg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;480&quot; data-original-width=&quot;700&quot; height=&quot;273&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*I4vKwR9X33DoNz36I1IooQ.jpeg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://pjreddie.com/media/files/papers/yolo_1.pdf&quot;&gt;YOLO&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;YOLO 알고리즘을 간단히 설명하면 다음과 같다.&lt;br /&gt;&lt;br /&gt;image = readImage()&lt;br /&gt;cells = 검색 셀 범위 설정&lt;br /&gt;index = 0&lt;br /&gt;for cell in cells&lt;br /&gt;&amp;nbsp; &amp;nbsp;maxPrediction = 0.0&lt;br /&gt;&amp;nbsp; &amp;nbsp;for region in cell.region&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; cell_image = image.getRegionImage(region)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; prediction[index] = prediction(cell_image)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; if(maxPrediction &amp;lt; prediction[index])&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;maxPrediction = prediction[index]&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;region = cell.grow(region)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; else&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;index++&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;break&amp;nbsp; &amp;nbsp; &lt;br /&gt;&lt;br /&gt;의사코드는 다음과 같다.&lt;br /&gt;&lt;br /&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt; 1&lt;br /&gt; 2&lt;br /&gt; 3&lt;br /&gt; 4&lt;br /&gt; 5&lt;br /&gt; 6&lt;br /&gt; 7&lt;br /&gt; 8&lt;br /&gt; 9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;26&lt;br /&gt;27&lt;br /&gt;28&lt;br /&gt;29&lt;br /&gt;30&lt;br /&gt;31&lt;br /&gt;32&lt;br /&gt;33&lt;br /&gt;34&lt;br /&gt;35&lt;br /&gt;36&lt;br /&gt;37&lt;br /&gt;38&lt;br /&gt;39&lt;br /&gt;40&lt;br /&gt;41&lt;br /&gt;42&lt;br /&gt;43&lt;br /&gt;44&lt;br /&gt;45&lt;br /&gt;46&lt;br /&gt;47&lt;br /&gt;48&lt;br /&gt;49&lt;br /&gt;50&lt;br /&gt;51&lt;br /&gt;52&lt;br /&gt;53&lt;br /&gt;54&lt;br /&gt;55&lt;br /&gt;56&lt;br /&gt;57&lt;br /&gt;58&lt;br /&gt;59&lt;br /&gt;60&lt;br /&gt;61&lt;br /&gt;62&lt;br /&gt;63&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#this is an Image of size 140x140. We will assume it to be black and white (ie only one channel, it would have been 140x140x3 for rgb)&lt;/span&gt;&lt;br /&gt;image &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; readImage()&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#We will break the Image into 7 coloumns and 7 rows and process each of the 49 different parts independently&lt;/span&gt;&lt;br /&gt;NoOfCells &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;7&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#we will try and predict if an image is a dog, cat, cow or wolf. Therfore the number of classes is 4&lt;/span&gt;&lt;br /&gt;NoOfClasses &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;4&lt;/span&gt;&lt;br /&gt;threshold &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #6600ee; font-weight: bold;&quot;&gt;0.7&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#step will be the size of step to take when moving across the image. Since the image has 7 cells step will be 140/7 = 20&lt;/span&gt;&lt;br /&gt;step &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; height(image)&lt;span style=&quot;color: #333333;&quot;&gt;/&lt;/span&gt;NoOfCells&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#stores the class for each of the 49 cells, each cell will have 4 values which correspond to the probability of a cell being 1 of the 4 classes&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#prediction_class_array[i,j] is a vector of size 4 which would look like [0.5 #cat, 0.3 #dog, 0.1 #wolf, 0.2 #cow]&lt;/span&gt;&lt;br /&gt;prediction_class_array &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; new_array(size(NoOfCells,NoOfCells,NoOfClasses))&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#stores 2 bounding box suggestions for each of the 49 cells, each cell will have 2 bounding boxes, with each bounding box having x, y, w ,h and c predictions. (x,y) are the coordinates of the center of the box, (w,h) are it&#39;s height and width and c is it&#39;s confidence&lt;/span&gt;&lt;br /&gt;predictions_bounding_box_array &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; new_array(size(NoOfCells,NoOfCells,NoOfCells,NoOfCells))&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#it&#39;s a blank array in which we will add the final list of predictions&lt;/span&gt;&lt;br /&gt;final_predictions &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; []&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#minimum confidence level we require to make a prediction&lt;/span&gt;&lt;br /&gt;threshold &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #6600ee; font-weight: bold;&quot;&gt;0.7&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;for&lt;/span&gt; (i&lt;span style=&quot;color: #333333;&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;; i&lt;span style=&quot;color: #333333;&quot;&gt;&amp;lt;&lt;/span&gt;NoOfCells; i&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;i&lt;span style=&quot;color: #333333;&quot;&gt;+&lt;/span&gt;&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;):&lt;br /&gt; &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;for&lt;/span&gt; (j&lt;span style=&quot;color: #333333;&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;; j&lt;span style=&quot;color: #333333;&quot;&gt;&amp;lt;&lt;/span&gt;NoOfCells;j&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;j&lt;span style=&quot;color: #333333;&quot;&gt;+&lt;/span&gt;&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;):&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#we will get each &quot;cell&quot; of size 20x20, 140(image height)/7(no of rows)=20 (step) (size of each cell)&quot;&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#each cell will be of size (step, step)&lt;/span&gt;&lt;br /&gt;  cell &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; image(i:i&lt;span style=&quot;color: #333333;&quot;&gt;+&lt;/span&gt;step,j:j&lt;span style=&quot;color: #333333;&quot;&gt;+&lt;/span&gt;step) &lt;br /&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#we will first make a prediction on each cell as to what is the probability of it being one of cat, dog, cow, wolf&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#prediction_class_array[i,j] is a vector of size 4 which would look like [0.5 #cat, 0.3 #dog, 0.1 #wolf, 0.2 #cow]&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#sum(prediction_class_array[i,j]) = 1&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#this gives us our preidction as to what each of the different 49 cells are&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#class predictor is a neural network that has 9 convolutional layers that make a final prediction&lt;/span&gt;&lt;br /&gt;  prediction_class_array[i,j] &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; class_predictor(cell)&lt;br /&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#predictions_bounding_box_array is an array of 2 bounding boxes made for each cell&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#size(predictions_bounding_box_array[i,j]) is [2,5]&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#predictions_bounding_box_array[i,j,1] is bounding box1, predictions_bounding_box_array[i,j,2] is bounding box 2&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#predictions_bounding_box_array[i,j,1] has 5 values for the bounding box [x,y,w,h,c]&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#the values are x, y (coordinates of the center of the bounding box) which are whithin the bounding box (values ranging between 0-20 in your case)&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#the values are h, w (height and width of the bounding box) they extend outside the cell and are in the range of [0-140]&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#the value is c a confidence of overlap with an acutal bounding box that should be predicted&lt;/span&gt;&lt;br /&gt;  predictions_bounding_box_array[i,j] &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; bounding_box_predictor(cell)&lt;br /&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#predictions_bounding_box_array[i,j,0, 4] is the confidence value for the first bounding box prediction&lt;/span&gt;&lt;br /&gt;  best_bounding_box &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;  [&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt; &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;if&lt;/span&gt; predictions_bounding_box_array[i,j,&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;4&lt;/span&gt;] &lt;span style=&quot;color: #333333;&quot;&gt;&amp;gt;&lt;/span&gt; predictions_bounding_box_array[i,j,&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;4&lt;/span&gt;] &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;else&lt;/span&gt; &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;]&lt;br /&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;# we will get the class which has the highest probability, for [0.5 #cat, 0.3 #dog, 0.1 #wolf, 0.2 #cow], 0.5 is the highest probability corresponding to cat which is at position 0. So index_of_max_value will return 0&lt;/span&gt;&lt;br /&gt;  predicted_class &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; index_of_max_value(prediction_class_array[i,j])&lt;br /&gt;&lt;br /&gt;  &lt;span style=&quot;color: #888888;&quot;&gt;#we will check if the prediction is above a certain threshold (could be something like 0.7)&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;if&lt;/span&gt; predictions_bounding_box_array[i,j,best_bounding_box, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;4&lt;/span&gt;] &lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; max_value(prediction_class_array[i,j]) &lt;span style=&quot;color: #333333;&quot;&gt;&amp;gt;&lt;/span&gt; threshold:&lt;br /&gt;&lt;br /&gt;   &lt;span style=&quot;color: #888888;&quot;&gt;#the prediction is an array which has the x,y coordinate of the box, the height and the width&lt;/span&gt;&lt;br /&gt;   prediction &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; [predictions_bounding_box_array[i,j,best_bounding_box, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;:&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;4&lt;/span&gt;], predicted_class]&lt;br /&gt;&lt;br /&gt;   final_predictions&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;append(prediction)&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #007020;&quot;&gt;print&lt;/span&gt; final_predictions&lt;br /&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br /&gt;prediction함수는 딥러닝으로 훈련된 모델을 사용한다. 훈련 모델을 얻기위해서는 훈련 데이터를 미리 준비해야 한다. 준비 순서는 다음과 같다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*hUOIe8skkgMQx68-279z_A.jpeg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;534&quot; height=&quot;640&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*hUOIe8skkgMQx68-279z_A.jpeg&quot; width=&quot;425&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;훈련 데이터 획득&lt;/span&gt;&lt;br /&gt;이 단계를 수행하기 위해서는 객체 당 100개 정도 수준의 데이터가 필요하다. 가능한 예측해야할 데이터와 비슷한 자료가 필요하다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*ZqUXpif7jgmAsIwX7ZFdrQ.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;320&quot; data-original-width=&quot;640&quot; height=&quot;200&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*ZqUXpif7jgmAsIwX7ZFdrQ.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;라벨링(labeling) - 주석달기&lt;/span&gt;&lt;br /&gt;&lt;div&gt;&lt;a href=&quot;https://github.com/tzutalin/labelImg&quot;&gt;labelImg&lt;/a&gt;와 같은 도구를 이용해 이미지에 테두리 상자를 그리고, 라벨을 달아 놓는다. 사실 딥러닝 소스코드는 그리 어렵지 않은 수준이지만, 라벨링 작업은 매우 노동집약적이고 힘든 작업이다. 딥러닝 소스코드는 사실 이런 데이터가 된다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*osRdxUvKXSaOHX-9VyGbCQ.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;450&quot; data-original-width=&quot;800&quot; height=&quot;225&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*osRdxUvKXSaOHX-9VyGbCQ.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;모델학습&lt;/span&gt;&lt;/div&gt;&lt;div&gt;보통 GPU가 달린 컴퓨터를 이용해 학습을 시킨다. 이미 CNN과 같이 딥러닝 이미지 인식용 모델은 공개된 것이 많다. 예제도 많으니 이런 것들을 사용해 학습시킨다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;훈련에 필요한 데이터 량을 줄이는 것도 필요하다. 이와 관련된 &lt;a href=&quot;http://medium.com/nanonets/nanonets-how-to-use-deep-learning-when-you-have-limited-data-f68c0b512cab&quot;&gt;링크&lt;/a&gt;를 참고한다. 미리 훈련된 모델은 &lt;a href=&quot;https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md&quot;&gt;여기서&lt;/a&gt; 찾을 수 있다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*b1-9TBSK6GUMGWd27wcLvQ.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;411&quot; data-original-width=&quot;700&quot; height=&quot;233&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*b1-9TBSK6GUMGWd27wcLvQ.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;혹시, 텐서플로우나 케라스를 설치하지 않았고, 설치하는 데 힘들다면, 다음과 같이 이미 만들어진 도커 이미지를 사용할 수도 있다. 사용방법은 &lt;a href=&quot;https://github.com/NanoNets/RaspberryPi-ObjectDetection-TensorFlow&quot;&gt;여기&lt;/a&gt;를 참고한다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;sudo nvidia-docker run -p 8000:8000 -v `pwd`:data docker.nanonets.com/pi_training -m train -a ssd_mobilenet_v1_coco -e ssd_mobilenet_v1_coco_0 -p &#39;{&quot;batch_size&quot;:8,&quot;learning_rate&quot;:0.003}&#39;&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;학습된 모델 설명은 &lt;a href=&quot;https://github.com/NanoNets/RaspberryPi-ObjectDetection-TensorFlow&quot;&gt;여기서&lt;/a&gt; 얻을 수 있다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;라즈베리파이 딥러닝 실행 속도 개선&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;딥러닝 모델은 32비트 float 실수형 가중치로 구성된 행렬로 볼 수 있다. 딥러닝 모델 중 유명한 AlexNet은 크기만 거의 200MB이다. 이 행렬을 로딩해 실시간으로 계산한다는 것은 라즈베리파이 같은 임베디드 컴퓨터에서는 쉽지 않다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이런 이유로 32비트 float을 양자화해 8비트 정수로 변환시켜 사용한다. 이 결과로 딥러닝 모델 크기는 75%가 줄어든다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/0*Ey92vYBh1Wq2uHfH.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;442&quot; data-original-width=&quot;413&quot; height=&quot;320&quot; src=&quot;https://cdn-images-1.medium.com/max/800/0*Ey92vYBh1Wq2uHfH.png&quot; width=&quot;299&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;양자화 셀 스크립트는 다음과 같다.&lt;br /&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt; 1&lt;br /&gt; 2&lt;br /&gt; 3&lt;br /&gt; 4&lt;br /&gt; 5&lt;br /&gt; 6&lt;br /&gt; 7&lt;br /&gt; 8&lt;br /&gt; 9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;curl&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;-L&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;&quot;https:&lt;/span&gt;&lt;span style=&quot;background-color: #ffaaaa; color: red;&quot;&gt;/&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz&quot;&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;|&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;tar&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;-C&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;tensorflow&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/examples/label_image/data&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;-xz&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;bazel&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;build&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;tensorflow&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/tools/graph_transforms:transform_graph&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;bazel-bin&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/tensorflow/tools/graph_transforms/transform_graph&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;\&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--in_graph=tensorflow&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/examples/label_image/data/inception_v3_2016_08_28_frozen.pb&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;\&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--out_graph=&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/tmp/quantized_graph.pb&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;\&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--inputs=input&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;\&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--outputs=InceptionV3&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/Predictions/Reshape_1&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;\&lt;/span&gt;&lt;br /&gt;  &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--transforms=&#39;add_default_attributes&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;strip_unused_nodes&lt;/span&gt;&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;(type=float, shape=&quot;1,299,299,3&quot;)&lt;/span&gt;&lt;br /&gt;    &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;remove_nodes&lt;/span&gt;&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;(op=Identity, op=CheckNumerics)&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;fold_constants&lt;/span&gt;&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;(ignore_errors=true)&lt;/span&gt;&lt;br /&gt;    &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;fold_batch_norms&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;fold_old_batch_norms&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;quantize_weights&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;quantize_nodes&lt;/span&gt;&lt;br /&gt;    &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;strip_unused_nodes&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;sort_by_execution_order&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;라즈베리파이 설정&lt;/span&gt;&lt;/div&gt;&lt;div&gt;라즈베리파이에 카메라를 설치한다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/800/1*tMcyYPmB8aCJYXSS8Y2I8A.jpeg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;494&quot; data-original-width=&quot;590&quot; height=&quot;267&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*tMcyYPmB8aCJYXSS8Y2I8A.jpeg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;카메라에서 이미지를 가져오는 코드는 다음과 같이 매우 간단하다.&lt;/div&gt;&lt;br /&gt;import picamera, os&lt;br /&gt;from PIL import Image, ImageDraw&lt;br /&gt;camera = picamera.PiCamera()&lt;br /&gt;camera.capture(&#39;image1.jpg&#39;)&lt;br /&gt;os.system(&quot;xdg-open image1.jpg&quot;)&lt;br /&gt;&lt;br /&gt;딥러닝 모델을 다운로드한다.&lt;br /&gt;&lt;br /&gt;sudo nvidia-docker run -v `pwd`:data docker.nanonets.com/pi_training -m export -a ssd_mobilenet_v1_coco -e ssd_mobilenet_v1_coco_0 -c /data/0/model.ckpt-8998&lt;br /&gt;&lt;br /&gt;라즈베리파이에 텐서플로우와 모델을 설치한다.&lt;br /&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;sudo&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;apt-get&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;install&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;libblas-dev&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;liblapack-dev&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;python-dev&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;libatlas-base-dev&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;gfortran&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;python-setuptools&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;libjpeg-dev&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;sudo&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;pip&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;install&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;Pillow&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;sudo&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;pip&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;install&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;http:&lt;/span&gt;&lt;span style=&quot;background-color: #ffaaaa; color: red;&quot;&gt;/&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/ci.tensorflow.org/view/Nightly/job/nightly-pi-zero/lastSuccessfulBuild/artifact/output-artifacts/tensorflow-1.4.0-cp27-none-any.whl&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;git&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;clone&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;https:&lt;/span&gt;&lt;span style=&quot;background-color: #ffaaaa; color: red;&quot;&gt;/&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/github.com/tensorflow/models.git&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;sudo&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;apt-get&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;install&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;-y&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;protobuf-compiler&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;cd&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;models&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/research&lt;/span&gt;&lt;span style=&quot;background-color: #ffaaaa; color: red;&quot;&gt;/&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;protoc&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;object_detection&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/protos/*.proto&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;--python_out=.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;export&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;PYTHONPATH=$PYTHONPATH:&lt;/span&gt;&lt;span style=&quot;color: #996633;&quot;&gt;/home/pi/models/research:/home/pi/models/research/slim&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br /&gt;이제 모델을 실행해 이미지에서 객체를 인식해 보자.&lt;br /&gt;python ObjectDetectionPredict.py --model data/0/quantized_graph.pb --labels data/label_map.pbtxt --images /data/image1.jpg /data/image2.jpg&lt;br /&gt;&lt;br /&gt;라즈베리파이에서 이미지 인식 성능은 다음과 같다. 예를 들어, raster RCNN은 초당 34.52 예측을 할 수 있다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://cdn-images-1.medium.com/max/1000/1*Z1z6TWrmvpW5DQ0WPKkTFw.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;400&quot; data-original-width=&quot;800&quot; height=&quot;320&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*Z1z6TWrmvpW5DQ0WPKkTFw.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;NanoNets 기반 예측&lt;/span&gt;&lt;br /&gt;나노넷(NanoNets)은 앞의 준비과정보다 좀 더 단순하게 객체 인식을 할 수 있도록 해 준다. 나노넷은 GPU같이 값비싼 하드웨어가 필요없이 라즈베리파이 같은 장치에서도 사용하기 좋다.&lt;br /&gt;&lt;br /&gt;다음은 나노넷의 간단한 예제이다.&lt;br /&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt; 1&lt;br /&gt; 2&lt;br /&gt; 3&lt;br /&gt; 4&lt;br /&gt; 5&lt;br /&gt; 6&lt;br /&gt; 7&lt;br /&gt; 8&lt;br /&gt; 9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;import&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;picamera&lt;/span&gt;&lt;span style=&quot;color: #333333;&quot;&gt;,&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;json&lt;/span&gt;&lt;span style=&quot;color: #333333;&quot;&gt;,&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;requests&lt;/span&gt;&lt;span style=&quot;color: #333333;&quot;&gt;,&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;os&lt;/span&gt;&lt;span style=&quot;color: #333333;&quot;&gt;,&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;random&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;time&lt;/span&gt; &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;import&lt;/span&gt; sleep&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;from&lt;/span&gt; &lt;span style=&quot;color: #0e84b5; font-weight: bold;&quot;&gt;PIL&lt;/span&gt; &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;import&lt;/span&gt; Image, ImageDraw&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#capture an image&lt;/span&gt;&lt;br /&gt;camera &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; picamera&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;PiCamera()&lt;br /&gt;camera&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;capture(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;image1.jpg&#39;&lt;/span&gt;)&lt;br /&gt;&lt;span style=&quot;color: #007020;&quot;&gt;print&lt;/span&gt;(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;caputred image&#39;&lt;/span&gt;)&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#make a prediction on the image&lt;/span&gt;&lt;br /&gt;url &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;https://app.nanonets.com/api/v2/ObjectDetection/LabelFile/&#39;&lt;/span&gt;&lt;br /&gt;data &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; {&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;file&#39;&lt;/span&gt;: &lt;span style=&quot;color: #007020;&quot;&gt;open&lt;/span&gt;(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;image1.jpg&#39;&lt;/span&gt;, &lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;rb&#39;&lt;/span&gt;), \&lt;br /&gt;    &lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;modelId&#39;&lt;/span&gt;: (&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;&#39;&lt;/span&gt;, &lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;YOUR_MODEL_ID&#39;&lt;/span&gt;)}&lt;br /&gt;response &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; requests&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;post(url, auth&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;requests&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;auth&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;HTTPBasicAuth(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;YOUR_API_KEY&#39;&lt;/span&gt;, &lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&#39;&#39;&lt;/span&gt;), files&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;data)&lt;br /&gt;&lt;span style=&quot;color: #007020;&quot;&gt;print&lt;/span&gt;(response&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;text)&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #888888;&quot;&gt;#draw boxes on the image&lt;/span&gt;&lt;br /&gt;response &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; json&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;loads(response&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;text)&lt;br /&gt;im &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; Image&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;open(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;image1.jpg&quot;&lt;/span&gt;)&lt;br /&gt;draw &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; ImageDraw&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;Draw(im, mode&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;RGBA&quot;&lt;/span&gt;)&lt;br /&gt;prediction &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; response[&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;result&quot;&lt;/span&gt;][&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;][&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;prediction&quot;&lt;/span&gt;]&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;for&lt;/span&gt; i &lt;span style=&quot;color: black; font-weight: bold;&quot;&gt;in&lt;/span&gt; prediction:&lt;br /&gt;    draw&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;rectangle((i[&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;xmin&quot;&lt;/span&gt;],i[&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;ymin&quot;&lt;/span&gt;], i[&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;xmax&quot;&lt;/span&gt;],i[&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;ymax&quot;&lt;/span&gt;]), fill&lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt;(random&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;randint(&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;255&lt;/span&gt;),random&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;randint(&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;255&lt;/span&gt;),random&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;randint(&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;1&lt;/span&gt;, &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;255&lt;/span&gt;),&lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;127&lt;/span&gt;))&lt;br /&gt;im&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;save(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;image2.jpg&quot;&lt;/span&gt;)&lt;br /&gt;os&lt;span style=&quot;color: #333333;&quot;&gt;.&lt;/span&gt;system(&lt;span style=&quot;background-color: #fff0f0;&quot;&gt;&quot;xdg-open image2.jpg&quot;&lt;/span&gt;)&lt;br /&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;br /&gt;나노넷에 대한 상세한 내용은 다음 링크를 참고한다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://nanonets.com/object-detection-api/&quot;&gt;https://nanonets.com/object-detection-api/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/NanoNets/object-detection-sample-python&quot;&gt;https://github.com/NanoNets/object-detection-sample-python&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;마무리&lt;/span&gt;&lt;br /&gt;이 글에서는 라즈베리파이에서 딥러닝 모델을 실행해 객체 인식 탐색하는 방법을 알아보았다.&lt;br /&gt;이 글의 코드는 다음 링크를 참고하길 바란다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/NanoNets/RaspberryPi-ObjectDetection-TensorFlow&quot;&gt;모델 훈련 및 양자화 코드&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/NanoNets/IndianRoadsObjectDetectionDataset&quot;&gt;모델 훈련 나노넷 코드&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/NanoNets/TF-OD-Pi-Test&quot;&gt;라즈베리파이 기반 객체 예측 소스코드&lt;/a&gt;&amp;nbsp;및 &lt;a href=&quot;https://gist.github.com/sjain07/a30388035c0b39b53841c501f8262ee2&quot;&gt;나노넷 코드&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/NanoNets/IndianRoadsObjectDetectionDataset&quot;&gt;차량 인식용 라벨링 데이터셋&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://cocodataset.org/#download&quot;&gt;Coco 데이터셋&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;이 글에 대한 좀 더 상세한 내용은 다음 링크를 참고하길 바란다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;br /&gt;1.&amp;nbsp;&lt;a href=&quot;https://www.pyimagesearch.com/2017/10/16/raspberry-pi-deep-learning-object-detection-with-opencv/&quot;&gt;Raspberry Pi: Deep learning object detection with OpenCV&lt;/a&gt;&lt;br /&gt;2. &lt;a href=&quot;https://medium.com/nanonets/how-to-easily-detect-objects-with-deep-learning-on-raspberrypi-225f29635c74&quot;&gt;How to easily Detect Objects with Deep Learning on Raspberry Pi&lt;/a&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/3481365542832576238/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/01/blog-post.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/3481365542832576238'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/3481365542832576238'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2019/01/blog-post.html' title='라즈베리파이 기반 딥러닝 객체 인식 개발 방법'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-7632703252273490436</id><published>2018-12-27T00:05:00.002-08:00</published><updated>2019-01-16T06:00:45.503-08:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="블록체인"/><title type='text'>직접 간단히 만들어보는 블록체인과 가상화폐</title><content type='html'>&lt;br /&gt;&lt;div&gt;이 글은 블록체인 동작 메커니즘 이해하고자 하는 싶은 분을 위해 핵심 개념만 간단히 개발하는 과정을 공유한다.&lt;br /&gt;&lt;br /&gt;좀 더 자세한 내용은 아래 링크를 참고한다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2018/02/blog-post_22.html&quot;&gt;비트코인 소스 코드 빌드, 사용 및 블록체인 코드 구조 분석&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;우선 요구사항을 정해보자&lt;/span&gt;&lt;/div&gt;&lt;div&gt;블록체인 개발전에 블록체인 개념을 내포하는 몇가지 요구사항을 정의해야 한다.&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;가상화폐: 가치 교환을 위한 디지털 가치 보관 수단&lt;/li&gt;&lt;li&gt;지갑: 개인이나 조직 가상화폐를 보관하는 전자 계정&lt;/li&gt;&lt;li&gt;트랜잭션: 데이터의 변화를 기록한 단위&lt;/li&gt;&lt;li&gt;블록: 트랜잭션을 기록한 단위. 데이터 변조를 막기 위해 해쉬 암호화 사용&lt;/li&gt;&lt;li&gt;마이닝: 블록을 관리하는 컴퓨팅 소모 자원에 대한 대가 지급&lt;/li&gt;&lt;li&gt;스마트 계약: 상호간 거래시 계약 불이행을 방지하기 위한 수단&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;간단히 만들어 보는 블록체인&amp;nbsp;&lt;/span&gt;&lt;br /&gt;우선 요구사항을 바탕으로 아키텍처를 디자인해보자.&lt;br /&gt;&lt;br /&gt;요구사항에 해당하는 객체를 모두 클래스화한다. 그리고, 각 클래스간 관계를 디자인한다. 예를 들어, 코인과 화폐는 서로 관계가 있다.&lt;br /&gt;&lt;br /&gt;코인은 가치를 보관하는 개념이다. 트랜잭션은 쌍방간의 계약중 하나이며, 가치의 변경을 담는 역할이다. 블록은 트랜잭션의 변화를 기록한다. 블록은 링크드리스트(linked list) 자료구조로 정의된다. 블록의 위변조는 해쉬값으로 알 수 있다. 블록체인은 블록을 생성하고 관리한다. 스마트계약은 트랜잭션을 발생시킨다.&lt;br /&gt;&lt;br /&gt;&lt;div&gt;이를 디자인하면 다음과 같다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-fwF4jGFBQiY/XD8pS7_qJHI/AAAAAAAAMkQ/aon_qD-fauIGc2dKj8yvdwG_ZgQWXR3RgCLcBGAs/s1600/11.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;499&quot; data-original-width=&quot;879&quot; height=&quot;226&quot; src=&quot;https://3.bp.blogspot.com/-fwF4jGFBQiY/XD8pS7_qJHI/AAAAAAAAMkQ/aon_qD-fauIGc2dKj8yvdwG_ZgQWXR3RgCLcBGAs/s400/11.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;클래스 디자인(UML)&lt;/div&gt;&lt;br /&gt;앞의 디자인을 반영해 중요한 부분만 코딩하면 다음과 같다.&lt;br /&gt;&lt;div style=&quot;background: #ffffff; border-width: 0.1em 0.1em 0.1em 0.8em; border: solid gray; overflow: auto; padding: 0.2em 0.6em; width: auto;&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt; 1&lt;br /&gt; 2&lt;br /&gt; 3&lt;br /&gt; 4&lt;br /&gt; 5&lt;br /&gt; 6&lt;br /&gt; 7&lt;br /&gt; 8&lt;br /&gt; 9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;26&lt;br /&gt;27&lt;br /&gt;28&lt;br /&gt;29&lt;br /&gt;30&lt;br /&gt;31&lt;br /&gt;32&lt;br /&gt;33&lt;br /&gt;34&lt;br /&gt;35&lt;br /&gt;36&lt;br /&gt;37&lt;br /&gt;38&lt;br /&gt;39&lt;br /&gt;40&lt;br /&gt;41&lt;br /&gt;42&lt;br /&gt;43&lt;br /&gt;44&lt;br /&gt;45&lt;br /&gt;46&lt;br /&gt;47&lt;br /&gt;48&lt;br /&gt;49&lt;br /&gt;50&lt;br /&gt;51&lt;br /&gt;52&lt;/pre&gt;&lt;/td&gt;&lt;td&gt;&lt;pre style=&quot;line-height: 125%; margin: 0;&quot;&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;coin&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;double&lt;/span&gt; value &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;;&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;wallet&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   string accountAddress;&lt;br /&gt;   coin coin;&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;transaction&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   string fromAcccount, toAccount;&lt;br /&gt;   coin trasnferValue;&lt;br /&gt;   string &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;calculateHash&lt;/span&gt;() {&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;return&lt;/span&gt; SHA256(&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;this&lt;/span&gt;)};&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;block&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   &lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;const&lt;/span&gt; &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;int&lt;/span&gt; MAX_BLOCK_TRANSCTION &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;40&lt;/span&gt;&lt;br /&gt;   &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;int&lt;/span&gt; countTransaction &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #0000dd; font-weight: bold;&quot;&gt;0&lt;/span&gt;;&lt;br /&gt;   transaction[MAX_BLOCK_TRANSACTION];&lt;br /&gt;   block&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; previousBlock &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #007020;&quot;&gt;NULL&lt;/span&gt;;&lt;br /&gt;   block&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; nextBlock &lt;span style=&quot;color: #333333;&quot;&gt;=&lt;/span&gt; &lt;span style=&quot;color: #007020;&quot;&gt;NULL&lt;/span&gt;;&lt;br /&gt;&lt;br /&gt;   &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;int&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;insertTransaction&lt;/span&gt;(transaction&lt;span style=&quot;color: #333333;&quot;&gt;&amp;amp;&lt;/span&gt; t);&lt;br /&gt;   string &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;calculateHash&lt;/span&gt;();&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;blockChain&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   block&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; createGenesisBlock();&lt;br /&gt;   coin&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;miningBlock&lt;/span&gt;(&lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;int&lt;/span&gt; hash, block&lt;span style=&quot;color: #333333;&quot;&gt;&amp;amp;&lt;/span&gt; block);&lt;br /&gt;   block&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;insertBlock&lt;/span&gt;(block&lt;span style=&quot;color: #333333;&quot;&gt;*&lt;/span&gt; b);&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #008800; font-weight: bold;&quot;&gt;class&lt;/span&gt; &lt;span style=&quot;color: #bb0066; font-weight: bold;&quot;&gt;smartContract&lt;/span&gt;&lt;br /&gt;{&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;public:&lt;/span&gt;&lt;br /&gt;   &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;void&lt;/span&gt; setScript(string code);&lt;br /&gt;   &lt;span style=&quot;color: #333399; font-weight: bold;&quot;&gt;bool&lt;/span&gt; &lt;span style=&quot;color: #0066bb; font-weight: bold;&quot;&gt;execute&lt;/span&gt;();&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: #997700; font-weight: bold;&quot;&gt;private:&lt;/span&gt;&lt;br /&gt;   string code;&lt;br /&gt;   python contractScript;&lt;br /&gt;}&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: right;&quot;&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;style by &lt;a href=&quot;http://hilite.me/&quot;&gt;hilite&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;마무리&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이 글은 블록체인과 스마트 계약 구현 원리를 이용해 보기 위해 간단히 아키텍처를 디자인해보고, 코드로 구현해 보았다. 사실, 이외 여러 기능과 구성요소가 필요하나, 다양한 블록체인 플랫폼의 핵심적인 내용은 비슷하다. 좀 더 상세한 내용은 다음 레퍼런스를 참고하길 바란다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;/b&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://cryptonomics.show/2018/08/27/episode-5-smart-money/&quot;&gt;SMART MONEY&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://etherscripter.com/0-5-1/&quot;&gt;EtherScripter&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://medium.com/crypto-currently/build-your-first-smart-contract-fc36a8ff50ca&quot;&gt;Build Your First Smart Contract&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://blockgeeks.com/guides/blockchain-developer/&quot;&gt;Blockchain Tutorial | How To Become A Blockchain Developer&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.amazon.com/Blocky-explains-Blockchain-Brett-Biery/dp/1775324222&quot;&gt;Blocky explains Blockchain&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/7632703252273490436/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blog-post_27.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/7632703252273490436'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/7632703252273490436'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blog-post_27.html' title='직접 간단히 만들어보는 블록체인과 가상화폐'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-fwF4jGFBQiY/XD8pS7_qJHI/AAAAAAAAMkQ/aon_qD-fauIGc2dKj8yvdwG_ZgQWXR3RgCLcBGAs/s72-c/11.PNG" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6108473949070335688</id><published>2018-12-16T23:07:00.004-08:00</published><updated>2019-01-13T05:14:41.014-08:00</updated><title type='text'>Blue Z IoT 오픈소스  프로젝트</title><content type='html'>&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;이 글은 BlueZ IoT 오픈소스 프로젝트를 간략히 설명한다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bluz는 Arduino처럼 작동하지만 Bluetooth LE (BLE) 통신 기능이 내장된 개발 키트이다. 이 BLE 연결을 통해 장치는 REST API를 통해 전 세계 어느 곳에서나 하드웨어에 액세스할 수있게 해주는 Particle 클라우드와 통신할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://bluz.io/img/bluz_layout_vertical.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em; text-align: center;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;772&quot; height=&quot;400&quot; src=&quot;https://bluz.io/img/bluz_layout_vertical.png&quot; width=&quot;385&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;BluZ 개념도&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;함수를 호출하고, 변수를 가져오고, 이벤트를 게시 또는 구독하고, 웹 훅을 트리거하고, 웹 IDE를 통해 무선으로 프로그래밍 할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bluz는 배터리 수명이 긴 무선 애플리케이션에 이상적이다. BLE를 사용하면, bluz는 몇 달 또는 몇 년 동안 코인 셀 배터리로 지속될 수 있으며, 모두 클라우드에 연결되어 액세스 할 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bluz는 Arduino에서 사용되는 것과 동일한 언어인 Wiring으로 프로그래밍되어 있으므로 많은 호환 가능한 개발 키트가 사용 가능하다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;레퍼런스는 아래 링크를 참고한다.&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://bluz.io/&quot;&gt;bluz.io&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6108473949070335688/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blue-z-iot.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6108473949070335688'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6108473949070335688'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blue-z-iot.html' title='Blue Z IoT 오픈소스  프로젝트'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-1227372688780323333</id><published>2018-12-10T01:56:00.001-08:00</published><updated>2018-12-11T03:11:43.920-08:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="딥러닝"/><category scheme="http://www.blogger.com/atom/ns#" term="머신러닝"/><title type='text'>마이크로소프트 딥러닝 인공지능 도구</title><content type='html'>몇 년사이에 마이크로소프트사의 딥러닝 인공지능 도구가 크게 발전한 것 같다. 물론 오픈소스 기반인데다 무료라 사용하기 어렵지 않다.&lt;br /&gt;&lt;br /&gt;이 글은 대표적인 이 회사의 인공지능 도구를 소개한다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/ko-kr/free/services/machine-learning&quot;&gt;Machine Learning based on Azure&lt;/a&gt;: 다양한 머신러닝 도구를 12개월동안 체험 사용할 수 있음.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-QfeyLV3oksQ/XA41b1lAnoI/AAAAAAAAMeI/MEbfUNAma50EuDKwaJxk2WNB_Cyyeo44ACLcBGAs/s1600/1.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;508&quot; data-original-width=&quot;933&quot; height=&quot;174&quot; src=&quot;https://3.bp.blogspot.com/-QfeyLV3oksQ/XA41b1lAnoI/AAAAAAAAMeI/MEbfUNAma50EuDKwaJxk2WNB_Cyyeo44ACLcBGAs/s320/1.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://studio.azureml.net/&quot;&gt;마이크로소프트 Azure Machine Learning Studio&lt;/a&gt;: 그래프를 연결하는 방식으로 다양한 딥러닝 모델을 손쉽게 무료로 코딩할 수 있음. 다양한 예제를 함께 제공함&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-PiZWSaOxcf8/XA-a-Nq6NJI/AAAAAAAAMe0/8eJhxFvP_UAShXIvc2JXZMP_Pg6QtCWXwCLcBGAs/s1600/6.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;828&quot; data-original-width=&quot;1600&quot; height=&quot;206&quot; src=&quot;https://2.bp.blogspot.com/-PiZWSaOxcf8/XA-a-Nq6NJI/AAAAAAAAMe0/8eJhxFvP_UAShXIvc2JXZMP_Pg6QtCWXwCLcBGAs/s400/6.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;https://notebooks.azure.com/&quot;&gt;Azure Notebooks&lt;/a&gt;: 쥬피터 노트북 기반 다양한 프로젝트를 무료로 개발할 수 있음&lt;/li&gt;&lt;li style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;https://www.customvision.ai/&quot;&gt;Custom Vision&lt;/a&gt;: 딥러닝 모델 관련 설정 및 코딩 없이, 손쉽게 이미지를 업로드하면 딥러닝 모델을 개발할 수 있음&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-8ovjujlwqtc/XA42_N1vQ_I/AAAAAAAAMec/j10UiEAMcOw1lpOgDr7vtfPjCrCurP2CwCLcBGAs/s1600/3.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;672&quot; data-original-width=&quot;916&quot; height=&quot;234&quot; src=&quot;https://3.bp.blogspot.com/-8ovjujlwqtc/XA42_N1vQ_I/AAAAAAAAMec/j10UiEAMcOw1lpOgDr7vtfPjCrCurP2CwCLcBGAs/s320/3.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.captionbot.ai/&quot;&gt;Caption Bot&lt;/a&gt;: 비전 딥러닝 모델을 이용한 간단한 서비스로 이미지를 올리면, 자동으로 객체과 상호관계를 인식해 설명을 해줌&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-l8PnkbOtB-s/XA43o_yHxDI/AAAAAAAAMek/wteOGFewUHkQU1TIWQUC2AlBnXksqLSFQCLcBGAs/s1600/5.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;935&quot; data-original-width=&quot;900&quot; height=&quot;320&quot; src=&quot;https://4.bp.blogspot.com/-l8PnkbOtB-s/XA43o_yHxDI/AAAAAAAAMek/wteOGFewUHkQU1TIWQUC2AlBnXksqLSFQCLcBGAs/s320/5.PNG&quot; width=&quot;308&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/1227372688780323333/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blog-post.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1227372688780323333'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1227372688780323333'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/12/blog-post.html' title='마이크로소프트 딥러닝 인공지능 도구'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-QfeyLV3oksQ/XA41b1lAnoI/AAAAAAAAMeI/MEbfUNAma50EuDKwaJxk2WNB_Cyyeo44ACLcBGAs/s72-c/1.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6881596914028289485</id><published>2018-11-18T05:33:00.000-08:00</published><updated>2018-11-18T05:33:04.255-08:00</updated><title type='text'>아마존 AWS 딥렌즈(DeepLens) 사용기</title><content type='html'>이 글은 연구용으로 여름에 구매했던 아마존 AWS 딥렌즈(DeepLens)의 간단한 사용기이다. 연말이 되어서야 아래한글 연구행정 문서질을 어느정도 정리하고, 시간이 되어 딥렌즈를 꺼내놓고 분석하고 사용법을 정리한다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;개요&lt;/span&gt;&lt;br /&gt;딥렌즈는 아마존에서 개발한 딥러닝 기반 비전용 카메라이다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-46xGuOZb-6k/W_Fm5WZIkuI/AAAAAAAAMbs/zFsNqG2je0MIJzOWqOH5dK1glftkptezACLcBGAs/s1600/%25EB%258B%25A4%25EC%259A%25B4%25EB%25A1%259C%25EB%2593%259C.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1106&quot; data-original-width=&quot;640&quot; height=&quot;320&quot; src=&quot;https://3.bp.blogspot.com/-46xGuOZb-6k/W_Fm5WZIkuI/AAAAAAAAMbs/zFsNqG2je0MIJzOWqOH5dK1glftkptezACLcBGAs/s320/%25EB%258B%25A4%25EC%259A%25B4%25EB%25A1%259C%25EB%2593%259C.jpg&quot; width=&quot;185&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-SgtYOuAdnTw/W_Fm5MRXsUI/AAAAAAAAMbo/wLe6suJJEKwAhTocZabcnEu6AcsLMELxACLcBGAs/s1600/%25EB%258B%25A4%25EC%259A%25B4%25EB%25A1%259C%25EB%2593%259C%2B%25281%2529.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1106&quot; data-original-width=&quot;640&quot; height=&quot;320&quot; src=&quot;https://4.bp.blogspot.com/-SgtYOuAdnTw/W_Fm5MRXsUI/AAAAAAAAMbo/wLe6suJJEKwAhTocZabcnEu6AcsLMELxACLcBGAs/s320/%25EB%258B%25A4%25EC%259A%25B4%25EB%25A1%259C%25EB%2593%259C%2B%25281%2529.jpg&quot; width=&quot;185&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;딥렌즈를 이용하면, 미리 훈련된 신경망 모델을 클릭만 해서 딥렌즈에 적용하여, 다양한 비전 프로젝트를 손쉽게 진행할 수 있다. 이미 아마존에는 다양한 최신 신경망 모델이 업로드되어 있어, 적용에 그리 어렵지 않다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;딥렌즈 스펙&lt;/span&gt;&lt;br /&gt;딥렌즈 스펙은 다음과 같다.&lt;br /&gt;&lt;br /&gt;Hardware&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;Intel Atom® processor&lt;br /&gt;Gen9 graphics&lt;br /&gt;Ubuntu 16.04 LTS&lt;br /&gt;106 GFLOPS performance&lt;br /&gt;Dual band Wi-Fi&lt;br /&gt;4 MP camera with MJPEG&lt;br /&gt;H.264 encoding at 1080p resolution&lt;br /&gt;Storage&lt;br /&gt;8 GB RAM&lt;br /&gt;16 GB memory&lt;br /&gt;32 GB SD card&lt;br /&gt;Inputs / Outputs&lt;br /&gt;2 USB ports&lt;br /&gt;Micro HDMI&lt;br /&gt;Audio out&lt;/blockquote&gt;Software&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;AWS Greengrass pre-configured&lt;br /&gt;Cl-DNN (compute library for deep neural networks)&lt;/blockquote&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;셋업&lt;/span&gt;&lt;br /&gt;딥렌즈를 구입하고, 다음 영상을 참고해 셋업한다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe width=&quot;320&quot; height=&quot;266&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/nINqpklf7Eo/0.jpg&quot; src=&quot;https://www.youtube.com/embed/nINqpklf7Eo?feature=player_embedded&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;딥러닝 모델 설치&lt;/span&gt;&lt;br /&gt;이 예제에서는 객체를 탐지하는 CNN 모델을 적용할 것이다. 이 모델은 이미 훈련되어 있으며, 딥렌즈에 설치하면, 바로 실행할 수 있다. 다음 영상을 참고하자.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe width=&quot;320&quot; height=&quot;266&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/-JDLpSsO45A/0.jpg&quot; src=&quot;https://www.youtube.com/embed/-JDLpSsO45A?feature=player_embedded&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;딥러닝 모델 설치&lt;/span&gt;&lt;br /&gt;지금까지 딥렌즈 사용법을 간단히 살펴보았다. 딥러닝도 점차 사용하기 쉬워지고 있다. 지금은 딥러닝이 특별한 사람들만 사용하는 기술처럼 보이지만, 아마존, 마이크로소프트와 같이 대기업 소프트웨어가 손쉽게 딥러닝 기술을 사용할 수 있는 도구를 출시하고 있어, 조만간 대중화되리라 생각한다. 그때는 누구나 드래그 드롭으로 딥러닝을 개발하고, 응용 프로그램을 만들 수 있을 것이다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6881596914028289485/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/11/aws-deeplens.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6881596914028289485'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6881596914028289485'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/11/aws-deeplens.html' title='아마존 AWS 딥렌즈(DeepLens) 사용기'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-46xGuOZb-6k/W_Fm5WZIkuI/AAAAAAAAMbs/zFsNqG2je0MIJzOWqOH5dK1glftkptezACLcBGAs/s72-c/%25EB%258B%25A4%25EC%259A%25B4%25EB%25A1%259C%25EB%2593%259C.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-462286539275757906</id><published>2018-11-03T06:42:00.000-07:00</published><updated>2018-11-04T22:28:54.703-08:00</updated><title type='text'>간단한 BIM 기반 스마트 계약 개발하기</title><content type='html'>이 글에서는 BIM 기반 스마트 계약을 개발할 때, 어떤 방식으로 진행하는 지를 간략히 설명한다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;스마트 계약 개발 절차&lt;/b&gt;&lt;br /&gt;개발은 보통 요구사항 정의, 분석, 설계, 개발 및 테스트로 진행된다.&amp;nbsp; 요구사항 정의 시 사용되는 방법 중 하나가 유스케이스 분석이다. 유스케이스 분석을 통해, 실제 사용 사례와 시나리오를 정리한다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;유스케이스 정의&lt;/b&gt;&lt;br /&gt;BIM의 경우 제일 큰 이슈 중 하나가 디지털 모델 변경이 다수 관계자간에 진행되어, 모델의 신뢰성 보장이 어렵다는 것이다. 신뢰성 보장을 위해서는 모델에 대한 이슈 발생과 처리 시 과정을 추적할 수 있어야 한다. 이슈 관리 이력을 분산원장(블록체인)에 저장해, 모델 변경 이력을 추적할 수 있도록 하고, 모델에 대한 신뢰성을 확보한다. 그래서, 유스케이스를 BIM 협업 상황에서 모델 변경 관련된 모델링 이슈 이력 관리로 한다. 모델 변경 시 관련 트랜잭션 정보는 다음과 같이 가정한다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;1. BIM file URL = resource_type://address+directory&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;2. Issue No = IS###&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;3. Issue reason = enum {element_collision, element_missing, invalid_data, etc}&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;4. Sender = email&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;5. Receiver = email&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;6. Date = YYYY/MM/DD&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;7. State = enum {open, progress, solved, close}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;구현해 보기&lt;/b&gt;&lt;br /&gt;앞의 유스케이스를 스마트 계약으로 구현해 보면 다음과 같다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;pragma solidity ^0.4.0;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;contract BIM_modeling_issue {&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; struct Issue {&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; uint no;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; string url;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; uint reason;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; string sender, receiver;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; string date;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; uint state;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; };&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; Issue[] issues;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; /// Create a issue&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; function BIM_modeling_issue(uint8 num) public {&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; issues.length = num;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; function findIssueBySender(string sender) public Issue returns (Issue _is) {&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; for(uint8 i = 0; i &amp;lt; issues.length; i++)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; {&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if(issues[i].sender == sender) {&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;_is = issues[i];&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&amp;nbsp; &amp;nbsp; }&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;div&gt;BIM 모델링 이슈 데이터를 관리하는 Issue 구조체를 정의하고, issues 배열을 만든다. sender가 생성한 issue를 찾는 findIssueBySender라는 간단한 함수를 만들어 보았다. 이 스크립트는 Solidity 계약 개발을 지원하는&amp;nbsp;&lt;a href=&quot;https://remix.ethereum.org/&quot;&gt;REMIX&lt;/a&gt;등에서 실행할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;레퍼런스&lt;/b&gt;&lt;br /&gt;&lt;a href=&quot;https://remix.readthedocs.io/en/latest/&quot;&gt;Welcome to Remix documentation!&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://www.c-sharpcorner.com/article/create-your-first-smart-contract-in-ethereum-with-ganache-remix-ide/&quot;&gt;Create Your First Smart Contract In Ethereum With Ganache And Remix IDE&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://codeburst.io/build-your-first-ethereum-smart-contract-with-solidity-tutorial-94171d6b1c4b&quot;&gt;Build Your First Ethereum Smart Contract with Solidity — Tutorial&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/462286539275757906/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/11/bim.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/462286539275757906'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/462286539275757906'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/11/bim.html' title='간단한 BIM 기반 스마트 계약 개발하기'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-5880486418521723135</id><published>2018-10-31T05:00:00.003-07:00</published><updated>2018-11-04T21:48:02.640-08:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="교육"/><title type='text'>Google 에서 제안하는 어린이 코딩 도구</title><content type='html'>집에서도 할 수 있는 코딩 방법 중 구글에서 제안한 유용한 도구를 설명한 &lt;a href=&quot;https://www.educatorstechnology.com/2015/01/4-powerful-tools-from-google-to-teach.html&quot;&gt;사이트&lt;/a&gt;가 있어 잠깐 소개한다. 코딩에 흥미를 갖게 하는 도구들이 소개되어 있는 데, 어린이들도 쉽게 할 수 있는 것들이라 부모와 충분히 함께 할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&lt;a href=&quot;http://gym.pencilcode.net/&quot;&gt;코드짐(Code Gym)&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;구글에서 제공하는 오픈소스 코딩 도구로 그리기, 음악, 그래픽 패턴등을 코딩을 통해 만들고 즐길 수 있다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-7pQ8e4v6nXU/W9_YRO5M9MI/AAAAAAAAMY8/jY3u5rmcT20cE_DSSfc7GP0WuuChWLBugCLcBGAs/s1600/code1.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;957&quot; data-original-width=&quot;947&quot; height=&quot;320&quot; src=&quot;https://3.bp.blogspot.com/-7pQ8e4v6nXU/W9_YRO5M9MI/AAAAAAAAMY8/jY3u5rmcT20cE_DSSfc7GP0WuuChWLBugCLcBGAs/s320/code1.PNG&quot; width=&quot;316&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;a href=&quot;https://blockly-games.appspot.com/&quot;&gt;블로키(Blockly)&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;코딩으로 재미있는 다양한 그림을 만들 수 있는 도구이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-U9q2E1u2xhI/W9_YvP_c0mI/AAAAAAAAMZI/4KgUBlD6XosHJpB8W2U6CDjqs1xVQOQ9ACLcBGAs/s1600/code3.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;893&quot; data-original-width=&quot;931&quot; height=&quot;306&quot; src=&quot;https://3.bp.blogspot.com/-U9q2E1u2xhI/W9_YvP_c0mI/AAAAAAAAMZI/4KgUBlD6XosHJpB8W2U6CDjqs1xVQOQ9ACLcBGAs/s320/code3.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;a href=&quot;https://www.madewithcode.com/&quot;&gt;Made with Code&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;코딩으로 다양한 게임과 스토리를 만드는 도구이다. 설명이 잘 되어 있어, 따라하는 데 그리 어렵지 않다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-kMSzekPTYpw/W9_YmX5E4iI/AAAAAAAAMZE/TbGxWG9-dLEDVyxLr040_ceKka1urADTQCLcBGAs/s1600/code2.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;925&quot; data-original-width=&quot;950&quot; height=&quot;311&quot; src=&quot;https://4.bp.blogspot.com/-kMSzekPTYpw/W9_YmX5E4iI/AAAAAAAAMZE/TbGxWG9-dLEDVyxLr040_ceKka1urADTQCLcBGAs/s320/code2.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;a href=&quot;http://appinventor.mit.edu/explore/&quot;&gt;MIT 앱 인벤터(app inventor)&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;스마트폰에 실행되는 앱을 블록 코딩 방식으로 만들 수 있다. MIT에서 개발되었으며, 오픈소스이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-WbRR-Z-Qy2A/W9_ZMizQ4LI/AAAAAAAAMZY/JNR7JpiPmg4BcHYQ2q2VrYPS4pbPQbdigCLcBGAs/s1600/code4.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;770&quot; data-original-width=&quot;833&quot; height=&quot;295&quot; src=&quot;https://3.bp.blogspot.com/-WbRR-Z-Qy2A/W9_ZMizQ4LI/AAAAAAAAMZY/JNR7JpiPmg4BcHYQ2q2VrYPS4pbPQbdigCLcBGAs/s320/code4.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/5880486418521723135/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/10/google.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5880486418521723135'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5880486418521723135'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/10/google.html' title='Google 에서 제안하는 어린이 코딩 도구'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-7pQ8e4v6nXU/W9_YRO5M9MI/AAAAAAAAMY8/jY3u5rmcT20cE_DSSfc7GP0WuuChWLBugCLcBGAs/s72-c/code1.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-686980121142617848</id><published>2018-09-21T21:08:00.002-07:00</published><updated>2018-10-09T07:53:42.691-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="딥러닝"/><title type='text'>딥러닝 훈련용 대용량 이미지의 하둡 파일 준비 방법</title><content type='html'>이 글은&amp;nbsp;딥러닝 훈련용 이미지 데이터 준비 방법을 간단히 설명한다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;학습용 빅데이터 준비 순서&lt;/span&gt;&lt;/b&gt;&lt;br /&gt;우선, 학습할 데이터 목적을 분명히 정한다. 훈련할 딥러닝 모델 종류에 따라 데이터 구조 및 형식이 적절히 변환되어야 할 수 있다. 훈련 및 검증 데이터 크기가 얼마 정도가 되어야 하는 지 결정한다. 대략 학습용 데이터를 준비하는 순서는 다음과 같다.&lt;br /&gt;&lt;br /&gt;1. 학습용 빅데이터 활용 목적 결정&lt;br /&gt;2. 빅데이터 형식, 구조 및 크기 결정&lt;br /&gt;3. 빅데이터 수집 방법 결정&lt;br /&gt;4. 빅데이터 관리 방법 결정&lt;br /&gt;5. 빅데이터 수집&lt;br /&gt;6. 빅데이터 정리&lt;br /&gt;7. 빅데이터 라벨링 및 주석 작업&lt;br /&gt;8. 작업된 데이터 품질 확인&lt;br /&gt;9. 훈련 및 검증용 빅데이터 준비&lt;br /&gt;&lt;br /&gt;이제 딥러닝 훈련용 하둡 데이터 준비 방법을 간단히 살펴보자.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;딥러닝 훈련용 하둡 데이터&lt;/span&gt;&lt;/b&gt;&lt;br /&gt;빅데이터중에 멀티미디어 데이터는 하둡파일로 저장해 관리하는 것이 편리하다. 비전과 관련된 많은 딥러닝 예제에서는 하둡파일인 HDF5를 사용한다. 참고로 하둡파일 구조는 다음 링크를 참고한다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://sites.google.com/site/bimprinciple/in-the-news/bigdeiteocheolileulwihanbunsanpailsiseutemhdf&quot;&gt;하둡 파일 구조 및 사용법&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;딥러닝에 필요한 데이터는 매우 많은데, 예를 들어, ImageNet에 있는 학습 데이터는 거의 2 백만 개 이미지이다. 이런 상황에서 모든 이미지를 메모리로 로드하고, 이미지 전처리를 적용한 후, 네트워크에 전달하여 훈련, 검증 또는 테스트하는 것은 현명하지 않다.&lt;br /&gt;&lt;br /&gt;하나의 HDF5 파일에 많은 수의 이미지를 저장하고, 일괄적으로 데이터를 로딩할 수 있다. HDF5는 데이터를 관리, 조작, 압축 및 저장하는 기능을 제공한다. 이 글에서는 개와 고양이 이미지를 HDF5로 저장 및 로딩해본다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;이미지 및 레이블 지정&lt;/b&gt;&lt;br /&gt;먼저 모든 이미지에 대한 레이블을 지정해야 한다. 각 고양이 이미지에 label = 0을 지정하고, 각 강아지 이미지에 label = 1을 지정한다. 그리고, 학습 모델 가중치가 특정한 학습 시기에 편중되지 않도록 데이터를 임의로 뒤집고 섞어야 한다. 데이터 세트는 훈련용 60%, 검사 20), 테스트 20%로 나눈다. 아래 예제는&amp;nbsp;&lt;a href=&quot;http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html&quot;&gt;machinelearninguru.com&lt;/a&gt;&amp;nbsp;을 참고하였다.&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;background-color: #f7f7fa; border-radius: 5px; border: 2px solid rgb(226, 226, 232); box-sizing: border-box; clear: none; color: #333333; font-family: inherit; font-size: 13px; font-stretch: inherit; font-variant-east-asian: inherit; font-variant-numeric: inherit; line-height: 20px; margin-bottom: 20px; overflow-wrap: break-word; overflow: auto; padding: 15px; vertical-align: baseline; white-space: pre-wrap; word-break: break-all;&quot;&gt;from random import shuffle&lt;br /&gt;import glob&lt;br /&gt;shuffle_data = True  # shuffle the addresses before saving&lt;br /&gt;hdf5_path = &#39;Cat vs Dog/dataset.hdf5&#39;  # address to where you want to save the hdf5 file&lt;br /&gt;cat_dog_train_path = &#39;Cat vs Dog/train/*.jpg&#39;&lt;br /&gt;&lt;br /&gt;# read addresses and labels from the &#39;train&#39; folder&lt;br /&gt;addrs = glob.glob(cat_dog_train_path)&lt;br /&gt;labels = [0 if &#39;cat&#39; in addr else 1 for addr in addrs]  # 0 = Cat, 1 = Dog&lt;br /&gt;&lt;br /&gt;# to shuffle data&lt;br /&gt;if shuffle_data:&lt;br /&gt;    c = list(zip(addrs, labels))&lt;br /&gt;    shuffle(c)&lt;br /&gt;    addrs, labels = zip(*c)&lt;br /&gt;    &lt;br /&gt;# Divide the hata into 60% train, 20% validation, and 20% test&lt;br /&gt;train_addrs = addrs[0:int(0.6*len(addrs))]&lt;br /&gt;train_labels = labels[0:int(0.6*len(labels))]&lt;br /&gt;&lt;br /&gt;val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]&lt;br /&gt;val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]&lt;br /&gt;&lt;br /&gt;test_addrs = addrs[int(0.8*len(addrs)):]&lt;br /&gt;test_labels = labels[int(0.8*len(labels)):]&lt;/pre&gt;&lt;b&gt;HDF5 파일 생성&lt;/b&gt;&lt;br /&gt;h5py 및 PyTables 같은 HDF5 형식을 생성하는 함수가 있다.&lt;br /&gt;&lt;br /&gt;이미지를 저장하기 위해 각&amp;nbsp;이미지 데이터 세트마다 배열 구조를 정의해야 한다. 보통, 데이터 IMAGE_HEIGHT, IMAGE_WIDTH, image_depth 이다. 배열을 만들 때 데이터 유형은 dtype이다.&lt;br /&gt;&lt;br /&gt;하둡파일 생성방법은 테이블 방식과 h5py 함수를 이용해 직접 생성하는 방식이 있다.&lt;br /&gt;&lt;br /&gt;테이블 방식은 empty 배열을 생성하는 create_earray 를 사용할 수 있다. 여기에 데이터를 추가 할 수 있다. 레이블은 create_array를 사용하는 것이 더 편리하다. 배열 dtype을 설정하려면 uint8에 대해 tables.UInt8Atom()과 같은 테이블 dtype을 사용할 수 있다. create_earray 및 create_array 메소드 첫 번째 속성은 데이터 그룹을 작성하여 데이터를 관리 할 수있는 데이터 그룹 이다. 그룹은 HDF5 파일 폴더와 비슷하다.&lt;br /&gt;&lt;br /&gt;h5py 방식은 create_dataset을 사용하여 배열을 만든다. 배열을 정의 할 때는 정확한 크기를 결정해야한다. 레이블에 create_dataset을 사용해 즉시 레이블을 지정할 수 있다. numpy 유형을 사용하여 배열의 dtype을 직접 설정할 수 있다.&lt;br /&gt;&lt;br /&gt;아래는 테이블을 이용해 하둡파일을 생성한다.&lt;br /&gt;&lt;pre style=&quot;background-color: #f7f7fa; border-radius: 8px; border: 2px solid rgb(226, 226, 232); box-sizing: border-box; clear: none; color: #333333; font-family: inherit; font-size: 13px; font-stretch: inherit; font-variant-east-asian: inherit; font-variant-numeric: inherit; line-height: 20px; margin-bottom: 20px; overflow-wrap: break-word; overflow: auto; padding: 15px; vertical-align: baseline; white-space: pre-wrap; word-break: break-all;&quot;&gt;import numpy as np&lt;br /&gt;import tables&lt;br /&gt;&lt;br /&gt;data_order = &#39;tf&#39;  # &#39;th&#39; for Theano, &#39;tf&#39; for Tensorflow&lt;br /&gt;img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved&lt;br /&gt;&lt;br /&gt;# check the order of data and chose proper data shape to save images&lt;br /&gt;if data_order == &#39;th&#39;:&lt;br /&gt;    data_shape = (0, 3, 224, 224)&lt;br /&gt;elif data_order == &#39;tf&#39;:&lt;br /&gt;    data_shape = (0, 224, 224, 3)&lt;br /&gt;&lt;br /&gt;# open a hdf5 file and create earrays&lt;br /&gt;hdf5_file = tables.open_file(hdf5_path, mode=&#39;w&#39;)&lt;br /&gt;&lt;br /&gt;train_storage = hdf5_file.create_earray(hdf5_file.root, &#39;train_img&#39;, img_dtype, shape=data_shape)&lt;br /&gt;val_storage = hdf5_file.create_earray(hdf5_file.root, &#39;val_img&#39;, img_dtype, shape=data_shape)&lt;br /&gt;test_storage = hdf5_file.create_earray(hdf5_file.root, &#39;test_img&#39;, img_dtype, shape=data_shape)&lt;br /&gt;&lt;br /&gt;mean_storage = hdf5_file.create_earray(hdf5_file.root, &#39;train_mean&#39;, img_dtype, shape=data_shape)&lt;br /&gt;&lt;br /&gt;# create the label arrays and copy the labels data in them&lt;br /&gt;hdf5_file.create_array(hdf5_file.root, &#39;train_labels&#39;, train_labels)&lt;br /&gt;hdf5_file.create_array(hdf5_file.root, &#39;val_labels&#39;, val_labels)&lt;br /&gt;hdf5_file.create_array(hdf5_file.root, &#39;test_labels&#39;, test_labels)&lt;/pre&gt;이제 이미지를 하나씩 읽어 전처리하고 저장한다.&lt;br /&gt;&lt;pre style=&quot;background-color: #f7f7fa; border-radius: 8px; border: 2px solid rgb(226, 226, 232); box-sizing: border-box; clear: none; color: #333333; font-family: inherit; font-size: 13px; font-stretch: inherit; font-variant-east-asian: inherit; font-variant-numeric: inherit; line-height: 20px; margin-bottom: 20px; overflow-wrap: break-word; overflow: auto; padding: 15px; vertical-align: baseline; white-space: pre-wrap; word-break: break-all;&quot;&gt;# a numpy array to save the mean of the images&lt;br /&gt;mean = np.zeros(data_shape[1:], np.float32)&lt;br /&gt;&lt;br /&gt;# loop over train addresses&lt;br /&gt;for i in range(len(train_addrs)):&lt;br /&gt;    # print how many images are saved every 1000 images&lt;br /&gt;    if i % 1000 == 0 and i &amp;gt; 1:&lt;br /&gt;        print &#39;Train data: {}/{}&#39;.format(i, len(train_addrs))&lt;br /&gt;&lt;br /&gt;    # read an image and resize to (224, 224)&lt;br /&gt;    # cv2 load images as BGR, convert it to RGB&lt;br /&gt;    addr = train_addrs[i]&lt;br /&gt;    img = cv2.imread(addr)&lt;br /&gt;    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)&lt;br /&gt;    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)&lt;br /&gt;&lt;br /&gt;    # add any image pre-processing here&lt;br /&gt;&lt;br /&gt;    # if the data order is Theano, axis orders should change&lt;br /&gt;    if data_order == &#39;th&#39;:&lt;br /&gt;        img = np.rollaxis(img, 2)&lt;br /&gt;&lt;br /&gt;    # save the image and calculate the mean so far&lt;br /&gt;    train_storage.append(img[None])&lt;br /&gt;    mean += img / float(len(train_labels))&lt;br /&gt;&lt;br /&gt;# loop over validation addresses&lt;br /&gt;for i in range(len(val_addrs)):&lt;br /&gt;    # print how many images are saved every 1000 images&lt;br /&gt;    if i % 1000 == 0 and i &amp;gt; 1:&lt;br /&gt;        print &#39;Validation data: {}/{}&#39;.format(i, len(val_addrs))&lt;br /&gt;&lt;br /&gt;    # read an image and resize to (224, 224)&lt;br /&gt;    # cv2 load images as BGR, convert it to RGB&lt;br /&gt;    addr = val_addrs[i]&lt;br /&gt;    img = cv2.imread(addr)&lt;br /&gt;    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)&lt;br /&gt;    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)&lt;br /&gt;&lt;br /&gt;    # add any image pre-processing here&lt;br /&gt;&lt;br /&gt;    # if the data order is Theano, axis orders should change&lt;br /&gt;    if data_order == &#39;th&#39;:&lt;br /&gt;        img = np.rollaxis(img, 2)&lt;br /&gt;&lt;br /&gt;    # save the image&lt;br /&gt;    val_storage.append(img[None])&lt;br /&gt;&lt;br /&gt;# loop over test addresses&lt;br /&gt;for i in range(len(test_addrs)):&lt;br /&gt;    # print how many images are saved every 1000 images&lt;br /&gt;    if i % 1000 == 0 and i &amp;gt; 1:&lt;br /&gt;        print &#39;Test data: {}/{}&#39;.format(i, len(test_addrs))&lt;br /&gt;&lt;br /&gt;    # read an image and resize to (224, 224)&lt;br /&gt;    # cv2 load images as BGR, convert it to RGB&lt;br /&gt;    addr = test_addrs[i]&lt;br /&gt;    img = cv2.imread(addr)&lt;br /&gt;    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)&lt;br /&gt;    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)&lt;br /&gt;&lt;br /&gt;    # add any image pre-processing here&lt;br /&gt;&lt;br /&gt;    # if the data order is Theano, axis orders should change&lt;br /&gt;    if data_order == &#39;th&#39;:&lt;br /&gt;        img = np.rollaxis(img, 2)&lt;br /&gt;&lt;br /&gt;    # save the image&lt;br /&gt;    test_storage.append(img[None])&lt;br /&gt;&lt;br /&gt;# save the mean and close the hdf5 file&lt;br /&gt;mean_storage.append(mean[None])&lt;br /&gt;hdf5_file.close()&lt;/pre&gt;&lt;b&gt;HDF5 파일 읽기&lt;/b&gt;&lt;br /&gt;데이터가 HDF5 파일에 올바르게 저장되었는지 확인해야한다. 이를 위해 임의의 크기의 배치로 데이터를 로드하고 처음 다섯번째 배치의 첫 번째 이미지를 출력해 본다. 또한 각 이미지의 레이블을 확인한다.&lt;br /&gt;&lt;pre style=&quot;background-color: #f7f7fa; border-radius: 8px; border: 2px solid rgb(226, 226, 232); box-sizing: border-box; clear: none; color: #333333; font-family: inherit; font-size: 13px; font-stretch: inherit; font-variant-east-asian: inherit; font-variant-numeric: inherit; line-height: 20px; margin-bottom: 20px; overflow-wrap: break-word; overflow: auto; padding: 15px; vertical-align: baseline; white-space: pre-wrap; word-break: break-all;&quot;&gt;import tables&lt;br /&gt;import numpy as np&lt;br /&gt;&lt;br /&gt;hdf5_path = &#39;Cat vs Dog/dataset.hdf5&#39;&lt;br /&gt;subtract_mean = False&lt;br /&gt;&lt;br /&gt;# open the hdf5 file&lt;br /&gt;hdf5_file = tables.open_file(hdf5_path, mode=&#39;r&#39;)&lt;br /&gt;&lt;br /&gt;# subtract the training mean&lt;br /&gt;if subtract_mean:&lt;br /&gt;    mm = hdf5_file.root.train_mean[0]&lt;br /&gt;    mm = mm[np.newaxis, ...]&lt;br /&gt;&lt;br /&gt;# Total number of samples&lt;br /&gt;data_num = hdf5_file.root.train_img.shape[0]&lt;/pre&gt;이제 배치 목록을 만들고, 순서를 섞는다. 그리고, 각 배치의 모든 이미지를 한번에 로딩한다.&lt;br /&gt;&lt;pre style=&quot;background-color: #f7f7fa; border-radius: 8px; border: 2px solid rgb(226, 226, 232); box-sizing: border-box; clear: none; color: #333333; font-family: inherit; font-size: 13px; font-stretch: inherit; font-variant-east-asian: inherit; font-variant-numeric: inherit; line-height: 20px; margin-bottom: 20px; overflow-wrap: break-word; overflow: auto; padding: 15px; vertical-align: baseline; white-space: pre-wrap; word-break: break-all;&quot;&gt;from random import shuffle&lt;br /&gt;from math import ceil&lt;br /&gt;import matplotlib.pyplot as plt&lt;br /&gt;&lt;br /&gt;# create list of batches to shuffle the data&lt;br /&gt;batches_list = list(range(int(ceil(float(data_num) / batch_size))))&lt;br /&gt;shuffle(batches_list)&lt;br /&gt;&lt;br /&gt;# loop over batches&lt;br /&gt;for n, i in enumerate(batches_list):&lt;br /&gt;    i_s = i * batch_size  # index of the first image in this batch&lt;br /&gt;    i_e = min([(i + 1) * batch_size, data_num])  # index of the last image in this batch&lt;br /&gt;&lt;br /&gt;    # read batch images and remove training mean&lt;br /&gt;    images = hdf5_file.root.train_img[i_s:i_e]&lt;br /&gt;    if subtract_mean:&lt;br /&gt;        images -= mm&lt;br /&gt;&lt;br /&gt;    # read labels and convert to one hot encoding&lt;br /&gt;    labels = hdf5_file.root.train_labels[i_s:i_e]&lt;br /&gt;    labels_one_hot = np.zeros((batch_size, nb_class))&lt;br /&gt;    labels_one_hot[np.arange(batch_size), labels] = 1&lt;br /&gt;&lt;br /&gt;    print n+1, &#39;/&#39;, len(batches_list)&lt;br /&gt;&lt;br /&gt;    print labels[0], labels_one_hot[0, :]&lt;br /&gt;    plt.imshow(images[0])&lt;br /&gt;    plt.show()&lt;br /&gt;    &lt;br /&gt;    if n == 5:  # break after 5 batches&lt;br /&gt;        break&lt;br /&gt;&lt;br /&gt;hdf5_file.close()&lt;/pre&gt;&lt;br /&gt;이 코드를 이용해, 배치로 로딩한 이미지 데이터셋을 이용한 딥러닝 모델 훈련, 검증을 할 수 있을 것이다. 이와 관련된 코드는 &lt;a href=&quot;https://github.com/Machinelearninguru/Image-Processing-Computer-Vision/tree/master/Convolutional%20Neural%20Network/Convolutional%20Layers&quot;&gt;machinelearningrugu.com&lt;/a&gt;에서 제공한 &lt;a href=&quot;https://github.com/Machinelearninguru/Image-Processing-Computer-Vision/tree/master/Convolutional%20Neural%20Network/Convolutional%20Layers&quot;&gt;Github&lt;/a&gt;페이지에서 확인할 수 있다.&lt;br /&gt;&lt;br /&gt;만약 텐서플로우 레코드 형식인 TFRecords 로 처리하려면, 이 &lt;a href=&quot;http://machinelearninguru.com/deep_learning/data_preparation/tfrecord/tfrecord.html&quot;&gt;링크&lt;/a&gt;를 참고하라.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;참고 - 딥러닝 데이터 취득 센서 스펙&amp;nbsp;&lt;/span&gt;&lt;br /&gt;무인자율차 등에 사용하는 데이터 취득용 센서는 환경에 따라 취득할 수 있는 데이터 종류, 여건 등이 다르다. 아래 표는 이를 정리한 것이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-0734CU29Qmw/W7yzpJGnB1I/AAAAAAAAMKk/nZ9wC7GUtyAudfyATlWFf74ouLVBcyMYwCLcBGAs/s1600/f4.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;300&quot; data-original-width=&quot;759&quot; height=&quot;251&quot; src=&quot;https://1.bp.blogspot.com/-0734CU29Qmw/W7yzpJGnB1I/AAAAAAAAMKk/nZ9wC7GUtyAudfyATlWFf74ouLVBcyMYwCLcBGAs/s640/f4.PNG&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;센서 스펙(Distributed Deep Learning with Hadoop and TensorFlow)&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;참고 - 딥러닝 데이터 취득 센서 스펙&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div&gt;머신러닝 플랫폼은 사용하는 레이어에 따라 여러가지가 될 수 있다. Flux는 데이터 저장, 학습, 시뮬레이션, 관리까지 아우르는 플랫폼이다. 시뮬레이션 및 센서 데이터 교환을 위해 ROS를 사용하고 있다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-CrV3u_JooC0/W7yzpBGNNYI/AAAAAAAAMKg/W4XYU_vfxAEm1TFVtK03t_e4JNxlMaYKwCLcBGAs/s1600/f2.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;381&quot; data-original-width=&quot;750&quot; height=&quot;201&quot; src=&quot;https://3.bp.blogspot.com/-CrV3u_JooC0/W7yzpBGNNYI/AAAAAAAAMKg/W4XYU_vfxAEm1TFVtK03t_e4JNxlMaYKwCLcBGAs/s400/f2.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-WhOP_u_PPNA/W7yzpOUcrbI/AAAAAAAAMKo/XiwPzzMQ6u85ETErjAfS1ZlRhKHIkRKUACLcBGAs/s1600/f3.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;414&quot; data-original-width=&quot;727&quot; height=&quot;227&quot; src=&quot;https://2.bp.blogspot.com/-WhOP_u_PPNA/W7yzpOUcrbI/AAAAAAAAMKo/XiwPzzMQ6u85ETErjAfS1ZlRhKHIkRKUACLcBGAs/s400/f3.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;참고 - 딥러닝 모델 데이터 종류&lt;/span&gt;&lt;/b&gt;&lt;br /&gt;빅데이터를 저장하고 훈련 시 필요한 데이터를 딥러닝 모델에 공급하기 위해 데이터 형식을 구조화해야 한다. 데이터 구조는 앞서 설명한 바와 같이, 훈련, 검증 및 테스트로 구분하고, 각 데이터셋을 배치방식으로 로딩하기 위해 배치단위로 저장된다. 각 데이터는 학습 모델에 입력될 수 있는 데이터 구조로 정규화되어 저장되며, 이때 라벨 정보가 함께 있어야 한다.&lt;br /&gt;&lt;br /&gt;데이터 활용 목적에 따라 취득될 수 있는 데이터 종류는 다음과 같다.&lt;br /&gt;&lt;br /&gt;1. 이미지 형식&lt;br /&gt;이 데이터 형식은 카메라로 얻은 사진, 동영상 뿐 아니라 신호 등 시공간 이미지 데이터 등을 모두 포함한다. 이미지는 RGB 픽셀 단위, 정수나 실수로 표현된 신호값 등으로 구성될 수 있다.&lt;br /&gt;이미지는 프레임으로 구분되며, 프레임은 스트리밍(streaming) 가능한 형식으로 표현된다. 저장된 동영상 파일 포맷을 읽기 위해서는 포맷 해석을 위한 코덱(codec)이 필요하다. 보통, OpenCV같은 라이브러리는 이미지 영상 데이터를 읽고 쓸 수 있다.&lt;br /&gt;신호같은 데이터는 행렬 형식으로 이미지를 만들고 저장할 수 있다.&lt;br /&gt;&lt;br /&gt;2. 텍스트 형식&lt;br /&gt;텍스트 형식은 이미지 보다는 구조나 포맷이 간단하고, 읽고 쓰기가 편리하다. 텍스트 형식은 훈련용, 검증용 데이터셋 종류와 갯수를 구분할 수 있는 헤더 정보를 정의한다.&lt;br /&gt;&lt;br /&gt;3. 점군(포인트 클라우드) 형상&lt;br /&gt;점군은 대용량 데이터로 수백만개 이상 포인트가 포함된 구조이다. 수백만개 점군을 직접 훈련용 데이터로 사용할 수는 없으니, 세그먼테이션하여 분리된 점군을 적절히 샘플링하여, 3차원 grid 형식으로 저장한다. 이때 voxel 구조 등을 사용하기도 한다.&lt;br /&gt;&lt;br /&gt;기타 수치, 벡터 데이터, 관계 위상 정보 등이 있다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;/b&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html&quot;&gt;Saving and loading a large number of images (data) into a single HDF5 file&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/jwiegelmann/distributed-deep-learning-with-hadoop-and-tensorflow&quot;&gt;Distributed Deep Learning with Hadoop and TensorFlow&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://machinelearningmastery.com/prepare-photo-caption-dataset-training-deep-learning-model/&quot;&gt;How to Prepare a Photo Caption Dataset for Training a Deep Learning Model&lt;/a&gt;&amp;nbsp;(Keras)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://oopsmonk.github.io/_posts/2017-08-31-faster-r-cnn-use-caffe-framework&quot;&gt;Faster R-CNN Use Caffe Framework with Video&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.packtpub.com/mapt/book/big_data_and_business_intelligence/9781787123212/10/ch10lvl1sec96/capturing-and-processing-video-from-a-webcam&quot;&gt;Capturing and processing video from a webcam&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/zo7/deep-features-video&quot;&gt;Scripts to extract CNN features from video frames with Keras, github&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/&quot;&gt;Real-time object detection with deep learning and OpenCV&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2018/09/deep-learning-video-classification-python/&quot;&gt;Deep Learning Tutorial to Calculate the Screen Time of Actors in any Video (with Python codes)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.dlology.com/blog/how-to-run-object-detection-and-segmentation-on-video-fast-for-free/&quot;&gt;How to run Object Detection and Segmentation on a Video Fast for Free with R-CNN&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/&quot;&gt;How to (quickly) build a deep learning image dataset&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/&quot;&gt;Image Classification using Convolutional Neural Networks in Keras (simple)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8&quot;&gt;Simple Image Classification using Convolutional Neural Network — Deep Learning in python.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&quot;&gt;Building powerful image classification models using very little data&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/how-to-build-a-neural-network-with-keras-e8faa33d0ae4&quot;&gt;How to build a Neural Network with Keras&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://yeephycho.github.io/2016/08/15/image-data-in-tensorflow/&quot;&gt;A Tutorial on How to Feed Your Own Image Data to Tensorflow&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://tykimos.github.io/2017/03/08/CNN_Getting_Started/&quot;&gt;컨볼루션 신경망 모델 만들어보기&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://tykimos.github.io/2017/06/10/Model_Save_Load/&quot;&gt;학습 모델 보기/저장하기/불러오기&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/686980121142617848/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post_21.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/686980121142617848'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/686980121142617848'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post_21.html' title='딥러닝 훈련용 대용량 이미지의 하둡 파일 준비 방법'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://1.bp.blogspot.com/-0734CU29Qmw/W7yzpJGnB1I/AAAAAAAAMKk/nZ9wC7GUtyAudfyATlWFf74ouLVBcyMYwCLcBGAs/s72-c/f4.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-1336174325788335250</id><published>2018-09-18T22:26:00.000-07:00</published><updated>2018-09-24T08:22:31.249-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="로봇"/><title type='text'>연구용 로버 프레임 정리</title><content type='html'>연구 주제가 시설물 운영 관리를 위한 원격 스캔 및 모니티링이라 로버(rover)를 사용하지 않을 수 없다. 이 글에서는 가성비 괜찬은 로버 프레임을 간단히 소개한다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://www.warburtech.co.uk/products/robotics/robot.kits/nexus.10021.4wd.60mm.mecanum.wheel.robot.kit/&quot;&gt;4WD 메카넘휠 로버&lt;/a&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.warburtech.co.uk/products/robotics/robot.kits/nexus.10021.4wd.60mm.mecanum.wheel.robot.kit/images/nexus.10021.4wd.60mm.mecanum.wheel.robot.kit.000.small.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://www.warburtech.co.uk/products/robotics/robot.kits/nexus.10021.4wd.60mm.mecanum.wheel.robot.kit/images/nexus.10021.4wd.60mm.mecanum.wheel.robot.kit.000.small.jpg&quot; data-original-height=&quot;300&quot; data-original-width=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;개발 상세내용 -&amp;nbsp;&lt;span style=&quot;font-family: 돋움;&quot;&gt;https://daddynkidsmakers.blogspot.com/2016/06/3-4wd.html&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;font-family: 돋움; font-size: 13.33px; font-variant-east-asian: normal; font-variant-numeric: normal; margin: 5px;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;a href=&quot;https://www.alibaba.com/product-detail/Equivalent-connector-rover-5-rubber-track_60737719758.html?spm=a2700.galleryofferlist.normalList.1.7aa379edQwbqRh&quot;&gt;Equivalent connector rover 5 mobile car chassis&lt;/a&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://sc01.alicdn.com/kf/HTB1SY9jeAfb_uJkHFqDq6xVIVXaB/230059390/HTB1SY9jeAfb_uJkHFqDq6xVIVXaB.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;533&quot; data-original-width=&quot;800&quot; height=&quot;213&quot; src=&quot;https://sc01.alicdn.com/kf/HTB1SY9jeAfb_uJkHFqDq6xVIVXaB/230059390/HTB1SY9jeAfb_uJkHFqDq6xVIVXaB.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;background-color: white; color: #333333; font-family: &amp;quot;roboto&amp;quot;; font-size: 16px;&quot;&gt;&lt;a href=&quot;https://korean.alibaba.com/product-detail/The-multifunctional-rover-5-robot-mobile-60750371373.html?spm=a2700.galleryofferlist.normalList.338.1d1648bdVmjCwX&quot;&gt;The multifunctional rover 5 robot mobile car platform&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://sc02.alicdn.com/kf/HTB1bjxEgASWBuNjSszdq6zeSpXae/228841439/HTB1bjxEgASWBuNjSszdq6zeSpXae.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;405&quot; data-original-width=&quot;789&quot; height=&quot;164&quot; src=&quot;https://sc02.alicdn.com/kf/HTB1bjxEgASWBuNjSszdq6zeSpXae/228841439/HTB1bjxEgASWBuNjSszdq6zeSpXae.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;a href=&quot;https://www.alibaba.com/product-detail/Dagu-rover-5-tracked-chassis-mexico_60766662701.html&quot;&gt;Dagu rover 5 tracked chassis mexico articulated 4 wheel robot&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://sc01.alicdn.com/kf/HTB1.E6qncyYBuNkSnfoq6AWgVXai/228841439/HTB1.E6qncyYBuNkSnfoq6AWgVXai.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;800&quot; data-original-width=&quot;800&quot; height=&quot;320&quot; src=&quot;https://sc01.alicdn.com/kf/HTB1.E6qncyYBuNkSnfoq6AWgVXai/228841439/HTB1.E6qncyYBuNkSnfoq6AWgVXai.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;a href=&quot;https://www.alibaba.com/product-detail/Dagu-rover-5-tracked-chassis-mexico_60771429866.html&quot;&gt;Dagu rover 5 tracked chassis mexico articulated 4 wheel robot&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://sc02.alicdn.com/kf/HTB1EmHzejgy_uJjSZK9q6xvlFXa7/230059390/HTB1EmHzejgy_uJjSZK9q6xvlFXa7.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;534&quot; data-original-width=&quot;800&quot; height=&quot;213&quot; src=&quot;https://sc02.alicdn.com/kf/HTB1EmHzejgy_uJjSZK9q6xvlFXa7/230059390/HTB1EmHzejgy_uJjSZK9q6xvlFXa7.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/1336174325788335250/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post_18.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1336174325788335250'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1336174325788335250'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post_18.html' title='연구용 로버 프레임 정리'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-1441663965934972574</id><published>2018-09-17T23:35:00.000-07:00</published><updated>2018-09-20T04:30:09.671-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="딥러닝"/><category scheme="http://www.blogger.com/atom/ns#" term="머신러닝"/><title type='text'>케라스 기반 이미지 인식 딥러닝 모델 구현</title><content type='html'>오랜만에 급한 일이 약간 처리되어, 쌓아 둔 케라스(Keras) 기반 딥러닝 자료를 정리한다. 이 글은 Inception, VGG등 대표적인 딥러닝 모델을 설명하고, 케라스 기반 VGG 딥러닝 구현 예제를 소개한다. 이 예제에서는 구글에서 얻은 건축 이미지와 3D 이미지 예측 정확도를 간단히 테스트해본다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;이미지넷 인식 딥러닝 모델&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이미지넷 객체 인식 딥러닝 모델은 이미지넷 &lt;a href=&quot;https://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=2ahUKEwjz79_U28bdAhXMW7wKHf1RDe0QFjAAegQIABAB&amp;amp;url=http%3A%2F%2Fwww.image-net.org%2Fchallenges%2FLSVRC%2F&amp;amp;usg=AOvVaw0WyvvIJ60qzasCll0vCh5Q&quot;&gt;ImageNet Large Scale Visual Recognition Competition(ILSVRC)&lt;/a&gt; 대회를 통해 크게 발전되었다. 2014년 대회에서는 1000개 이미지 분류 문제가 있었고, 이를 위해, 이미지넷의 120만장 학습 이미지와 5만장 validation set, 10만장 test set을 사용할 수 있다.&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이 대회는 ground truth 와 가장 높은 확률로 예측된 클래스가 서로 일치하는 지 확인하는 top-1 정확도, 가장 높은 확률로 예측된 5개 클래스안에 ground truth 존재 여부를 확인하는 top-5 error rate로 순위를 매긴다. &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-VHADNEgspW0/W6ID2k1bd9I/AAAAAAAAMFc/4lsd1f9oNlQE5O0tCkPTQUuzDWl7RChGwCLcBGAs/s1600/nnarch1-1.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;432&quot; data-original-width=&quot;660&quot; height=&quot;261&quot; src=&quot;https://4.bp.blogspot.com/-VHADNEgspW0/W6ID2k1bd9I/AAAAAAAAMFc/4lsd1f9oNlQE5O0tCkPTQUuzDWl7RChGwCLcBGAs/s400/nnarch1-1.png&quot; width=&quot;400&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;Top-1 accuracy deep learning model(https://arxiv.org/abs/1605.07678)&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-JfD8rO4AOMI/W6ISNpoz5TI/AAAAAAAAMGk/pVLezUtXb6YiF3Ocl2PsziZlQniYBF5MwCLcBGAs/s1600/1*CqUPq-w3h3u7m1LTiXycxg.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;438&quot; data-original-width=&quot;693&quot; height=&quot;251&quot; src=&quot;https://2.bp.blogspot.com/-JfD8rO4AOMI/W6ISNpoz5TI/AAAAAAAAMGk/pVLezUtXb6YiF3Ocl2PsziZlQniYBF5MwCLcBGAs/s400/1*CqUPq-w3h3u7m1LTiXycxg.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;10 Testing Results (Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection))&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이미지 인식 문제에서 높은 정확도를 가진 모델 중 대표적인 것만 간략히 살펴본다.&amp;nbsp;&lt;/span&gt; &lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;LENET5: 1994년 개발된 모델로 컨볼루션 뉴럴네트워크 사용함. 이 모델은 1988년부터 Yann LeCun이 개발되어 LeNet5으로 이름지어짐. 이 모델은 컨볼루션 레이어 3개를 사용하여, 이미지 특징 벡터를학습하였음. 이 당시에는 GPU가 없어, 대용량 계산 시간을 줄이기 위해 희소 연결 행렬을 사용하였음&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-lWiHXG5Uh4k/W6IFosoeJUI/AAAAAAAAMFo/RUd3HyRSFkIJX1h0AmQjm_moQWansXz_wCLcBGAs/s1600/nnarch2_lenet.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;255&quot; data-original-width=&quot;880&quot; height=&quot;184&quot; src=&quot;https://3.bp.blogspot.com/-lWiHXG5Uh4k/W6IFosoeJUI/AAAAAAAAMFo/RUd3HyRSFkIJX1h0AmQjm_moQWansXz_wCLcBGAs/s640/nnarch2_lenet.jpg&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;AlexNet: 딥러닝 대부 중 한명인 Geoffrey E. Hinton제자인 2012년 Alex Krizhevsky가 발표한 이미지넷의 이미지 인식 정확도를 극적으로높인 첫번째 딥러닝 모델. Top 5 test error가 15.4%로 2위 모델보다(26.2%) 정확도가 매우 높음. 5개 컨볼루션 레이어와 3개 fully connected 레이어 사용함. 이 모델에서 ReLu(Rectified Linear Unit), over fitting 방지를 위한 Dropout 기법이 적용됨. GPU를 NVIDIA GTX 580 사용하였음&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-Uqz-sTvv5As/W6IGADvOyiI/AAAAAAAAMFw/cVs2rhHV9x0Q1Rx9EIJJRqp-ADvK2NDRQCLcBGAs/s1600/nnarch3_alexnet.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;172&quot; data-original-width=&quot;550&quot; src=&quot;https://1.bp.blogspot.com/-Uqz-sTvv5As/W6IGADvOyiI/AAAAAAAAMFw/cVs2rhHV9x0Q1Rx9EIJJRqp-ADvK2NDRQCLcBGAs/s1600/nnarch3_alexnet.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-HHRSAnYmtig/W6IXTJkwrtI/AAAAAAAAMHE/rtr0hkU3R0YoerXCc6kQcpROy7fIGhIbwCLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-19%2B18-30-30.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;324&quot; data-original-width=&quot;483&quot; height=&quot;267&quot; src=&quot;https://3.bp.blogspot.com/-HHRSAnYmtig/W6IXTJkwrtI/AAAAAAAAMHE/rtr0hkU3R0YoerXCc6kQcpROy7fIGhIbwCLcBGAs/s400/Screenshot%2Bfrom%2B2018-09-19%2B18-30-30.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;a href=&quot;https://keras.io/applications/#xception&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;Xception&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: black;&quot;&gt;: &lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;이미지 넷에서 0.945 정확도로 top-5 validation 획득한 모델. 입력 이미지는 299x299임 &lt;/span&gt;&lt;/li&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;a href=&quot;https://keras.io/applications/#vgg16&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;VGG&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: black;&quot;&gt;: 2014년 &lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;옥스포드 VGG 그룹에서 개발된 딥러닝 모델. 알렉스넷의 커널 크기를 11에서 3x3으로 줄였고, 성능을 높임. 19층 레이어를 쌓음. 이미지넷 정확도를 92.3%로 개선. 층이 깊어 역전파 될 때 그레디언트가 작아져 해가 수렴되지 않은 문제(gradient vanishing)가 있었음&amp;nbsp; &lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-d6aZWanZ7cY/W6IARAw5RlI/AAAAAAAAME0/0b29K4MO1Ng5_E357C7NeFTL03tpw8rZACLcBGAs/s1600/imagenet_vgg16.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;276&quot; data-original-width=&quot;470&quot; height=&quot;233&quot; src=&quot;https://3.bp.blogspot.com/-d6aZWanZ7cY/W6IARAw5RlI/AAAAAAAAME0/0b29K4MO1Ng5_E357C7NeFTL03tpw8rZACLcBGAs/s400/imagenet_vgg16.png&quot; width=&quot;400&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~frossard/post/vgg16/&quot;&gt;A visualization of the VGG architecture&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;ResNet&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;: &lt;/span&gt;2015년 이미지넷 ILSVRC에서 3.6% 에러율로 1등 차지한 모델. 참고로 인간 분류 오차가 5~10%임. 알렉스넷과 같은 전통적인 순차 네트워크와는 달리, ResNet은 exotic architecture로 네트워크 내에서 네트워크를 구조화한 모델임. 이런 구조는 마이크로 구조라는 블럭 빌딩 세트 집합으로 구성됨. residual block을 이용해 gradient vanishing문제 해결&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-Wn75WLtOjeE/W6IJbpFo32I/AAAAAAAAMF8/fi5rfT8_HowyE729t2JSbzHU2HSrO6hQACLcBGAs/s1600/CjLtXb0.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;472&quot; data-original-width=&quot;1506&quot; height=&quot;125&quot; src=&quot;https://3.bp.blogspot.com/-Wn75WLtOjeE/W6IJbpFo32I/AAAAAAAAMF8/fi5rfT8_HowyE729t2JSbzHU2HSrO6hQACLcBGAs/s400/CjLtXb0.png&quot; width=&quot;400&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;Residual block(ResNet) &lt;/div&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;a href=&quot;https://keras.io/applications/#inceptionresnetv2&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;Inception&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;color: black;&quot;&gt;: &lt;/span&gt;2015년 이미지넷에서 우승. VGG의 계산 시간/성능을 개선한 모델. 다양한 필터와 1x1 풀링(pooling) 기법 등 사용해 전체적으로 네트워크 연결을 줄임. 컨볼루션 필터을 쪼개어 연산수를 낮게 만듬. 이를 통해, 핵심적인 연산은 밀도있게 처리함&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-0FV45PKPZM0/W6IB74D2jhI/AAAAAAAAMFQ/CIUiY9koldMIuuw1ICKgjGRcttZZmev7wCLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-19%2B16-58-36.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;299&quot; data-original-width=&quot;718&quot; height=&quot;166&quot; src=&quot;https://3.bp.blogspot.com/-0FV45PKPZM0/W6IB74D2jhI/AAAAAAAAMFQ/CIUiY9koldMIuuw1ICKgjGRcttZZmev7wCLcBGAs/s400/Screenshot%2Bfrom%2B2018-09-19%2B16-58-36.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;DenseNet: 2016년 개발된 모델. 해를 좀 더 효과적으로 찾고 수렴시키기 위해, 역전파를 순차적으로 하는 것이 아닌 건너뛸수 있도록 네트워크 망을 개선함&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt; &lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-aBzk1kmSKrQ/W6IKGXqBxuI/AAAAAAAAMGE/AfXHnPDa1jA2nZgOUap0OGAPl0UlGMPMQCLcBGAs/s1600/EITg2BX.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;686&quot; data-original-width=&quot;961&quot; height=&quot;285&quot; src=&quot;https://3.bp.blogspot.com/-aBzk1kmSKrQ/W6IKGXqBxuI/AAAAAAAAMGE/AfXHnPDa1jA2nZgOUap0OGAPl0UlGMPMQCLcBGAs/s400/EITg2BX.png&quot; width=&quot;400&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;&amp;nbsp;&lt;a href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot;&gt;Densely Connected Convolutional Networks&lt;/a&gt;(2016)&lt;/span&gt;&lt;/div&gt;&lt;span style=&quot;color: black;&quot;&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;background-color: #fcfcfc; box-sizing: border-box; font-family: Lato, proxima-nova, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 14.4px; line-height: 24px; list-style-image: initial; list-style-position: initial; margin: 0px 0px 24px; padding: 0px;&quot;&gt;&lt;li style=&quot;box-sizing: border-box; list-style: disc; margin-left: 24px;&quot;&gt;&lt;a href=&quot;https://keras.io/applications/#mobilenet&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt;이외 MobileNet,&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://keras.io/applications/#densenet&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt; DenseNet,&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://keras.io/applications/#nasnet&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt; NASNet,&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;https://keras.io/applications/#mobilenetv2&quot; style=&quot;box-sizing: border-box; text-decoration-line: none;&quot;&gt;&lt;span style=&quot;color: black;&quot;&gt; MobileNetV2 등&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;span style=&quot;font-size: large;&quot;&gt;객체 인식 딥러닝 모델&lt;/span&gt;&lt;br /&gt;R-CNN(2013), FAST R-CNN(2015), FASTER R-CNN(2015), YOLO 등은 이미지 속 다양한 객체 경계를 탐색하는 모델이다. 이 문제는 경계 탐색 작업과 객체 분류 작업으로 구성된다.&lt;br /&gt;아래 링크에 이와 관련된 모델 및 구조가 설명되어 있다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://sites.google.com/site/bimprinciple/in-the-news/dibleoning-euliyonghangaegchegeomchulr-cnnyolossd&quot;&gt;딥러닝 기반 FAST 객체 탐색 기법 - CNN, YOLO, SSD&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;케라스 설치 및 사용 방법&lt;/span&gt;&lt;br /&gt;아래 링크를 참고해 케라스를 설치하고 실행되는 지 확인해 본다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://daddynkidsmakers.blogspot.com/2017/05/windows-10-tensorflow.html&quot;&gt;텐서 플로우 및 케라스 최신버전 설치 방법 (Windows 10)과 개념&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://daddynkidsmakers.blogspot.com/2018/07/1804.html&quot;&gt;우분투 18.04 아나콘다 기반 텐서플로우 케라스 설치 &lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;케라스 기반 VGG 딥러닝 모델 구현&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;케라스는 &lt;span class=&quot;st&quot;&gt;MXNet, Deeplearning4j, Tensorflow, Theano, 와 같은 &lt;/span&gt;다양한 딥러닝 프레임웍을 기능적으로 캡슐화한 딥러닝 프레임웍이다. 모델링이 직관적이고 간편해 많이 사용된다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;케라스에는 VGG, ResNet, Inception V3, MobileNet 등 다양한 딥러닝 모델이 이미 구현되어 있어, 가져다 사용하기만 하면 된다.&amp;nbsp; &lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;이 글에서는 VGG 딥러닝 모델을 케라스로 간단히 구현해 본다. 우선, 케라스, numpy, matplotlib 등은 설치되어 있다고 가정한다. VGG 모델은 이미 이미지넷이 훈련된 모델을 다운받아 사용한다. VGG로 이미지를 인식하는 코드는 다음과 같다. &lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;from keras.models import Sequential&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;import keras&lt;br /&gt;import numpy as np&lt;br /&gt;from keras.applications import vgg16, inception_v3, resnet50, mobilenet&lt;br /&gt;&lt;br /&gt;#VGG 모델을 로딩함&lt;br /&gt;vgg_model = vgg16.VGG16(weights=&#39;imagenet&#39;)&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;from keras.preprocessing.image import load_img&lt;br /&gt;from keras.preprocessing.image import img_to_array&lt;br /&gt;from keras.applications.imagenet_utils import decode_predictions&lt;br /&gt;import matplotlib.pyplot as plt&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;&lt;br /&gt;filename = &#39;/home/ktw/tensorflow/door1.jpg&#39;&lt;br /&gt;# 이미지 로딩. PIL format&lt;br /&gt;original = load_img(filename, target_size=(224, 224))&lt;br /&gt;print(&#39;PIL image size&#39;,original.size)&lt;br /&gt;plt.imshow(original)&lt;br /&gt;plt.show()&lt;br /&gt;&lt;br /&gt;# PIL 이미지를 numpy 배열로 변환&lt;br /&gt;# Numpy 배열 (height, width, channel)&lt;br /&gt;numpy_image = img_to_array(original)&lt;br /&gt;plt.imshow(np.uint8(numpy_image))&lt;br /&gt;plt.show()&lt;br /&gt;print(&#39;numpy array size&#39;,numpy_image.shape)&lt;br /&gt;&lt;br /&gt;# 이미지를 배치 포맷으로 변환&lt;br /&gt;# 데이터 학습을 위해 특정 축에 차원 추가&lt;br /&gt;# 네트워크 형태는 batchsize, height, width, channels 이 됨&lt;br /&gt;image_batch = np.expand_dims(numpy_image, axis=0)&lt;br /&gt;print(&#39;image batch size&#39;, image_batch.shape)&lt;br /&gt;plt.imshow(np.uint8(image_batch[0]))&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;# 모델 준비&lt;br /&gt;processed_image = vgg16.preprocess_input(image_batch.copy())&lt;br /&gt;&lt;br /&gt;# 각 클래스 속할 확률 예측&lt;br /&gt;predictions = vgg_model.predict(processed_image)&lt;br /&gt;&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;color: #274e13;&quot;&gt;# 예측된 확률을 클래스 라벨로 변환. 상위 5개 예측된 클래스 표시&lt;br /&gt;label = decode_predictions(predictions)&lt;br /&gt;print(label)&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;구글에서 검색해 얻은 문, 창문과 같은 건축 실내 요소 이미지들을 저장해 놓고, 입력해 얻은 결과는 다음과 같다. sliding door로 인식된 결과를 확인할 수 있다. &lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-zxNB7FsFCU4/W6IVhGC4n-I/AAAAAAAAMG4/G-ZLY8qf_jAExfcZbKCyrHzcAwqM_srSgCLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-19%2B18-23-07.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;599&quot; data-original-width=&quot;279&quot; height=&quot;640&quot; src=&quot;https://2.bp.blogspot.com/-zxNB7FsFCU4/W6IVhGC4n-I/AAAAAAAAMG4/G-ZLY8qf_jAExfcZbKCyrHzcAwqM_srSgCLcBGAs/s640/Screenshot%2Bfrom%2B2018-09-19%2B18-23-07.png&quot; width=&quot;297&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-qcxGb5-WqmQ/W6IVWsdlGnI/AAAAAAAAMG0/lqttykTQ_cMkexPAlydyqR4j29bv_xoxACLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-19%2B18-22-19.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;56&quot; data-original-width=&quot;613&quot; height=&quot;56&quot; src=&quot;https://4.bp.blogspot.com/-qcxGb5-WqmQ/W6IVWsdlGnI/AAAAAAAAMG0/lqttykTQ_cMkexPAlydyqR4j29bv_xoxACLcBGAs/s640/Screenshot%2Bfrom%2B2018-09-19%2B18-22-19.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;다른 테스트를 위해, 3D 모델링에서 캡쳐한 이미지의 인식 정확도를 확인해 보았다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-zKRcWlHPS-Q/W6L-NEsyr7I/AAAAAAAAMHU/za2iLc1kI6wov68BPjkY9x30AzZfRFoDwCLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-20%2B09-42-38.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;331&quot; data-original-width=&quot;615&quot; height=&quot;215&quot; src=&quot;https://3.bp.blogspot.com/-zKRcWlHPS-Q/W6L-NEsyr7I/AAAAAAAAMHU/za2iLc1kI6wov68BPjkY9x30AzZfRFoDwCLcBGAs/s400/Screenshot%2Bfrom%2B2018-09-20%2B09-42-38.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-nQihJ_NVfEs/W6L-uFEtxQI/AAAAAAAAMHc/aiwHYrJWkbQSVje4fkrBEGGhw1VfZRkSgCLcBGAs/s1600/Screenshot%2Bfrom%2B2018-09-20%2B10-58-05.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;314&quot; data-original-width=&quot;608&quot; height=&quot;206&quot; src=&quot;https://1.bp.blogspot.com/-nQihJ_NVfEs/W6L-uFEtxQI/AAAAAAAAMHc/aiwHYrJWkbQSVje4fkrBEGGhw1VfZRkSgCLcBGAs/s400/Screenshot%2Bfrom%2B2018-09-20%2B10-58-05.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;VGG딥러닝 모델에서 유사한 클래스가 인식된 것을 확인할 수 있다. 다만, 이미지넷에 올라온 객체가 본인이 제시한 이미지와는 상이한 부분이 있어 정확도가 높지는 않다. BIM과 같은 3D모델에서 캡쳐한 이미지가 유사하게 인식되나, 마찬가지로 정확도가 그리 높지는 않다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;테스트해본 결과를 보면, 정확도를 높이기 위해서는 목적에 맞는 훈련용 데이터 확보와 처리가 필수적이라는 것을 알 수 있다. 딥러닝 모델은 훈련된 데이터셋에 대한 부분만 정확도 높게 예측할 뿐이다.&amp;nbsp; &lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스 &lt;/span&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.pyimagesearch.com/2016/08/10/imagenet-classification-with-python-and-keras/&quot;&gt;ImageNet classification with Python and Keras&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/&quot;&gt;Keras Tutorial : Using pre-trained Imagenet models&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://keras.io/applications/&quot;&gt;Models for image classification with weights trained on ImageNet&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/1441663965934972574/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1441663965934972574'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/1441663965934972574'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/09/blog-post.html' title='케라스 기반 이미지 인식 딥러닝 모델 구현'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-VHADNEgspW0/W6ID2k1bd9I/AAAAAAAAMFc/4lsd1f9oNlQE5O0tCkPTQUuzDWl7RChGwCLcBGAs/s72-c/nnarch1-1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6025840594628190650</id><published>2018-07-13T06:41:00.003-07:00</published><updated>2018-07-22T00:55:06.717-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="IoT"/><category scheme="http://www.blogger.com/atom/ns#" term="머신러닝"/><title type='text'>우분투 18.04 아나콘다 기반 텐서플로우 케라스 설치</title><content type='html'>아래 글은 우분투 18.04 기반 텐서플로우 케라스 설치 방법을 간략히 요약한 것이다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;a href=&quot;https://www.pugetsystems.com/labs/hpc/Install-TensorFlow-with-GPU-Support-the-Easy-Way-on-Ubuntu-18-04-without-installing-CUDA-1170/&quot; rel=&quot;nofollow&quot;&gt;Install TensorFlow with GPU Support the Easy Way on Ubuntu 18.04 (without installing CUDA)&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;아나콘다를 사용하기 때문에 설치는 매우 쉽다. 아래는 설치 후 테스트한 노트북 화면이다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-6pgEtW-TBnA/W0isAxyXZvI/AAAAAAAAL8k/m8LiW0nBh48o2dPb_XOt5SUjkEEYNArHQCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-07-13%2B22-39-42.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; height=&quot;360&quot; src=&quot;https://4.bp.blogspot.com/-6pgEtW-TBnA/W0isAxyXZvI/AAAAAAAAL8k/m8LiW0nBh48o2dPb_XOt5SUjkEEYNArHQCLcBGAs/s640/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-07-13%2B22-39-42.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6025840594628190650/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/07/1804.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6025840594628190650'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6025840594628190650'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/07/1804.html' title='우분투 18.04 아나콘다 기반 텐서플로우 케라스 설치'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-6pgEtW-TBnA/W0isAxyXZvI/AAAAAAAAL8k/m8LiW0nBh48o2dPb_XOt5SUjkEEYNArHQCLcBGAs/s72-c/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-07-13%2B22-39-42.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-3487795870154454310</id><published>2018-07-09T22:05:00.001-07:00</published><updated>2018-07-09T22:07:03.260-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="IoT"/><title type='text'>손쉬운 해킹 도구</title><content type='html'>이 글은 간단한 해킹 도구에 대한 내용을 요약한다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/im2_atPAYgo/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/im2_atPAYgo?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;Hacker Warehouse&lt;/div&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;네트워크 패킷 감시 - &lt;a href=&quot;https://www.wireshark.org/download.html&quot;&gt;Wireshark&lt;/a&gt;, PCap&lt;/li&gt;&lt;li&gt;네트워크 포트 해킹 - &lt;a href=&quot;https://nmap.org/&quot;&gt;Nmap&lt;/a&gt;&lt;/li&gt;&lt;li&gt;무선 네트워크 해킹 - &lt;a href=&quot;https://hackerwarehouse.com/product/alfa-802-11bgn-long-range-usb-wireless-adapter/&quot;&gt;Alfa 어답터&lt;/a&gt;&lt;/li&gt;&lt;li&gt;무선 네트워크 해킹 - &lt;a href=&quot;https://hackaday.com/tag/tp-link/&quot;&gt;TP-LINK&lt;/a&gt;&lt;/li&gt;&lt;li&gt;카드 복제 해킹 - &lt;a href=&quot;https://samy.pl/magspoof/&quot;&gt;MagSpoof&lt;/a&gt;&lt;/li&gt;&lt;li&gt;RFID 태그 복제 - &lt;a href=&quot;https://hackerwarehouse.com/product/proxmark3-kit/&quot;&gt;Proxmark3 Kit&lt;/a&gt;&lt;/li&gt;&lt;li&gt;차량 해킹 - &lt;a href=&quot;https://www.wired.com/2015/07/gadget-hacks-gm-cars-locate-unlock-start/&quot;&gt;GM 온스타 앱 해킹&lt;/a&gt;&lt;/li&gt;&lt;li&gt;차량 해킹 - &lt;a href=&quot;https://hackaday.com/2017/02/23/universal-radio-hacker/&quot;&gt;라디오 USB&lt;/a&gt;&lt;/li&gt;&lt;li&gt;노트북 해킹 - &lt;a href=&quot;https://thehackernews.com/2015/06/how-to-hack-computers.html&quot;&gt;PITA&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://hackadaycom.files.wordpress.com/2017/02/urh-featured.jpg?w=800&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;250&quot; data-original-width=&quot;800&quot; height=&quot;125&quot; src=&quot;https://hackadaycom.files.wordpress.com/2017/02/urh-featured.jpg?w=800&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;Universal Radio Hacker (hackaday.com)&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;레퍼런스&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;Jenny List, 2017.2, Universal Radio Hacker, hackaday.com&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://smartincome.tistory.com/306&quot;&gt;인터넷 합법 해킹도구&lt;/a&gt;&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/3487795870154454310/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/07/blog-post.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/3487795870154454310'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/3487795870154454310'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/07/blog-post.html' title='손쉬운 해킹 도구'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/im2_atPAYgo/default.jpg" height="72" width="72"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-2178918561392348144</id><published>2018-06-20T08:51:00.001-07:00</published><updated>2018-06-30T20:02:04.353-07:00</updated><title type='text'>드론 기반 벨로다인 라이다 스캔 </title><content type='html'>&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;SLAM기술은 LiDAR기술이 저렴해 지면서 점점 더 다양한 분야에 확산되고 있다. 이미 드론이나 무인자율주행차량에 장착된 지 오래이며, 일부는 농업, 광업과 같은 특수한 분야에까지 응용되고 있다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/rzTScFbkdG0/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/rzTScFbkdG0?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://vision.eng.au.dk/future-cropping/uav_lidar/&quot;&gt;UAV LIDAR mapping for crop fields&lt;/a&gt;&amp;nbsp;(&lt;a href=&quot;http://wiki.ros.org/ethzasl_icp_mapping&quot;&gt;SLAM&lt;/a&gt;)&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/2178918561392348144/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/blog-post_20.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/2178918561392348144'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/2178918561392348144'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/blog-post_20.html' title='드론 기반 벨로다인 라이다 스캔 '/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/rzTScFbkdG0/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-4373744562986707626</id><published>2018-06-19T03:48:00.001-07:00</published><updated>2018-07-24T00:32:30.299-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="그래픽스"/><category scheme="http://www.blogger.com/atom/ns#" term="비전"/><title type='text'>밸로다인 LiDAR 센서와 VeloView 사용기</title><content type='html'>이 글은 밸로다인(Velodyne) LiDAR 센서와 VeloView 사용기를 간략히 공유한다.&lt;br /&gt;&lt;br /&gt;진행 중인 연구과제 핵심 기술을 좀 더 깊게 이해하기 위해, 벨로다인 센서를 구입해 분석중이다. 2014년부터 진행한 비전 역설계 과제의 활용 센서는 Kinect, Intel RGBD sensor, RPLiDAR 였다. 이때 목적은 저렴한 스캔 기술이 가능한지 파악하는 것이었다. 그때 문제는 정확도와 밀도였는 데, Trimble TX5 LiDAR에 비해 현격하게 차이나는 정확도와 밀도는 플랜트와 같은 정밀 엔지니어링에 활용하기 어려운 수준이었다(플랜트 대상).&lt;br /&gt;&lt;br /&gt;밸로다인센서 VLP-16은 IMU 데이터를 입력받을 수 있는 데이터 통합 보드를 함께 제공한다. &lt;a href=&quot;http://velodynelidar.com/vlp-16.html&quot;&gt;센서 스펙&lt;/a&gt;은 다음과 같다. 참고로, TX5 같은 전문적인 LiDAR 센서는 최소 수백만 포인트 이상 획득되는 데 실시간은 아니며, 가격이 고가이다. 참고로, 저가 모델인 VLP-16은 7~8백만원대로 구입할 수 있다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Dual Returns&lt;/li&gt;&lt;li&gt;830 grams&lt;/li&gt;&lt;li&gt;16 Channels&lt;/li&gt;&lt;li&gt;100m Range&lt;/li&gt;&lt;li&gt;Up to 600,000 Points per Second&lt;/li&gt;&lt;li&gt;360° Horizontal FOV&lt;/li&gt;&lt;li&gt;±15° Vertical FOV&lt;/li&gt;&lt;li&gt;Low Power Consumption&lt;/li&gt;&lt;li&gt;Protective Design&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;벨로다인에서 얻은 (X, Y, Z, I) 데이터로 구성된 포인트 클라우드 데이터에는 가속도 값이 포함되어 있지 않다. 센서가 기울어지면, 데이터도 함께 기울어지므로, 이를 보정할려면, IMU에서 제공하는 Xa, Ya, Za 가속도 값이 필수적이다. 통합 보드에 IMU를 장착하고, 데이터를 취득하면, (X, Y, Z, I, Xa, Ya, Za) 값이 함께 TCP/IP 케이블을 통해 컴퓨터에 전달되는 구조이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-HFglUF8ircA/WyjfSsq1spI/AAAAAAAAL3U/oRr80wmXPZcEmxb15XrOirw8YDu-o42DwCLcBGAs/s1600/a3.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://3.bp.blogspot.com/-HFglUF8ircA/WyjfSsq1spI/AAAAAAAAL3U/oRr80wmXPZcEmxb15XrOirw8YDu-o42DwCLcBGAs/s320/a3.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;센서, 데이터 통합 보드 및 통신 케이블&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-AsfTX6dbVpY/WyjfSbVUiUI/AAAAAAAAL3M/vjQY7JARABko7WVx2NEXwAli8D7JuexawCLcBGAs/s1600/a5.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://4.bp.blogspot.com/-AsfTX6dbVpY/WyjfSbVUiUI/AAAAAAAAL3M/vjQY7JARABko7WVx2NEXwAli8D7JuexawCLcBGAs/s320/a5.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;벨로다인 라이다 센서&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-aANk6AYsQ3A/WyjfSjTlG8I/AAAAAAAAL3Q/ceBvDWlwavQo3xyrt8rUJP4BN4r_1-wuACLcBGAs/s1600/a.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;320&quot; src=&quot;https://3.bp.blogspot.com/-aANk6AYsQ3A/WyjfSjTlG8I/AAAAAAAAL3Q/ceBvDWlwavQo3xyrt8rUJP4BN4r_1-wuACLcBGAs/s320/a.jpg&quot; width=&quot;240&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;데이터 통합 보드&lt;/div&gt;&lt;br /&gt;이론상 VLP-16센서는 100미터까지 스캔을 할 수 있다. 본인은 사무실 공간에서 스캔을 해 보았는 데, 600 미터제곱 면적의 사무실 공간 벽체까지 스캔되는 것을 확인하였다. 참고로, 사무실은 둥근 직사각형 모양이며, 중간에서 벽체까지 거리는 25미터 정도이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-_bZGHamSa_k/WyjfTU-cdpI/AAAAAAAAL3Y/IAGuRxROuxQsGUvDwgwQkdVF_dwevtR3ACLcBGAs/s1600/b.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://4.bp.blogspot.com/-_bZGHamSa_k/WyjfTU-cdpI/AAAAAAAAL3Y/IAGuRxROuxQsGUvDwgwQkdVF_dwevtR3ACLcBGAs/s320/b.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;스캔된 포인트 클라우드 모습&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;밸로다인 센서를 구동하는 프로그램은 VeloView이다. 윈도우에서는 VeloView를 설치하면드라이버가 함께 설치된다. TCP/IP4 네트워크 등 설정 후, 프로그램을 실행하고 연결된 라이다 장치를 VLP-16으로 선택하면 바로 점군을 실시간으로 볼 수 있다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-N5GsZcJ8qo0/W0LFzkquv6I/AAAAAAAAL40/5C9b9Lq2Mn8R2BaoMFoTSbj4ci7rUmJdwCLcBGAs/s1600/untitled3.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://4.bp.blogspot.com/-N5GsZcJ8qo0/W0LFzkquv6I/AAAAAAAAL40/5C9b9Lq2Mn8R2BaoMFoTSbj4ci7rUmJdwCLcBGAs/s320/untitled3.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;TCP/IP4 설정&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;단, TCP/IP 이더넷 케이블 통신이므로, 방화벽이 있는 경우, 비활성화해야 한다. 우분투 리눅스에서는 아래 github 링크에서 다운로드 받은 VeloView 소스를 빌드해야 한다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://wiki.ros.org/velodyne/Tutorials/Getting%20Started%20with%20the%20Velodyne%20VLP16&quot;&gt;ROS, Velodyne Tutorial Wiki&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/apoorv98/sensor-docs/blob/master/docs/source/vlp-16.rst&quot;&gt;VLP16 github&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/virgileTN/VLP16-utilities/wiki/Velodyne-ROS&quot;&gt;VLP16 ROS wiki&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;VeloView는 포인트 클라우드를 시계열방식으로 캡쳐할 수 있는 기능있다. .pcap 점군 캡쳐파일을 저장한 후, 다시 재생할 수 있다. VeloView의 자세한 기능은 다음 영상을 참고한다.&lt;/div&gt;&lt;div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/H34u4dDbTIE/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/H34u4dDbTIE?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;ParaView는 획득된 점군을 분석하고, 처리하는 프로그램으로 구입시 함께 포함되어 있다. 오픈소스이므로, 다운로드받아 설치해도 된다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://www.paraview.org/wp-content/uploads/2015/02/freidburg-view-types-edl-elevation1.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;378&quot; data-original-width=&quot;637&quot; height=&quot;189&quot; src=&quot;https://www.paraview.org/wp-content/uploads/2015/02/freidburg-view-types-edl-elevation1.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://www.paraview.org/lidar/&quot;&gt;ParaView&lt;/a&gt;&amp;nbsp;활용 예&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;3차원 점군은 대용량이다. 임베디드 보드는 대용량 점군 처리가 가능한 것이어야 하며, 다음과 같은 것을 추천한다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;NVIDIA TX1, &lt;a href=&quot;https://www.nvidia.com/ko-kr/autonomous-machines/embedded-systems-dev-kits-modules/&quot;&gt;TX2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.hardkernel.com/main/products/prdt_info.php&quot;&gt;ODROID XU4&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.lattepanda.com/&quot;&gt;LATTEPANDA&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://www.nvidia.com/content/dam/en-zz/ko_kr/Solutions/intelligent-machines/nvidia-jetson/intelligent-machines-jetson-tx2-625-ud.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;380&quot; data-original-width=&quot;625&quot; height=&quot;193&quot; src=&quot;https://www.nvidia.com/content/dam/en-zz/ko_kr/Solutions/intelligent-machines/nvidia-jetson/intelligent-machines-jetson-tx2-625-ud.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;NVIDIA TX2&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-CSqDdZmjoME/W1bVy6myHaI/AAAAAAAAL-M/av_wzrzezX4uT16vjtyWWO8ewXJijo4OgCLcBGAs/s1600/TX2.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://2.bp.blogspot.com/-CSqDdZmjoME/W1bVy6myHaI/AAAAAAAAL-M/av_wzrzezX4uT16vjtyWWO8ewXJijo4OgCLcBGAs/s320/TX2.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;NVIDIA TX2 &lt;a href=&quot;http://connecttech.com/product/orbitty-carrier-for-nvidia-jetson-tx2-tx1/&quot;&gt;CARRIER BOARD&lt;/a&gt;(캐리어 보드. TX2 개발보드 크기가 너무 커 이동성이 떨어진다면 캐리어 보드를 사용하면 된다)&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: left;&quot;&gt;다음은 라떼판다(LATTE PANDA) 임베디드 컴퓨터에 VELOVIEW를 설치한 후 실행한 모습이다. 큰 문제 없이 포인트 클라우드가 실시간으로 획득되어 가시화되는 것을 확인할 수 있다.&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-D9y1iR4DDOc/W0LFwmHFjiI/AAAAAAAAL4o/DQ6ozklfR_wbfNmsjbBMHBZayqLaJx94wCLcBGAs/s1600/untitle4.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://3.bp.blogspot.com/-D9y1iR4DDOc/W0LFwmHFjiI/AAAAAAAAL4o/DQ6ozklfR_wbfNmsjbBMHBZayqLaJx94wCLcBGAs/s320/untitle4.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&amp;nbsp;&lt;a href=&quot;https://1.bp.blogspot.com/-lBFQirpKCMU/W0LFxEpY1wI/AAAAAAAAL4s/efLOyu5H1KIHM2RxzKWL6h2yz5izpqxggCLcBGAs/s1600/untitled.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;240&quot; src=&quot;https://1.bp.blogspot.com/-lBFQirpKCMU/W0LFxEpY1wI/AAAAAAAAL4s/efLOyu5H1KIHM2RxzKWL6h2yz5izpqxggCLcBGAs/s320/untitled.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-LUTm72MaIao/W0ao6YOVS3I/AAAAAAAAL78/Br3D96-uIm4bTYqN6kC-9kl8SPTPD99xwCLcBGAs/s1600/Capture2.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;565&quot; data-original-width=&quot;1024&quot; height=&quot;176&quot; src=&quot;https://2.bp.blogspot.com/-LUTm72MaIao/W0ao6YOVS3I/AAAAAAAAL78/Br3D96-uIm4bTYqN6kC-9kl8SPTPD99xwCLcBGAs/s320/Capture2.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-A5Om9WPLkRg/W0ao6f9We0I/AAAAAAAAL8A/T1BWrX7uoUUJ48_yY-fUOwaAmAGbzjpEACLcBGAs/s1600/Capture3.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;564&quot; data-original-width=&quot;500&quot; height=&quot;320&quot; src=&quot;https://2.bp.blogspot.com/-A5Om9WPLkRg/W0ao6f9We0I/AAAAAAAAL8A/T1BWrX7uoUUJ48_yY-fUOwaAmAGbzjpEACLcBGAs/s320/Capture3.PNG&quot; width=&quot;283&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;br /&gt;아래는 ODROID XU4에 VLP16를 마운트해 만든 드론 기반 LiDAR 스캔 프로젝트 사례이다.&amp;nbsp;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/rzTScFbkdG0/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/rzTScFbkdG0?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://vision.eng.au.dk/future-cropping/uav_lidar/&quot;&gt;UAV LIDAR mapping for crop fields&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이제, 엔지니어링 전용 라이다, 토탈 스테이션과 밸로다인 센서의 정확도, 밀도를 확인 비교해 볼 계획이다.&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/4373744562986707626/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/lidar-veloview.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/4373744562986707626'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/4373744562986707626'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/lidar-veloview.html' title='밸로다인 LiDAR 센서와 VeloView 사용기'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-HFglUF8ircA/WyjfSsq1spI/AAAAAAAAL3U/oRr80wmXPZcEmxb15XrOirw8YDu-o42DwCLcBGAs/s72-c/a3.jpg" height="72" width="72"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6315941478720468887</id><published>2018-06-13T06:57:00.004-07:00</published><updated>2018-06-13T06:58:48.872-07:00</updated><title type='text'>어린이를 위한 코딩 로봇 </title><content type='html'>이 글은 코딩을 배우기에 적당한 코딩 로봇을 간략히 소개합니다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/hJiEoOvvIlk/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/hJiEoOvvIlk?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;1.Fable : A Modular Robot for everyone&lt;br /&gt;&lt;a href=&quot;https://goo.gl/tXSH1N&quot;&gt;https://goo.gl/tXSH1N&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;2. Tenergy ODEV Tomo STEM Robot 2-in-1 Transformable and Programmable APP Controlled Robot&lt;br /&gt;&lt;a href=&quot;http://amzn.to/2GwP4EG&quot;&gt;http://amzn.to/2GwP4EG&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;3. Makeblock mBot Kit - STEM Education - Arduino - Scratch 2.0 - Programmable Robot Kit for Kids to Learn Coding, Robotics and Electronics (2.4G Version - School Prefer)&lt;br /&gt;&lt;a href=&quot;http://amzn.to/2DQWjt6&quot;&gt;http://amzn.to/2DQWjt6&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;4. WowWee COJI The Coding Robot Toy&lt;br /&gt;&lt;a href=&quot;http://amzn.to/2DKPJAh&quot;&gt;http://amzn.to/2DKPJAh&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;5. Evo App-Connected Coding Robot&lt;br /&gt;&lt;a href=&quot;http://amzn.to/2GvzVn0&quot;&gt;http://amzn.to/2GvzVn0&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6315941478720468887/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/blog-post.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6315941478720468887'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6315941478720468887'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/06/blog-post.html' title='어린이를 위한 코딩 로봇 '/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/hJiEoOvvIlk/default.jpg" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-5833033717611999446</id><published>2018-05-29T06:12:00.002-07:00</published><updated>2018-06-03T08:12:36.261-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="IoT"/><category scheme="http://www.blogger.com/atom/ns#" term="그래픽스"/><category scheme="http://www.blogger.com/atom/ns#" term="머신러닝"/><title type='text'>우분투 18.04와 NVIDIA 드라이버 설치 솔류션</title><content type='html'>어김없이 우분투 LTS가 버전업되었다.&lt;br /&gt;&lt;br /&gt;우리는 수많은 난관을 헤쳐나가야 하는 버전업을 선택할 것인가, 현재에 안주할 것인가를 선택해야 한다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-Pid3WCFZPh8/Ww1Sbte5XzI/AAAAAAAALvc/cWmnTllVQ8U5_a4CIclLA7O1MbxzNXRQwCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B22-15-13.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;292&quot; data-original-width=&quot;558&quot; height=&quot;167&quot; src=&quot;https://4.bp.blogspot.com/-Pid3WCFZPh8/Ww1Sbte5XzI/AAAAAAAALvc/cWmnTllVQ8U5_a4CIclLA7O1MbxzNXRQwCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B22-15-13.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;사서 고생 or 현실 안주&lt;/div&gt;&lt;br /&gt;구글링을 해 보니 18.04버전은 더 좋아졌다는 커멘트가 많다. 버전업 되었는 데 당연하겠지라고 무시하려 하다가 혹시 그 거지같은 NVIDIA, UNITY 이슈 해결되었을지 모른다는 기대로 부팅 USB를 만들어본다(결국 이 문제는 그대로 남아있었다.T.T~).  &lt;br /&gt;&lt;br /&gt;우분투(UBUNTU)와 NVIDIA 그래픽카드 궁합은 서로 좋지 않다. 컴퓨터에 NVIDIA가 설치되어 있고, 우부투 설치 시 화면이 안보이거나 저해상도라 설치하기 어렵다면 심중팔구 NVIDIA 드라이버 문제이다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-vGnYgl14ApM/Ww1MG0sl53I/AAAAAAAALu0/y2kychz59yU1dr1oUtIjblmaxmzbqz5ZgCLcBGAs/s1600/2cpvn9w.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;480&quot; data-original-width=&quot;640&quot; height=&quot;240&quot; src=&quot;https://4.bp.blogspot.com/-vGnYgl14ApM/Ww1MG0sl53I/AAAAAAAALu0/y2kychz59yU1dr1oUtIjblmaxmzbqz5ZgCLcBGAs/s320/2cpvn9w.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&amp;nbsp;저해상도 문제(옵션이 안보이니 설치가 불가능 T.T~)&lt;a href=&quot;https://www.servethehome.com/wp-content/uploads/2013/10/Cursor-Blinking-Screen.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;401&quot; data-original-width=&quot;721&quot; height=&quot;177&quot; src=&quot;https://www.servethehome.com/wp-content/uploads/2013/10/Cursor-Blinking-Screen.jpg&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;황당하기 그지 없는 &lt;a href=&quot;http://daddynkidsmakers.blogspot.dk/2018/03/black-screen.html&quot;&gt;블랙 스크린&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-Wjy3kAdIWsQ/Ww1M2tliMPI/AAAAAAAALvA/yeoOM8RJiwwbpo26Tr7AavjRkRpWFcDxQCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-51-24.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;384&quot; data-original-width=&quot;679&quot; height=&quot;180&quot; src=&quot;https://4.bp.blogspot.com/-Wjy3kAdIWsQ/Ww1M2tliMPI/AAAAAAAALvA/yeoOM8RJiwwbpo26Tr7AavjRkRpWFcDxQCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-51-24.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;무한 로긴 &lt;/div&gt;&lt;br /&gt;이런 문제로 날밤 새고, 아까운 시간과 체력을 날린게 얼마인가. 우분투 10번 설치는 기본. 수명 줄어드는 것이 느껴진다.&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-msDh7J65hZg/Ww1NkASUNxI/AAAAAAAALvI/RUKrnYz5VDUKRyjs3stpSY1S4Sd5EZqwwCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-54-25.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;382&quot; data-original-width=&quot;307&quot; height=&quot;320&quot; src=&quot;https://1.bp.blogspot.com/-msDh7J65hZg/Ww1NkASUNxI/AAAAAAAALvI/RUKrnYz5VDUKRyjs3stpSY1S4Sd5EZqwwCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-54-25.png&quot; width=&quot;257&quot; /&gt;&lt;/a&gt;&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;시지프스 빙의(ㅅㅂ)&lt;/div&gt;&lt;br /&gt;물론, BIOS에서 NVIDIA를 비활성화하고 내장 그래픽으로 우분투를 사용할 수도 있다. 만약, 당신이 우분투로 유투브 영화나 뮤직 비디오 감상에만 사용한다면, 이 방법은 충분히 효과적이다. &lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-MPgPiipJuYM/Ww1OEE92HkI/AAAAAAAALvQ/hCz4N3NYZxsCcb8-HcussyZlUFHJUK6OQCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-56-21.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;485&quot; data-original-width=&quot;852&quot; height=&quot;182&quot; src=&quot;https://1.bp.blogspot.com/-MPgPiipJuYM/Ww1OEE92HkI/AAAAAAAALvQ/hCz4N3NYZxsCcb8-HcussyZlUFHJUK6OQCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-56-21.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;하지만, 지구 정복?을 꿈꾸는 개발자나 연구자라면 NVIDIA GPU를 사용해 딥러닝(DEEP LEARNING) 모델을 만들고 싶거나, 비전, 그래픽, &lt;a href=&quot;http://wiki.ros.org/kinetic/Installation/Sourcemac&quot;&gt;ROS&lt;/a&gt; 등 관련된 다양한 오픈소스 패키지를 사용해 보고 싶을 테고, 내장 그래픽카드로 설치된 우분투는 아무 의미 없는 운영체제나 마찬가지일 것이다. 그렇다고, 아마존(AMAZON) 머신러닝 인스턴스를 사용하기에는 내것이 아닌것 같고, 용량이나 기간을 많이 사용할수록 결국 돈 내야 한다는 것이 맘에 들지 않는다.&lt;br /&gt;&lt;br /&gt;수많은 구글링과 시행착오 끝에 찾은 NVIDIA 우분투 그래픽 드라이버 베스트 솔류션 테크트리는 다음과 같다. &lt;br /&gt;&lt;ol&gt;&lt;li&gt;우분투 18.04 설치 USB 디스크 준비&amp;nbsp; &lt;/li&gt;&lt;li&gt;컴퓨터 부팅 시 F2를 눌어 BIOS 로 진입&lt;/li&gt;&lt;li&gt;그래픽 가속이나 NVIDIA 관련 메뉴를 찾아 가속기능을 비활성화함&lt;/li&gt;&lt;li&gt;재부팅&lt;/li&gt;&lt;li&gt;우분투 18.04 설치: 2번 단계로 인해 내장 그래픽이 동작하고, 설정 화면이 다 보일 만큼 충분한 해상도로 설정 가능할 것임&lt;/li&gt;&lt;li&gt;재부팅 후 우분투 로긴&lt;/li&gt;&lt;li&gt;우분투에서 터미널 실행 후 아래 명령 입력&lt;/li&gt;&lt;ol&gt;&lt;li&gt;sudo apt-get purge nvidia-*&amp;nbsp;&lt;/li&gt;&lt;li&gt;리부팅&lt;/li&gt;&lt;li&gt;sudo apt-get install nvidia-352&lt;/li&gt;&lt;li&gt;리부팅&lt;/li&gt;&lt;/ol&gt;&lt;li&gt;부팅 시 F2 눌러 BIOS 진입&lt;/li&gt;&lt;li&gt;그래픽 가속이나 NVIDIA 관련 메뉴를 찾아 가속기능을 활성화함&lt;/li&gt;&lt;li&gt;터미널에서 sudo nvidia-setting 실행해 잘 동작하는 NVIDIA 상태 확인&lt;/li&gt;&lt;/ol&gt;이 후 우리는 NVIDIA 가속된 아름다운 우분투 화면을 볼 수 있다.^^&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-3C9OUulBvxA/Ww1Lug6kjfI/AAAAAAAALus/vrGfMlPqvOEJ3NfLldZQluHa4iIiXn6rQCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-46-17.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; height=&quot;360&quot; src=&quot;https://4.bp.blogspot.com/-3C9OUulBvxA/Ww1Lug6kjfI/AAAAAAAALus/vrGfMlPqvOEJ3NfLldZQluHa4iIiXn6rQCLcBGAs/s640/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B21-46-17.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;이제 수많은 오픈소스 패키지를 apt-get install 할 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-BGSzB5bduGk/WxQFN2czPoI/AAAAAAAAL1w/DWtQ4iMjil08sWfPxJ1qvE0qeScp2IuNQCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-06-02%2B16-00-13.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; height=&quot;180&quot; src=&quot;https://1.bp.blogspot.com/-BGSzB5bduGk/WxQFN2czPoI/AAAAAAAAL1w/DWtQ4iMjil08sWfPxJ1qvE0qeScp2IuNQCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-06-02%2B16-00-13.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-3AMfnSoeJQQ/Ww1iMVh2gbI/AAAAAAAALv8/fYUDRIs_omM3zqdOeTGnSi2t1MzMYS-KgCLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B23-22-25.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;407&quot; data-original-width=&quot;791&quot; height=&quot;164&quot; src=&quot;https://4.bp.blogspot.com/-3AMfnSoeJQQ/Ww1iMVh2gbI/AAAAAAAALv8/fYUDRIs_omM3zqdOeTGnSi2t1MzMYS-KgCLcBGAs/s320/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B23-22-25.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;OpenCV, PCL, ROS Kinectic full desktop version 도 잘된다^^&lt;/div&gt;&lt;br /&gt;유명한 &lt;a href=&quot;https://benchmark.unigine.com/heaven&quot;&gt;Unigine Heaven&lt;/a&gt; 를 설치해 GPU 성능 테스트를 해 본다. GPU full option에서 30 fps 이상 찍는다. &lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-tAb3UfzwXIY/Ww1xPacjOuI/AAAAAAAALwc/kP-ERCeeGhAAWQVn-49BXHRjeFVzF5kYACLcBGAs/s1600/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-30%2B00-24-25.png&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;900&quot; data-original-width=&quot;1600&quot; height=&quot;225&quot; src=&quot;https://1.bp.blogspot.com/-tAb3UfzwXIY/Ww1xPacjOuI/AAAAAAAALwc/kP-ERCeeGhAAWQVn-49BXHRjeFVzF5kYACLcBGAs/s400/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-30%2B00-24-25.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;ㅎ 이 감동의 순간을 즐기자. &lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;br /&gt;블랙 스크린은 &lt;a href=&quot;http://daddynkidsmakers.blogspot.com/2018/03/black-screen.html&quot;&gt;이 링크&lt;/a&gt;를 참고한다.&lt;br /&gt;한글 등 설정은 &lt;a href=&quot;https://minwook-shin.github.io/after-Installing-18.04/&quot;&gt;이 링크&lt;/a&gt;를 참고한다. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/5833033717611999446/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/05/1804-nvidia.html#comment-form' title='4개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5833033717611999446'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/5833033717611999446'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/05/1804-nvidia.html' title='우분투 18.04와 NVIDIA 드라이버 설치 솔류션'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-Pid3WCFZPh8/Ww1Sbte5XzI/AAAAAAAALvc/cWmnTllVQ8U5_a4CIclLA7O1MbxzNXRQwCLcBGAs/s72-c/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7%252C%2B2018-05-29%2B22-15-13.png" height="72" width="72"/><thr:total>4</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-2307919660953923491</id><published>2018-05-07T21:27:00.001-07:00</published><updated>2018-05-14T18:33:14.730-07:00</updated><title type='text'> 지능적 비전 지원을 위한 Azure 기반 프로젝트 키넥트 </title><content type='html'>키넥트 사용했던 분들 꽤 많았을 겁니다. 이렇게 좋은 센서를 생산 중단한 마이크로소프트가 이해되지 않았던 적이 있었죠. 역시 마소는 우리의 기대를 저버리지 않고 훨씬 좋아진 키넥트 센서를 꾸준히 개발하고 있었습니다.&lt;br /&gt;&lt;br /&gt;이 글은 &lt;a href=&quot;https://developer.microsoft.com/en-us/perception&quot;&gt;마이크로소프트&lt;/a&gt;의 지능적 비전 지원을 위한&amp;nbsp;Azure 기반&amp;nbsp;&lt;a href=&quot;https://www.linkedin.com/pulse/introducing-project-kinect-azure-alex-kipman/&quot;&gt;프로젝트 키넥트&lt;/a&gt;&amp;nbsp;기술 소개입니다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-YSpis_FZfRY/Wvo2ojSUspI/AAAAAAAALs4/wi7AgvZWvOYdTy1a2wmeaW2_JwnmQY_pwCLcBGAs/s1600/i2.JPG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;583&quot; data-original-width=&quot;1600&quot; height=&quot;145&quot; src=&quot;https://2.bp.blogspot.com/-YSpis_FZfRY/Wvo2ojSUspI/AAAAAAAALs4/wi7AgvZWvOYdTy1a2wmeaW2_JwnmQY_pwCLcBGAs/s400/i2.JPG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;Satya Nadella의 Build 기조 연설에서 Azure 에서 Project Kinect 지원을 소개했습니다. 단순히 키넥트만 지원하는 것이 아니라, Azure와 연계되는 딥러닝 등 다양한 도구와 연결되어, 재미있고 유용한 유스케이스 구현이 가능함을 언급하였습니다.&lt;br /&gt;&lt;br /&gt;주변 공간과 사물을 인식할 수 있는 능력을 Kinect와 Azure 연계된 머신러닝 등 도구가 지웜함으로써 지능적인 지각을 가능하게 해 줍니다. Azure AI 서비스와 적은 전력 소모와 높은 정확도로 동작하는 Kinect 의 ToF 깊이 센서 기술은 심도 이미지를 이용한 다양한 비전이 가능해 집니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; class=&quot;YOUTUBE-iframe-video&quot; data-thumbnail-src=&quot;https://i.ytimg.com/vi/B_BXmoTy61o/0.jpg&quot; frameborder=&quot;0&quot; height=&quot;266&quot; src=&quot;https://www.youtube.com/embed/B_BXmoTy61o?feature=player_embedded&quot; width=&quot;320&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;건축가인 Cyrus Bamji는 이 센서를 이용해&amp;nbsp;ISSCC (International Solid-State Circuits Conference) 컨퍼런스에 활용 사례를 발표하였고 호평을 받았습니다. 이 새로운 키넥트 센서는 HoloLens의 차기 버전을 제공할 센서이기도 합니다. 센서 스펙은 다음과 같습니다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;1024x1024 픽셀&lt;/li&gt;&lt;li&gt;225-950mw 저전력소모&lt;/li&gt;&lt;li&gt;원거리 캡쳐 가능한 넓은 동작범위&lt;/li&gt;&lt;li&gt;햇빛에 덜 민감한 글로벌 셔터 다중 위상 깊이 계산 기술&lt;/li&gt;&lt;li&gt;고주파수 낮은 피크 전류 작동&lt;/li&gt;&lt;/ul&gt;XBox360 Kinect를 처음 만들었을 때 많은 사람들이 관심을 가졌고, 크리에이티브 개발자들은 게임을 넘어 다양한 분야에 이를 사용했었습니다. &lt;a href=&quot;https://microsoft.hackster.io/en-US/products/kinect-sensor&quot;&gt;창의적인 작품&lt;/a&gt;이 만들어졌습니다. 작년 2세대 키넥트 생산은 중단했지만, 인텔 RealSense 개발에 마이크로소프트는 계속 협력했었습니다.&lt;br /&gt;&lt;br /&gt;HoloLens 3세대는 Kinect 깊이 감지 기술을 이용해 더욱 놀라운 결과를 보여줄 계획입니다. 여기에서는 사람과 공간 환경을 이해하고, 시선, 몸짓, 음성으로 입력을 받으며, 3D 홀로그램과 몰입형 공간 사운드를 지원할 것입니다. 4세대는 진보된 키넥트 센서를 사용해 지능형 클라우드 및 인텔리전트에 연결된 서비스를 지원합니다 .&lt;br /&gt;&lt;br /&gt;Azure는 이미 머신 러닝, 인지 기술, IoT Edge를 지원하고 있습니다. Azure AI 서비스와 통합되어 점점 더 많은 센서를 기반으로 하는 생태계가 풍성해 질 것입니다. 자세한 내용는 다음 링크를 확인하시길 바랍니다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://developer.microsoft.com/perference&quot;&gt;마이크로소프트 개발자 사이트&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.microsoft.com/en-us/events/build/content/project-kinect-on-azure&quot;&gt;Project Kinect on Azure&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://developer.microsoft.com/en-us/perception&quot;&gt;Perception-powered intelligent edge dev kits&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;점점 더 흥미롭고 재미있는 혼합현실 세상이 펼쳐지는 것 같습니다.^^</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/2307919660953923491/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/05/azure.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/2307919660953923491'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/2307919660953923491'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/05/azure.html' title=' 지능적 비전 지원을 위한 Azure 기반 프로젝트 키넥트 '/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-YSpis_FZfRY/Wvo2ojSUspI/AAAAAAAALs4/wi7AgvZWvOYdTy1a2wmeaW2_JwnmQY_pwCLcBGAs/s72-c/i2.JPG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-6035821751868037435</id><published>2018-03-02T16:45:00.002-08:00</published><updated>2018-04-05T19:19:37.128-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="리눅스"/><title type='text'>우분투 운영체계 폴더 구조 및 핵심 명령어</title><content type='html'>이 글은 우분투 운영체계 폴더 구조 및 명령어를 정리한다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;span style=&quot;font-size: large;&quot;&gt;폴더 구조&amp;nbsp; &lt;/span&gt;&lt;br /&gt;우분투 폴더 구조는 다음과 같다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-HGcYVIiZAxQ/Wpn7FBf20aI/AAAAAAAALXE/pGkAu_8KMDMXeq-RbRM7YWRW3_CkQWYMwCLcBGAs/s1600/hN4lt.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;474&quot; data-original-width=&quot;584&quot; height=&quot;323&quot; src=&quot;https://3.bp.blogspot.com/-HGcYVIiZAxQ/Wpn7FBf20aI/AAAAAAAALXE/pGkAu_8KMDMXeq-RbRM7YWRW3_CkQWYMwCLcBGAs/s400/hN4lt.jpg&quot; width=&quot;400&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;우분투 파일 구조(Ask Ubuntu)&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;우분투는 리눅스 일종으로 리눅스 폴더 파일 시스템표준 FSSTND(Linux File System Standard)을 따른다.&lt;br /&gt;&lt;br /&gt;/&lt;br /&gt;루트. 최상위 폴더&lt;br /&gt;&lt;br /&gt;/bin&lt;br /&gt;기본적인 명령어가 저장된 폴더. &lt;br /&gt;&lt;br /&gt;/boot&lt;br /&gt;리눅스 부트로더(Boot Loader)가 존재하는 폴더. 즉, GRUB 과 같은 부트로더에 관한 파일들(grub.conf 등)이 존재&lt;br /&gt;&lt;br /&gt;/dev&lt;br /&gt;시스템 디바이스(device)파일을 저장하고 있는 폴더. &lt;br /&gt;&lt;br /&gt;/etc&lt;br /&gt;시스템의 설정파일이 존재하는 폴더. &lt;br /&gt;/etc/sysconfig 시스템 제어판용 설정파일&lt;br /&gt;/etc/passwd 사용자관리 설정파일 &lt;br /&gt;/etc/named.conf DNS 설정파일&lt;br /&gt;&lt;br /&gt;/etc/mai/&lt;br /&gt;sendmail.cf 나 access 파일등의 sendmail 의 설정파일들이 존재하는 폴더.&lt;br /&gt;&lt;br /&gt;/etc/ssh/&lt;br /&gt;SSH 서비스, 즉 sshd 데몬에서 사용하는 각종 설정파일들이 존재하는 폴더.&lt;br /&gt;&lt;br /&gt;/etc/skel/&lt;br /&gt;계정사용자 생성시의 초기화파일들이 저장된 폴더(useradd 에서 사용함)&lt;br /&gt;&lt;br /&gt;/etc/rc.d/&lt;br /&gt;부팅레벨별 부팅스크립트파일들이 존재하는 폴더.&lt;br /&gt;&lt;br /&gt;/etc/rc.d/init.d/&lt;br /&gt;시스템 초기화 파일들의 실제파일들이 존재함. /etc/pam.d/&lt;br /&gt;&lt;br /&gt;/etc/xinetd.d/&lt;br /&gt;xinetd 수퍼데몬에 의해 서비스되는 서비스설정파일이 존재함.&lt;br /&gt;&lt;br /&gt;/home&lt;br /&gt;사용자의 홈폴더&lt;br /&gt;&lt;br /&gt;/lib&lt;br /&gt;커널모듈파일과 라이브러리파일&lt;br /&gt;&lt;br /&gt;/media&lt;br /&gt;DVD, CD-ROM, USB 등과 같은 탈부착이 가능한 장치들의 마운트포인트로 사용되는 폴더.&lt;br /&gt;&lt;br /&gt;/mnt&lt;br /&gt;/media 폴더와 비슷한 용도로 탈부착이 가능한 장치들에 대하여 일시적인 마운트포인트로 사용하는 폴더.&lt;br /&gt;&lt;br /&gt;/proc&lt;br /&gt;가상파일시스템. 현재 메모리에 존재하는 모든 작업들이 파일형태로 존재하는 곳&lt;br /&gt;&lt;br /&gt;/root&lt;br /&gt;시스템 최고관리자인 root 사용자의 개인 홈폴더.&lt;br /&gt;&lt;br /&gt;/sbin&lt;br /&gt;ifconfig, e2fsck, ethtool, halt 등과 같이 주로 시스템 관리자들이 사용하는 시스템관리자용 명령어를 저장하고 있는 폴더.&lt;br /&gt;&lt;br /&gt;/tmp&lt;br /&gt;공용폴더&lt;br /&gt;&lt;br /&gt;/usr&lt;br /&gt;시스템이 아닌 일반사용자들이 주로 사용하는 폴더&lt;br /&gt;&lt;br /&gt;/usr/bin/&lt;br /&gt;일반 사용자들이 사용가능한 명령어 파일들이 존재하는 폴더.&lt;br /&gt;&lt;br /&gt;/usr/X11R6/&lt;br /&gt;X 윈도우 시스템의 루트 폴더&lt;br /&gt;&lt;br /&gt;/usr/local/&lt;br /&gt;MySQL, Apache, PHP 등과 같은 어플리케이션들을 소스로 컨파일설치할 때 사용되는 장소&lt;br /&gt;&lt;br /&gt;/var&lt;br /&gt;시스템운용중에 생성되었다가 삭제되는 데이터를 일시적으로 저장하기 위한 폴더&lt;br /&gt;&lt;br /&gt;/lost+found&lt;br /&gt;연결이 끊어진 inode 들이 숫자파일형태로 존재하는 곳&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: large;&quot;&gt;명령어&amp;nbsp; &lt;/span&gt;&lt;br /&gt;주로 잘 사용하지 않는 명령어지만, 문제가 있었을 때 사용해야하는 명령어를 정리해 본다. &lt;br /&gt;&lt;ul&gt;&lt;li&gt;ps: 프로세스 리스트 &lt;/li&gt;&lt;li&gt;df -h: 디스크 마운트 정보 확인&lt;/li&gt;&lt;li&gt;alias: 명령어 간소화하기 &lt;/li&gt;&lt;li&gt;apropos: 관련된 명령어 찾기 &lt;/li&gt;&lt;li&gt;arch: 컴퓨터 종류 알기 &lt;/li&gt;&lt;li&gt;arp: 같은 서브넷의 IP 보여주기 &lt;/li&gt;&lt;li&gt;at: 작업 시간 정하기 &lt;/li&gt;&lt;li&gt;atd: 계획성 있는 작업 실행하기 &lt;/li&gt;&lt;li&gt;awk: 특정 패턴 문자 처리하기 &lt;/li&gt;&lt;li&gt;a2p: 펄 파일로 바꾸기 &lt;/li&gt;&lt;li&gt;badblocks: 배드 블럭 검사하기 &lt;/li&gt;&lt;li&gt;bc: 계산기 &lt;/li&gt;&lt;li&gt;biff: 메일 수신 소리로 확인하기 &lt;/li&gt;&lt;li&gt;bg: 후면작업; 배경화면 설정 &lt;/li&gt;&lt;li&gt;bind: 키나 함수 순서 결합하기 &lt;/li&gt;&lt;li&gt;break: 루프 빠져나가기 &lt;/li&gt;&lt;li&gt;cal: 달력보기 &lt;/li&gt;&lt;li&gt;builtin: 내부 명령어 알아보기 &lt;/li&gt;&lt;li&gt;case: 조건 처리하기 &lt;/li&gt;&lt;li&gt;cat: 화면상에서 파일 보기 &lt;/li&gt;&lt;li&gt;cd: 디렉토리 변경하기 &lt;/li&gt;&lt;li&gt;cfdisk: 디스크 설정하기 &lt;/li&gt;&lt;li&gt;chattr: 파일 속성 변경하기 &lt;/li&gt;&lt;li&gt;chfn: 사용자 정보 변경하기 &lt;/li&gt;&lt;li&gt;chgrp: 파일, 디렉토리가 속했던 그룹 바꾸기 &lt;/li&gt;&lt;li&gt;chmod: 파일 권한 바꾸기 &lt;/li&gt;&lt;li&gt;chown: 파일 주인 바꾸기 &lt;/li&gt;&lt;li&gt;chsh: 지정된 셸 바꾸기 &lt;/li&gt;&lt;li&gt;cksum: CRC값을 점검한다 &lt;/li&gt;&lt;li&gt;clear: 화면 청소하기 &lt;/li&gt;&lt;li&gt;clock: CMOS 시각을 조정하기 &lt;/li&gt;&lt;li&gt;cmp: 파일 비교하기 &lt;/li&gt;&lt;li&gt;colcrt: 문자 변환 필터 &lt;/li&gt;&lt;li&gt;colrm: 열 삭제하기 &lt;/li&gt;&lt;li&gt;column: 가로 정렬하기 &lt;/li&gt;&lt;li&gt;comm: 파일 비교 출력하기 &lt;/li&gt;&lt;li&gt;command: 명령어 알아보기 &lt;/li&gt;&lt;li&gt;continue: 루프 계속돌기 &lt;/li&gt;&lt;li&gt;cp: 파일 복사하기 &lt;/li&gt;&lt;li&gt;cpio: 복사본 만들기 &lt;/li&gt;&lt;li&gt;crontab: cron을 관리한다 &lt;/li&gt;&lt;li&gt;csplit: 파일에 서식, 규칙 정하기 &lt;/li&gt;&lt;li&gt;cut: 필요한 필드만 출력하기 &lt;/li&gt;&lt;li&gt;date: 날짜 보기 &lt;/li&gt;&lt;li&gt;dd: 블럭장치 읽고 쓰기 &lt;/li&gt;&lt;li&gt;debugfs: ext2 파일 시스템 디버깅하기 &lt;/li&gt;&lt;li&gt;declare: 변수 선언하기 &lt;/li&gt;&lt;li&gt;df: 파일 시스템의 사용량 보기 &lt;/li&gt;&lt;li&gt;dirs: 디렉토리 목록 표시하기 &lt;/li&gt;&lt;li&gt;dmesg: 부팅 메시지 보기 &lt;/li&gt;&lt;li&gt;: X윈도우 환경에서 printk 메세지를 기본으로 못보는데 dmesg를 통해서 확인할수 있다&lt;/li&gt;&lt;li&gt;dnsdomainname: DNS 이름 출력 &lt;/li&gt;&lt;li&gt;domainname: NIS 이름 출력&amp;amp;설정 &lt;/li&gt;&lt;li&gt;du: 디렉토리와 파일의 용량 파악하기 &lt;/li&gt;&lt;li&gt;dumpe2fs: 파일 시스템 정보 보기 &lt;/li&gt;&lt;li&gt;echo: 표준 출력하기 &lt;/li&gt;&lt;li&gt;eject: 장치 해제하기 &lt;/li&gt;&lt;li&gt;elm: 메일 관련 &lt;/li&gt;&lt;li&gt;enable: 내부 명령어 지정 &lt;/li&gt;&lt;li&gt;env: 환경변수 출력하기 &lt;/li&gt;&lt;li&gt;eval: 인수 읽기 &lt;/li&gt;&lt;li&gt;exec: 셸 명령어 실행하기 &lt;/li&gt;&lt;li&gt;exit: 종료하기 &lt;/li&gt;&lt;li&gt;expand: 탭을 공백으로 변환하기 &lt;/li&gt;&lt;li&gt;export: 변수 지정하기 &lt;/li&gt;&lt;li&gt;e2fsck: 파일 시스템 복구하기 &lt;/li&gt;&lt;li&gt;fc: 지정된 편집기 받기 &lt;/li&gt;&lt;li&gt;fdformat: 플로피 디스크 포맷하기 &lt;/li&gt;&lt;li&gt;fdisk: 파티션 나누기 &lt;/li&gt;&lt;li&gt;fg: 지정된 작업을 전면 프로세스로 시작하기 &lt;/li&gt;&lt;li&gt;file: 파일 종류 보기 &lt;/li&gt;&lt;li&gt;find: 파일 찾기 eg) find ./ -name ./* &lt;/li&gt;&lt;li&gt;finger: 사용자 정보 알기 &lt;/li&gt;&lt;li&gt;fold: 정형화하기 &lt;/li&gt;&lt;li&gt;fmt: 정형화하기 &lt;/li&gt;&lt;li&gt;for: 반복 실행하기 &lt;/li&gt;&lt;li&gt;free: 메모리 사용량 알아보기 &lt;/li&gt;&lt;li&gt;fsck: 파일 시스템 검사하기 &lt;/li&gt;&lt;li&gt;fstab: 파일 시스템에 대한 고정적인 정보 저장하기 &lt;/li&gt;&lt;li&gt;ftp: 파일 전송 프로그램 &lt;/li&gt;&lt;li&gt;fuser: 프로세스 ID 출력 &lt;/li&gt;&lt;li&gt;getkeycodes: 매핑 테이블 출력하기 &lt;/li&gt;&lt;li&gt;grep: 특정 문자: 열 검색하기 &lt;/li&gt;&lt;li&gt;gzexe: 실행 파일 압축하기 &lt;/li&gt;&lt;li&gt;gzip: 압축하기 &lt;/li&gt;&lt;li&gt;halt: 시스템 종료하기 &lt;/li&gt;&lt;li&gt;hash: 기억해 두기; index 역할 &lt;/li&gt;&lt;li&gt;head: 파일의 앞부분 출력하기 &lt;/li&gt;&lt;li&gt;help: 도움말 보여주기 &lt;/li&gt;&lt;li&gt;host: 호스트 정보 보기 &lt;/li&gt;&lt;li&gt;history: 사용 명령어 목록보기 &lt;/li&gt;&lt;li&gt;hostname: 서버 이름 알기 &lt;/li&gt;&lt;li&gt;id: 계정 정보 알기 &lt;/li&gt;&lt;li&gt;if: 조건문 실행하기 &lt;/li&gt;&lt;li&gt;ifconfig: 랜카드에 주소 할당하기 &lt;/li&gt;&lt;li&gt;imolamod: 모듈 설치하기 &lt;/li&gt;&lt;li&gt;inetd: 인터넷 서비스의 최상위 데몬 &lt;/li&gt;&lt;li&gt;init: 실행 단계 정하기 &lt;/li&gt;&lt;li&gt;ispell: 철자법 검사하기 &lt;/li&gt;&lt;li&gt;jobs: 수행중인 프로세스 알기 &lt;/li&gt;&lt;li&gt;kbd_mode: 키보드 모드 출력하기 &lt;/li&gt;&lt;li&gt;kill: 프로세스 죽이기&amp;nbsp; 강제종료 : kill -9&amp;nbsp; PID&lt;/li&gt;&lt;li&gt;klogd: 커널 로그 데몬 &lt;/li&gt;&lt;li&gt;ldd: 공유 라이브러리의 의존성 알기 &lt;/li&gt;&lt;li&gt;less: 페이지 단위로 출력하기 &lt;/li&gt;&lt;li&gt;let: 정규식 표현하기 &lt;/li&gt;&lt;li&gt;lilo: 부팅하기 &lt;/li&gt;&lt;li&gt;ln: 링크하기 &lt;/li&gt;&lt;li&gt;locate: 패턴에 맞는 파일 찾기 &lt;/li&gt;&lt;li&gt;login: 로그인하기 &lt;/li&gt;&lt;li&gt;logger: 시스템 로그 기록하기 &lt;/li&gt;&lt;li&gt;logname: 사용자 로그인명 보여주기 &lt;/li&gt;&lt;li&gt;logout: 로그인 셸 종료하기 &lt;/li&gt;&lt;li&gt;look: 특정 단어 검색하기 &lt;/li&gt;&lt;li&gt;losetup: 중복 장치 확인하기 &lt;/li&gt;&lt;li&gt;lpd: 프린트 데몬 &lt;/li&gt;&lt;li&gt;lpq: 현재 프린트 작업 상태 출력하기 &lt;/li&gt;&lt;li&gt;lpr: 출력하기 &lt;/li&gt;&lt;li&gt;lprm: 대기열에 있는 문서 삭제하기 &lt;/li&gt;&lt;li&gt;ls: 디렉토리 내용보기 &lt;/li&gt;&lt;li&gt;lsattr: 파일 시스템의 속성 보여주기 &lt;/li&gt;&lt;li&gt;lsdev: 하드웨어 장치 출력하기 &lt;/li&gt;&lt;li&gt;lsmod: 모듈 정보 출력하기 lnsmod: 묘둘 올리기 rmmod : 모듈 내리기&lt;/li&gt;&lt;li&gt;mail: 메일 관련 &lt;/li&gt;&lt;li&gt;make: 컴파일하기 &lt;/li&gt;&lt;li&gt;man: 매뉴얼 보기 &lt;/li&gt;&lt;li&gt;mattrib &lt;/li&gt;&lt;li&gt;mbadblocks &lt;/li&gt;&lt;li&gt;mcd &lt;/li&gt;&lt;li&gt;mcopy &lt;/li&gt;&lt;li&gt;mdel &lt;/li&gt;&lt;li&gt;mdeltree &lt;/li&gt;&lt;li&gt;mdir &lt;/li&gt;&lt;li&gt;mesg: 메시지를 받을 수 있는지 확인하기 &lt;/li&gt;&lt;li&gt;mformat &lt;/li&gt;&lt;li&gt;minfo &lt;/li&gt;&lt;li&gt;mkdir : 디렉토리 만들기 &lt;/li&gt;&lt;li&gt;mke2fs: 파일 시스템 생성하기 &lt;/li&gt;&lt;li&gt;mkfs: 파일 시스템 만들기 &lt;/li&gt;&lt;li&gt;mknod: 특수 파일 만들기 &lt;/li&gt;&lt;li&gt;mkswap: 스왑 영역 지정하기 &lt;/li&gt;&lt;li&gt;mlabel &lt;/li&gt;&lt;li&gt;mmd &lt;/li&gt;&lt;li&gt;mount &lt;/li&gt;&lt;li&gt;mmount &lt;/li&gt;&lt;li&gt;mmove &lt;/li&gt;&lt;li&gt;mpartition &lt;/li&gt;&lt;li&gt;mount: 장치 연결하기 &lt;/li&gt;&lt;li&gt;more: 화면 단위로 출력하기&amp;nbsp; ls -al | more&lt;/li&gt;&lt;li&gt;mrd &lt;/li&gt;&lt;li&gt;mren &lt;/li&gt;&lt;li&gt;mtoolstest &lt;/li&gt;&lt;li&gt;mtype &lt;/li&gt;&lt;li&gt;mutt: 메일 관련 &lt;/li&gt;&lt;li&gt;mv: 파일 옮기기 &lt;/li&gt;&lt;li&gt;mzip &lt;/li&gt;&lt;li&gt;netstat: 현재 네트웍 상황 보기 &lt;/li&gt;&lt;li&gt;nice: 프로세스 우선 순위 변경하기 &lt;/li&gt;&lt;li&gt;od: 8진수로 파일 보기 &lt;/li&gt;&lt;li&gt;passwd: 암호 입력하기 &lt;/li&gt;&lt;li&gt;pidof: 실행중인 프로그램의 프로세스 ID 찾기 &lt;/li&gt;&lt;li&gt;pine: 메일 관련 &lt;/li&gt;&lt;li&gt;ping: 네트웍 확인하기 &lt;/li&gt;&lt;li&gt;popd: pushd 취소 &lt;/li&gt;&lt;li&gt;ps: 프로세스 상태 알기 ps -aux&lt;/li&gt;&lt;li&gt;pstree: 프로세스 상관관계 알기 &lt;/li&gt;&lt;li&gt;pwd: 절대경로 보여주기 &lt;/li&gt;&lt;li&gt;quota: 디스크 한계량 알기 &lt;/li&gt;&lt;li&gt;rarp: rarp 테이블 관리하기 &lt;/li&gt;&lt;li&gt;rcp: 원격 호스트에 파일 복사하기 &lt;/li&gt;&lt;li&gt;rdev: 루트, 스왑장치, 램 크기, 비디오 모드를 조사하고 설정하기 &lt;/li&gt;&lt;li&gt;rdate: 네트웍으로 시간 설정하기 &lt;/li&gt;&lt;li&gt;reboot: 재부팅하기 &lt;/li&gt;&lt;li&gt;readonly: 읽기 전용으로 표시하기 &lt;/li&gt;&lt;li&gt;renice: 프로세스 우선 순위 바꾸기 &lt;/li&gt;&lt;li&gt;reset: 터미널 초기화하기 &lt;/li&gt;&lt;li&gt;restore: 다시 저장하기 &lt;/li&gt;&lt;li&gt;rlogin: 바로 접속하기 &lt;/li&gt;&lt;li&gt;rm: 파일 지우기 &lt;/li&gt;&lt;li&gt;rmdir : 디렉토리 지우기 rm -rf&lt;/li&gt;&lt;li&gt;route: 라우팅 테이블 추가/삭제하기 &lt;/li&gt;&lt;li&gt;rpm: 프로그램 추가/삭제 &lt;/li&gt;&lt;li&gt;rpm2cpio: rpm을 cpio로 변환하기 &lt;/li&gt;&lt;li&gt;rsh: 원격으로 명령어 실행하기 &lt;/li&gt;&lt;li&gt;rup: 호스트 상태 출력하기 &lt;/li&gt;&lt;li&gt;rusers: 호스트에 로그인한 사용자 출력하기 &lt;/li&gt;&lt;li&gt;rwall: 호스트 사용자에게 메시지 뿌리기 &lt;/li&gt;&lt;li&gt;script: 기록하기 &lt;/li&gt;&lt;li&gt;set: 변수값 설정하기 &lt;/li&gt;&lt;li&gt;setup: 시스템 관련 설정하기 &lt;/li&gt;&lt;li&gt;showmount: 호스트의 마운트 정보 보여주기 &lt;/li&gt;&lt;li&gt;shutdown: 전원 끄기 &lt;/li&gt;&lt;li&gt;sleep: 잠시 쉬기 &lt;/li&gt;&lt;li&gt;source: 스크립트 번역하기 &lt;/li&gt;&lt;li&gt;split: 파일 나누기 &lt;/li&gt;&lt;li&gt;ssh: 암호화된 원격 로그인하기 &lt;/li&gt;&lt;li&gt;stty: 터미널라인 설정 보여주기 &lt;/li&gt;&lt;li&gt;su: 계정 바꾸기 &lt;/li&gt;&lt;li&gt;suspend: 셸 중단하기 &lt;/li&gt;&lt;li&gt;swapoff : 스왑 해제하기 &lt;/li&gt;&lt;li&gt;swapon: 스왑 활성화하기 &lt;/li&gt;&lt;li&gt;sync: 버퍼 재설정하기 &lt;/li&gt;&lt;li&gt;syslogd: 로그인 과정 설정하기 &lt;/li&gt;&lt;li&gt;tac: 거꾸로 보기 &lt;/li&gt;&lt;li&gt;tail: 문서 끝부분 출력하기 &lt;/li&gt;&lt;li&gt;talk: 이야기하기 &lt;/li&gt;&lt;li&gt;tar: 파일 묶기 &lt;/li&gt;&lt;li&gt;tcpdchk: tcp wrapper 설정하기 &lt;/li&gt;&lt;li&gt;tcpmatch: 네트웍 요청에 대해 예측하기 &lt;/li&gt;&lt;li&gt;tee: 표준 입력으로부터 표준 출력 만들기 &lt;/li&gt;&lt;li&gt;telnet: 원격접속하기 &lt;/li&gt;&lt;li&gt;test: 테스트하기 &lt;/li&gt;&lt;li&gt;times: 셸에서의 사용자와 시스템 시간 출력하기 &lt;/li&gt;&lt;li&gt;top: cpu 프로세스 상황 보여주기 &lt;/li&gt;&lt;li&gt;tr: 문자열 바꿔주기 &lt;/li&gt;&lt;li&gt;true: 종료 코드 리턴하기 &lt;/li&gt;&lt;li&gt;type: 유형 보기 &lt;/li&gt;&lt;li&gt;ul: 밑줄 처리해서 보여주기 &lt;/li&gt;&lt;li&gt;ulimit: 제한하기 &lt;/li&gt;&lt;li&gt;umask: 매스크 모드 설정하기 &lt;/li&gt;&lt;li&gt;umount: 장치 해제하기 &lt;/li&gt;&lt;li&gt;unalias: 별명 제거하기 &lt;/li&gt;&lt;li&gt;uname: 시스템 정보 보기 &lt;/li&gt;&lt;li&gt;unexpand: 공백 문자를 탭으로 변환하기 &lt;/li&gt;&lt;li&gt;uniq: 중복된 문장 찾기 &lt;/li&gt;&lt;li&gt;useradd: 사용자 계정 만들기 &lt;/li&gt;&lt;li&gt;userdel: 계정 삭제하기 &lt;/li&gt;&lt;li&gt;usermod: 사용자 계정정보 수정하기 &lt;/li&gt;&lt;li&gt;unset: 설정 변수 해제 &lt;/li&gt;&lt;li&gt;uptime: 시스템 부하 평균 보여주기 &lt;/li&gt;&lt;li&gt;users: 로그인된 사용자 보여주기 &lt;/li&gt;&lt;li&gt;w: 시스템에 접속한 사용자 상황 알아보기 &lt;/li&gt;&lt;li&gt;wait: 프로세스 기다리기 &lt;/li&gt;&lt;li&gt;wall: 모든 사용자에게 메시지 보내기 &lt;/li&gt;&lt;li&gt;wc: 문자, 단어, 라인수 세기 &lt;/li&gt;&lt;li&gt;whatis: 명령어의 간단한 설명보기 &lt;/li&gt;&lt;li&gt;while: 루프 명령어 &lt;/li&gt;&lt;li&gt;who: 사용자 알기 &lt;/li&gt;&lt;li&gt;write: 콘솔 상에서 간단한 메시지 보내기 &lt;/li&gt;&lt;li&gt;xcopy: 반복적으로 복사하기 &lt;/li&gt;&lt;li&gt;XFree86 &lt;/li&gt;&lt;li&gt;ypchfn: NIS에서 사용하는 chfn 명령어 &lt;/li&gt;&lt;li&gt;ypchsh: NIS에서 사용하는 chsh 명령어 &lt;/li&gt;&lt;li&gt;yppasswd: NIS에서 사용하는 passwd 명령어 &lt;/li&gt;&lt;li&gt;zcat: 압축 파일 보기 &lt;/li&gt;&lt;li&gt;zcmp: 압축 파일 비교하기 &lt;/li&gt;&lt;li&gt;zforce: 강제로 gz 만들기 &lt;/li&gt;&lt;li&gt;zgrep: 압축 상태에서 grep 실행하기 &lt;/li&gt;&lt;li&gt;zmore: 압축 상태에서 more 실행하기 &lt;/li&gt;&lt;li&gt;znew: .Z 파일을 .gz로 다시 압축하기&lt;/li&gt;&lt;/ul&gt;&lt;span style=&quot;font-size: large;&quot;&gt;레퍼런스&lt;/span&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://webdir.tistory.com/101&quot;&gt;리눅스 디렉토리 구조&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://delirussum.tistory.com/entry/Ubuntu-%EC%9A%B0%EB%B6%84%ED%88%AC-%ED%84%B0%EB%AF%B8%EB%84%90-%EB%AA%85%EB%A0%B9%EC%96%B4-%EB%AA%A8%EC%9D%8C&quot;&gt;우분투 터미널 명령어 모음&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://amazingguni.github.io/blog/2016/05/devops-chapter-4-disk&quot;&gt;리눅스 디스크 관리&lt;/a&gt;&lt;/li&gt;&lt;li&gt;리눅스 용량 차이 문제(&lt;a href=&quot;http://greenfinger.tistory.com/180&quot;&gt;#1&lt;/a&gt;, &lt;a href=&quot;http://tumblr.lunatine.net/post/13628840969/faq-linux-%EB%94%94%EC%8A%A4%ED%81%AC-%EC%82%AC%EC%9A%A9%EB%9F%89%EC%9D%98-%EC%B0%A8%EC%9D%B4-df-%EB%AA%85%EB%A0%B9%EA%B3%BC-du&quot;&gt;#2&lt;/a&gt;)&amp;nbsp; &lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/6035821751868037435/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/blog-post_2.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6035821751868037435'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/6035821751868037435'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/blog-post_2.html' title='우분투 운영체계 폴더 구조 및 핵심 명령어'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-HGcYVIiZAxQ/Wpn7FBf20aI/AAAAAAAALXE/pGkAu_8KMDMXeq-RbRM7YWRW3_CkQWYMwCLcBGAs/s72-c/hN4lt.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-4427749842776214085</id><published>2018-03-02T16:44:00.001-08:00</published><updated>2018-04-08T20:22:31.711-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="리눅스"/><title type='text'>우분투 백업 및 스냅샷 만들기 방법 소개</title><content type='html'>이 글은 우분투 백업 및 스냅샷 만드는 방법을 소개한다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-LRSjyjtdU0c/WsrcZiXtYnI/AAAAAAAALm8/QNk0DVHLD7QjNRWUtc3UrHwrvcdg1CNsQCLcBGAs/s1600/s8.PNG&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;336&quot; data-original-width=&quot;705&quot; height=&quot;152&quot; src=&quot;https://4.bp.blogspot.com/-LRSjyjtdU0c/WsrcZiXtYnI/AAAAAAAALm8/QNk0DVHLD7QjNRWUtc3UrHwrvcdg1CNsQCLcBGAs/s320/s8.PNG&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;여기서 백업은 user 폴더 밑에 데이터를 보관하는 것을 말하고, 스냅샷은 시스템 운영체계 데이터까지 모두 보관하는 것을 말한다.&lt;br /&gt;&lt;br /&gt;보통 우분투에서 백업은 deja-dup, 스냅샷은&amp;nbsp; timeshift, Backup in time, rsnapshot와 같은 도구를 사용한다. 사용방법은 어렵지 않은 데, deja-dup는 시스템 운영체계까지는 저장하지 않는다. &lt;br /&gt;&lt;br /&gt;사용 방법은 다음 링크를 참고한다.&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://tipsonubuntu.com/2016/07/30/create-system-restore-points-ubuntu-16-04/&quot;&gt;Making a snaphot&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.linux.com/learn/total-system-backup-and-recall-deja-dup%20&quot;&gt;Backup system using deja-dup&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/4427749842776214085/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/blog-post.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/4427749842776214085'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/4427749842776214085'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/blog-post.html' title='우분투 백업 및 스냅샷 만들기 방법 소개'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-LRSjyjtdU0c/WsrcZiXtYnI/AAAAAAAALm8/QNk0DVHLD7QjNRWUtc3UrHwrvcdg1CNsQCLcBGAs/s72-c/s8.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-5201956450461596914.post-8780753954810407357</id><published>2018-03-02T05:29:00.001-08:00</published><updated>2018-03-27T06:52:53.266-07:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="비전"/><title type='text'>우분투 블랙 스크린 문제 해결 방법</title><content type='html'>&lt;span style=&quot;font-size: small;&quot;&gt;이 글은 고질적인 우분투 블랙 스크린(black screen) 문제 솔류션 트리를 간략히 요약한다. 이 문제는 우분투 부팅했는 데, 로그인 조차 안되는 검정색 화면만 보여지는 현상이다.&amp;nbsp; &lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;블랙 스크린 문제는 14.04, 16.04 모두 공통적으로 발생된다. 주 발생 원인은 NVIDIA + Unity + ubuntu 간에 충돌 발생이다. 충돌 발생 원인은 매우 다양하다. 정상적인 apt-get install 설치 후에도 발생할 수 있다. &lt;/span&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이번엔 터치패드 패키지 욕심내어 설치하다, 노트북이 또 벽돌 되어 버렸다(Deja-dup 백업도 의미 없다. 다시 솔류션 트리를 수행하고, 아애 그 과정을 영원히 기록해 놓을 요량으로 글을 쓴다). &lt;/span&gt;그냥 운이 없으면 블랙 스크린을 만난다고 보면 될 것이다. &lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://pbs.twimg.com/profile_images/832120588391084032/mev3Bs7D_400x400.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;400&quot; data-original-width=&quot;400&quot; height=&quot;200&quot; src=&quot;https://pbs.twimg.com/profile_images/832120588391084032/mev3Bs7D_400x400.jpg&quot; width=&quot;200&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;욕심내지 말껄 T.T~ &lt;/div&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: small;&quot;&gt;블랙 스크린은 로그인 메시지도 안뜨는 벽돌 상태로 변하기 때문에, 당하면 멘붕 오게 된다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://www.servethehome.com/wp-content/uploads/2013/10/Cursor-Blinking-Screen.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;401&quot; data-original-width=&quot;721&quot; height=&quot;177&quot; src=&quot;https://www.servethehome.com/wp-content/uploads/2013/10/Cursor-Blinking-Screen.jpg&quot; width=&quot;320&quot; /&gt;&amp;nbsp;&lt;/a&gt;&lt;/div&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;정신이 붕괴되는 빌어먹을 블랙 스크린(처음 대면하면 우주에 혼자 미아가 된 듯 너무 막연하고 황당하다)&lt;/div&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;본인은 두대의 노트북을 이렇게 날려먹고, 수십번의 블랙 스크린과 무한 구글링을 경험했다. 지금은 아래 솔류션 트리로 한 두시간 만에 벽돌 노트북을 살릴 수 있다. &lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: large;&quot;&gt;1. 터미널 모드 부팅 및 NVIDIA 드라이버 재설치&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;부팅 시 grub에서 e 키를 입력해, grub 스크립트의 부팅 옵션에 nomodeset 옵션을 추가한 후 F10입력해 부팅함. 이후, 터미널모드(CTRL+ALT+F1)로 부팅한다. 그리고, nvidia 드라이버를 삭제 후, 재 설치해야 한다.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get purge nvidia-*&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo add-apt-repository ppa:graphics-drivers/ppa&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get update&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;NVIDIA GTX 1070일 경우 다음과 같이 해당 버전의 드라이버를 설치한다. 아니면, 본인 GTX 버전에 맞는 드라이버 번호를 확인하고, 설치하라.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get install nvidia-384&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;(혹은 367, 375)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;font-size: large;&quot;&gt;2. 우분투 데스크탑 재설치 &lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;운이 없다면, 블랙 스크린 문제가 계속 발생할 것이다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;이 경우, 다음과 같이, unity, nvidia, ubuntu-desktop, ubuntu-session을 모두 purge하고, 재부팅 후 다시 설치한다. &lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get purge unity* &lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get purge &lt;/span&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;nvidia-&lt;/span&gt;* &lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get install ubuntu-desktop&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;sudo apt-get install ubuntu-session &lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;혹시, 디펜던시 에러가 발생한다면 해당 버전 패키지를 설치하여 해결한다(&lt;/span&gt;&lt;span style=&quot;font-size: small;&quot;&gt;&lt;span style=&quot;font-size: x-small;&quot;&gt;&lt;a href=&quot;https://askubuntu.com/questions/884413/unable-to-install-libgtk2-0-dev-on-ubuntu-16-04&quot; rel=&quot;nofollow&quot;&gt;링크&lt;/a&gt; 참고)&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://daddynkidsmakers.blogspot.com/feeds/8780753954810407357/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/black-screen.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/8780753954810407357'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/5201956450461596914/posts/default/8780753954810407357'/><link rel='alternate' type='text/html' href='http://daddynkidsmakers.blogspot.com/2018/03/black-screen.html' title='우분투 블랙 스크린 문제 해결 방법'/><author><name>Daddy Maker</name><uri>http://www.blogger.com/profile/02275758703365576780</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-26oh4jMYFpA/W_Cx4KIss7I/AAAAAAAAMas/x_o3u-0Aqo448M9L-D6WRCJq81XT9YhEwCK4BGAYYCw/s220/%25EC%25BA%25A1%25EC%25B2%2598.PNG'/></author><thr:total>1</thr:total></entry></feed>