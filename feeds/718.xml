<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by 이용환 on Medium]]></title>
        <description><![CDATA[Stories by 이용환 on Medium]]></description>
        <link>https://medium.com/@leeyh0216?source=rss-7d11002906ed------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*rLlrdHTu8sUPBgPs4ZUdfQ.jpeg</url>
            <title>Stories by 이용환 on Medium</title>
            <link>https://medium.com/@leeyh0216?source=rss-7d11002906ed------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sun, 12 May 2019 11:07:24 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/@leeyh0216" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Distributed System — Processes(1)]]></title>
            <link>https://medium.com/@leeyh0216/distributed-system-processes-1-9101d5c5ceee?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/9101d5c5ceee</guid>
            <category><![CDATA[multithreading]]></category>
            <category><![CDATA[threads]]></category>
            <category><![CDATA[distributed-systems]]></category>
            <category><![CDATA[os]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Wed, 31 Oct 2018 13:49:41 GMT</pubDate>
            <atom:updated>2018-10-31T13:49:41.236Z</atom:updated>
            <content:encoded><![CDATA[<h3>Distributed System — Processes(1)</h3><p>Distributed System 3판의 3. Process의 Thread usage in nondistributed systems까지 요약한 글입니다.</p><h3>Threads</h3><h4>Introduction to threads</h4><p>분산 시스템에서의 스레드(Thread)의 역할을 이해하기 위해서는, 프로세스(Process)가 무엇이고, 프로세스와 스레드가 어떤 관계인지 아는 것이 중요하다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*t1Q5ptcwhrNdTTUJvM_oPQ.png" /></figure><p>OS(Operating System)는 프로그램을 실행하는데에 필요한 Virtual Processor를 생성하고, Virtual Processor들은 각자 다른 프로그램을 실행시킬 수 있다.</p><p>Virtual Processor라는 개념이 매우 생소해서, 관련 내용을 찾아보고 나름대로 정리해보았다.</p><p>일반적으로 우리가 사용하는 CPU를 프로세서(Processor)라고 부르고, 이 Processor 안에서 실제로 연산을 수행하는 부품이 코어(Core)이다.</p><p>OS는 여러 프로세스가 동시(Concurrent)에 동작하는 것처럼 보이기 위해 Time Sharing 기법을 사용하여 <a href="https://en.wikipedia.org/wiki/Processor_sharing">프로세서를 공유(Processor Sharing)</a> 한다.</p><p>Virtual Processor는 프로세스에게 할당되는 물리 코어의 양 혹은 비율을 표현하는 용어이다.</p><p>예를 들어 1 코어를 단위 시간동안 2개의 프로세스가 균등하게 나누어 쓴다면 1개의 프로세스는 0.5 Core의 Virtual Processor를 사용한다고 생각할 수 있다.</p><p>약간은 다르게 번역되었을 수 있지만, Virtual Processor에 대한 내용이 잘 나와있지 않아 <a href="https://www.ibm.com/support/knowledgecenter/TI0002C/p8hat/p8hat_virtualproc.htm">IBM Knowledge Center의 Virtual Processor</a>를 번역하여 일반적인 OS에 맞게 해석해보았다.</p><p>Virtual Processor가 실행시키는 프로그램의 정보(CPU Register, Memory maps, Open files, Accounting Information, Privileges 등)를 가지고 있는 개체를 Process Context라고 부르며, OS에서는 이러한 다수의 Process Context를 Process Table이라는 이름으로 관리한다.</p><p>즉, 실행 중인 프로그램을 프로세스라고 부르며, 프로세스는 Virtual Processor에게 할당되어 실행되고, 실행 정보는 Process Context에 저장된다.</p><p>OS는 개별 프로세스가 다른 프로세스의 영역을 침범하여 부작용을 일으킬 수 없도록 한다(프로세스들을 격리시킨다). 이는 <strong>여러 프로세스들이 동일한 CPU와 하드웨어 자원을 공유하는 것을 알 수 없도록 병행 투명성(Concurrency Transparency)을 제공하려는 목적</strong>이다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/900/0*XQ5yfaNx7RhO_Dd8.png" /><figcaption>Process Context Switching(출처: <a href="https://www-sys-aics.riken.jp/ResearchTopics/os/ulp/">https://www-sys-aics.riken.jp/ResearchTopics/os/ulp/</a>)</figcaption></figure><p>병행 투명성을 달성하는데에는 비용이 발생한다. 예를 들면, CPU가 실행 중이던 프로세스의 Context 를 저장하고, 실행 할 프로세스의 Context를 로드하는 Context Switching도 병행 투명성을 달성하기 위한 비용이다.</p><p>프로세스와 비슷하게, 스레드도 다른 스레드와 독립적으로 코드 조각을 실행시킨다.</p><p>그러나 프로세스와 달리 높은 수준의 병행 투명성을 달성할 필요가 없다. 프로세스 내 스레드 간의 잘못된 접근에 따른 데이터 문제는 OS가 아닌 개발자의 책임이기 때문이다.</p><p>그렇기 때문에 스레드 시스템은 여러 스레드들이 공유하기 위한 CPU 정보 정도의 <strong>최소한의 정보만을 유지</strong>하며, Thread Context는 Processor Context와 스레드 관리를 위한 정보만을 가지고 있다.(이렇게 적은 정보를 유지하고 있기 때문에 스레드 간 문맥 교환(Thread Context Switching)이 프로세스 간 문맥 교환(Process Context Switching)보다 비용이 적고, 결과적으로 Multi Process Program보다 Multi Thread Program이 더 빠르게 동작할 수 있다)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/525/1*OJBPtisq4L0Cv-w4uD5npw.png" /></figure><p>결과적으로 Process Context가 여러 개의 Thread Context를 포함하고 있고, 각 Thread Context가 Processor Context를 가지는 구성이 된다.</p><h4>Thread usage in nondistributed systems</h4><p>분산 시스템에서의 스레드의 역할을 논하기 전에 비-분산 시스템에서의 스레드의 역할을 생각해보자. 멀티스레드 어플리케이션은 싱글스레드 어플리케이션에 비해 몇몇 장점을 가지고 있다.</p><ol><li>싱글 스레드 프로그램에서는 Blocking System Call이 호출되었을 때 System Call이 끝나기 전까지 전체 프로그램이 멈추지만, 멀티스레드 프로그램에서는 새로운<strong> 스레드를 생성하여 해당 Blocking System Call을 처리</strong>하도록하여 멈추지 않게 할 수 있다.</li><li>Multi Core 혹은 Multi Processor 시스템에서 멀티스레드 프로그램을 실행시킬 때 <strong>병렬성(Parallelism)을 부각</strong>시킬 수 있다는 것이다. 이 경우 각 스레드는 다수의 Core 혹은 Processor에게 할당되어 병렬로 수행된다.</li><li>Unix와 같은 대규모 시스템은 작은 프로세스 여러개가 협력하여 구성한다. 프로세스 끼리는 직접적인 <strong>데이터 공유가 불가능하므로 IPC</strong>(Inter Process Communication)을 사용하는데, IPC의 최대 <strong>약점은 IPC를 수행하는 과정에서 Process Context Switching이 발생</strong>한다는 점이다. 멀티 프로세스가 아닌 <strong>멀티 스레드 어플리케이션으로 구현하면 공유 데이터를 사용</strong>할 수 있기 때문에 이러한 <strong>Context Switching비용이 감소</strong>(Process Context Switching보다 비용이 적은 Thread Context Switching 사용)하게 된다.</li></ol><h4>Thread implementation</h4><p>스레드는 보통 Thread Package로 구성되어 제공된다. 대부분의 Package는 스레드의 생성/파괴, 동기화 변수 등과 관련된 Operation을 제공한다.</p><p>Thread Package를 구현하는 방법에는 두가지 관점이 존재한다.</p><ol><li>Thread Library 전체가 User Space에서 동작하게 하는 것(User Level)</li><li>Kernel에서 Thread의 존재를 알고 이를 스케쥴링할 수 있게 하는 것(Kernel Level)</li></ol><p>User Level Thread Library에는 몇몇 장점이 존재한다.</p><ol><li>스레드의 생성/파괴가 User Address Space에서만 발생하기 때문에 비용이 적게 든다.</li><li>Thread Context Switching의 비용이 적다. CPU Register가 사용할 값만 새로운 Thread의 정보로 바꿔주면 되기 때문에 Memory map, TLB, CPU Accounting 등을 변경할 필요가 없기 때문이다.</li></ol><p>User Level Thread Library의 최대 단점은 many-to-one threading model(여러 개의 Thread가 하나의 Schedule 객체로 묶인 것)구현에서 발생한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Om3nrFpARev-i_C_zq_BQw.png" /></figure><p>위의 그림의 A, B, C Thread는 OS에서 바라보는 Scheduling 단위(일반적으로 Process로 배우지만, Thread 단위로 Scheduling 된다)이다. A Thread 내부의 회색 Thread Box들은 User Level에서 구현한 Thread이다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/652/0*BlR1f4LPE05tWRv1.jpg" /><figcaption>Process status State Diagram(출처: <a href="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html">https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html</a>)</figcaption></figure><p>위의 그림은 Process(Thread)의 상태 다이어그램인데, RUNNING 상태의 Process는 I/O 혹은 Event 수신 등의 Blocking System Call을 호출하거나 호출 당하게 되면 WAITING 상태로 변경되는 것을 볼 수 있다.</p><p>A Thread의 경우 내부 6개의 Thread 중 1개라도 Blocking System Call을 호출하게 되면 바로 WAITING 상태로 변경되기 때문에 나머지 5개의 Thread 또한 Block 되게 된다.</p><p>이러한 문제는 1개의 Thread가 1개의 Scheduling 단위인 one-to-one threading model(OS Level Thread)에서는 발생하지 않는다.</p><p>물론 Thread의 생성/파괴, 동기화 등은 OS의 System Call을 사용하기 때문에 비용이 발생하며, Thread Context Switching 비용 또한 이제 Process Context Switching 만큼이나 비싼 비용이 발생한다.</p><p><strong>Advanced: Lightweight Processes</strong></p><p>User Level과 Kernel(OS) Level의 Thread를 결합한 many-to-many threading model도 존재하며, 이 모델은 Lightweight Processes(LWP) 형태로 구현되었다. 이는 1개의 프로세스(heavy-weight) 안에 여러 개의 Lightweight Process(LWP)가 존재하는 형태이다.</p><p>System은 Process에게 Application Level에서 Thread를 생성/파괴, 동기화할 수 있는 Thread Package를 제공하며, 제공되는 Operation 들은 User Space에서 동작하기 때문에 Kernel의 간섭을 받지 않는다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/588/1*MAuNNWGjWRR20odp-48pTQ.png" /></figure><p>LWP는 자신만의 Stack과 Scheduler를 가지며, LWP들은 Thread들의 추적을 위한 Thread Table을 공유한다.</p><p>LWP가 Scheduling Routine을 실행하여 실행 가능한(Runnable) Thread를 찾으면, 해당 Thread로 Context Switch를 한다.</p><p>만약 Thread에서 Blocking System Call을 호출하는 경우 아래와 같이 진행된다.</p><ol><li>실행 흐름이 User Mode 에서 Kernel Mode로 변경된다.</li><li>현재 LWP가 더이상 실행 불가하므로, OS는 다른 LWP로 Context Switch를 진행한다.</li><li>실행 흐름이 Kernel Mode에서 User Mode로 변경된다.</li><li>선택된 LWP가 자신이 선택한 Thread를 실행한다.</li></ol><p>LWP와 User Level Thread Package를 결합하여 사용하는 이점은 아래와 같다.</p><ol><li>Thread의 생성/파괴, 동기화 등의 Operation 비용이 싸다. 또한 Kernel의 간섭도 받지 않는다(User Level Operation)</li><li>Process에게 LWP가 충분히 할당되는 경우, 한 Thread의 Blocking System Call이 전체 Process를 멈추지 않는다(동일 Process의 Thread가 다른 LWP에게 선택되어 실행될 수 있기 때문)</li><li>Application은 LWP의 존재를 알 필요 없이 User Level Thread Package만 사용하면 된다.</li><li>LWP는 Multi-Processing 환경에서 동작하기 용이하다.</li></ol><p>LWP 사용에서의 유일한 단점은 LWP 자체의 생성/파괴는 Kernel Level에서 일어나기 때문에 여전히 비싼 Operation이라는 것이다.</p><h4>LWP and Scheduling Scope in Oracle Documentation</h4><p>Oracle의 <a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h032e/index.html">Understanding Basic Multithreading Concepts</a> 문서에도 Lightweight Process가 다음과 같이 설명되어 있다.</p><p><em>Thread Library는 Kernel에서 지원하는 Lightweight Process들을 제어합니다. LWP는 Code나 System Call을 호출하는 Virtual CPU라고 생각하면 됩니다.</em></p><p>그 아래에는 Scheduling Scope이 설명되어 있다. Scheduling Scope에는 Process Scope(Unbound Threads)와 System Scope(Bound Threads)가 존재하며, 자세한 내용은 아래와 같다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/402/0*JA0xMne4YRfD_0LU.gif" /><figcaption>출처: Understanding Basic Multi-threading Concepts — Oracle(<a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h032e/index.html">https://docs.oracle.com/cd/E19455-01/806-5257/6je9h032e/index.html</a>)</figcaption></figure><p><strong>Process Scope(Unbound Threads)</strong></p><p>Unbound Threads는 PTHREAD_SCOPE_PROCESS 인자를 통해 생성된다.</p><p>이 Thread들은 User Space에서 Scheduling되며, Thread가 속한 Process가 할당받은 LWP Pool의 LWP들에 attach/detach 될 수 있다.(위의 사진을 보면 Unbounded Threads는 Threads Library를 통해 랜덤한 LWP에 할당되는 것을 볼 수 있다)</p><p>우리가 일반적으로 사용하는 Thread가 이 Scope를 가진다.</p><p><a href="http://man7.org/linux/man-pages/man3/pthread_attr_setscope.3.html">pthread_attr_setscope — Linux Manual</a> 페이지에는 아래와 같이 기술되어 있다.</p><p>PTHREAD_SCOPE_PROCESS 인자를 통해 생성된 Thread는 동일한 Process에서 생성된 다른 Thread들과 자원을 차지하기 위해 경쟁한다.</p><p><strong>System Scope(Bounded Threads)</strong></p><p>Bound Threads는 PTHREAD_SCOPE_SYSTEM 인자를 통해 생성된다.</p><p>Bound Thread는 생애주기 동안 동일한 LWP에 영구적으로 attach 되며, OS의 Scheduling을 받는다.(위의 사진을 보면 Bounded Threads는 LWP와 1:1로 결합되어 있는 것을 볼 수 있다)</p><p><a href="http://man7.org/linux/man-pages/man3/pthread_attr_setscope.3.html">pthread_attr_setscope — Linux Manual</a> 페이지에는 아래와 같이 기술되어 있다.</p><p>PTHREAD_SCOPE_SYSTEM 인자를 통해 생성된 Thread는 시스템 내에 존재하는 모든 Thread들과 자원을 차지하기 위해 경쟁한다.</p><p>결론적으로 Process Scope에서는 Process 에 할당된 LWP가 넉넉하지 않거나 사용 가능한 LWP가 없는 경우 Thread가 실행될 수 없지만, System Scope에서는 무조건 자신을 위한 LWP가 있기 때문에 OS Scheduling만 받으면 되서 RTOS에 적합하다고 되어 있던 것 같다.</p><p>생각보다 Thread Model(one-to-one, one-to-many, many-to-many)이 나오게 된 배경도 복잡하고, LWP의 개념도 확실히 잡고 갈 수 있어 좋았던 것 같다.</p><p>비록 내용을 이해하는데는 1주일이 걸렸지만…</p><p>혹시 Java의 Thread가 어떻게 동작하는지 알고 싶으신 분은 <a href="https://medium.com/@unmeshvjoshi/how-java-thread-maps-to-os-thread-e280a9fb2e06">How Java thread maps to OS Thread?</a> 글을 참고하시길 바란다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9101d5c5ceee" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[BOJ] 1149: RGB 거리]]></title>
            <link>https://medium.com/@leeyh0216/boj-1149-rgb-%EA%B1%B0%EB%A6%AC-7202ea823ee0?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/7202ea823ee0</guid>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Sat, 20 Oct 2018 01:18:54 GMT</pubDate>
            <atom:updated>2018-10-20T01:18:54.584Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/524/0*Tiuh8M0Xv-mMTGHN.png" /></figure><ul><li>문제 링크: <a href="https://www.acmicpc.net/problem/1149">https://www.acmicpc.net/problem/1149</a></li></ul><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/cf262aa2a8c1ac33be7d0f5490012c37/href">https://medium.com/media/cf262aa2a8c1ac33be7d0f5490012c37/href</a></iframe><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7202ea823ee0" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[BOJ] 10815: 숫자 카드]]></title>
            <link>https://medium.com/@leeyh0216/boj-10815-%EC%88%AB%EC%9E%90-%EC%B9%B4%EB%93%9C-feb37cd4a934?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/feb37cd4a934</guid>
            <category><![CDATA[online-judge]]></category>
            <category><![CDATA[binary-search]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Fri, 19 Oct 2018 13:52:20 GMT</pubDate>
            <atom:updated>2018-10-19T13:52:20.232Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/524/0*n8hkBM-dgkmTOsdI.png" /></figure><ul><li>문제 링크: <a href="https://www.acmicpc.net/problem/10815">https://www.acmicpc.net/problem/10815</a></li></ul><p>정렬되지 않은 두 배열(크기는 각각 M, N)이 주어지고, 아래 배열의 값들이 위의 배열에 존재하는지 확인하는 문제이다.</p><ol><li>위의 배열을 정렬한다.</li><li>아래 배열을 순회하며 각 값이 위의 배열에 존재하는지 확인한다. 이진 탐색을 사용하면 logN 만에 찾을 수 있다.</li></ol><p>이 문제의 시간 복잡도는 MlogM(위의 배열 정렬 시간)+ NlogM(아래 정렬의 각 요소에 대해 위의 배열에서 검색 시간)이 될 것이다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b71213e836c7c51ba611b2f981bba0be/href">https://medium.com/media/b71213e836c7c51ba611b2f981bba0be/href</a></iframe><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=feb37cd4a934" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[BOJ] 10867: 중복 빼고 정렬하기]]></title>
            <link>https://medium.com/@leeyh0216/boj-10867-%EC%A4%91%EB%B3%B5-%EB%B9%BC%EA%B3%A0-%EC%A0%95%EB%A0%AC%ED%95%98%EA%B8%B0-783052304b3?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/783052304b3</guid>
            <category><![CDATA[algorithms]]></category>
            <category><![CDATA[counting-sort]]></category>
            <category><![CDATA[merge-sort]]></category>
            <category><![CDATA[sorting-algorithms]]></category>
            <category><![CDATA[online-judge]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Fri, 19 Oct 2018 13:04:18 GMT</pubDate>
            <atom:updated>2018-10-19T13:04:18.915Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/524/0*57-sfcejHjPjeEP8.png" /></figure><ul><li>문제 링크: <a href="https://www.acmicpc.net/problem/10867">https://www.acmicpc.net/problem/10867</a></li></ul><p>문제 조건에 입력의 갯수는 10만개까지 들어올 수 있는데, 입력 값의 범위는 -1000 ~ 1000까지라고 명시되어 있다.</p><p>합병 정렬(Merge Sort)을 이용해도 되지만 입력 값의 범위가 작기 떄문에 계수 정렬(Counting Sort)를 사용해서 풀어도 된다.</p><ol><li>합병정렬(Merge Sort)를 이용한 풀이</li></ol><ul><li>입력 배열에 대한 정렬 수행</li><li>중복된 값은 한번만 출력해야 하기 때문에, 이전에 출력할 값을 저장해 놓을 임시 변수를 할당하고, for문을 돌면서 임시 변수에 저장된 값이 아니라면 출력, 저장된 값이라면 Continue.</li></ul><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/61e726e9ca86ad377dbce5e51b990744/href">https://medium.com/media/61e726e9ca86ad377dbce5e51b990744/href</a></iframe><p>2. 계수 정렬(Counting Sort)를 이용한 풀이</p><ul><li>입력 값의 범위인 -1000 ~ 1000을 저장하기 위한 크기 2002짜리 배열 선언</li><li>배열의 값들을 입력받을 때 1000씩 더해서 0 ~ 2000의 범위의 값으로 만든 후, 해당 입력값에 해당하는 배열 요소의 값을 1 증가.</li><li>0 ~ 2000의 배열을 순회하며 요소의 값이 0이 아닐 경우 인덱스를 출력</li></ul><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/cadc887bcb2003ae85e6b19ed6638509/href">https://medium.com/media/cadc887bcb2003ae85e6b19ed6638509/href</a></iframe><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=783052304b3" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Spark SQL]]></title>
            <link>https://medium.com/@leeyh0216/spark-sql-6dc3d645cc31?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/6dc3d645cc31</guid>
            <category><![CDATA[sql]]></category>
            <category><![CDATA[optimization]]></category>
            <category><![CDATA[spark]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Sun, 14 Oct 2018 13:50:51 GMT</pubDate>
            <atom:updated>2018-10-14T13:54:44.662Z</atom:updated>
            <content:encoded><![CDATA[<h3>Spark Internal Part 3. Spark SQL’s Catalyst Optimizer</h3><h4>with Deep Dive into Spark SQL’S Catalyst Optimizer</h4><p>처음 Spark을 접했을 때가 벌써 3년 전이고, 그 당시에는 RDD를 이용하여 프로그래밍 하는 것이 더 편했다.</p><p>그런데 최근 회사에서 PIG Script로 작성된 ETL 프로그램을 Spark으로 옮기다보니 SQL을 통해 처리할 수 있는 로직에 대해서는 Spark SQL을 사용하는 것이 RDD를 사용하는 것보다 더 편하다는 것을 알게 되었다.</p><p>그 이유는 아래와 같다.</p><ol><li>사용하는 데이터 포맷이 Parquet이고, SQL만으로 처리할 수 있는 경우 Schema에 매핑되는 클래스를 정의할 필요가 없다.</li><li>RDD의 경우 개발자가 최적화를 해야하지만, Spark SQL에서는 Catalyst Optimizer가 최적화를 대신해준다(물론 일부 Configuration은 사용자가 상황에 맞게 바꾸어주어야 한다).</li><li>Dataframe(a.k.a Dataset[Row])은 Untyped Data인 Row를 사용하기 때문에 연산에 제한이 있었지만 Dataset은 Typed Data로 변환하여 처리하기 때문에 Dataframe보다는 좀 더 복잡한 연산이 가능하다.</li></ol><p>그래도 아직 부족한 부분이 있다면 GroupByKey(Dataset에서는 (key, Iterable[DataType])형태로 처리되지 않음)인데, 이 부분 또한 Dataset &lt;-&gt; RDD 간 변환이 자유롭기 때문에 어느정도는 커버 가능하다고 본다.</p><p>이 글에서는 Databricks Blog와 Spark Summit에서 발표된 Deep Dive into Spark SQL’S Catalyst Optimizer 번역 및 요약과 약간의 코드 분석을 진행할 예정이다.</p><p><a href="https://www.instagram.com/shibabread/">이승현 - Lee seunghyun (@shibabread) * Instagram photos and videos</a></p><p>재미있는 그림이 많습니다! 마음에 드는 그림이 있으시다면 좋아요 부탁드려요~</p><h3>Deep Dive into Spark SQL’s Catalyst Optimizer</h3><p><em>이 내용은 Databricks Blog의 </em><a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html"><em>Deep Dive into Spark SQL’S Catalyst Optimizer</em></a><em>를 요약/정리한 것입니다.</em></p><p>Spark SQL은 Spark을 구성하는 요소 중 가장 최신의 기술적으로 발전 된 요소 중 하나입니다.</p><p>Spark SQL을 구현하기 위해 Scala Functional Programming 구조를 기반으로 확장 가능한 Optimizer인 Catalyst를 구현하였습니다. Catalyst의 확장 가능한 설계는 두가지 목적을 가지고 있습니다.</p><ol><li>Spark SQL에 새로운 최적화 요소나 기술 추가를 쉽게 할 수 있게 하는 것</li><li>외부 개발자들이 Optimizer를 확장시키는 것을 가능하게 하는 것</li></ol><h4>Trees</h4><p>Catalyst를 구성하는 주요 데이터 타입은 Node Object로 구성된 Tree이다.</p><p>Node 타입들은 다음과 같은 속성을 가진다.</p><ul><li>TreeNode 클래스를 상속받는다.</li><li>0개 이상의 자식을 가질 수 있다.</li><li>변경 가능하지 않다(immutable).</li><li>transformation 함수를 통해서 만들어진다.</li></ul><p>아래와 같이 3개의 노드 클래스가 존재한다고 생각해보자.</p><ul><li>Literal(value: Int): 상수 값을 표현하는 Node</li><li>Attribute(name: String): Input Row에 대한 Attribute(ex. “x”)</li><li>Add(left: TreeNode, right: TreeNode): 두 Node 표현의 합</li></ul><p>이 클래스들로 x+(1+2)를 표현하면 아래와 같이 표현이 가능하고,</p><p>Add(Attribute(x), Add(Literal(1), Literal(2)))</p><p>트리 형태로 그려보면 아래와 같이 그릴 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/300/0*oUJjVqkb57qYPsqd.png" /><figcaption>그림1. Tree 형태로 표현한 Expression(출처: <a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a>)</figcaption></figure><p>위의 Tree 예제가 실제로 Spark SQL에서 어떻게 쓰이는지에 대해서 감이 잘 오지 않았는데, <a href="https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s">A Deep Dive into Spark SQL’s Catalyst Optimizer with Yin Haui</a> 영상과 Spark SQL 코드를 참고하여 확인하였다.</p><p>일단 위 영상에서 Expression, Attribute, Query Plan 등의 용어 설명이 나온다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b76fb96360b17a8d5d0ada13dcff42a6/href">https://medium.com/media/b76fb96360b17a8d5d0ada13dcff42a6/href</a></iframe><p><strong>Expression</strong></p><p>입력 값에 의해 계산되는 새로운 값을 나타낸다. 위의 쿼리에서의 Expression의 예는 아래와 같다.</p><ul><li>1 + 2 + t1.value</li><li>t1.id = t2.id (boolean 타입 값이 생성된다)</li></ul><p><strong>Attribute</strong></p><p>Dataset의 컬럼 혹은 데이터 연산에 의해 새롭게 생성된 컬럼을 의미한다. 위의 쿼리에서의 Attribute의 예는 아래와 같다.</p><ul><li>t1.id (Dataset의 컬럼)</li><li>v (1 + 2 + t1.value에 의해 생성된 컬럼)</li></ul><p><strong>Query Plan</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/809/1*1xsB2G6DOIn_IJWR9Q9qCg.png" /><figcaption>Query Plan(출처: <a href="https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s">A Deep Dive into Spark SQL’s Catalyst Optimizer with Yin Huai</a>)</figcaption></figure><p>Input Dataset에 적용하여 새로운 Dataset을 생성해내는 Aggregate, Join, Filter와 같은 연산을 의미한다.</p><p>위와 같은 개념을 숙지하고 코드를 보았는데 Spark SQL 관련 코드는 RDD쪽 코드보다 상대적으로 상속 계층도 엄청 많고 타입이 너무 많아서 일부 내용밖에 파악하지를 못했다.</p><p>대략적으로 상속 관계를 파악해보면 다음과 같다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/941/1*wbLZ-MpE6nA_wYCoCx4fJw.jpeg" /></figure><p>정말 상속 계층이 엄청나게 복잡하다. 그래도 다이어그램을 그리면서 Expression과 QueryPlan의 정확한 차이점을 파악할 수 있었다.</p><p>Expression 중 위에서 등장했던 Add의 코드를 보면 아래와 같다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*eipaHPFN2WXdA00O6hMmvA.png" /></figure><p>symbol, decimalMethod 등 해당 Expression을 표현하는 문자열 정보와 실제 연산을 수행하는 nullSafeEval 함수가 정의되어 있다.</p><p>nullSafeEval에서 호출하는 numeric.plus의 정의를 따라가보면 아래와 같은 코드가 등장한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*K9haqZbZuTVpGrtyElZqNg.png" /></figure><p>실제 코드가 들어가야 하는 부분이 비어있는걸 보면, 위의 implicit을 이용하여 해당 구문을 처리하는 것 같이 보인다.</p><p>결론적으로 위에서 Tree는 Logical Planning 단계에서는 LogicalPlan과 Expression으로 구성되는 것을 확인할 수 있었다.</p><p>Physical Planning 단계에서는 다른 방식으로 구현이 되었는지 TreeNode를 사용하지 않고 있었다.</p><h4>Rules</h4><p>새로운 Tree는 Tree를 다른 Tree로 변경(transformation)하는 Rule을 이용하여 생성할 수 있다.</p><p>Rule을 통해 입력으로 들어온 Tree 전체를 변환할 수도 있지만, 특정 구조를 가진 Sub Tree를 찾아 변경하는 Pattern Matching Set을 적용하는 방식이 일반적이다.</p><p>Catalyst에서 Tree는 하위 모든 노드에 재귀적으로 Pattern Matching 함수를 수행하는 transform 함수를 제공한다.</p><p>우리는 아래와 같이 두 개의 상수를 더하는 Add Operation을 하나의 Literal로 Fold(접는)하는 Rule을 구현할 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/451/1*-5dXAk_5JGZT6zOB2xRmCQ.png" /><figcaption>그림2. 두 개의 상수를 더하는 Add Operation을 Folding하는 Rule(출처: <a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a>)</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OsgDL6fxO3spNHymw0W27Q.png" /><figcaption>위 Fold를 그림으로 표현해 보았다</figcaption></figure><p>Transform에서 사용되는 Pattern Matching 표현식은 입력 가능한 모든 Tree의 Subset과 일치하는 부분 함수여야 한다.</p><p><em>-&gt; 위에서 내가 작성한 코드를 예로 들자면, Add Operation의 left와 right에 올 수 있는 Node의 경우의 수는 48~51번째 줄에 정의되었다. 즉, Add Operation의 apply 함수 내의 Pattern Matching 표현식은 입력 가능한 모든 Tree의 Subset과 일치한다고 표현할 수 있다.</em></p><p>Catalyst는 이러한 Rule을 Tree에 수행한 뒤, Rule을 적용할 수 없는 Tree의 경우 해당 Tree를 건너 뛰거나 더 하위 Tree에 대해 Rule을 수행(하위 Tree는 Rule이 적용될 수도 있으므로)한다. 따라서 Catalyst의 Rule은 Optimization이 필요한 Tree에 대해서만 적용되고 그렇지 않는 Tree에 대해서는 적용되지 않는다.</p><p>Rule은 동일한 Transform 호출 내에서 여러 개의 패턴과 일치할 수 있기 때문에, 여러 Transform을 호출하지 않고 한번에 처리할 수 있도록 패턴을 정확히 구현하는 것이 중요하다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/455/1*oWN3oL4uxT1zsA2RzQO68g.png" /><figcaption>그림3. Add 표현은 위와 같이 세부적으로 나뉠 수 있다(출처: <a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a>)</figcaption></figure><p>위의 그림3이 이해가 잘 되지 않았었는데, 워낙 간략한 Operation이라서 그랬던 것 같다.</p><p>만일 Literal Add 연산이 엄청 복잡하거나 Recursive 했다면 Literal(0)인 부분에 대해서는 left나 right를 그대로 반환하여 계산을 줄이는 것이 더 좋은 방법일 수 있기 때문에, 위와 같이 세분화하는 것이 좋다고 서술한 것 같다.</p><p>Tree를 완전히 Transform 하기 위해서는 Rule이 여러 번 적용되어야 할 수 있다. Catalyst는 Rule을 Batch라는 단계로 묶고, 각 Batch를 Tree가 Rule을 적용해도 변경되지 않은 지점인 Fixed Point까지 반복해서 실행한다.</p><p>위 부분이 정확히 어떤 의미인지 파악하기가 어려워서 코드를 확인해보았다.</p><p>Rule을 Batch로 묶어 실행시켜주는 클래스는 RuleExecutor(Abstract)이며, 실제로 Batch를 실행시키는 코드는 아래와 같다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/684/1*SXRhp3v7WP8kbBjYkTh0RA.png" /><figcaption>RuleExecutor.scala</figcaption></figure><p>48 Line의 apply 함수를 통해 Batch를 실행시키며, 51 Line에서와 같이 Batch 객체에 대해 foreach문을 수행하여 Rule을 실행한다.</p><p>59Line에서 실제 Rule을 수행하고, 72 Line에서는 Iteration을 1 증가시킨다.</p><p>73 Line에서 maxIteration을 초과하여 수행하였는지(Fixed Point) 확인하고, 초과하지 않았을 경우에도 81 Line에서처럼 이전 Plan과 Rule을 통과한 Plan이 동일할 경우 더이상 해당 Rule을 적용하지 않는 것을 확인할 수 있었다.</p><h4>Using Catalyst in Spark SQL</h4><p>Catalyst에서는 4개 부분으로 나누어 Tree에 Transformation을 수행한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-Y67uNfSbchtJTDb.png" /><figcaption>Catalyst에서 SQL Query를 분석하여 RDD Code까지 Generation하는 과정(출처: <a href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a>)</figcaption></figure><ol><li>Analysis</li><li>Logical Plan Optimization</li><li>Physical Planning</li><li>Code Generation</li></ol><p><strong>Analysis</strong></p><p>Spark SQL은 SQL Parser에서 반환한 Abstract Syntax Tree(AST) 혹은 Dataframe 객체의 Relation을 계산(연산)하는 것으로부터 시작된다.</p><p>두 경우 모두 Relation이 분석되지 않은 Attribute 참조나 Relation을 포함하고 있다: 예를 들어 “SELECT col FROM sales” 쿼리에서</p><ul><li>col의 타입이 무엇인지</li><li>col이라는 컬럼 이름이 Valid한지</li></ul><p>에 대한 정보를 sales 테이블을 확인하기 전까지는 알 수 없다.</p><p>Spark SQL은 Catalyst Rule과 Catalog object(Data source의 모든 Table을 Tracking하는 객체)을 이용하여 이러한 Attribute를 분석한다.</p><p>Catalog라는 용어가 나오는데, Hive와 같은 External Datasource에 존재하는 Table이나 SparkSession에 등록된 Global, Temporary View 등을 관리하는 객체라고 생각하면 된다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*SYB7zSO5XKWOuikATDyVAA.png" /><figcaption>SessionCatalog.scala</figcaption></figure><p>위 코드는 SessionCatalog의 선언부이며, 주석에서와 같이 Hive Metastore를 Proxy로 제공하거나, Spark Session에 속한 View들을 관리한다고 나와 있다.</p><p><strong>Logical Optimizations</strong></p><p>Logical Optimization 단계에서는 Logical Plan에 Rule 기반 Optimization을 적용한다. Rule Based Optimization은 Constant Folding, Predicate Pushdown, Projection Pruning, Null Propagation, Boolean Expression Simplification 등의 Rule 들을 적용한다.</p><p>위에서 언급한 Optimization이 무엇이고, 대략적으로 어떻게 구현되어 있는지 확인해보았다.</p><p><strong>Constant Folding</strong></p><p>컴파일러 최적화에서도 사용하는 기법인데, 상수 표현식을 Runtime Time에 계산하지 않고 Compile Time에 미리 계산해버리는 방법이다.</p><p>예를 들어 아래와 같은 쿼리가 있을 때,</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/435a3bd56adcb903d5a43b2a544cdc4d/href">https://medium.com/media/435a3bd56adcb903d5a43b2a544cdc4d/href</a></iframe><p>B의 경우 1+2는 Runtime에 모든 Row에 대해 Evaluation 하는 것보다 Compile Time(Optimization 단계)에서 미리 3으로 계산해버리는 것이 처리 속도를 높일 수 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*85VQVlq6ZCeWsXTViXp-pQ.png" /><figcaption>expressions.scala 내의 ConstantFolding</figcaption></figure><p>위 코드는 Spark SQL에 포함되어 있는 ConstantFolding 코드이며, 인자로 들어온 Logical Plan이 Literal일 경우 그대로 반환하고, Foldable한 Plan일 경우 Evaluation 후 Literal로 만들어 반환한다.</p><p><strong>Predicate Pushdown</strong></p><p>일반적인 RDBMS에서도 사용하는 기법이다. 쿼리 밖에 있는 조건절을 쿼리 안쪽으로 넣는 방법이다.</p><p>이전 글에서도 설명한 예시인데, 아래와 같은 쿼리가 있을 때</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c3c2ab193b16a434f0af8eeb38db5c13/href">https://medium.com/media/c3c2ab193b16a434f0af8eeb38db5c13/href</a></iframe><p>Sub Query 밖에 있는 Where 절을 Sub Query 안쪽으로 밀어넣게 되면 불필요한 deptno에 대한 연산이 줄어들게 된다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/806/1*htO10SiSnqzs9kyXTJPEhg.png" /><figcaption>출처: <a href="https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s">https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s</a></figcaption></figure><p>위에서 언급한 영상의 내용 중 Predicate Pushdown에 대한 그림이 있어 첨부하였다.</p><p>위 그림을 보면 좌측의 경우 t1 테이블과 t2 테이블을 Join한 후 Filter를 수행한다. 어차피 t2.id가 50000 이하인 값에 대해서는 Join이후에 걸러지므로 Join이전에 Filter를 적용해버리는 방식이다.</p><p><strong>Projection Pruning</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/865/1*l2HrWQkl5tS-SzoMJwN7qQ.png" /><figcaption>출처: <a href="https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s">https://www.youtube.com/watch?v=RmUn5vHlevc&amp;t=994s</a></figcaption></figure><p>연산에 필요한 컬럼만을 가져오는 기법이다. Pruning이 적용되지 않았다면 좌측 최상단 Project 과정까지 올라가면서 t1, t2 테이블의 모든 컬럼들을 가지고 가겠지만, Pruning을 적용하게 되면 Scan 이후 필요한 컬럼만을 Project하므로 성능이 개선된다.</p><p><strong>Physical Planning</strong></p><p>Physical Planning 단계에서는 Logical Plan을 이용하여 1개 이상의 Physical Plan을 만들어낸다.</p><p>Cost Based Optimization이나 Spark Operation 관련 Optimization을 진행한다.</p><p><strong>Code Generation</strong></p><p>만들어진 Plan을 각 장비에서 실행시킬 수 있도록 Java Byte Code로 변환한다.</p><h4>마치며</h4><p>사실 Physical Planning이나 Code Generation 부분은 조금 보다가 말았다.</p><p>이 글을 쓰려고 자료를 보고 공부하는데만 해도 이틀정도가 걸려서 더 보다가는 내 할일을 못할 것 같았다.</p><p>그래도 Spark SQL이 내부적으로 어떤 방식으로 동작하는지는 알 수 있었고, 예제를 직접 코딩해보아 좋았던 시간이었다.</p><p>예제는 아래와 같이 구현하였으며, 구현하면서 들었던 생각은 코딩 자체보다 Expression Tree의 규칙을 정하고 클래스를 설계(위의 클래스 다이어그램을 보면 엄청나게 정교하게 설계되어있다)하는게 더 어렵다는 생각이 들었다.</p><p>이 코드를 작성하면서 Pattern Matching이나 Case Class에 대해 더 잘 공부할 수 있었다. 혹시 Scala 공부 중인 분이면 예제 코드를 구현해보는 것도 나쁘지 않은 생각일 것 같다.(<a href="https://medium.com/@leeyh0216/scala%EB%A1%9C-dsl-%ED%9D%89%EB%82%B4%EB%82%B4%EB%B3%B4%EA%B8%B0-561c22869a62?source=your_stories_page---------------------------">https://medium.com/@leeyh0216/scala%EB%A1%9C-dsl-%ED%9D%89%EB%82%B4%EB%82%B4%EB%B3%B4%EA%B8%B0-561c22869a62?source=your_stories_page---------------------------</a> 글도 참고 바랍니다)</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/6a1fa0e6edf2ddac9c8e18c22722f8c9/href">https://medium.com/media/6a1fa0e6edf2ddac9c8e18c22722f8c9/href</a></iframe><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=6dc3d645cc31" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[Scala for J] Trait]]></title>
            <link>https://medium.com/@leeyh0216/scala-for-j-trait-87b1e3287683?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/87b1e3287683</guid>
            <category><![CDATA[traits]]></category>
            <category><![CDATA[scala]]></category>
            <category><![CDATA[interfaces]]></category>
            <category><![CDATA[java]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Sat, 13 Oct 2018 10:18:05 GMT</pubDate>
            <atom:updated>2018-10-13T10:18:05.453Z</atom:updated>
            <content:encoded><![CDATA[<h4>Scala for Java Programmer: Interface vs Trait</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/493/0*QZ46dCS14HdPBUfy.png" /></figure><p>Scala에는 Trait이라는 단위가 있다.</p><p>보통 Java의 Interface와 많이 비교하는데, Java 1.7 버전까지의 Interface와 비교해보자면 Scala의 Trait이 압도적인 기능을 제공한다고 볼 수 있다(Java 1.8의 Interface에는 default가 추가되어 Trait을 많이 따라잡았다).</p><p>이 글에서는 Trait의 기본 개념과 활용 방법을 Java Interface와 비교하여 적어보고자 한다.</p><p>글의 내용은 Programming in Scala(마틴 오더스키, 에이콘 출판사)를 참고하였다.</p><p><a href="https://www.instagram.com/shibabread/">이승현 - Lee seunghyun (@shibabread) * Instagram photos and videos</a></p><p>재미있는 그림이 많습니다! 마음에 드는 그림이 있으시다면 좋아요 부탁드려요~</p><p>예제에도 ShibaBread가 등장합니다!!</p><h3>Interface와 Trait의 공통점</h3><h4>구현의 강제</h4><p>Java의 Interface는 구현을 강제(약속)하는데에 그 목적이 있다.</p><p>Trait 또한 구현을 강제하는 기능을 가지고 있다.</p><p>가게 점원을 추상화한 Clerk라는 Interface와 Trait을 각각 만들어보자.</p><p><strong>IClerk.java</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/01310fa26fb0a6593ce09edca63d0298/href">https://medium.com/media/01310fa26fb0a6593ce09edca63d0298/href</a></iframe><p><strong>Clerk.scala</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e7ca646eebe4c090107587cd77840fe0/href">https://medium.com/media/e7ca646eebe4c090107587cd77840fe0/href</a></iframe><p>두 코드 모두 동일하게 생성자는 없고, 내부에는 함수의 선언만 존재한다.</p><p>Interface와 Clerk를 구현/믹스인 하는 클래스에서는 반드시 greeting() 함수를 구현해주어야 한다.</p><p>아래는 Java의 IClerk Interface와 Scala의 Clerk Trait을 구현한 ShibaBreadClerk 클래스이다.</p><p><strong>ShibaBreadClerk.java</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c978bc73d58a5d2eef40fad9eeda95c6/href">https://medium.com/media/c978bc73d58a5d2eef40fad9eeda95c6/href</a></iframe><p>자바에서 Interface 상속 시에는 implements 키워드를 사용하고, 1개 이상의 Interface를 상속받을 경우 ,로 연결해주면 된다.</p><p><strong>ShibaBreadClerk.scala</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9eb38c2a9336337867c988c9dccf17c5/href">https://medium.com/media/9eb38c2a9336337867c988c9dccf17c5/href</a></iframe><p>Scala의 경우 Trait 1개를 단독으로 구현할 경우 extends 키워드를 사용하고, 2개 이상의 Trait을 사용할 경우 with 키워드로 연결해주면 된다.</p><h4>기본 함수의 제공(Java 1.8 이상)</h4><p>Java 1.7 까지는 Interface에 구현된 함수를 넣는 것이 불가능했지만, Java 1.8부터는 default 키워드를 통해 함수 구현체를 넣는 것이 가능해졌다.</p><p>즉, Java 1.7 이하 버전에서는 차이점이지만, Java 1.8 버전 이상에서부터는 공통점이라고 볼 수 있다.</p><p>Scala의 Trait에서는 별도의 키워드 없이도 함수 구현을 추가할 수 있다.</p><p><strong>IClerk.java(default 함수 추가)</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/5a3d41cd085c51f2e60852944efd621a/href">https://medium.com/media/5a3d41cd085c51f2e60852944efd621a/href</a></iframe><p><strong>IClerk.scala</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/ebeb8d8ec01547bab9ebc307957f6d94/href">https://medium.com/media/ebeb8d8ec01547bab9ebc307957f6d94/href</a></iframe><h3>Interface와 Trait의 차이점</h3><p>사실 Java 1.7까지는 Interface의 default 메소드 구현이 불가능하기 때문에 기본 함수의 제공 또한 차이점이 될 수 있다.</p><p>하지만 위에서 기본 함수 제공에 대한 내용을 기술했기 때문에, 차이점에서는 빼기로 한다.</p><p>이를 제외한 둘의 차이는 ‘변경을 쌓아올릴 수 있는가?’에 대한 것이다.</p><h4>변경 쌓아 올리기</h4><p>Java의 ArrayList는 동기화(Synchronize)를 고려하지 않고 만들어진 객체이기 때문에, Multi Thread 환경에서는 다음 3가지 방법을 사용해야 한다.</p><ul><li>ArrayList 가 들어간 Critical Section을 synchronized으로 감싼다.</li><li>Collections 에서 제공하는 synchronizedList를 통해 ArrayList를 초기화한다.</li><li>ArrayList를 상속받아 Concurrent한 ArrayList를 만든다.</li></ul><p>Scala에서는 Trait을 이용하여 이미 만들어진 클래스의 기능에 변경을 추가할 수 있다(어찌보면 3번째 방법인 상속과 유사하다)</p><p>위에서 만든 ShibaBreadClerk 클래스를 다시 한번 보자.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9eb38c2a9336337867c988c9dccf17c5/href">https://medium.com/media/9eb38c2a9336337867c988c9dccf17c5/href</a></iframe><p>어떤 경우에나 greeting 함수를 호출하면 “안녕하세요! 시바브레드입니다~”가 출력된다.</p><p>ShibaBreadClerk이 일하는 가게는 지점 별로 아래와 같이 가게 오픈 시간이 다르다.</p><ul><li>10시 ~ 18시 까지만 여는 가게</li><li>24시간 여는 가게</li></ul><p>또, ShibaBreadClerk는 언제든 그만둘 수 있고, 그 자리를 다른 점원(CatClerk, HorseClerk)이 대체할 수 있다고 한다.</p><p>이런 경우에는 상속보다 Trait의 변경 쌓아올리기를 사용하는 것이 더 좋을 수 있다.</p><p>일단 모든 Clerk이 상속받아야 하는 AbstractClerk 클래스를 만든다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/a6f09f5981107ebc65d8ab9fddbe7e2c/href">https://medium.com/media/a6f09f5981107ebc65d8ab9fddbe7e2c/href</a></iframe><p>현재 시각을 표현하는 currentHour(0~23 범위를 가짐) 필드와 greeting이라는 함수 선언을 가지고 있다.</p><p>아까 만들어둔 Clerk Trait을 AbstractClerk을 상속받도록 변경한다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/727bffe960f1e97ab5cd0dd47395fb9c/href">https://medium.com/media/727bffe960f1e97ab5cd0dd47395fb9c/href</a></iframe><p>ShibaBreadClerk, CatClerk, HorseClerk 클래스를 Clerk Trait을 믹스인하여 만든다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/64d8031fda14867a388ea5d1532d5b38/href">https://medium.com/media/64d8031fda14867a388ea5d1532d5b38/href</a></iframe><p>이제 여는 시간에 따라 greeting 구현을 변경할 수 있는 Trait을 만들어보도록 하자.</p><p>24시간 오픈하는 매장은 currentHour에 관계 없이 무조건 인사해야 하기 때문에 별도로 구현할 필요는 없고, 10시 ~ 18시까지만 여는 가게에서만 사용할 DayClerk Trait을 만들면 된다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8271b29fa32c68ea44e6dfc9674b4449/href">https://medium.com/media/8271b29fa32c68ea44e6dfc9674b4449/href</a></iframe><p>ShibaBreakClerk, CatClerk, HorseClerk에서 greeting을 구현할 때 override 키워드를 사용한 것과 다르게, 쌓아올릴 수 있는 변경을 사용할 Trait에서는 override abstract 키워드를 이용하여 함수를 구현한다.</p><p>이제 DayClerk을 기존 Clerk에 적용해보도록 하자.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/541e7335c79e016e2e0edaf4e0479581/href">https://medium.com/media/541e7335c79e016e2e0edaf4e0479581/href</a></iframe><p>4번째 shiba1객체를 초기화할 때는 일반적인 객체 선언과 동일하게 new ShibaBreadClerk()을 통해 초기화하였다.</p><p>DayClerk Trait과 같이 사용하기 위해서는 객체 초기화 시 with 구문 옆에 Trait 이름을 써주면 된다.</p><p>위 프로그램의 출력은 아래와 같다.</p><p>All Day Clerk<br>안녕하세요! 시바브레드입니다 ~ <br>DayClerk<br>이 매장은 10시부터 18시까지만 이용가능합니다.</p><p>이러한 방법을 사용하면 내가 만든 클래스를 건드리지 않고 함수에 기능을 추가할 수 있다.</p><p>만일 어떤 매장에서 인사 정책이 변경되어 인사를 한 후, 고객에게 “도움이 필요하십니까? 아니면 혼자 쇼핑하시겠습니까?” 라는 추가 멘트를 줘야 하는 경우가 발생했다고 가정해보자.</p><p>이럴 경우 아래와 같이 Trait 하나를 더 구현한 뒤,</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f0c6cea27144239a30808673f490f2b0/href">https://medium.com/media/f0c6cea27144239a30808673f490f2b0/href</a></iframe><p>with 키워드를 통해 변경 하나를 더 쌓아올리면 된다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f61abced7b1e3164385a86f836f53d3c/href">https://medium.com/media/f61abced7b1e3164385a86f836f53d3c/href</a></iframe><p>Trait의 적용 순서는 맨 우측에 선언된 Trait부터 좌측으로 이동한다.</p><p>즉, 위의 코드 4번째 줄에서 선언한 additionalGreetShiba의 greeting 함수는 DayClerk Trait의 greeting -&gt; AdditionalGreetTrait을 거쳐 원래 ShibaBreadClerk의 greeting이 호출된다.</p><p>AdditionalGreetClerk<br>Before Open<br>이 매장은 10시부터 18시까지만 이용가능합니다.<br>After Open<br>안녕하세요! 시바브레드입니다 ~ <br>도움이 필요하십니까? 아니면 혼자 쇼핑하시겠습니까?</p><p>이전에도 Github Blog에</p><p><a href="https://leeyh0216.github.io/2017/03/dev-scala-trait.html">leeyh0216&#39;s blog</a></p><p>로 포스팅한 적이 있었는데, 오랫만에 다시 Scala 문법을 보면서 작성해보았다.</p><p>물론 Trait의 쌓아올릴수 있는 변경을 적용하기 위해서는 클래스 설계가 매우 정교해져야 하지만, 제대로 설계한 이후에는 각 기능을 추가하는데에 어려움을 겪지 않을 것 같다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=87b1e3287683" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Scala로 DSL 흉내내보기]]></title>
            <link>https://medium.com/@leeyh0216/scala%EB%A1%9C-dsl-%ED%9D%89%EB%82%B4%EB%82%B4%EB%B3%B4%EA%B8%B0-561c22869a62?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/561c22869a62</guid>
            <category><![CDATA[sql]]></category>
            <category><![CDATA[dsl]]></category>
            <category><![CDATA[scala]]></category>
            <category><![CDATA[gradle]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Sat, 13 Oct 2018 04:43:39 GMT</pubDate>
            <atom:updated>2018-10-13T04:43:39.620Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*JleVUb8Uwgi-Q-cm" /></figure><p>Gradle을 사용하면서 DSL(Domain Specific Language, 도메인 특화 언어)을 접하게 되었다.</p><p>빌드 스크립트를 만드는 것과 같이 ‘한정된 주제’ 내에서 ‘반복적인 일’을 하는 상황에서는 일반적인 프로그래밍 언어보다 DSL을 만들어 제공하는 것이 매우 합리적이라는 생각이 든다.</p><p>데이터 분석에서 비개발자인 사용자분들은 SQL을 통해 데이터를 추출할 수 있는 하이브(Apache Hive)를 많이 사용하는데, 아무래도 SQL 자체가 정적이다 보니 한계가 있을 수 있다.</p><p>그러던 도중 ‘Scala를 통해 DSL을 만들고, 이를 비개발자인 사용자분들에게 제공하면 동적으로 데이터 분석을 편하게 할 수 있지 않을까?’ 라는 생각이 들었다.</p><p>그래서 간단하게 Scala를 통해 DSL 형식으로 SQL문을 만들어보는 예제를 작성해보았다.</p><p>예제 수준이므로 모든 SQL문 포팅하기는 힘들고, 간단히 SELECT, WHERE, GROUPBY Operation만을 지원하는 DSL을 만들어볼 예정이다.</p><p><a href="https://www.instagram.com/shibabread/">이승현 - Lee seunghyun (@shibabread) * Instagram photos and videos</a></p><p>재미있는 그림이 많습니다! 마음에 드는 그림이 있으시다면 좋아요 부탁드려요~</p><h3>케이스 클래스(Case Class)와 패턴 매칭(Pattern Matching)</h3><p>Scala에서는 케이스 클래스(Case Class)와 패턴 매칭(Pattern Matching)이라는 기능을 제공한다.</p><p>Java의 case문의 경우 값에 대한 분기 밖에 제공하지 않지만, Scala의 경우 객체의 형태에 따른 분기 또한 제공한다.</p><p><em>이 글에서 스칼라의 문법 설명을 하기는 어렵기 때문에, 해당 개념이 궁금하다면 </em><a href="https://docs.scala-lang.org/ko/tutorials/tour/case-classes.html.html"><em>케이스 클래스</em></a><em> 와 </em><a href="https://docs.scala-lang.org/ko/tutorials/tour/pattern-matching.html.html"><em>패턴 매칭</em></a><em> 페이지를 확인해보기를 바란다.</em></p><p>아래 코드는 패턴 매칭을 통해 AbstractFile이라는 클래스를 상속받은 디렉토리(Directory)과 파일(ConcreteFile)를 구분하는 예시이다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/8c4db992f98b5ce447323431d7546ff4/href">https://medium.com/media/8c4db992f98b5ce447323431d7546ff4/href</a></iframe><p>코드를 실행하면 아래와 같은 결과를 얻을 수 있다.</p><p>This is Directory. Directory Name: /home/leeyh0216<br>This is Concrete File. Parent Directory: /home/leeyh0216, File Name: test.out</p><p>이 기능을 활용하여 SQL에서 지원하는 Operation 들의 결합 가능성에 대해 체크할 예정이다.</p><h3>연산자(Operation) 정의하기</h3><p>위에서 소개한 케이스 클래스와 패턴 매칭 기능을 활용하여, SQL의 구문 3개(SELECT, WHERE, GROUPBY)를 Operation으로 정의해보았다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/34e10588ea28554f2d3f864333437964/href">https://medium.com/media/34e10588ea28554f2d3f864333437964/href</a></iframe><p>일단 모든 Operation들을 추상화하는 Operation이라는 Trait을 정의한다.</p><p>그 후 우리가 원하는 3가지 Operation(SELECT, WHERE, GROUPBY)를 케이스 클래스로 정의한다.</p><h4>Select</h4><p>SELECT은 테이블을 조회하는데에 사용되는 가장 기본적인 구문이다.</p><p>Select 클래스의 생성자는 테이블에서 선택할 컬럼 목록(columns: String*)을 인자로 받을 수 있게 해 놓았다.</p><p>Select 클래스의 from 메서드는 테이블명(tableName: String)을 인자로 전달받아 테이블(Table) 객체를 초기화하여 반환한다. 테이블 클래스는 아래에서 설명할 예정이다.</p><p>Select Object의 경우 Select 객체를 생성할 수 있는 함수인 select를 제공한다.</p><p>new를 통해 새로운 Select 객체를 생성하는 대신, select 함수를 이용하여 좀 더 DSL 처럼 보이게 할 예정이다.</p><h4>WhereOperation, GroupByOperation</h4><p>WhereOperation의 경우 WHERE 구문을 추상화한 클래스이며, GroupByOperation의 경우 GROUPBY 구문을 추상화한 클래스이다.</p><p>WhereOperation은 WHERE절(whereClause: String)을 생성자 인자로 전달받고, GroupByOperation은 그룹핑을 수행할 컬럼 목록(keyCols: String*)을 생성자 인자로 전달받는다.</p><p>또한 3개 클래스(Select, WehreOperation, GroupByOperation) 모두 toString() 메서드를 Override하여 문자열 형태로 구문을 생성할 수 있다.</p><h3>테이블(Table) 정의하기</h3><p>테이블 클래스는 우리가 만드는 SQL DSL의 핵심 클래스로써, DSL 구문의 Context라고 볼 수 있다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/99761da585bc4829e050af6306bf19c4/href">https://medium.com/media/99761da585bc4829e050af6306bf19c4/href</a></iframe><h4>필드 구성</h4><p>테이블 클래스의 필드는 OperationStack 객체만 존재한다.</p><p>OperationStack은 테이블에 적용되는 SQL 구문들을 저장하는 스택(Stack) 객체이다.</p><h4>메소드 구성</h4><p>메소드는 테이블을 생성하는데 사용되는 select을 제외한 where과 groupby, 그리고 and가 있다.</p><p>테이블 클래스는 빌더 패턴으로 만들어져 있기 때문에 toString() 메소드를 제외한 모든 메소드는 테이블 객체 자신을 반환하도록 만들어져 있다.</p><ol><li>where 메소드</li></ol><p>테이블에 WhereOperation을 적용한다. 인자로 전달받은 whereCluase(String)을 이용해 WhereOperation 객체를 생성하여 OperationStack에 집어넣는다.</p><p>2. groupby 메소드</p><p>테이블에 GroupByOperation을 적용한다. 인자로 전달받은 keyCols(String*)을 이용해 GroupByOperation을 생성하여 Operation 스택에 집어넣는다.</p><p>3. and 메소드</p><p>WHERE 절을 구성하는 조건이 여러 개 있을 경우 and 메소드를 사용할 수 있다.</p><p>만일 OperationStack이 비어 있을 경우 AND 구문을 사용할 수 없으므로 IllegalArgumentException을 발생시키도록 require구문을 넣어놓았다.</p><p>OperationStack이 비어있지 않을 경우 맨 위의 Operation을 선택하여 패턴매칭을 수행한다.</p><p>만일 선택된 Operation이 WhereOperation일 경우 기존 WhereOperation의 WhereCluase에 새로운 AND 구문을 추가한 WhereClause 객체를 생성하여 반환하여 OperationStack의 맨 위에 넣는다.</p><p>선택된 Operation이 WhereOperation이 아닐 경우 IllegalArgumentException을 발생시킨다.</p><p>4. toString 메소드</p><p>다른 빌더 클래스들이 .build()를 제공하는 것과 다르게 Table 클래스에서는 toString()을 Overriding하여 생성된 구문을 반환하도록 하였다.</p><h3>DSL 구문 작성해보기</h3><p>위에서 만든 클래스들을 이용하여 DSL 구문을 작성/테스트 해보았다.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/ccd0f0013be0d835246a7ffcfd341ad4/href">https://medium.com/media/ccd0f0013be0d835246a7ffcfd341ad4/href</a></iframe><p>스칼라에서는 함수로 전달되는 인자가 1개일 경우, 함수를 감싸는 ()을 사용하지 않아도 되기 때문에 위와 같이 DSL 처럼 표현할 수 있다.</p><p>위 테스트의 결과는 아래와 같다.</p><p>SELECT<br> a,b<br>FROM<br> tbl<br>GROUPBY (a,b)<br>WHERE a is not null and b is null<br> <br>requirement failed: 빈 구문에 and를 적용할 수 없습니다.<br>and 구문을 사용할 수 없는 조건입니다.</p><p>간단하게 Scala의 케이스 클래스, 패턴매칭과 빌더 패턴을 이용하여 DSL을 만들어보았다.</p><p>이렇게 Scala 를 통해 DSL을 만들고, Spark SQL과 Core에 결합하면 ‘비 개발자들도 동적으로 데이터 분석이 가능하지 않을까?’ 라는 생각이 든다.</p><p>좀 더 발전시켜서 프로젝트화 해보고 싶다는 생각 또한 들었다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=561c22869a62" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Distributed System — Introduction]]></title>
            <link>https://medium.com/@leeyh0216/distributed-system-introduction-c50883fcd3a0?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/c50883fcd3a0</guid>
            <category><![CDATA[computer-science]]></category>
            <category><![CDATA[distributed-systems]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Tue, 09 Oct 2018 12:57:43 GMT</pubDate>
            <atom:updated>2018-10-09T12:57:43.046Z</atom:updated>
            <content:encoded><![CDATA[<h3>Distributed System — Introduction</h3><p>전통적인 웹서비스나 RDBMS부터 Hadoop, 블록체인 등의 최신 기술까지 모두 분산 시스템 구조는 필수적으로 적용되어 있다.</p><p>이러한 시스템들을 사용하면서 어렴풋이 분산 시스템에 대한 개념이나 특징을 체득했을지는 몰라도 정확한 개념을 알고 사용하지는 않고 있다.</p><p>그 와중에 Distributed Systems라는 서적이 PDF 형태로 제공(<a href="https://www.distributed-systems.net/index.php/books/distributed-systems-3rd-edition-2017/">https://www.distributed-systems.net/index.php/books/distributed-systems-3rd-edition-2017/</a> 페이지에서 다운로드 가능)되고 있는 것을 알게 되었고, 공부하고 있다.</p><p>이 책을 읽으며 그간 사용해왔던 시스템들이 얼마나 분산 시스템의 개념과 특징을 잘 적용했고 이를 얼마나 잘 추상화했는지 알 수 있었다.</p><p>이 글은 위 서적의 Introduction 부분을 번역 및 요약한 글이다.</p><p>컴퓨터 시스템의 변화는 압도적으로 진행되고 있다.</p><p>1945년 모던 컴퓨터 시대가 시작된 이후부터 1985년까지 컴퓨터는 매우 크고 비쌋다. 더욱이 다른 컴퓨터와 연결할 방법이 없었기 때문에 이 시대의 컴퓨터들은 다른 컴퓨터들과 독립적으로 동작했다.</p><p>1980년대 중반부터 이러한 상황을 바꾸는 2개의 기술 발전이 있었다.</p><ol><li>강력한 마이크로프로세서의 개발</li></ol><p>8bit 에서 시작한 프로세스가 이제 16,32 bit를 거쳐 64bit까지 발전했다. 또한 멀티코어 CPU가 등장하므로써 우리는 이제 병렬성을 고려하여 프로그램을 개발해야 한다.</p><p>2. 고속 네트워크의 발전</p><p>LAN(Local Area Networks)을 통해 수천 대의 컴퓨터를 연결할 수 있고, 수 마이크로초 이내에 적은 양의 정보를 전달할 수 있다. 많은 양의 정보의 경우 몇십억 bps(bits per second) 의 속도로 전달할 수 있다.</p><p>WAN(Wide Area Networks)을 통해서는 지구 상의 수십억 대의 컴퓨터를 적게는 10에서 많게는 몇백억 bps 정도의 속도로 전달할 수 있다.</p><p>이러한 기술의 발전은 대규모 네트워크 컴퓨터 시스템을 쉽게 구성할 수 있게 했다. 이러한 컴퓨터들은 대부분 지리적으로 분산되어 있기 때문에, <strong>분산 시스템(Distributed System)</strong>이라고 불리운다.</p><h3>What is a distributed system?</h3><p><em>A distributed system is a collection of autonomous computing elements that appears to its users as a single coherent system.</em></p><p>분산 시스템은 사용자에게는 하나의 시스템으로 보이는 독립적인 컴퓨터들의 집합이다.</p><p>위 정의는 분산 시스템의 2가지 특징을 말하고 있다.</p><p>첫번째 특징은 <strong>분산 시스템을 구성하는 각 컴퓨팅 요소들이 독립적으로 동작</strong>할 수 있다는 것이다. 이러한 컴퓨팅 요소들을 일반적으로 노드(Node)라고 부르며, 이는 하드웨어 장치나 소프트웨어 프로세스가 될 수 있다.</p><p>두번째 특징은 사용자들이 <strong>분산 시스템을 다룰 때 단일 시스템을 다루는 것처럼 느낀다는 것</strong>이다. 이것은 각 노드들이 다른 노드들과 협업하여 동작하는 방법이 필요하다는 의미이다. 이러한 협업을 구성하는 것은 분산 시스템 개발의 핵심이다.</p><h4><strong>Characteristic 1: Collection of autonomous computing elements</strong></h4><p>현대 분산 시스템은 다양한 종류의 노드(Small Devices ~ High Performance Computers)로 구성될 수 있다. 분산 시스템을 구성하는 노드들이 다른 노드들과 독립적으로 실행될 수는 있다. 하지만 완전히 독립적으로 동작한다면, 그들을 같은 시스템 안에 넣을 필요가 없다.</p><p>실제로 노드들은 서로 메시지를 주고받으면서 동일한 목표를 달성하도록 프로그래밍된다. 노드들은 수신한 메시지에 반응하여 프로세스를 수행하고 다시 다른 노드로 메시지를 전달하는 방식으로 동작한다.</p><p>각 노드들의 이러한 일련의 처리 과정에서 중요한 점은, 각 노드들이 각자 자신의 notion of time을 가지고 있다는 것이다. 다르게 표현한다면, Global Clock이 존재하지 않는 것과 같다. 이러한 Global Clock의 부재는 분산 시스템에서의 동기화(Synchronization)와 코디네이션(Coordination)에 대한 질문으로 이어질 수 있으며, 이는 6장에서 다루게 된다.</p><p>분산 시스템이 어떤 노드들로 구성되어 구성되어 있고, 노드들이 어떤 노드와 통신할 수 있는지에 알 수 있게 하기 위하여 Group(Membership) 관리도 필요하다. Group은 Open Group과 Closed Group으로 나뉘어진다.</p><ul><li>Open Group: 시스템에 존재하는 어떠한 노드도 그룹 가입이 가능하다. 각 노드는 시스템에등록된 모든 노드에게 메시지를 보낼 수 있다.</li><li>Closed Group: 그룹에 가입된 노드끼리만 통신할 수 있다. 그룹에 들어오고 나가는 매커니즘이 분리되어 있다.</li></ul><p>이러한 그룹의 권한 관리는 매우 복잡하다.</p><p>첫번째로, 노드의 인증(Authenticate) 과정이 제대로 설계되지 않았다면 이 부분이 시스템의 병목(Bottleneck)이 될 수 있다.</p><p>두번째로, 각 노드가 다른 그룹의 멤버와 통신할 수 있는지 아닌지에 대해서도 설계해야 한다. 그렇지 않은 경우 침입자(Intruder)에 의한 시스템 혼란(Havoc)이 올 수 있다.</p><p>마지막으로, 멤버와 멤버가 아닌 노드들이 통신할 수 있는지에 대해서도 설계해야 한다. 이는 시스템 신뢰성에 대한 문제를 발생시킬 수 있다.</p><p>Overlay Network는 분산 시스템을 구성하는 예를 보여준다.</p><ol><li><strong>구조화 오버레이(Structed overlay)</strong></li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*_yCQLfy8n2IJN5WK.gif" /><figcaption>구조화 오버레이의 예(트리 형태), 출처: <a href="https://www.computer.org/csdl/mags/ic/2007/05/w5036-abs.html">https://www.computer.org/csdl/mags/ic/2007/05/w5036-abs.html</a></figcaption></figure><ul><li>네트워크 구성 시 토폴로지(Topology)가 반영된다.</li><li>노드 별로 연결 가능한 이웃 노드가 정해져 있다.</li><li>노드 간 연결이 구조화되어 있기 때문에 메시지 전송 시 전송 횟수가 크게 늘어나지 않는다.</li><li>노드 탐색이 유연하지 않다.</li></ul><p><strong>2. 비구조화 오버레이(Unstructured Overlay)</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/887/0*V3hlhauOMgF_XcL3.png" /><figcaption>비구조화 오버레이의 예. 출처: <a href="https://en.wikipedia.org/wiki/File:Unstructured_peer-to-peer_network_diagram.png">https://en.wikipedia.org/wiki/File:Unstructured_peer-to-peer_network_diagram.png</a></figcaption></figure><h4>Characteristic 2: Single coherent system</h4><p>단일 시스템 관점(Single Coherent view)을 사용자에게 제공하는 것은 도전적인 일이다.</p><p>예를들어, 최종 사용자는 자신이 실행한 작업이 어떤 노드에서 실행되고 있는지 알 수 없어야 한다. 또한 데이터가 어디에 저장되고 복제되는지에 대한 것도 사용자는 알 수 없어야 한다.</p><p>이러한 특징을 <strong>분산 시스템의 투명성(Distribution transparency)</strong>이라고 부르며, 이를 달성하는 것은 분산 시스템 설계의 매우 중요한 목표이다.</p><p>또한 분산 시스템은 네트워크 상에서 여러 개의 노드로 구성되어 있기 때문에, 일부 시스템 실패를 피할 수 없다. 하지만 분산 시스템에서 동작하는 응용 프로그램들은 이러한 일부 노드의 실패에서 정상적으로 동작할 수 있어야 한다.</p><h3>Design Goals</h3><h4>Supporting resource sharing</h4><p>사용자는 분산 시스템 상의 자원을 쉽게 공유하고 접근할 수 있어야 한다. 자원은 데이터, 파일, 서비스, 네트워크 등 어떠한 것도 될 수 있다.</p><h4><strong>Making distribution transparent</strong></h4><p>분산 시스템은 프로세스와 자원이 시스템을 구성하는 물리적인 컴퓨터에 분산되어 있다는 사실을 감추어야 한다(Offering Coherent View). 이를 <strong>프로세스와 자원의 투명성</strong>을 달성한다고 한다.</p><p><strong>Type of distribution transparency</strong></p><p>투명성의 개념은 분산 시스템의 여러 부분의 관점에서 생각해볼 수 있다. 각 관점에서의 투명성은 아래와 같으며, 개체(object)라는 표현은 프로세스 혹은 리소스를 의미한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5oIpS0aTFdE1RUoFl9vCAw.png" /><figcaption>여러 관점에서의 분산 시스템에서의 투명성</figcaption></figure><p><strong>접근 투명성(Access Transparency)</strong>은 데이터 표현의 차이와 개체 접근 방법을 숨긴다. 기본적으로 장비 설계구조를 숨기며, 더 나아가 데이터들이 이런 다른 장비 설계와 운영체제 하에서 어떻게 다르게 표현되는지를 숨긴다.</p><p>예를 들어 분산 시스템은 다른 운영체제가 설치된 노드들로 구성될 수 있고, 각기 다른 운영체제는 File Naming Convention, File Operation 등에서 차이를 가질 수 있다. 이러한 저레벨(Low Level)수준의 세부사항은 사용자와 응용 프로그램으로부터 숨기는 것이 좋다.</p><p><strong>위치 투명성(Location Transparency)</strong>은 사용자가 자신이 사용하는 개체가 시스템 상에 물리적으로 어디에 위치해있는지 숨기는 것이다.</p><p>예를 들어 <a href="http://www.prenhall.com/index.html">http://www.prenhall.com/index.html</a> 이라는 URL(Uniform Resource Locator)은 해당 사이트가 동작하는 웹서버에서 index.html 파일이 실제로 어디에 위치하는지에 대한 단서를 제공하지 않는다.</p><p><strong>재배치 투명성(Relocation Transparency)</strong>은 개체가 옮겨지는 것에 대한 정보를 사용자에게서 숨긴다.</p><p>위의 예에서 사용자는 index.html 파일이 원래 파일인지, 새로운 파일이 기존 파일을 대체한 것인지 알 수 없다. 또한 재배치 투명성은 Cloud Computing에서 매우 중요한 주제 중 하나이다.</p><p><strong>복제 투명성(Replication Transparency)</strong>은 리소스의 복사본이 여러개 있는 것을 사용자에게서 숨기는 것이다.</p><p>리소스는 가용성을 높이거나, 리소스 사용시의 퍼포먼스를 높이기 위해서(Locality 관점에서의 접근같다) 복제가 이루어진다.</p><p>복제 투명성을 달성하기 위해서는 복제 대상 파일이 여러 위치에 같은 이름으로 존재해야 하고, 위치 투명성이 보장되어 사용자가 자신이 사용하는 파일이 복제본인지 아닌지에 대한 것을 알 수 없어야 한다.</p><p><strong>병행 투명성(Concurrency Transparency)</strong>은 동일한 자원을 다른 사용자가 사용하고 있다는 것을 숨기는 것이다.</p><p>공유 자원에 동시 접근(Concurrent)하는 것에서 가장 중요한 문제는 자원을 일관적인 상태로 유지하는 것이다. 이러한 일관적인 상태는 시스템에서 락(Locking Mechanisms)을 제공하므로써 달성할 수 있다.</p><p>락을 제공하는 시스템에서 사용자들은 공유 자원 접근 시 순서대로 독점 접근을 할 수 있다. 더 나아가 트랜잭션(Transaction)을 사용하게 할 수도 있지만, 이러한 방법은 분산 시스템에서 구현하기 어렵고, 확장(Scalability) 이슈를 만들어낼 수도 있다.</p><p><strong>실패 투명성(Failure Transparency)</strong>은 사용자들이 일부 시스템의 실패와 이를 복구하는 과정에 대해 숨기는 것이다.</p><p>실패 투명성에서 가장 어려운 것은 실제로 모든 자원이 사용할 수 없게 되었는지, 아니면 실패한 자원을 복구하는 과정에서 응답시간이 늦어지는지를 구분할 수 없는 것이다.</p><p><strong>Degree of distribution transparency</strong></p><p>모든 투명성을 만족시키는 것은 불가능하며, 가능하더라도 모든 상황을 만족시킬 수는 없다.</p><p>높은 투명성(High degree of transparency)을 만족시키는 것과 시스템 성능(Performance of a system)사이에는 Trade Off가 발생하기 때문이다.</p><p>따라서 모든 투명성을 만족시킬 필요는 없으며,<strong> 최대한 달성하려고 노력</strong>하면 되는 것이다.</p><h4>Being open</h4><p>개방성(Openness)은 분산 시스템의 또다른 중요한 목표 중 하나이다. 개방된 분산 시스템은 다른 시스템이 쉽게 사용 및 연동할 수 있는 시스템이다.</p><p>개방형이라는 것은 시스템 구성요소가 자신이 제공하는 구문(Syntax)과 의미(Semantics)를 설명하는 표준 규칙을 준수한다는 것이다. 즉, 구성 요소와 상호작용할 수 있는 인터페이스(Interface)를 잘 정의하는 것이다.</p><p>컴포넌트는 인터페이스를 제공하므로써 다른 임의의 프로세스와 일관된 방식으로 상호작용이 가능해진다.</p><p><strong>상호 운용성(Interoperability)</strong>은 이러한 인터페이스를 통해 두개의 다른 시스템이나 컴포넌트가 서로에 의지하여 동작할 수 있는 특징을 의미한다.</p><p><strong>이식성(Portability)</strong>은 A 시스템에서 동작하던 응용 프로그램이 동일한 인터페이스를 가진 B시스템에서도 수정 없이 동작할 수 있는 것을 의미한다.</p><p><strong>확장성(Extensibility)</strong>은 시스템을 구성하는 컴포넌트를 다른 컴포넌트로 교체할 수 있어야 한다는 것을 의미한다.</p><h4><strong>Being Scalable</strong></h4><p><strong>Scalability dimensions</strong></p><p>시스템의 확장성은 최소 3개의 차원에서 측정할 수 있다.</p><ul><li>규모 확장성(Size scalability)</li><li>지리적 확장성(Geographical scalability)</li><li>관리 확장성(Administrative scalability)</li></ul><p><strong>규모 확장성(Size scalability)</strong>을 가진 시스템에서는 시스템 자원을 쉽게 추가할 수 있다.</p><p>특정 서버에 의존적인 서비스들은 요청량(Request)가 늘어날 수록 병목현상(Bottleneck)이 발생하게 된다. 대부분 병목현상을 일으키는 원인은 아래 세가지이다.</p><ul><li>Computational capacity, limited by CPUs</li><li>Storage capacity, including the I/O transfer rate</li><li>The network between the user and the centralized service</li></ul><p>이러한 병목현상들을 해결하는 방법은 아래 Scaling Techniques 에서 다루도록 한다.</p><p><strong>지리적 확장성(Geographical scalability)</strong>을<strong> </strong>가진 시스템에서는 사용자와 시스템이 물리적으로 멀리 떨어져있어 발생하는 통신 지연을 알아차리기 어렵다.</p><p>분산 시스템은 Local Area Network 상에서 이용하도록 설계되었기 때문에, Synchronous Communication 을 기반으로 한다. 때문에 LAN 환경에서는 수백 마이크로초에서 처리되던 요청도 WAN 환경으로 넘어간다면 수백 밀리초까지도 처리 시간이 늘어날 수 있다.</p><p>이러한 문제에 대한 대응책도 추후에 다룰 예정이다.</p><p><strong>관리적 확장성(Administrative scalability)</strong>을 가진 시스템은 여러 시스템 관리 조직이 시스템을 관리할지라도 쉽게 관리할 수 있다.</p><p><strong>Scaling techniques</strong></p><ol><li>Scaling up &amp; out</li></ol><p>대부분 분산 시스템에서 발생하는 성능(Performance) 문제는 서버와 네트워크의 성능(Capacity)의 한계에서 발생한다. 이러한 문제를 해결하기 위해 Scaling up과 Scaling out이라는 기법을 사용한다.</p><p>Scaling up은 부족한 자원의 성능(Capacity)을 향상(CPU 업그레이드, 메모리 증설, 네트워크 증설 등)시키는 기법이다.</p><p>Scaling out은 장비를 추가하므로써 전체 성능을 증가시키는 방법이다.</p><p>2. Partitioning and distribution</p><p>파티셔닝(Partitioning)과 분산(Distribution) 기법은 컴포넌트를 시스템 전반에 걸쳐 작게 나누어 쪼개는 방법이다.</p><p>서적에는 DNS(Domain Name Server)와 Web 구조를 통해 설명했는데, 내가 익숙한 MongoDB의 Sharding 기반으로 이해했다.</p><p>Sharding은 Collection(RDBMS에서의 Table) 단위로 제공하는데, Sharding 기능이 적용된 Collection에 데이터를 저장할 때는 데이터를 Index 기반으로 나누어 여러 서버에 저장한다. Sharding을 통해 얻어낼 수 있는 장점은 아래와 같다.</p><ul><li>데이터가 여러 서버에 나뉘어 저장되기 때문에 큰 규모의 Collection도 구성할 수 있다. Sharding을 적용하지 않으면 단일 Collection의 크기는 서버 Disk에 제한을 받게 된다.</li><li>Read 시 Broker를 통해 데이터가 실제로 저장되어 있는 서버 목록을 전달받은 후 실제 Read Operation은 해당 서버들에 대해서 수행한다. 따라서 Read 부하 분산을 이뤄낼 수 있다.</li></ul><p>3. Replication</p><p>복제(Replication) 또한 두 가지 장점을 가지는데 파티셔닝과 분산에서 언급한 장점과 겹치는 부분이 있다.</p><ul><li>가용성(Availability)이 높아진다. Process의 Replication의 경우 SPOF(Single point of failure)를 막을 수 있고, Data의 Replication의 경우 서버 문제로 인한 데이터 유실을 막을 수 있다.</li><li>부하 분산(Load Balancing)을 얻어낼 수 있다. 동일한 Process 혹은 Data가 여러 서버에 걸쳐 존재하기 때문에 요청을 분산시킬 수 있다.</li></ul><p>4. Caching</p><p>캐싱(Caching)은 복제(Replication)의 특별한 형태이다.</p><p>복제와 같이 자원을 복사하는 것은 같지만, 캐싱은 자원 소유자가 아닌 사용자에 의해 결정된다.</p><p>캐싱과 복제 모두 복사본 간에 일관성(Consistency) 문제를 일으킬 수 있다.</p><p>예를 들어, 웹 사용자들은 동일 페이지를 접근하는 경우 웹 브라우저에 저장된 캐시 데이터를 보는 경우가 존재하는데, 이미 원본이 변경되었을지라도 변경된 내용이 사용자의 페이지에 반영되지 않는다. 이는 캐시 데이터의 일관성이 보장되지 않기 때문이다.</p><p>이와 다르게 캐시 데이터의 일관성이 강력하게 보장되어야 하는 경우가 있다.</p><p>주식이나 경매 시장이 그 예인데, 이러한 경우 원본의 변경 사항을 복제본에게 전달하는 방식으로 일관성을 유지할 수 있다.</p><p>더 나아가 원본 데이터를 동시에 변경하는 요청이 발생할 경우, 복사본에도 이러한 요청이 순차적으로 반영되어야 한다.</p><p>복제(+캐싱)는 이러한 전역적 동기화(Global Synchronization) 과정을 필요로 하며, 전역적 동기화는 성능 향상이 매우 어렵거나 불가능하다. 이 부분은 추후 7 챕터에서 설명하도록 한다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c50883fcd3a0" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Spark Internal Part 2. Spark의 메모리 관리(2)]]></title>
            <link>https://medium.com/@leeyh0216/spark-internal-part-2-spark%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC-2-db1975b74d2f?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/db1975b74d2f</guid>
            <category><![CDATA[memory-management]]></category>
            <category><![CDATA[apache-spark]]></category>
            <category><![CDATA[spark]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Sun, 07 Oct 2018 16:46:44 GMT</pubDate>
            <atom:updated>2018-10-07T16:46:44.808Z</atom:updated>
            <content:encoded><![CDATA[<h4>Unified Memory Management in Spark 1.6(1)</h4><p>이 글은 Andrew Or 와 Josh Rosen 두 분께서 Apache Spark Jira <a href="https://issues.apache.org/jira/browse/SPARK-10000">[SPARK-10000] Consolidate storage and execution memory management</a> 에 첨부한 문서를 번역한 글입니다.</p><p>해당 문서는 Spark 1.5 이하 버전에서의 메모리 관리 방식과 단점에 대해 설명한 후(Existing memory management), 이를 해결하기 위해 도입할 예정인 Unified Memory Manager의 설계(Design)와 구현(Implementation)으로 전개됩니다.</p><p>문서 자체가 10 페이지가 넘기 때문에 하나의 글로 작성하기 보단 Spark 1.5 이하 버전과 이후 버전을 나누어 번역하려 합니다.</p><p>이 글에서는 Existing memory management(1.5버전 이하에서 사용되는) 내용에 대해 서술하고, Unrolling이라는 과정에 대해 코드 분석을 진행해 보았습니다.</p><p>Unrolling에 대해 다룬 글이 별로 없고, 몇몇 글에서 언급한 내용과 문서의 내용이 일치하지 않아 최대한 코드로만 접근해보았습니다.</p><h3>Overview</h3><p>Spark에서의 메모리 사용은 크게 2개(Execution, Storage)로 나눌 수 있습니다.</p><p>Execution 메모리는 Shuffle, Join, Sort, Aggregation에서 사용되는 메모리를 지칭하며, Storage 메모리는 Caching이나 클러스터 전반에 내부 데이터를 전파하는데에 사용되는 메모리를 지칭합니다.</p><p>Spark 1.5를 포함한 하위 버전에서는 위 2개의 메모리 공간이 정적으로 구성되었기 때문에, 서로의 공간에 할당된 메모리 공간을 가져와 사용할 수 없었습니다. 이러한 엄격한 분리로 인해 몇몇 제약사항들이 발생했습니다.</p><ul><li>모든 Workload에 사용할만한 적절한 기본값이 없다.</li><li>Memory Fraction을 튜닝할 때 사용자가 내부 구조를 잘 알고 있어야 한다.</li><li>Cache를 사용하지 않는 프로그램의 경우 사용가능한 메모리 중 매우 적은 영역만을 사용한다.</li></ul><p><strong>이 글은 기존의 메모리 영역을 통합하여 이러한 제약사항을 없애는 것이 목표입니다.</strong></p><p>최종 결과물은 성능 개선과 사용자가 최적의 메모리 사용량을 튜닝하는 필요성을 없애는 것입니다. 또한, 메모리 할당을 더이상 어플리케이션 단위로 고정 설정하지 않기 때문에 단일 어플리케이션이 과도한 Spilling 없이도 여러 종류의 Workload를 지원할 수 있어야 합니다.</p><h3>Existing memory management</h3><p>Spark의 기존 메모리 관리는 정적인 메모리 분할(Memory fraction)을 통해 구조화 되어 있습니다.</p><p>메모리 공간은 3개의 영역으로 분리되어 있습니다. 각 영역의 크기는 JVM Heap 크기를 Spark Configuration에 설정된 고정 비율로 나누어 정해집니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9GAKR18DBS1Aqz-0qmZZgA.png" /></figure><ul><li><strong>Execution: </strong>이 영역은 Shuffle, Join, Sort, Aggregation 등을 수행할 때의 중간 데이터를 버퍼링하는데에 사용됩니다. 이 영역의 크기는 spark.shuffle.memoryFraction(기본값: 0.2)를 통해 설정됩니다.</li><li><strong>Storage:</strong> 이 영역은 주로 추후에 다시 사용하기 위한 데이터 블록들을 Caching하기 위한 용도로 사용되며, Torrent Broadcast(?)나 큰 사이즈의 Task 결과를 전송하기 위해서도 사용됩니다. 이 영역의 크기는 spark.storage.memoryFraction(기본값: 0.6)을 통해 설정됩니다.</li><li>Other: 나머지 메모리 공간은 주로 사용자 코드에서 할당되는 데이터나 Spark에서 내부적으로 사용하는 메타데이터를 저장하기 위해 사용됩니다. 이 영역은 관리되지 않는 공간이기 때문에 더이상 언급하지 않을 것이며, 기본값은 0.2입니다.</li></ul><p>각 영역 메모리에 상주된 데이터들은 자신이 위치한 메모리 영역이 가득 찬다면 Disk로 Spill됩니다. Storage 영역의 경우 Cache된 데이터는 전부 Drop되게 됩니다. 모든 경우에서 데이터 Drop이 발생하면 I/O 증가 혹은 Recomputation으로 인한 성능 저하가 나타나게 됩니다.</p><h4>Memory fraction breakdown</h4><p>잠재적인 OOM(Out of memory error)을 피하기 위해 Spark의 메모리 관리는 예상치 못한 큰 Item이 데이터 내에 들어오는 것과 같은 상황에 ‘매우’ 유의합니다. 이러한 이유때문에 각 영역에서는 Safety Fraction영역을 Data Skew를 위한 추가 버퍼로 제공합니다.</p><p><em>-&gt; 내가 알고 있었던 Data Skew는 데이터가 특정 노드로 편중되는 현상이고 단순 번역을 해 보아도 동일한 뜻으로 해석되는데, 구글 번역에 넣고 돌려보면 위 문장에서의 Data Skew는 ‘데이터 분출’이라고 해석된다. 사실 ‘데이터 분출’이 더 맥락에 맞긴한데 정확히 해석되지 않기 때문에 원문 표현을 그대로 가져다 쓴다.</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/395/1*0WfWQar3_fOQYHbcy8_LXA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6wQMz_kslOg6qvTorkq20g.png" /></figure><p>이는 Spill이 발생하는 기본 제한이 전체 Heap 공간 중 16%(spark.shuffle.memoryFraction * spark.shuffle.safetyFraction)밖에 되지 않는다는 것을 의미합니다. 어떠한 데이터도 Cache하지 않는 어플리케이션들은 Heap 공간을 낭비하게 됩니다. 이 과정에서 작업들은 중간 데이터들을 불필요하게 Disk에 Spill한 후 즉시 읽어들입니다. Unroll Fraction에 대해서는 다른 Section에서 언급할 예정입니다.</p><h4>Execution memory management</h4><p>Execution 메모리는 JVM에서 실행되는 Active Task 작업들이 나누어 가집니다. 위의 영역들에 정적으로 메모리가 할당되는 것과 달리 Task들에게 메모리를 할당하는 것은 동적입니다.</p><p>Spark은 각 Slot에 고정된 Chunk를 할당하는 방법을 사용하지 않습니다. Spark은 동일한 JVM에서 동작하고 있는 Active Task가 없는 경우 하나의 Task에 사용가능한 모든 Execution 메모리를 할당하기도 합니다.</p><p>이러한 동작을 할 수 있도록 몇몇 메모리 매니저들이 존재합니다.</p><ul><li><strong>ShuffleMemoryManager</strong>: Global Accounting과 Policy Enforcement를 담당합니다. ShuffleMemoryManager는 얼마나 많은 메모리를 Task에게 할당할지를 결정하는 중앙 중재자입니다. JVM 당 1개씩 존재합니다.</li><li><strong>TaskMemoryManager</strong>: Task 별로 메모리 할당과 Bookkeeping을 담당합니다. TaskMemoryManager는 On-Heap Block을 추적하기 위한 Page Table과 Task가 종료될 때 모든 Page가 해제되지 않는 경우 Exception을 발생시켜 Memory Leak을 추적하는 기능이 구현되어 있습니다. 내부적으로 TaskMemoryManager는 ExecutorMemoryManager를 사용하여 실제 Allocation과 Free를 수행합니다.</li><li><strong>ExecutorMemoryManager</strong>: ExecutorMemoryManager는 On-Heap과 Off-Heap 메모리 할당을 담당합니다. 또한 ExecutorMemoryManager에는 Task 간에 Free된 Page 재사용을 허용하기 위한 Weak Reference Pool이 구현되어 있습니다.</li></ul><p>이러한 메모리 매니저들은 아래와 같이 상호작용합니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KKu8oEOnVg3_5F5QRnIOtA.png" /></figure><ol><li>Task가 메모리에 큰 공간을 할당받기를 원한다면 ShuffleMemoryManager에게 X byte 할당을 요청합니다.</li><li>ShuffleMemoryManager가 요청을 허용했다면, Task는 TaskMemoryManager에게 X byte 할당을 요청합니다.</li><li>TaskMemoryManager는 요청을 수신한 후 Page Table을 업데이트합니다.</li><li>ExecutorMemoryManager에게 X byte 할당을 요청합니다.</li><li>ExecutorMemoryManager는 Task가 사용할 수 있도록 실제로 X byte를 할당합니다.</li></ol><p><strong>Memory allocation policy</strong></p><p>각 Task는 ShuffleMemoryManager로부터 Execution 메모리의 1/N(N은 Active Task의 갯수)를 얻을 수 있습니다. 만일 할당 요청의 일부만이 받아들여졌다면, Task는 메모리에 상주해있는 데이터를 Disk로 Spill합니다.</p><p>과도한 Spill을 피하기 위해 Task는 전체 메모리의 1/(2N)을 획득할 수 있을 때까지 Spill을 수행하지 않습니다. 만일 1/(2N)을 얻을 수 없을 정도로 메모리가 부족한 경우, 메모리 할당 요청은 다른 Task가 메모리의 데이터를 Spill하여 남는 공간을 공유하기 전까지 Block 됩니다.</p><p><strong>예시</strong></p><ul><li>Executor가 시작된 후 Task A가 먼저 실행됨</li><li>Task A는 다른 Task들이 존재하지 않기 때문에 전체 Execution 메모리를 할당받음</li><li>두번째 Task인 Task B가 실행됨. N이 2가 되었기 때문에, B는 Execution 메모리의 1/4(=1/2N)을 획득하기 전까지 Block 됨</li><li>Task A가 메모리에 상주하고 있던 데이터를 Spill 하여 Execution 메모리의 1/4가 확보되는 경우 Task B가 실행되고, 이후에는 두 작업 모두 Spill이 가능해짐</li></ul><p><strong>Note</strong></p><p>Task A는 메모리 매니저로부터 메모리 할당을 받는데에 실패할 때까지(더이상 할당해줄 메모리가 없을 때까지) Spill을 수행하지 않습니다. 그동안에는 새로운 Task들은 이미 동작 중인 Task들이 모든 메모리를 점유하고 있기 때문에 Starvation 상태에 빠지게 됩니다. 이것은 Spilling mechanism을 강제하는 방식으로 해결할 수 있지만 이 문서의 범위에서 벗어나 있습니다.</p><h4>Storage memory management</h4><p>Storage 영역은 BlockManager에 의해 관리된다. 주 사용 목적은 RDD Partition을 Caching하는 것이지만, Torrent broadcast나 Driver로 대규모 작업 결과를 보내는데에도 사용된다.</p><p><strong>Storage Level</strong></p><p>각 Block은 해당 Block이 Memory, Disk, Off-Heap 중 어디에 저장될지 명시하는 Storage Level에 연관되어 있다. Block은 Memory가 부족할 때 Memory에서 Disk로 Evict되어 Memory와 Disk 모두에 존재하는 경우도 있다.</p><p>Storage Level은 또한 Block이 Serialized 된 형태로 저장되는지 아닌지에 대해서도 명시합니다. MEMORY_AND_DISK_SER Storage Level은 특히 주목해야합니다. MEMORY_AND_DISK_SER Storage Level에서는 Block이 이미 Serialized 된 ByteArray 상태로 Memory에 존재하기 때문에 Disk로 Evict할 때 Serialize하지 않아도 되서 Evict 비용이 저렴합니다.</p><p><strong>Eviction policy</strong></p><p>현재 Eviction policy는 LRU(Least Recently Used) 알고리즘이 적용되어 있습니다. 여기에는 2가지 예외가 있습니다.</p><ul><li>RDD의 Block을 Cache하기 위해서 해당 RDD를 Evict하지 않습니다.</li><li>Unrolling이 실패할 경우, 해당 블록은 바로 Evict 됩니다.</li></ul><p><strong>Unrolling</strong></p><p>BlockManager는 Iterator 형태로 Block 데이터를 수신한 후, Block이 메모리에 상주해야하는 경우에는 Iterator를 Array 형태로 Unroll 합니다.</p><p>그러나 전체 Iterator가 메모리에 들어갈 수 없을 경우가 있기 때문에(메모리 공간이 데이터 크기보다 작을 경우), BlockManager는 OOM(Out of memory error)를 피하기 위해 Array로 Unroll하기 위한 공간이 적당한지 체크하며 점진적으로 Unroll을 수행합니다.</p><p>Unrolling을 위해 사용되는 메모리는 Storage 공간입니다. Block이 존재하지 않는 경우에 Unrolling은 Storage 공간을 모두 사용할 수 있습니다. 반면에 Unrolling은 메모리 공간이 부족한 경우 spark.storage.unrollFraction 값에 의해 20%까지 줄어들 수 있습니다.</p><h4>Unrolling에 대하여</h4><p>Unrolling이라는 과정이 있다는 것을 이번에 처음 알게 되었다. 출판된 서적에서는 본적이 없었던 것 같고, <a href="https://0x0fff.com/spark-memory-management/">해외 블로그에 작성된 글</a>에서는 간간히 등장했다. 결국은 코드에서 Unroll 과정을 찾아보기로 했고, <a href="https://medium.com/@leeyh0216/spark-internal-part-1-rdd%EC%9D%98-%EB%82%B4%EB%B6%80-%EB%8F%99%EC%9E%91-d50eb7a235e6">Spark Internal Part 1. RDD의 내부동작</a> 에서 RDD가 연산되는 과정을 따라갔었는데, 해당 코드 이후에 Unroll 과정이 등장하는 것을 확인하였다. 다시 한번 해당 코드부터 추적을 시작하여 Unrolling이 어떤 과정인지 알아보도록 한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/674/1*iUbxth3D9-e5hBaFnQJBfg.png" /><figcaption>RDD.scala의 getOrCompute 함수</figcaption></figure><p>위 코드를 보면 332 Line에서 RDD를 구성하는 Partition의 Block ID를 가져오고, 335 Line에서 해당 Block을 연산하기 위해 BlockManager의 getOrCompute 함수를 호출한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/689/1*U_SK_YdMfX_tpWlkasNGwA.png" /><figcaption>BlockManager.gerOrElseUpdate 함수</figcaption></figure><p>getOrElseUpdate 의 819 Line에서는 우리가 연산할 RDD Block을 Local 혹은 Remote에서 가져온다.</p><p>826 Line에서는 doPutIterator 함수를 호출하여 Block에 대해 우리가 map, reduce 를 통해 전달한 함수 f를 적용하게 된다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/699/1*kkUnzXGaW8O4-rabpdTv4A.png" /><figcaption>BlockManager.doPutIterator 함수</figcaption></figure><p>doPutIterator 함수에서는 StorageLevel에 따라 MemoryStore, DiskStore 객체를 통해 Unrolling을 수행하게 된다.</p><p>1109 Line을 보면 MemoryStore 객체의 putIteratorAsValues 함수를 호출하고, 이 함수는 다시 MemoryStore 객체의 putIterator 함수를 호출한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/665/1*CO3U1VXwosi9TBGsKARKMg.png" /><figcaption>MemoryStore.putIterator 함수 정의</figcaption></figure><p>putIterator 함수의 167 Line 주석을 보면 Iterator가 메모리보다 큰 경우에 OOM이 발생할 수 있기 때문에 충분한 메모리 공간을 확보하며 Iterator를 점진적으로 Unroll한다고 쓰여 있다.</p><p>그렇다면 실제 Unroll 이 어떻게 수행되는지 코드를 통해 확인해보자.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/684/1*VWiE2olROnElba2h1xqv9A.png" /><figcaption>MemoryStore.putIterator 함수의 194 ~ 217 Line 초기화 부분</figcaption></figure><p>putIterator 함수의 194 ~ 217 Line은 Unrolling을 하기 위한 설정들을 로드한다.</p><p>198 Line의 initialMemoryThreshold은 Unrolling에 사용되는 메모리의 초기값인데, 이 값은 아래와 같이 spark.storage.unrollMemoryThreshold 속성값을 사용하며, 초기 값은 1024*1024 이다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/543/1*F3C3fbu5d-Fm7zu6pC1jMg.png" /></figure><p>200 Line의 memoryCheckPeriod는 Iterator를 돌며 몇개의 요소를 로드했을 때마다 남은 메모리 공간을 체크할 것인지에 대한 값이다.</p><p>spark.storage.unrollMemoryCheckPeriod를 사용하며 기본 값은 16이다. 즉, 16개의 요소를 로드할 때마다 남은 메모리 공간을 체크한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/595/1*gPH6Or4QqIL9YV_kUQ1eVw.png" /></figure><p>memoryGrowthFactor는 메모리 할당 요청을 할 때마다 몇배씩 증가하여 요청할 것인가에 대한 값이다.</p><p>209 Line에서는 reserveUnrollMemoryForThisTask 함수를 호출하여 Unrolling에 필요한 메모리 공간을 할당받는다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/648/1*57t1BTeN6faSZbxX7O16DQ.png" /></figure><p>551 Line에서와 같이 MemoryManager 객체의 acquireUnrollMemory를 호출하여 필요한 메모리를 할당받으며 기본적으로 1.6 이상부터는 UnifiedMemoryManager를 사용하고, LegacyMode를 사용할 경우에만 StaticMemoryManager를 사용한다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/680/1*R1xzwbc8BfWLON_6VkJL-Q.png" /></figure><p>220 Line부터 기존 Block에 f를 적용한 결과(values)를 저장하는 과정을 보여준다.</p><p>부모 RDD Block에 f를 적용한 결과인 values의 크기가 현재 사용가능한 메모리 공간보다 작은 경우에는 문제가 없겠지만, 만일 큰 경우에는 Iterator의 모든 요소들을 메모리로 올리는 과정에서 OOM이 발생할 것이다.</p><p>따라서 Iteration 과정 중 일정 주기마다 메모리를 체크하여, 할당받은 메모리 공간을 초과할 경우 추가적으로 메모리를 할당받는 과정을 거친다.</p><p>222 Line을 보면 memoryCheckPeriod마다 메모리 체크를 수행하는 것을 확인할 수 있고, 225 Line에서는 연산 결과를 저장하는 ValuesHolder(Vector) 객체의 크기와 할당받은 메모리 크기를 비교하여 메모리가 부족한 경우 228 Line에서와 같이 메모리를 재할당받은 후 Iteration을 진행해나가는 것을 볼 수 있다.</p><p>3년 전 Spark 1.6 버전에서 RDD를 사용할 때만해도 OOM이 두려웠는데, 요즘은 Spark SQL을 사용하고 GroupBy 관련 코드보다는 Join 위주로 작성하는 경우가 대부분이라서 메모리 관련 오류를 겪어본 적이 없었던 것 같다.</p><p>이 글을 번역하면서 메모리 관리 자체보다는 다른 개발자들이 문제 상황에 직면해서 이를 어떻게 풀어나가는지에 대해 더 많이 공감하게 되었던 것 같다.</p><p>특히 Unrolling에 대해 코드분석을 진행하는 과정에서 Iterator 패턴 사용과 메모리 관련 코드 설계를 얼마나 치밀하게 했는지 느낄 수 있었고, 향후에 이러한 접근방식을 내 프로젝트에도 적용할 수 있을 것이라 생각한다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=db1975b74d2f" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[자료구조] 1. 연결리스트]]></title>
            <link>https://medium.com/@leeyh0216/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-1-%EC%97%B0%EA%B2%B0%EB%A6%AC%EC%8A%A4%ED%8A%B8-ca96a40e44f0?source=rss-7d11002906ed------2</link>
            <guid isPermaLink="false">https://medium.com/p/ca96a40e44f0</guid>
            <category><![CDATA[data-structures]]></category>
            <category><![CDATA[linked-lists]]></category>
            <category><![CDATA[arraylist]]></category>
            <dc:creator><![CDATA[이용환]]></dc:creator>
            <pubDate>Wed, 03 Oct 2018 04:04:31 GMT</pubDate>
            <atom:updated>2018-10-03T04:23:04.958Z</atom:updated>
            <content:encoded><![CDATA[<h3>배열의 한계</h3><p>대부분의 프로그래밍 언어에서는 데이터의 집합을 표현하기 위해 배열(Array)을 제공한다.</p><p>배열은 초기화 시 설정된 값으로 크기가 정해지며, 크기를 변경하기 위해서는 는 원하는 크기의 새로운 배열을 선언한 뒤 값을 복사하는 방법 밖에 없다.(C언어에서의 realloc을 사용한 크기 확장은 제외한다)</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/39c95bb5899af5cf2fe21890ecf0f478/href">https://medium.com/media/39c95bb5899af5cf2fe21890ecf0f478/href</a></iframe><p>위의 코드는 Java에서 배열의 크기를 확장하는 예제이며 단순화하면 아래와 같은 방식으로 동작한다.</p><ol><li>크기 N인 배열을 선언하여 사용한다.</li><li>N+1번째 요소를 삽입할 때 삽입할 공간이 부족하기 때문에 새로운 배열을 선언하고, 기존 배열의 값을 새로운 배열에 복사한 후 N+1번째 요소를 삽입한다.</li><li>기존 배열을 가리키던 변수가 새로운 배열을 가리키도록 한다.</li></ol><p>이 과정을 거치면 아래와 같은 부작용을 가지게 된다.</p><ol><li>새로운 크기의 배열을 선언하는 과정에서 메모리를 소모하게 된다.</li><li>이전 배열에서 새로운 배열로 값을 복사하는 과정에서 시간이 소요된다.</li><li>기존 배열을 참조하고 있던 다른 변수들의 참조는 변경되지 않기 때문에 여전히 이전 배열을 가리키고 있다.</li></ol><h4>분할상환분석</h4><p><a href="https://ko.wikipedia.org/wiki/%EB%B6%84%ED%95%A0%EC%83%81%ED%99%98%EB%B6%84%EC%84%9D">분할상환분석</a>은 전반적인 연산 집합에 대해 비용이 높은 연산, 비용이 덜한 연산 모두를 함께 고려하는 기법이다.</p><p>배열 삽입 연산의 시간 복잡도를 생각해보면</p><ul><li>배열의 크기가 충분할 때는 O(1)</li><li>배열에 여유 공간이 없을 경우 위의 방식으로 배열 확장이 필요하므로 O(N)</li></ul><p>과 같이 최적의 경우와 최악의 경우를 생각해볼 수 있다.</p><p>배열 공간이 부족할 경우 N만큼의 공간을 확장할 경우 X*N번째 요소를 삽입할 때마다 최악의 경우가 발생하게 된다.</p><p>그러나<strong> N번째 연산에 발생하는 비용을 1~N-1번째 연산에 분산시킨다고 생각해보면 평균적인 시간 복잡도는 O(1)</strong>, 즉 상수 시간이 된다.</p><p>결과적으로 분할상환분석으로 보았을 때는 배열의 크기 제한으로 인한 부작용은 거의 없는 것이나 다름없다. 단지 배열의 크기를 늘이는 그 과정을 프로그래밍하기가 귀찮을(…) 뿐이다.</p><h3>연결 리스트(Linked List)</h3><p>배열의 단점을 극복하기 위하여 대부분의 서적에서 대안으로 제시하는 자료구조는 연결 리스트(Linked List)이다.</p><p>연속적인 메모리 공간에 값이 나열되어 있는 배열과 달리, 연결 리스트는 각 구성 요소들의 내부에 다음 요소를 가리키는 Pointer나 Reference가 존재하여 연결되는 구조이다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/646/0*zIaUfHhWBMgYfIGG" /><figcaption>연결 리스트를 가장 잘 나타낸 그림(출처: <a href="http://www.rubyguides.com/2017/08/ruby-linked-list/">http://www.rubyguides.com/2017/08/ruby-linked-list/</a>)</figcaption></figure><h4>연결 리스트의 장점</h4><ul><li>크기가 정해져있지 않으므로 새로운 요소를 추가할 때 크기 제한에서 자유롭다.</li><li>배열과 달리 중간에 요소를 추가/삭제하기가 쉽다.(빠른 것은 아니다)</li></ul><h4>연결 리스트의 단점</h4><ul><li>인덱스(Index) 기반으로 값에 접근이 불가능하다.</li><li>값을 찾는(탐색하는) 시간이 크기에 비례한다.</li></ul><h4>코드 구현</h4><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/dc3f24bc74e248224f20a7b0225e780e/href">https://medium.com/media/dc3f24bc74e248224f20a7b0225e780e/href</a></iframe><h4>시간 복잡도</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/808/1*sCIAAiBG-wvHPO5zGzmMBg.png" /></figure><h3>다른 자료구조와의 비교</h3><h4>Array List vs Linked List</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DbO5l3A6VzRgA8i0hGCCgA.png" /></figure><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/ArrayList.html">ArrayList</a>는 Java의 util 패키지(java.util.ArrayList)에서 제공하는 Collection 클래스로써, List Interface를 구현한 크기 변경이 가능한 배열이다.(Thread-Safe하지 않기 때문에 Multi Thread 환경에서는 Vector 사용을 추천)</p><p>배열 기반의 자료구조이기 때문에, 크기가 변한다는 점 이외에는 배열과 동일한 특성을 가지고 있다.</p><p>ArrayList의 삽입 메서드를 따라가다보면 내부 배열의 크기가 부족할 경우 크기를 증가시키는 grow라는 메서드가 있다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/797/1*kEAWHcj0VgAOngZsgeCnDg.png" /></figure><p>내부 배열인 elementData의 크기를 newCapacity로 늘여주는 코드를 맨 아래에서 확인할 수 있다.</p><p>이 연산 자체의 시간복잡도는 O(N)이지만, 분할상환분석 할 경우 전체 삽입 연산의 시간 복잡도는 O(1)이 된다.</p><h3>추가 내용</h3><h4>Multi Thread 환경에서 Array List를 사용하는 방법</h4><p>위에서 Array List는 Thread Safe 하지 않기 때문에 Vector 를 사용하라고 적어 놓았다.</p><p>Synchronized 키워드를 활용하면 Array List에 Lock을 걸어 사용할 수도 있겠지만, Java에서는 Array List를 Synchronized하게 만들어 주는 메소드도 제공한다.</p><p>Collections.synchronizedList이며, 사용 예제는 아래 링크로 가보면 확인할 수 있다.</p><p><a href="https://docs.oracle.com/javase/7/docs/api/java/util/Collections.html#synchronizedList(java.util.List)">Collections (Java Platform SE 7 )</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ca96a40e44f0" width="1" height="1">]]></content:encoded>
        </item>
    </channel>
</rss>