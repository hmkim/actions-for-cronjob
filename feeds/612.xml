<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="http://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-6029100972813152037</id><updated>2019-05-12T15:14:56.167+09:00</updated><category term="kr"/><category term="machine learning"/><category term="GAN"/><category term="PR12"/><category term="bloggertip"/><category term="mathematics"/><category term="DANN"/><category term="setup"/><category term="ICLR2018"/><category term="en"/><category term="skimpaper"/><category term="dsp"/><category term="topology"/><category term="개발"/><category term="cs231n"/><title type='text'>Jaejun Yoo&#39;s Playground</title><subtitle type='html'>READ A LOT, THINK IN PICTURES, CODE IT, VISUALIZE MORE!</subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link rel='next' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default?start-index=26&amp;max-results=25'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><generator version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>65</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1797523556505861360</id><published>2019-05-11T20:30:00.000+09:00</published><updated>2019-05-11T20:41:08.892+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (0)</title><content type='html'>이 시리즈는 signal processing을 학부 때 배웠으나 여러 이유로 이해를 잘 하지 못하다가 뒤늦게서야 유용성을 깨닫고 개인적으로 공부하며 정리한 흔적이다.&lt;br /&gt;&lt;br /&gt;결국 machine learning을 하든 deep learning을 하든 모두 신호를 다루기 위한 도구일 따름이고, 내가 주로 다루는 신호가 이미지라는 형태를 띄고 있을뿐 근본적으로 디지털 신호 처리에서 다루는 내용에서 벗어나지 않는다는 생각이 들었다.&lt;br /&gt;&lt;br /&gt;이런 맥락에서 신호 처리에 대해 좀 더 잘 알고 싶다는 생각에 정리를 시작하였는데, 대부분의 글은 주로 EPFL의 Martin Vetterli 교수님이 저술하신 textbook을 기반으로 요약하였다.&lt;br /&gt;&lt;br /&gt;앞으로 쓸 글들은 (얼마나 걸릴지는 모르겠지만) 모두 신호처리의 기본에 대해 대학교 학부생을 위한 기초 수준으로 작성될 것이다. 스스로가 그 이상을 설명할만큼 잘 알고 있다고 생각하지도 않는만큼 차후 시간이 흘러 내가 다시 이 글을 보더라도 이해가 쉽게 하겠다는 목적을 갖고 글을 정리한다.&lt;br /&gt;&lt;br /&gt;약간의 선형대수학, 신호처리에 대한 기초 지식 그리고 더 나가서 해석학을 들어본 적이 있다면 보다 깊은 이해에 도움이 될 것이지만, 그런 선행 지식이 없이도 어렵지 않게 이해할 수 있는 수준으로 작성하고자 노력하였다.&lt;br /&gt;&lt;br /&gt;간단한 예시 그리고 덜 형식적인 설명을 바탕으로 신호처리라는 딱딱한 주제에 대해 쉽게 접근할 수 있도록 작성하였으며 이해하기 쉬운 설명을 위해 수학적 엄밀성 강조하지는 않겠지만 언제나 정확한 설명을 하는 것에 주안점을 두었다. 계획된 목차는 아래와 같다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;목차 (planned)&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing?&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1797523556505861360/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html' title='Signal Processing For Communications (0)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-9158657182315759528</id><published>2019-05-11T20:03:00.001+09:00</published><updated>2019-05-11T20:30:47.667+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (1)</title><content type='html'>&lt;div&gt;&lt;h2&gt;What Is Digital Signal Processing?&lt;/h2&gt;&lt;/div&gt;&lt;br /&gt;신호(signal)와 신호 처리(signal processing) 대해서 정의를 내리자면 각각 다음과 같다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;b&gt;신호:&lt;/b&gt; 시간 혹은 공간에 대해 변화하는 현상에 대한 formal description&lt;br /&gt;&lt;b&gt;신호 처리:&lt;/b&gt; 신호에 들어있는 정보를 바꾸거나 분석하는 any operation.&lt;/div&gt;&lt;/blockquote&gt;예를 들어 주변 온도를 우리가 Celsius degree라는 물리적 변수를 기준으로 시간에 따른 온도의 변화를 기록하는 경우, 이렇게 만들어진 data set은 온도 &quot;신호&quot;가 될 것이다. 이 신호에 대한 가장 단순한 &quot;처리&quot;로는 월간 온도 평균과 같은 어떤 파라미터를 계산하는 것이 있겠다.&lt;br /&gt;&lt;br /&gt;또한 신호 처리는 어떤 물리적인 값 자체에 직접 가해지는 것이 아니라 물리적인 값의 &quot;abstract representation&quot;을 기반으로 수행된다는 점이 중요하다. 이런 abstract representation의 방식에 따라서 신호 처리의 기본 단위(unit)가 정해진다.&lt;br /&gt;&lt;br /&gt;한편 &quot;디지털 (digital)&quot;이라는 수식어구는 라틴어 digitus에서 유래한 것으로 손가락을 의미하는데, counting은 가장 기초적이고 오래된 abstraction이다. 즉, 디지털 신호 처리는 시간을 포함한 모든 것들에 정수(integer number)와 같이 countable한 abstraction representation을 사용한다는 것을 의미한다.&lt;br /&gt;&lt;br /&gt;좀 더 구체적 예시로는, 주변 온도를 측정한 각각의 관측(instants)이 셀 수 있는 집합(the days in a month)을 이루고 각 관측값(measure)들 역시도 온도계의 눈금 단위와 같이 유한한 수의 집합으로 표현되는 것을 생각해보면 된다.&lt;br /&gt;&lt;br /&gt;재미있는 점은 디지털 신호 처리에서는 신호가 &quot;어디서 유래한 것인가에 관계없이&quot;&amp;nbsp;이를 &quot;정수로 표현 가능한&quot;&amp;nbsp;abstract representation을 사용한다는 것이다. 지금은 이 사실이 별 달리 중요해보이지 않을 수 있으나, 이 특징이 디지털 신호처리가 지금과 같이 크게 발전할 수 있었던 큰 동력이라는 점은 앞으로 차차 분명해지리라 생각한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Analog vs. Digital worlds&lt;/h2&gt;&lt;br /&gt;세계에 대한 &quot;digital&quot; 혹은 정수를 이용한 표현 방식은 우리가 다루는 문제가 가축이나 날짜를 세는 것과 같이 간단할 때까지는 아무 문제가 없이 잘 동작했으나, 점차 세상이 복잡해지고 이를 설명하는 모델 역시도 복잡해질 필요가 생기면서 한계에 부닥쳤다.&lt;br /&gt;&lt;br /&gt;신호 처리 쪽 용어로 얘기하자면 정수로 표현되는 세계가 &quot;analog&quot;와 같이 연속적인 세계를 설명하는 잣대로 사용하기에는 너무 초보적이고 거칠어서 마치 시계공이 망치를 들고 있는 것과 같다는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 무한대와 무한소로 나눠질 수 있는 연속적인 analog 세계의 analytical 모델을 사용하면 이론적으로 분석하기는 편할지언정 실제로 이를 사용하기 위해서는 언제나 유한하고 이산적인 digital 세계로 내려와야한다는 점이다.&lt;br /&gt;&lt;br /&gt;예를 들어 온도를 측정하는 것만해도 우리가 얻을 수 있는 것은 언제나 일정 간격(time)을 두고 측정한 관측값들뿐 임의의 시간에 대해 해당하는 온도에 대한 관계를 보여주는 analytical 모델이 아니다.&lt;br /&gt;&lt;br /&gt;따라서 analog와 digital representation이 서로 만족할만한 합의에 이르기 위한 부단한 노력들이 이루어져 왔고, series expansion이나 numerical integration과 같은 알고리즘들이 analytic 결과를 practically computable한 형태로&amp;nbsp;만들기 위한 노력의 예시들이다.&lt;br /&gt;&lt;br /&gt;디지털 신호 처리가 멋진 것은 이렇게 양분된 두 세계가 서로 가장 만족스러운 형태로 합의에 이를 수 있도록 한다는 점이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Discrete Time&lt;/h2&gt;&lt;br /&gt;아날로그 기록 방식의 가장 큰 문제점은 신호를 추상화 하여 기록하는 것이 아닌 하나의 물리적인 현상을 또 다른 물리적 현상으로 옮기는 것에 불과하다는 점이다. 이 때문에 근본적으로 아날로그 신호는 기록(recording)의 형태에 따라 각각 다른 신호 처리 시스템이 필요하다. 예를 들어 우리가 온도 변화 함수 $f(t)$를 알고 있고,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s1600/fig1-5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;275&quot; src=&quot;https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s400/fig1-5.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Analytical and empirical averages&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;일정 간격 $[T_0, T_1]$ 사이에 일어난 온도 변화의 평균값을 알고싶다면 이에 대한 analytical solution은 다음과 같은 적분 방적식을 푸는 것이다: $$\bar{C} = \frac{1}{T_1-T_0}\int_{T_0}^{T_1} f(t) dt.$$ 그러나 analytic model이 없는 현실에서는 어떤 기기를 사용하여 온도를 측정, 기록하였을 것이고 그 데이터를 가지고 평균 온도를 계산할 것이다. 만약 온도가 thermograph를 이용하여 그래프의 형태로 기록되었다면 plainmeter라는 면적을 구하는 기계적 도구를 사용하여 면적을 알 수 있을 것이다. 그러나 온도 변화가 thermocouple과 같이 전압을 이용하여 기록을 하는 경우 학부 전자기초 시간에 배우는 RC 네트워크로 voltage integration 회로를 만들어 평균값을 계산해야 할 것이다. 이렇듯 아날로그 신호에서는 평균을 구하는 매우 단순한 예에서도 각 경우마다 특정한 디자인이 필요하기에 범용적으로 사용할 수 있는 방식을 고안하기 어렵다는 것을 알 수 있다.&lt;br /&gt;&lt;br /&gt;한편, 디지털 방식과 같이 하루에 한 번씩 측정한 온도에 대해 평균을 구하는 것은 매우 쉽다: $$\hat{C}=\frac{1}{D}\sum^D_{n=1}c_n.$$ 단순히 초보적인 덧셈과 나눗셈만 수행하면 원하는 값을 얻을 수 있다! 그렇다면,&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;$\bar{C}$와 $\hat{C}$의 차이가 (만약 있다면) 얼마나 되는가?&quot;&lt;/blockquote&gt;만약 저 자연계 어딘가에 $f(t)$라는 온도 함수가 있다는 것을 받아들인다면 하루 주기($T_s$)마다 측정한 $c_n$ 온도 측정값들은 이 함수의 $samples$라고 할 수 있다: $$c_n=f(nT_s).$$ 이런 맥락에서 보면 $\hat{C}$는 $\bar{C}$의 Riemann approximation이라고 할 수 있으며 앞선 질문은 이 approximation의 질 즉, continuous-time 함수에서 일부 샘플들만 취함으로써 우리가 얼마나 정보를 버렸는지에 대해 묻는 것과 같다.&lt;br /&gt;&lt;br /&gt;이에 대한 정답은 놀랍게도 해당 물리적 현상이 &quot;그렇게 빨리 변하지 않는다&quot;는 가정 하에,&amp;nbsp; 두 representation이 &quot;완벽히 일치한다&quot;는 것이다. 즉, continuous-time function과 우리가 얻은 측정 샘플들 간의 정보 손실이 전혀 없다.&lt;br /&gt;&lt;br /&gt;잠시 가정에 대한 걱정을 내려놓고 이 사실이 얘기해주는 것에만 집중해보면 매우 놀랍게도&lt;br /&gt;&lt;ol&gt;&lt;li&gt;아날로그와 디지털 세계가 완전히 공존하는 것이 가능하다는 뜻이며&amp;nbsp;&lt;/li&gt;&lt;li&gt;우리가 두 세계 사이를 오갈 수 있는 매우 강력한 도구를 갖고 있다는 것이다 (sampling theorem).&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;20세기 초에 발견된 이 놀라운 정리는 우리가 가진 샘플들을 바탕으로 임의의 continous-time function를 알아내는 것이 가능하다는 것을 말해준다:&lt;br /&gt;$$f(t)=\sum_{n=-\infty}^\infty c_n \frac{\sin(\pi(t-nT_s)/T_s)}{\pi(t-nT_s)/T_s}.$$ 따라서 이론적으로는 우리가 측정값들을 가지고만 있다면 이를 바탕으로 continous-time 형태로 표현하는 것이 가능하며, 이것은 이어서 우리가 갖고 있는 매우 강력한 수학적 도구인 미분을 사용하여 함수를 분석하는 것이 가능해진다는 것을 뜻한다. 더 좋은 점은 continous-time에서 이루어진 미분과 같은 분석이 항상 discrete-time에 대응하는 방식이 존재하여 굳이 우리가 얻은 측정값들을 가지고 continous domain으로 옮겨서 분석한 후 다시 discrete domain으로 내려오는 복잡한 방식을 취할 것 없이 discrete domain에서 바로 분석을 하면 된다는 것이다.&lt;br /&gt;&lt;br /&gt;Discrete과 continuous representations 사이의 equivalence는 우리가 샘플을 얻는 속도에 비해&amp;nbsp;다루는 신호가 얼마나 충분히 &quot;느린가&quot;에 달려 있다. 즉, 연속된 샘플을 측정하는 사이에 신호가 갑자기 이상하게 움직이지 않고 충분히 부드럽게 (smooth and well behaved) 움직인다면 문제가 없다는 뜻이다.&lt;br /&gt;&lt;br /&gt;그래서 sampling theorem이 해주는 역할은 (좀 더 쉽게 설명하자면) 신호가 갖는 최대 주파수와 우리가 얼마나 자주 혹은 빨리 샘플을 얻어야 하는지에 대한 정량적인 기준을 알려주는 것이다. 대다수의 학부 수준 디지털 신호 처리 과목의 반절 혹은 그 이상은 이 sampling theorem을 배우기 위한 준비와 theorem의 의미에 대해 공부하는 것이다. 특히 주파수 영역은 Fourier transform을 사용하여 알아낼 수 있기에 이를 신호 처리 과목에서 중요하게 다루며 배우는 것이라 할 수 있는데, 재미있는 점은 Fourier transform이라는 것 자체가 주기성을 띄는 함수들을 &lt;i&gt;&quot;셀 수 있는&quot;&lt;/i&gt; 값들로 표현하기 위한 도구로서 사용된다는 것이다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;Everything comes together.&quot;&lt;/blockquote&gt;&lt;h2&gt;Discrete Amplitude&lt;/h2&gt;&lt;br /&gt;시간 연속성에 대한 문제는 sampling theorem으로 어느 정도 해결이 되었지만, 여전히 남아있는 문제가 하나 있다. 현실 세계의 한계로 인해 실제 측정을 할 때 생기는 오차는 우리가 어찌 할 수 없는 문제다.&lt;br /&gt;&lt;br /&gt;만약 우리가 analytical model을 다룬다면 시간축뿐만 아니라 함수 값 역시도 연속적인 성격을 갖고 있다. 그러나 현실에서는 절대로 이와 같은 무한대의 정밀성을 얻을 수 없다는 것은 자명하다. (아무리 온도계의 눈금을 잘게 쪼개어 기록을 하더라도 한계가 있는 것처럼)&lt;br /&gt;&lt;br /&gt;따라서 실제로는 우리가 얻는 측정값들도 결국 유한한 숫자들의 집합이고 그렇다면 이들은 셀 수 있기에 정수로 mapping하는 것이 가능하다. 이러한 과정을 quantization이라고 부르고 이는 sampling과 함께 digital signal을 얻는데 필수적인 요소가 된다.&lt;br /&gt;&lt;br /&gt;Quantization은 정보 손실을 어쩔 수 없는 것으로 받아들인다는 점에서 연속체 문제를 시간에 비해 매우 거칠게 해결하는 것이라 할 수 있다. 여기에는 그럴 수 밖에 없는 이유가 있는데 그게 바로 신호 처리를 하다보면 언제나 만나게 되는 &quot;noise&quot;이다.&lt;br /&gt;&lt;br /&gt;우리가 어떠한 기계적 기록 장치를 쓴다고 해도 아날로그 기록을 하는 기기라면 언제나 noise가 함께하게 된다. Noise는 자연에서 오는 것이고 이를 완전히 제거하는 것은 불가능하기 때문에 신호 처리를 할 때 일정 수준의 정밀성으로 만족하는 정도로 합의를 하는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 noise가 단순히 측정에서만의 문제가 아니라 처리를 할 때도 함께한다는 점이다.&lt;br /&gt;여기서 디지털 신호 처리의 또 다른 장점이 나오는데, 디지털 신호 처리는 언제나 셀 수 있는 정수의 수열을 다루기 때문에 디지털 영역에서는 processing으로 인한 noise가 생기지 않는다.&lt;br /&gt;&lt;br /&gt;매우 자명한 예로 신호를 복제하는 것을 생각해보면, 테이프를 복사하는 것은 원본 테이프를 복사본과 그 복사본을 이용한 다음 복사본으로 넘어갈 때마다 추가적인 nosie가 더해져서 점점 음질이 열화하는 것을 알 수 있지만 mp3의 경우 원본과 복사본이 근본적으로 차이가 없다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Terminology&lt;/h2&gt;&lt;br /&gt;마지막으로 용어에 대해 한가지 짚고 넘어가겠다. Amplitude에 대한 정확성은 사실 하드웨어에 달린 문제로 예를 들자면 CD와 DVD는 서로 precision 즉 샘플 당 담는 정보량에 차이가 있다. 이렇게 amplitude에 대한 정밀성은 하드웨어에 의존적이므로 사실상 신호 처리 이론에 대해 배우거나 개발할 때는 quantization을 고려하지 않고 마치 연속된 실수 값인 것 마냥 취급한다. 따라서 사실상 우리가 앞으로 배우는 것은 엄밀히 말하자면 모두 discrete-time signal processing이라 불러야 맞고 digital signal processing은 실제 기기의 영역에서 이뤄지는 일임을 알아야한다. 그러나 quantization을 고려하지 않는 것이 좀 더 이론적으로 다루기도 쉽고 일반적인 분석이 가능하기 때문에 이를 잘 구별하지 않고 digital signal processing이라 얘기한다는 점을 분명히 알아야한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b&gt;To be continued ... (planned)&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing?&lt;/a&gt;&amp;nbsp;(done)&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/9158657182315759528/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html' title='Signal Processing For Communications (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s72-c/fig1-5.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-243971491237100208</id><published>2019-05-07T17:31:00.001+09:00</published><updated>2019-05-07T17:35:17.718+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><category scheme="http://www.blogger.com/atom/ns#" term="topology"/><title type='text'>공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)</title><content type='html'>&lt;h2&gt;공이 점점 비눗방울처럼 변할 때&lt;/h2&gt;&lt;br /&gt;이전에 소개했던&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;처럼&amp;nbsp;고차원으로 갈 때 우리의 직관이 얼마나 달라질 수 있는지를 알려주는 또 다른 좋은 예시를 소개해보자.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구의 부피&lt;/h3&gt;&lt;br /&gt;또다시 &lt;a href=&quot;https://en.wikipedia.org/wiki/Ball_(mathematics)&quot; target=&quot;_blank&quot;&gt;공(ball)&lt;/a&gt;이다! 수학적인 용어에서의 공은 간단히 말해 겉껍질이 자기보다 한차원 낮은 &lt;a href=&quot;https://en.wikipedia.org/wiki/N-sphere&quot;&gt;구(sphere)&lt;/a&gt;로 쌓여있는 닫힌 공간 전체, 즉, 안이 꽉 찬 공간을 뜻한다. 1차원 공(ball)은 선(line segment)이고 2차원 공은 원반(disk), 3차원 공은 음...공(ordinary ball)이다. 대응되는 구(sphere)를 생각해보면 0차원 구는 시작과 끝 점(point), 1차원 구는 원(circle), 2차원 구는 구(ordinary sphere)다.&lt;br /&gt;&lt;br /&gt;이런 공의 부피를 바탕으로 초등학교 시절 배운 내용 수준만으로 아주 쉽고 간단하게 고차원에서는 직관이 우리를 배반한다는 것을 보일 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;이전 글&lt;/a&gt;과 같이 먼저 쉽고 우리 직관이 잘 통하는 2차원에서부터 시작해보자:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s1600/high_dim_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s200/high_dim_1.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;우리 모두 초등학교 때, 원의 부피, 즉 2차원에서의 넓이를 구하는 것은 배웠을 것이다: $$V_2(r)=\pi r^2.$$ 한 차원 더 나가서,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s1600/high_dim_2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s200/high_dim_2.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;3차원 공의 부피는 $$V_3=\frac{4\pi}{3}r^3$$이라는 것도 열심히 외웠을 것이다.&lt;br /&gt;&lt;br /&gt;그리고 아마도 이걸 $d$차원에 대해 일반화하는 공식은 테이블 형태로 &quot;심화 학습&quot; 뭐 이런 형태로 가볍게 보여주고 지나갔을 것이다: $$V_d(r)=k_d r^d.$$ 여기서 $k_d$는 상수다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구각 (Spherical shell)&lt;/h3&gt;&lt;br /&gt;이제부터 좀 재미있는 실험을 할텐데, 원점을 중심으로 반지름이 1인 구와 반지름이 $1-\epsilon$으로 그보다 아주 약간 ($\epsilon\ll 1$만큼) 공 두 개를 준비하고 이 두 공 부피의 차를 구해보자: $$V_d(1) - V_d(1-\epsilon).$$&lt;br /&gt;이걸 겉 껍데기를 구하는 것이라 해서 구각(spherical shell)이라 하는데 두 공의 반지름의 차이가 $\epsilon$만큼 나기 때문에 우리가 생각하는 겉껍질(구각)이 차지하는 부피는 매우 작다.&lt;br /&gt;&lt;br /&gt;만약 정확히 그 비율이 얼마나 되는지 알고 싶다면 반지름이 1인 구와 위에서 구한 구각의 비율을 구하면 될텐데 이 비율은 간단히: $$\frac{V_d(1) - V_d(1-\epsilon)}{V_d(1)}=1-(1-\epsilon)^d$$가 될 것이다.&lt;br /&gt;&lt;br /&gt;이제 준비물은 모두 모았으니 사고 실험을 해보면 재미있는 일이 벌어지는 것을 알 수 있다.&amp;nbsp; 점점 고차원으로 갈수록 ($d\rightarrow \infty$) 두번째 항의 값이 0에 가까워지고 공과 구각의 비율이 1로 수렴한다! 즉, &lt;i&gt;&quot;공이 점점 비눗방울처럼 바뀌는 것&quot;&amp;nbsp;&lt;/i&gt;이다.&lt;br /&gt;&lt;br /&gt;모든 부피가 껍데기에만 몰려있고 안이 텅텅 비어있는 매우 요상한 &quot;속이 꽉찬&quot; 공이 될 것이다. 이 역시도&amp;nbsp;고차원으로 넘어갈 때, 우리의 직관이 얼마나 틀릴 수 있는지 보여주는 좋은 예시로 이 글을 읽는 다른 분들에게도 brain candy가 되었길 기대한다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;딴 이야기 (for those who are interested in GANs)&lt;/h3&gt;&lt;br /&gt;재미있는 GAN blog 글로 유명한&amp;nbsp;inFERENCe가 &quot;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;&quot;라는 제목으로 글을 써서 화제가 된 적이 한 번 있는데, 생각보다 복잡하게 설명을 해서 이해하기 어려울 수 있지만 사실 지금 한 얘기를 다른 방식으로 열심히 적은 것이다.&lt;br /&gt;&lt;br /&gt;GAN 모델을 학습시킨 다음 High dimensional Gaussian latent space에서 walking을 하기 위해 두 latent vector간의 interpolation을 할 때, 왜 linear interpolation을 하면 문제가 될 수 있는지 이 글을 읽으신 분들이 이해가 쉽게 될 것이라 생각한다.&lt;br /&gt;&lt;br /&gt;어떤 의미에서는 중간이 텅 비어있는데 겉껍질을 타고(polar) 움직여야지(interpolate) 중간을 쑥 뚫고(linear) 움직이면 본적이 없는 latent vector가 model로 들어갈 수 있기 때문이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;,&amp;nbsp;&lt;span style=&quot;text-align: start;&quot;&gt;inFERENCe&lt;/span&gt;&amp;nbsp;2017. 11. 09.&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/243971491237100208/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html' title='공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s72-c/high_dim_1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6213532524610182574</id><published>2018-09-02T22:18:00.002+09:00</published><updated>2018-09-02T22:18:57.919+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;표면적인 수준에서의 개선&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;표면적 수준이란 좋은 이름을 짓고, 좋은 설명을 달고, 코드를 보기 좋게 정렬하는 따위를 의미한다.&quot;&lt;/blockquote&gt;&lt;br /&gt;책의 첫 단락은 표면적인 수준에서의 개선부터 시작합니다. 이런 수정은 코드를 통째로 바꾸거나 동작하는 방식을 변화시키지 않고 &#39;그 자리에서&#39; 곧바로 만들 수 있기에 첫 시작으로 매우 적절하다 생각합니다.&lt;br /&gt;&lt;br /&gt;물론 가독성에 관련된 논의는 이 수준보다 더 나아가 많은 내용을 담고 있겠으나 이는 차차 살펴갈 것이며 먼저 1부에서는 폭넓게 적용할 수 있고, 그다지 많은 노력을 요구하지 않는 내용을 우선적으로 다룹니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이름에 정보 담기&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;변수, 함수, 혹은 클래스 등의 이름을 결정할 때는 항상 같은 원리가 적용합니다.&amp;nbsp;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;이름을 일종의 설명문으로 간주해야 한다.&quot;&lt;/blockquote&gt;충분한 공간은 아니지만, 좋은 이름을 선택하면 생각보다 많은 정보를 전달할 수 있다는 것이죠. 구체적으로는 아래의 여섯 가지 방법을 제안합니다.&lt;br /&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;특정한 단어 고르기&lt;/li&gt;&lt;li&gt;보편적인 이름 피하기 (혹은 언제 그런 이름을 사용해야 하는지 깨닫기)&lt;/li&gt;&lt;li&gt;추상적인 이름 대식 구체적인 이름 사용하기&lt;/li&gt;&lt;li&gt;접두사 혹은 접미사로 이름에 추가적인 정보 덧붙이기&lt;/li&gt;&lt;li&gt;이름이 얼마나 길어져도 좋은지 결정하기&lt;/li&gt;&lt;li&gt;추가적인 정보를 담을 수 있게 이름 구성하기&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;앞으로는 책에 나온 내용을 모두 다 소개하기 보다는 개중 제가 재미있었던 내용들을 좀 골라서 예시와 함께 알아보겠습니다.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;특정한 단어 고르기&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;매우 구체적인 단어를 선택하여 &quot;무의미한&quot; 단어를 피하자.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;예를 들어 &quot;get&quot;은 지나치게 보편적입니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;def GetPage(url):&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;여기서 &quot;get&quot;보다는 메소드가 어디에서 페이지를 가져오는 지 알려줄 수 있게 FetchPage() 혹은 DownloadPage()와 같이 구체적으로 명명하는 것이 더 좋습니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;사실 위 예시보다 다음 예시가 더 좋았는데요. 다음과 같이 BinaryTree 클래스에서&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;class BinaryTree {&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; int Size();&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;div&gt;} &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;우리는 Size() 메소드가 반환하는 것이 무엇일 지 이름만 봐서는 알 수 없습니다. 트리의 높이, 노드의 개수, 혹은 트리의 메모리 사용량이 될 수도 있겠죠.&amp;nbsp; 따라서 Height(), NumNodes(), 혹은 MemoryBytes() 등이 더 의미 있는 이름이라는 것에는 모두 동의하리라 생각합니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;같은 맥락에서 저자들은 thesaurus를 뒤져보고 더 나은 이름을 생각하기를 권합니다. 다만 너무 &quot;재치&quot; 있는 이름보다는 명확하고 간결한 이름이 더 좋습니다. 다음에 이어지는 내용들도 사실 같은 내용인데 예제들과 소소한 팁 위주로 살펴보곘습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;tmp나 retval 같은 표편적인 이름 피하기&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;변수값을 설명하는 이름을 사용하라&quot;&lt;/blockquote&gt;&lt;br /&gt;예를 들어, 다음과 같이 Euclidean norm을 계산하는 자바스크립트 코드에서&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;var euclidean_norm = function (v) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; var &lt;b&gt;retval&lt;/b&gt; = 0.0;&lt;br /&gt;&amp;nbsp; &amp;nbsp; for (var = i = 0; i&amp;lt;v.length; i+=1)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;b&gt;retval&lt;/b&gt; += v[i];&lt;br /&gt;&amp;nbsp; &amp;nbsp; return Math.sqrt(&lt;b&gt;retval&lt;/b&gt;);&lt;br /&gt;};&lt;/div&gt;&lt;div&gt;&lt;br /&gt;retval보다는 sum_squares라고 이름을 붙여준다면 변수의 목적을 바로 이해할 수 있으며 나중에 버그를 잡을 때도 용의합니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;retval&lt;/b&gt;&amp;nbsp;+= v[i]; 부분이&amp;nbsp;&lt;b&gt;sum_squares&lt;/b&gt; += v[i]; 였다면 훨씬 눈에 잘 띄었겠죠.&lt;br /&gt;&lt;br /&gt;물론 아래와 같이 정말로 대상이 짧게 임시적으로만 존재하고, 임시적 존재 자체가 변수의 가장 중요한 용도일 때는 tmp와 같은 변수를 사용할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;두 변수를 서로 교환하는 알고리즘 예:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (right&amp;lt;left) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;b&gt;tmp&lt;/b&gt; = right;&lt;br /&gt;&amp;nbsp; &amp;nbsp; right = left;&lt;br /&gt;&amp;nbsp; &amp;nbsp; left = &lt;b&gt;tmp&lt;/b&gt;;&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;같은 맥락으로 i, j, iter, it 같은 이름이 인덱스나 루프 반복자로 사용되는 것은 충분히 괜찮습니다. 다만 이 역시도 디버깅의 용이성을 위해서 아래와 같이 소속을 표현해준다면 더 좋겠죠.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;(i, j, k) -&amp;gt; (club_i, members_j, users_i) or (ci, mj, ui)&lt;br /&gt;&lt;br /&gt;활용 예:&lt;br /&gt;if (clubs[ci].members[ui] == users[mi]) # 버그! 처음 문자가 일치 하지 않는다.&lt;/div&gt;&lt;br /&gt;따라서 표편적인 이름이 항상 나쁜 것은 아니지만, 이를 사용하려면 &lt;b&gt;꼭 그렇게 해야하는 이유가 있어야 합니다.&amp;nbsp;&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;br /&gt;&lt;h3&gt;추가적인 정보를 이름에 추가하기&lt;span style=&quot;font-weight: normal;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;단위(sec, millisecond, kg 등)를 포함하거나 다른 중요한 속성(unsafe, utf_8 등)이 있을 때는 변수에 그런 내용을 추가해주면 좋습니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;start -&amp;gt; start_ms, elapsed -&amp;gt; elapsed_ms&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;html -&amp;gt; html_utf-8 # html의 바이트가 UTF-8으로 변환되었다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;이름은 얼마나 길어야 하는가?&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;만일 변수가 좁은 scope (예: 끽해야 몇 줄 안의 함수 scope)에서 사용된다면 멤버 변수가 &quot;m&quot;과 같이 매우 짧은 이름을 사용해도 별 문제가 없으나 이 변수의 scope이 클래스나 전역으로 넓어지면 가독성이 매우 떨어지게 되므로 상황에 따라 잘 사용하라고 하는군요.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;게다가 요즘은 긴 이름을 입력하는 것이 자동완성 기능으로 매우 편해져서 그리 주저할 일이 아닙니다. 그렇기 때문에 약어와 축약형은 매우 보편적인 경우(string-&amp;gt; str과 같이)를 제외하고는 지양하는 편이 좋겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이에 좀 더 더한다면 ConvertToString()에서 ToString()과 같이 불필요한 단어를 제거해서 간결하게 만드는 등의 팁이 있으나 앞의 내용들이 더 핵심에 가까운 것으로 보입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이로써 이름에 정보를 넣는 방법에 대해 요약해보았습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;책에서 다음 장은 의미를 오해하기 쉬운 이름들에 대한 팁입니다만 사실 오늘 소개한 내용에 어느 정도 포함되는 것 같습니다. 다음 글에서는 미학(Aesthetics) 즉 &quot;눈을 편하게&quot; 하는 코드에 대해 정리하겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6213532524610182574/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-643283542644223785</id><published>2018-09-02T12:32:00.000+09:00</published><updated>2018-09-02T12:34:46.558+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#71. Categorical Reparameterization with Gumbel Softmax&lt;/h2&gt;&lt;br /&gt;이 리뷰에서는 NIPS 2016 workshop에 같이 발표되었고 최근 ICLR 2017에 발표된 두 편의 논문을 리뷰하겠습니다. 재미있는 점은 이 두 편의 논문들이 똑같은 아이디어를 바탕으로 정확히 같은 수식을 사용하여 arXiv에도 고작 하루 차이로 올라왔다는 것입니다. 아이디어가 공중에 떠다닌다는 말이 정말 맞는가 싶습니다. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ty3SciyoIyk&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;(추신) 24분 부분에 질문 주신 부분에 대해 답이 미진한것 같아 끝나고 곰곰히 생각해본 답글을 여기에 추가합니다.&amp;nbsp; 둘 다 categorical dist를 만드는데 다른 방법을 사용할 뿐이라는것이 맞는 답인것 같습니다. 우리가 nn으로부터 샘플링을 하고 싶으면 logit을 받아서 softmax를 통과시켜서 확률값을 얻어서 이를 바탕으로 분포에 값을 넣어주고 그 분포로부터 샘플을 뽑는 방법이 있겠구요 (이 방법이 준범님이 말씀하신 보통의 방식인 것 같습니다. 결국 마지막 단에서 softmax하여 확률 값을 주니까요) 다만 샘플링을 하지 않고 확률값 자체를 라벨과 빼서 에러를 계산하는데 사용되는 것이라 백프롭에서는 문제가 없는것 같습니다. 자기자신으로 1이니까 그렇다고 생각하는데 혹 이상하면 말씀주세요. 그리고 두번째 방법이 logit에 검벨에서 뽑은 노이즈를 더하여 argmax를 통과시켜서 값을 얻으면 그 자체가 discrete categorical dist에서 나온 샘플입니다. 여기서 argmax를 softmax로 relaxation한 것이 gumbel softmax trick이구요 그래서 이렇게 복잡하게 과정을 거친 이유는 말씀드린 바와 같이 미분이 가능하게 해서 중간에 node가 껴있을때 gradient를 계산하기 위해서인 것으로 이해하면 되지 않을까 싶습니다.﻿&lt;br /&gt;&lt;br /&gt;&lt;b&gt;(paper1)&lt;/b&gt; Categorical Reparameterization with Gumbel Softmax and&lt;br /&gt;&lt;b&gt;(paper2)&lt;/b&gt; The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables&lt;br /&gt;&lt;br /&gt;Paper1: &lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;https://arxiv.org/abs/1611.01144&lt;/a&gt;&lt;br /&gt;Paper2: &lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;https://arxiv.org/abs/1611.00712&lt;/a&gt;&lt;br /&gt;슬라이드: &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/643283542644223785/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html' title='[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/ty3SciyoIyk/default.jpg" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-868743091536295491</id><published>2018-09-01T18:40:00.001+09:00</published><updated>2018-09-02T14:56:38.765+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. </title><content type='html'>많은 분들이 그러실텐데 저 역시도 항상 좋은 코드란 어떤 것인지 알고 싶었습니다. 이런 고민을 듣고 최근 회사 동료인 전상혁님이 &quot;The Art of Readable Code&quot;라는 책을 추천해주시기에 책을 도서관에서 빌려 읽고 있는데 정말 많이 배우고 있습니다. 책의 내용이 좋아서 한 권 사서 두고두고 읽으려 합니다.&lt;br /&gt;&lt;br /&gt;이런 내용들을 코드에 직접 적용하면서 체득하는 것이 가장 좋겠지만 당장 단기간에 이뤄질 수 있는 일은 아니기에, 일단은 좋은 내용들이 머리에 좀 더 오래 남기를 바라며 책 내용을 정리해서 올리고자 합니다.&lt;br /&gt;&lt;br /&gt;나중에 이 글을 찾은 분 혹은 미래의 나 스스로에게 초심자의 입장에서 어떤 점들이 도움이 되었는지를 보여줄 수 있을거라 기대합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이 책은 무엇에 대한 것인가?&lt;/h2&gt;&lt;br /&gt;이 책은 매우 읽기 편한 코드를 작성하는 방법을 설명하는데요. C++, 파이썬, 자바스크립트, 자바 등을 포함한 다양한 언어로 작성된 코드를 예로 들며 설명해줍니다. 중간중간 껴있는 삽화들도 매우 재치있고 각 장의 주제와 연관되어 있어 이해를 도와줍니다.&lt;br /&gt;&lt;br /&gt;재밌는 점은 언어들을 다 알지 못하더라도 책을 읽는 데는 별 어려움이 없다는 것입니다.&lt;br /&gt;저자들이 얘기하기론 &quot;코드의 가독성&quot;이라는 개념 자체가 언어로부터 독립적이기 때문이라고 하지만 제가 보기엔 여기서 저자들의 내공이 드러나는 것이 아닌가 싶습니다.&lt;br /&gt;&lt;br /&gt;크게 아래와 같이 4부로 나누어&lt;br /&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;표면적인 수준에서의 개선&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;루프와 로직를 단순화하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;코드를 재작성하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;선택된 주제들&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;여러 측면에서 코드를 이해하기 쉽게 만드는 방법을 설명해줍니다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;가독성의 기본 정리&lt;/h2&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;b&gt;&quot;코드는 다른 사람이 그것을 이해하는 데 들이는 시간을 최소화하는 방식으로 작성되어야 한다.&quot;&lt;/b&gt;&lt;/blockquote&gt;&lt;br /&gt;분량이 적다고 항상 좋은 것이 아닙니다. 좋은 예로 주석도 사실은 &quot;코드를 더하는 행위&quot;지만 코드를 더 빨리 이해하게 도와줍니다. 적은 분량으로 코드를 작성하는 것이 좋은 목표긴 하지만, 이해를 위한 시간을 최소화하는 것이 더 좋은 목표입니다.&lt;br /&gt;&lt;br /&gt;또 다른 예로,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;return exponent &amp;gt;=0 ? mantissa * (1 &amp;lt;&amp;lt;exponent) : mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;/div&gt;&lt;br /&gt;라는 코드보다는&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (exponent &amp;gt;=0) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa * (1 &amp;lt;&amp;lt; exponent);&lt;br /&gt;} else {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;이렇게 바꾼 코드가 앞서보다 간결하진 않지만 더 이해하기 쉽습니다.&lt;br /&gt;&lt;br /&gt;이해를 위한 시간은 코드의 효율성, 아키텍처, 테스트의 용이성과 같은 다른 목표와 충돌할까봐 걱정할 수도 있으나, 저자들의 경험에 따르면 대다수의 경우 이러한 조건은 거의 아무런 방해가 되지 않다고 합니다.&lt;br /&gt;&lt;br /&gt;가장 기본적인 대원칙은 코드를 &quot;읽기 쉽게&quot; 만드는 원리가 적용될 때마다 의심의 여지가 생기면 언제나 가독성의 기본 정리가 다른 어떤 규칙보다 앞선다는 점입니다.&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;&quot;이 코드는 이해하기 쉬운가?&quot;&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;br /&gt;만일 정리가 되지 않을 코드를 고치고 싶을 때는 먼저 뒤로 한 걸음 물러나서 스스로에게 물어보는 것이 중요합니다: &quot;이 코드는 이해하기 쉬운가?&quot;. 만약 그렇다면 다른 코드로 건너뛰어도 별 상관이 없습니다.</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/868743091536295491/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. '/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-649523289300133464</id><published>2018-08-04T18:02:00.000+09:00</published><updated>2018-09-02T15:04:31.122+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>What is the relationship between orthogonal, correlation and independence?</title><content type='html'>제게는 마주칠 때마다 헷갈려서 다시 고민하게 되는 개념들이 있는데, 그 중 대표적인 것이 바로 이 세 가지 녀석들입니다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;Orthogonality, Correlation, Independence.&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;오늘도 다시 한 번 마주칠 일이 있어서 또 하루종일 공부하는 우매한 짓을 저지른 후, 다시는 이러지 않도록(....이러고선 또 언젠가 다시 이 포스트를 보고 공부하겠지...뻔해...) 정리를 해보고자 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Independence&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Independence&quot;&lt;/b&gt;는 통계적인 개념입니다. 두 random variables X와 Y의 joint distribution이 marginal distribution의 곱으로 표현이 될 때 statistically independent하다고 말한다. 각 variable의 density를 $f$라고 하면:&lt;/div&gt;&lt;div&gt;$$f(x,y) = f(x)f(y),$$&lt;/div&gt;&lt;div&gt;좀 더 일반적으로는 cumulative distribution function을 $F$라고 할 때,&amp;nbsp;&lt;/div&gt;&lt;div&gt;$$F(x,y) = F(x)F(y)$$&lt;/div&gt;&lt;div&gt;라고 표현할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Correlation&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Correlation&quot;&lt;/b&gt;은 independence와 관련이 있으나 좀 더 약한 통계적 개념으로 두 random variables 간 (Pearson) correlation은 정규화된(standardized) variables의 곱의 기대값을 말합니다:&lt;/div&gt;&lt;div&gt;$$\begin{align*}\rho_{XY} &amp;amp;= \mathbf{E}\left[\frac{X-\mathbf{E}[X]}{\sqrt{\mathbf{E}[(X-\mathbf{E}[X])^2]}}\frac{Y-\mathbf{E}[Y]}{\sqrt{\mathbf{E}[(Y-\mathbf{E}[Y])^2]}}\right]\\&lt;br /&gt;&amp;amp;= \frac{cov(X,Y)}{\sigma_X\sigma_Y}.\end{align*}$$&lt;br /&gt;이 때, $\rho_{XY}=0$는 variables X와 Y가 서로&lt;i&gt; uncorrelated&lt;/i&gt; 되어있다는 말입니다. 한 가지 유의할 점은 두 random variables가 independent하면 항상 uncorrelated이지만 그 역은 성립하지 않는다는 점입니다. (순방향은 정의에 맞게 식을 전개해보면 되고, 역은 counter example을 들어 쉽게 증명할 수 있습니다.)&lt;br /&gt;&lt;br /&gt;순방향에 대한 식 전개:&lt;br /&gt;&lt;div class=&quot;proof&quot;&gt;$$\begin{align*}\mathbf{E}[XY]&amp;amp;=\int\int xyP_{X,Y}(x,y)dxdy \\&lt;br /&gt;&amp;amp; = \int\int xyP_X(x)P_Y(y)dxdy\\&lt;br /&gt;&amp;amp;=\mathbf{E}[X]\mathbf{E}[Y] \end{align*}$$&lt;br /&gt;역방향에 대한 counter examples:&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;여기서 한 가지 헷갈리는 부분이 나오는데요. 지금까지 얘기한 independence는 statistical independence인데 이게 linear independence랑 서로 관련이 있으면서도 다르다는 것입니다. Linear dependent한 경우 statistically dependent 입니다. 이는 $\alpha X = Y$를 만족하는 non-zero scalar $\alpha$가 있을 때,&lt;br /&gt;$$cov(X,Y)=cov(\frac{1}{\alpha}Y,Y) = \frac{1}{\alpha}Var(Y) \neq 0 $$&lt;br /&gt;인 것으로 확인할 수 있습니다. 그러나&amp;nbsp; X와 Y가 linear independent할지라도 $\rho_{XY}\neq 0$일 수 있기 떄문에 linear independence가 statistical independence를 보장해주지는 않죠.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Orthogonality&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;&quot;Orthogonality&quot;&lt;/b&gt;는 기하에서 온 개념으로 선형 대수학에서 일반적인 정의를 배울 수 있습니다.&amp;nbsp; 선형대수학에서 정의하는 것을 보면, 두 벡터 $u$ 와 $v$가 서로 orthogonal하다는 것은 두 벡터 간의 내적 $&amp;lt;u,v&amp;gt;$이 정의된 내적 공간(inner product spaces)에서 다음 조건을 만족한다는 것입니다:&lt;br /&gt;$$&amp;lt;u,v&amp;gt;=0.$$&lt;br /&gt;즉, 어떤 벡터 간의 orthogonality는 정의한 내적에 따라 달라지기 때문에 주의해야 합니다.&lt;br /&gt;&lt;br /&gt;내적은 여러 방식으로 정의될 수 있는데, 한 예로 벡터들이 다음과 같이 수열로 나타내질 때는 우리가 흔히 아는 dot product를 골라서 사용할 수 있겠습니다:&lt;br /&gt;$$u=(u_1,u_2,\cdots,u_n), &amp;lt;u,v&amp;gt;=\sum_{i=1}^{n}u_i v_j.$$&lt;br /&gt;앞서 설명을 유심히 봤으면 알겠지만 orthogonality는 본질적으로 통계적인 개념이 아닙니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Orthogonality&lt;/b&gt;는 본질적으로 &lt;b&gt;통계적인 개념이 아니다!&lt;/b&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br /&gt;그래서 우리가 헷갈리는 이유가 보통 선형대수학에서의 개념을 통계로 가져오면서 생기는 것에서 기인하는 경우가 많습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;A)&lt;/h3&gt;&lt;br /&gt;형식상 random variables의 공간은 vector space로 생각할 수 있습니다. 그러면 당연히 그 공간에서 내적을 다양한 방식으로 정의할 수도 있을텐데, 그 중 &lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot; target=&quot;_blank&quot;&gt;한 가지 방식&lt;/a&gt;이 바로 covariance를 내적으로 사용하는 것입니다:&lt;br /&gt;$$&amp;lt;X,Y&amp;gt; = cov(X,Y) = \mathbf{E}(X-\mathbf{E}[X])\mathbf{E}(Y-\mathbf{E}[Y]).$$&lt;br /&gt;두 random variables간 correlation이 0이면 covariance도 0이기 때문에, &lt;i&gt;이 정의에 의해서&lt;/i&gt;&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Uncorrelated_random_variables&quot; target=&quot;_blank&quot;&gt;($\mathbf{E}[X]$나 $\mathbf{E}[Y]$ 중 하나가 0인 경우) uncorrelatedness가 orthogonality와 정확히 같아집니다.&lt;/a&gt; 따라서 두 random variables가&amp;nbsp;&lt;b&gt;independent하면&amp;nbsp;&lt;/b&gt;&lt;b&gt;(그리고 둘 중 하나는 zero-centered일 때)&amp;nbsp;&lt;/b&gt;&lt;b&gt;서로 uncorrelated이며&lt;/b&gt; &lt;b&gt;orthogonal 하다&lt;/b&gt;고 얘기할 수 있습니다.&amp;nbsp;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot; target=&quot;_blank&quot;&gt;다른 방식&lt;/a&gt;으로는 $\mathbf{E}[XY]$으로도 내적을 정의할 수도 있습니다 (결국 같은 얘기).&lt;br /&gt;&lt;br /&gt;다만, 앞서 얘기한 바와 같이 그 역은 항상 성립하지는 않는데요. 즉, 두 random variable이 orthogonal하다고 해서 independent하지는 않습니다. 이 부분에서 헷갈리는 것이 &quot;음? 직교하는데 independent하지 않는 경우가 어떤게 있지?&quot; 하는 생각이 바로 들게 되죠.&lt;br /&gt;&lt;br /&gt;이 부분이 매우 어색하고 이상하다고 여겨지는 이유는 random variable을 어느 순간 fixed variable과 dot product를 가지고 노는 선형 벡터 쪽 영역으로 은근슬쩍 넘어가서 생각하기 때문입니다. 여기서의 직교는 내적을 covariance로 정의하였을 때를 기준으로 얘기하기 때문에 우리가 흔히 생각하던 fixed variable vectors 둘을 골라서 dot product한 기준으로 얘기하면 안 됩니다. 즉, 정의대로 orthogonal = uncorrelated인 경우만을 생각하면 uncorrelated이나 dependent인 경우는 쉽게 받아들일 수 있습니다.&lt;br /&gt;&lt;br /&gt;예를 들어 $X$가 $\{-1,0,1\}$ 중 하나의 값을 동일한 확률로 뽑는 random variable일 때 $Y=X^2$에 대해 $\rho_{XY}=0$이지만 dependent임을 쉽게 알 수 있습니다. 사실 $X$가 0을 기준으로 symmetric pdf를 가지면 그 모든 예시에 대해 $X$와 $Y$는 서로 (covariance-wise) orthogonal하지만 dependent합니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;B)&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;그러나 &lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/156554#156554&quot; target=&quot;_blank&quot;&gt;통계에서 다루는 모든 variables가 random variables는 아니라는 점&lt;/a&gt;에 주의해야 합니다. 특히, 선형 회귀 문제를 생각해보면 거기서 사용하는 입력값과 같은 독립 변수(independent variables)들은 random이 아니라 이미 &quot;정해진&quot; 값들입니다. Independent variables는 보통 수열로 주어지고 위에서 얘기한 바와 같이 자연스럽게 dot product를 내적으로 사용할 수 있겠습니다. 이 때, independent variables가 regression line에 대해 orthogonal인지 아닌지 등을 얘기하는데 이런 맥락에서 보면 애시당초 orthogonality는 statistical definition도 갖지 않고 random variable에 적용되는 얘기도 아니죠. (ANOVA에서의 &lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot; target=&quot;_blank&quot;&gt;orthogonal contrasts&lt;/a&gt; 등)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;정리해보자면 A)에서는 uncorrelatedness와 orthogonality는 사실 같은 것에 대한 다른 이름일뿐입니다. 따라서 가장 좋은 것은 random variable에 대해 uncorrelatedness를 말할 때는 orthogonality라는 용어를 사용하지 않는 것입니다. 그리고 같은 논지로 B)의 맥락에서는 non-random variable에 대해 correlation이라는 용어를 사용하는 것을 지양하는 것이 좋겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;더 읽어볼 것...&lt;/h2&gt;&lt;br /&gt;아래 reference로 달아둔 링크 중 &lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot; target=&quot;_blank&quot;&gt;&quot;Linearly Independent, Orthogonal, and Uncorrelated Variables&quot;&lt;/a&gt;라는 제목의 레포트가 있습니다. Non-random variable에 대해 내적으로 dot product를 사용하여&amp;nbsp;지금까지 본문에서 바라본 statistical 관점이 아니라 대수적 혹은 기하적 관점에서 바라본 논문 형태의 레포트인데요. 내용을 매우 잘 설명한 좋은(짧은) 논문이지만, 이 경우 내적이 dot product로 달라졌으므로, &lt;b&gt;orthogonality와 uncorrelatedness가 같지 않으며&lt;/b&gt; 자칫하면 지금까지 간신히 잡아둔 개념들이 더 헷갈릴 수 있습니다. 따라서 분명한 차이가 있다는 것을 염두에 두고 봐야 합니다.&lt;br /&gt;&lt;br /&gt;* 그리고 위 레포트에서는 non-random variable에 대해서도 correlation의 개념을 사용합니다. 엄밀히 말하자면 이는 지금까지가 우리가 얘기했던 population에 대한 correlation coefficient가 아닌 &lt;a href=&quot;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#For_a_sample&quot; target=&quot;_blank&quot;&gt;sample correlation coefficient일 때 성립합니다.&lt;/a&gt;&amp;nbsp;앞서는 random variable이 표본 공간(sample space)에 대해 정의된 함수이며, 이 때 함수(random variables)들에 대한 내적을 얘기한 것이었다면, 위 레포트에서는 fixed or predefined variable 즉, sample에 대한 얘기이므로 분명히 다릅니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;References&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/171347&quot;&gt;https://stats.stackexchange.com/a/171347&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&quot;&gt;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&quot;&gt;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot;&gt;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&quot;&gt;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot;&gt;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot;&gt;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/649523289300133464/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html' title='What is the relationship between orthogonal, correlation and independence?'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-7046349279022556648</id><published>2018-05-09T15:08:00.001+09:00</published><updated>2018-06-04T10:27:02.126+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Spectral Normalization for Generative Adversarial Networks</title><content type='html'>&lt;h2&gt;Spectral Normalization for Generative Adversarial Networks&lt;/h2&gt;&lt;h2&gt;&lt;div&gt;&lt;span style=&quot;font-size: small;&quot;&gt;TL;DR: A novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Keywords: Generative Adversarial Networks, Deep Generative Models, Unsupervised Learning&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Accept: (Oral)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Rating: 8-8-8&lt;/span&gt;&lt;br /&gt;&lt;b style=&quot;font-size: medium;&quot;&gt;Review:&lt;/b&gt;&lt;span style=&quot;font-size: small; font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://openreview.net/forum?id=B1QRgziT-&quot; style=&quot;font-size: medium; font-weight: 400;&quot;&gt;https://openreview.net/forum?id=B1QRgziT-&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium;&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Preferred network 그룹에서 나온 논문. (최근 핫한 일본 그룹) 그리고 Ian Goodfellow의 홍보 (보증?...) 개인적으로 매우 취향인 논문. &lt;/span&gt;(이후 더 자세히 리뷰 예정)&lt;span style=&quot;font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;GANs를 안정적으로 학습시키는 것을 새로운 weight normalization으로 해결해보고자 함. Spectral normalization이라 불리는 이 방법은,&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;ul style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;li&gt;Intensive hyper parameter이 필요없음. Lipshitz&amp;nbsp;constant가 유일한&amp;nbsp;hyperparameter&amp;nbsp;to be tuned. (심지어는 tuning 안 해도 잘 됨)&lt;/li&gt;&lt;li&gt;Implementation이 단순하고 computational cost가 적음.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Batch normalization이나 weight decay, feature matching on the discriminator와 같은 regularization tech.가 없이도 working 잘 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;2. Spectral Normalization&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;각 레이어의 spectral norm을 제약함으로써 Discriminator function $f$의 Lipschitz constant를 컨트롤 함.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;ReLU와 같은 activation function의 Lipschitz norm은 1이기 때문에 네트워크 전체를 볼 때 고려하지 않아도 되고, 결국 Weight의 Lipschitz norm을 나눠줌으로써 각 weight matrix $W$의 Lipschitz constant $\sigma(W)=1$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;$$\bar{W}_{SN}(W):=W/\sigma(W).$$&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;이를 바탕으로 $||f||_{Lip}$가 1로 상계를 갖도록(upper bounded) 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h3&gt;Gradient Analysis of the Spectrally&amp;nbsp;Normalized Weights&lt;/h3&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;The gradient of $\bar{W}_{SN}(W)$ w.r.t. $W_{ij}$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align} \frac{\partial\bar{W}_{SN}(W)}{\partial W_{ij}}&amp;nbsp; &amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{1}{\sigma(W)^2}\frac{\partial \sigma(W)}{\partial W_{ij}}W \\&amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{[u_1v_1^T]_{ij}}{\sigma(W)^2}W \\&amp;amp;= \frac{1}{\sigma(W)} (E_{ij} - [u_1v_1^T]_{ij}\bar{W}_{SN}) \end{align}&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 $E_{ij}$는 $(i,j)$-th entry는 1 나머지는 0인 행렬이고 $u_1$과 $v_1$이 first left and right singular vecotrs of $W$. $h$를 hidden layer라고 하면 아래가 성립함:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align}\frac{\partial V(G,D)}{\partial W}&amp;amp;=\frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-(\hat{E}[\delta^T\bar{W}_{SN}h])u_1v_1^T)\\&lt;br /&gt;&amp;amp;= \frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-\lambda u_1v_1^T) \end{align}&lt;br /&gt;여기서 $\delta:=(\partial V(G,D)/ \partial(\bar{W}_{SN}h))^T, \lambda:=\hat{E}[\delta^T(\bar{W}_{SN}h)]$이고 $\hat{E}[\cdot]$은 각 미니 배치의 empirical expectiation을 나타냄.&lt;br /&gt;For some $k\in \mathbb{R}$, $\hat{E}[\delta h^T]=ku_1v_1^T$일 때 $\frac{\partial V}{\partial W}=0$이 성립함.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 식 (5)의 해석이 매우 재미있는데, 식의 첫번째 항은 normalize되지 않은 weights에 대한 미분이므로 별다를 것이 없고 두번째 항이 추가된 것으로 생각해보면, 이를&amp;nbsp;adaptive regularization coefficient $\lambda$만큼 첫번째 singular component를 penalize하는 regularization 항으로 본다면 다음과 같은 해석이 가능함:&lt;br /&gt;&lt;br /&gt;$\lambda$가 양수라는 얘기는 $\delta$와 $\bar{W}_{SN}h$가 비슷한 방향을 가르키고 있다는 것을 의미함. 즉, $W$의 column space가 한 쪽 방향으로만 집중해서 update되는 것을 막아준다고 해석할 수 있음. 논문에서는 이를 통해 spectral normalization이 네트워크의 각 layer가 한 방향으로만 sensitive하지 않도록 막는다고 얘기함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;3. Spectral Normalization vs Other Regularization Techniques&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Weight normalization은 결과적으로 너무 강한 constraint를 걸어버리는 경향이 있음. Weight normalization은 weight matrix의 rank를 1이 되도록 강제함 (matrix norm과 weight normalization definition에 의해 수식을 보면 확인할 수 있음).&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;그런데 이렇게 하면 discriminator가 하나의 feature만을 보고 probability distribution을 구별해야하기 때문에 discriminator가 매우 sensitive하고 unstable하게 만드는 경향이 있음.&lt;br /&gt;&lt;br /&gt;Orthonormal regularization on each weight는 spectral normalization과 유사하면서도 학습을 안정화해주기는 하지만,&lt;br /&gt;$$||W^TW-I||_F^2$$&lt;br /&gt;weights를 orthonormal하게 하므로써 (모든 singular value를 1로 강제하기 때문에) spectrum의 envelop을 망치고 중요한 정보를 잃어버리는 경향이 있음. Spectral normalization은 spectrum의 scale만을 조절하기 때문에 (최대 값을 1) 이와는 다름.&lt;br /&gt;&lt;br /&gt;GP와 같은 경우는 위에서 설명한 다른 normalization tech.들과 같은 문제는 없지만 현재 generative distribution의 support에 매우 강하게 엮여있다는 약점이 있음. 이 때문에 학습이 진행됨에 따라 generative distribution의 support도 바뀌기 때문에 학습 과정이 불안정적이 된다는 단점이 생김. Spectral normalization은 학습하는 함수를 operator space에서 regularize하기 때문에 들어오는 데이터 batch에 보다 덜 민감한 것을 볼 수 있음.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;4. Experiments&lt;/h2&gt;&lt;br /&gt;최초로 단일 네트워크로 이미지넷 1000개 범주의 이미지를 생성한 방법인 것만으로도 큰 의미를 지님.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;/h2&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/7046349279022556648/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html' title='[Paper Skim] Spectral Normalization for Generative Adversarial Networks'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s72-c/SNGAN2.png" height="72" width="72"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1857320262473439791</id><published>2018-05-01T08:09:00.001+09:00</published><updated>2018-05-01T10:07:50.973+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;AmbientGAN: Generative Models From Lossy Measurements&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;How to learn GANs from noisy, distorted, partial observations&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt; Generative models, Adversarial networks, Lossy measurements&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Rating: 8-7-7&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Review:&amp;nbsp;&lt;/b&gt;&lt;a href=&quot;https://openreview.net/forum?id=Hy7fDog0b&quot;&gt;https://openreview.net/forum?id=Hy7fDog0b&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;GAN을 학습시키기 위해서 고퀄리티 샘플들이 필요한데 (예시: 노이즈가 없는 사진들) 보통 그런 경우가 많지 않다는 것을 지적하고 이를 해결하고자 한 논문.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;즉, 샘플에 occlusion이나 noise, blur 등의 문제가 있는 데이터셋만으로도 원래와 같이 고퀄리티 샘플(occulusion noise blur 혹은 unknown any noise가 없는)을 생성할 수 있는 Generative model을 학습하고자 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;직관적인 이해를 위해 결과부터 좀 소개하자면:&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이렇게 맨 왼쪽과 같이 patch가 잘려서 zero가 되는 noise function으로 더럽혀진 데이터셋만 있는 경우에도 generator가 맨 오른쪽과 같이 어느정도 얼굴 형태를 생성해내는 모델을 학습함. (중간은 baseline)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;개인적으로 재미있었던 실험은 MNIST 데이터를 패딩을 바탕으로 크기를 키운 다음 임의의 각도로 회전하고 한쪽 방향으로 sum 된 1D 데이터로 squash한 데이터들을 바탕으로 학습을 해도 generator가 아래와 같이 어느정도 숫자를 generate하는 모델을 학습해내는 것.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;추가 정보로 회전각을 넣어주었을 때 더 잘 복원됨. (오른쪽, 사실 이건 의료 영상에서 CT와 같은 projection으로 생각해보면 자명함)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 논문이 재미있는건 이렇게 이미지가 복원이 되는 조건을 명확하게 하고 수학적으로 증명을 하였다는 점.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;네트워크 구조도&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Generator가 먼저 깨끗한 이미지 $X_g$를 만들면 $f_{\theta}$가 이를 corrupt하는 noise function을 학습해서 $Y_g$를 만들어내고 Discriminator가 corrupt된 real data $Y_r$와 이를 비교하게 하는 구조.&lt;br /&gt;&lt;br /&gt;풀고자 하는 문제를 참 잘 특정해서 잡았다고 생각하는 것이, 우리가 얻을 수 있는 데이터는 실제로는 이미 어떤 unknown noise function에 의해 corrupt 되어 나온 것인 경우가 많다는 것이 기본 바탕.&lt;br /&gt;&lt;br /&gt;AmbientGANs에서는 데이터가 충분히 많기만 하다면, 이런 noise function을 학습하고 기존의 data distribution을 복원하는 것이 가능하다는 것을 analytically &amp;amp; empirically 보임.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이거 보고 나서 결과를 improve해볼 수 있는 idea들이 몇 개 생각나긴 했는데 해보고 싶은것들이 막 생깁니다ㅋㅋ 당장 recon loss와 cyclic loss를 붙여볼 수 있겠네요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;참고자료&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;(slideshare) &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&quot;&gt;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1857320262473439791/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html' title='[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s72-c/ambiGAN1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-673973366306707726</id><published>2018-05-01T07:28:00.000+09:00</published><updated>2018-05-01T10:23:16.712+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation</title><content type='html'>&lt;h2&gt;&lt;b&gt;Progressive Growing of GANs for Improved Quality, Stability, and Variation&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;Train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt;&amp;nbsp;generative adversarial networks, unsupervised learning, hierarchical methods&lt;/div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Rating: 8-8-8&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Review:&lt;/b&gt;&amp;nbsp;&lt;a href=&quot;https://openreview.net/forum?id=Hk99zCeAb&quot;&gt;https://openreview.net/forum?id=Hk99zCeAb&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;GANs를 학습하는 새로운 방법을 제안.&lt;br /&gt;핵심 아이디어는 generator와 discriminator를 점진적으로 키운다는 것: 저해상도에서 시작해서 세밀한 점들을 배울 수 있도록 새로운 레이어들을 추가하는 방식.&lt;br /&gt;이런 방식을 취함으로 인해 GANs을 보다 안정적이면서 빠르게 학습하는 것이 가능해졌다고 얘기함; CelebA 1024^2 해상도 이미지를 만들어 내는 네트워크 학습.&lt;br /&gt;또한 CIFAR10에서 비지도학습 방식으로 생성된 이미지들의 종류가 다양하도록 할 수 있는 간단한 방법을 제안함. Inception score가 8.80에 달한다고 함.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;br /&gt;고해상도 이미지를 만드는 것은 매우 어려운데 그 이유는 해상도가 높을 수록 생성한 이미지인지를 구분하는 것이 쉬워지기 때문.&lt;br /&gt;게다가 큰 해상도 이미지로 인해 메모리 문제로 더 작은 minibatches를 사용하게되고 학습 안정성에 문제가 됨.&lt;br /&gt;여기서 저자들의 주요 insight는 generator와 discriminator를 점진적(progressively)으로 키우는 것.&lt;br /&gt;&lt;br /&gt;기존의 GAN 수식은 학습된 생성 모델이 굳이 학습 데이터 분포 전체를 모두 표현할 필요가 없었음. (?)&lt;br /&gt;기존의 공통된 의견은 이미지의 질과 다양성이 서로 tradeoff 관계라는 것이었으나 최근 Odena et al. 2017에 의해 다른 의견이 제기됨. (확인 필요)&lt;br /&gt;다양성에 대한 측정 방법에 대해 매우 많은 방식들이 제안되고 있는데:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;including inception score (Salimans et al., 2016), multi-scale structural similarity (MS-SSIM) (Odena et al., 2017; Wang et al., 2003), birthday paradox (Arora &amp;amp; Zhang, 2017), and explicit tests for the number of discrete modes discovered (Metz et al., 2016).&amp;nbsp;&lt;/blockquote&gt;PGGAN에서는 이 외에 다양성을 보다 북돋기 위해 사용한 방법을 설명하고 이미지의 질과 다양성을 측정하기 위한 새로운 metric을 제안하였음.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;2. Progressive Growing of GANs&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;키 아이디어 정리: 단계별 학습 (구몬??!)&lt;/b&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;The complex mapping from latents to high-resolution images is easier to learn in steps&quot;&amp;nbsp;&lt;/blockquote&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;아래 그림에서 볼 수 있듯이 점진적으로 네트워크 레이어를 추가할 때 sudden shock이 일어나지 않도록 새로 추가하는 레이어를 부드럽게 (fade in) 넣어줌.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;3. Increasing Variation using Minibatch Standard Deviation&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이미지가 다양하게 생성되도록 하기 위해 GANs이 학습 데이터의 일부분만 집중하는 성질이 있는 것을 고려하여 Salimans et al. (2016)에서는 Minibatch discrimination 방식을 제안했었음. Feature statistics를 계산할 때 각각의 이미지만 보는 것이 아니라 minibatch 전체에 대해 계산하므로써 생성된 이미지와 학습 이미지들이 비슷한 statistics를 갖도록 하자는게 아이디어였음. (구체적 방식은 다시 &lt;b&gt;체크&lt;/b&gt;) PGGAN에서는 이 접근 방식을 보다 단순하게 만들면서도 다양성은 증대하는 방법을 제안함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 방식은 parameter 학습이 필요하거나 새로운 hyperparameter가 필요하지 않음. 먼저 minibatch에 있는 각 spatial location에서의 feature 각각의 stardard deviation을 계산함. 이 estimates를 모든 features와 spatical locations에 대해 평균을 내고 하나의 값을 계산함. 이 값을 복사해서 모든 spatial locations와 minibatch에 대해 concat하는 방식으로 (constant) feature map을 하나 추가함. 이 레이어는 discriminator의 어느 위치에도 들어갈 수 있으나 inset it towards the end가 가장 좋은 성능을 보였음.&amp;nbsp;&lt;/div&gt;&lt;div&gt;Parallel work으로 Lin et al. (2017)이 이와 유사한 방식(multiple images를 discriminator에 보여주는 것이 좋은 이유)을 이론적으로 설명한 바 있음. (&lt;b&gt;체크&lt;/b&gt;)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;4. Normalization in Generation and Discriminator&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;GANs에서의 normalization은 signal magnitude와 competition을 제한하는 쪽에 주안점을 두어야한다고 생각함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.1 Equalized Learning Rate&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;기존의 방식들이 weight initialization에 심혈을 기울이는 것과는 달리 여기서는 초기값은 대충 표준정규분포로 주되 runtime 중 weights의 scale을 조절하는 방향을 취함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.2 Pixelwise Feature Vector Normalization in Generator&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Generator와 Discriminator가 서로 경쟁한 끝에 발산하는 경우를 막기 위해서 generator에서 하나의 conv layer를 지날때마다 각 pixel의 feature vector를 정규화.&amp;nbsp;&lt;/div&gt;&lt;div&gt;이 방식이 실험 결과는 크게 바꾸지 않았지만 signal magnitude가 급격히 커지는 현상을 매우 효과적으로 없애주었다고 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;5. Multi-Scale Statistical Similarity for Assesing GAN results&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;서로 다른 GAN을 비교하는 것은 여러모로 쉽지 않음. MS-SSIM(Odena et al., 2017)과 같은 방식은 large-scale mode collapse를 잘 발견하지만 color나 texture의 작은 loss들을 발견하지 못하는 단점들이 알려져있음. 그리고 학습 데이터와의 유사한 정도를 직접적으로 고려하지 않기 때문에 문제가 있음.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;PGGAN에서는 각 scale 별로 학습데이터와 생성 데이터의 local structure가 서로 유사해야한다는 intuition을 바탕으로 local image patches의 분포 간의 multi-scale statistical similarity를 확인하는 방식을 취함(Laplacian pyramid, Burt &amp;amp; Adelson, 1987 다시 &lt;b&gt;체크&lt;/b&gt;).&amp;nbsp;&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;6. Experiments&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&amp;nbsp;판타스틱함!&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;h2&gt;Stillcut from ICLR oral presentation&amp;nbsp;&lt;/h2&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;Video presentation&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;iframe allowfullscreen=&#39;allowfullscreen&#39; webkitallowfullscreen=&#39;webkitallowfullscreen&#39; mozallowfullscreen=&#39;mozallowfullscreen&#39; width=&#39;530&#39; height=&#39;266&#39; src=&#39;https://www.blogger.com/video.g?token=AD6v5dyLwnBUd0xRKCGi2PzX9PMySP41bXJuvw5lPbKrU7e1F8Q1rO66QrLCD-yKPAMH6fWI2yqXNJ87XEJ1aL-xDg&#39; class=&#39;b-hbp-video b-uploaded&#39; frameborder=&#39;0&#39; /&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/673973366306707726/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html' title='[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s72-c/pggan1.PNG" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-3983669769096239575</id><published>2018-02-24T15:00:00.001+09:00</published><updated>2018-08-04T22:24:05.873+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (3)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html&quot;&gt;저번 글&lt;/a&gt;까지 하여 우리는 이제 드디어 parameter의 좋고 나쁨을 정량화할 방법에 대해 얘기해볼 때가 되었습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Loss function&lt;/h2&gt;&lt;br /&gt;지금까지는 response variable이 어떻게 생성되고 각각의 관찰값에 따라 각 분포에 대한 parameters를 어떻게 계산하는지에 대해 알아보았습니다. 자, 그럼 어떤 parameters가 좋은 것인지 어떻게 정량화할 수 있을까요?&lt;br /&gt;&lt;br /&gt;시작하기에 앞서, 잠시&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;를 예측하는 것을 상기해보겠습니다. 만약 우리가 고양이 그림을 모델에게 넣어준다면 다음의 binomial distribution가 주어졌을 때, $\phi\approx0$이도록 계산을 해야겠지요.&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;\begin{cases}&lt;br /&gt;1 - \phi &amp;amp; \text{outcome = cat}\\&lt;br /&gt;\phi &amp;amp; \text{outcome = dog}\\&lt;br /&gt;\end{cases}$$&lt;br /&gt;가장 완벽한 경우, $\phi=0$가 될 것입니다. 그리고 loss function이 우리가 얼마나 답에 가까이 갔는지 정량화해주겠지요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum likelihood estimation&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;앞서 글들에서 소개하였던 세 개의 분포들 각각은 $\mu,\phi,\pi$와 같은 parameter를 갖습니다. 임의의 $y$를 주면 각 분포가 현재 우리가 관찰한 값이 나올 확률을 알려주게 되지요. (예를 들어 continuous-valued random variables의 경우, 분포는 확률 밀도 함수가 되고 이 함수가 우리가 찾는 확률 값에 비례하는 어떤 값을 내뱉습니다.)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;만약 $y$를 고정하고 parameter 값들이 바뀌도록 설정한다면 같은 함수가 이제는 likelihood function이 됩니다. 이 함수가 하는 일은 고정된 $y$ 값에 대해서 현재 parameter의 likelihood에 대해 알려주는 것이죠.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;위에 설명히 명확하지 않다면 아래의 예시들을 생각해보시면 됩니다:&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;모로코 사람 한 명이 바(bar)에 들어왔다. 그는 소매 한 짝이 없어진 축구 저지를 입고 있다. 눈에는 멍이 들었고 바지에는 피가 묻어있었다. 이 사람은 오늘 어떤 하루를 보냈을까?&lt;br /&gt;&lt;ol&gt;&lt;li&gt;집에서 책을 읽었을 것이다.&lt;/li&gt;&lt;li&gt;자전거 경주를 연습 중이었을 것이다.&lt;/li&gt;&lt;li&gt;축구 경기에서 (타 팀을 경멸하며 모두 종합격투기 선수인) 그의 친구들과 맥주를 마시며 놀았을 것이다.&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;우리는 현재 우리가 갖고 있는 데이터가 가장 나옴직한 parameter를 고르고 싶을 것이고, 바로 이게 &lt;i&gt;maximum likelihood estimate&amp;nbsp;&lt;/i&gt;입니다. 수학적으로는 다음과 같이 정의할 수 있습니다:&lt;br /&gt;$$\underset{\text{parameter}}{\arg\max}\ P(y\vert \text{parameter})$$&lt;br /&gt;지금까지 지겹도록 얘기한 것과 같이 $y$는 분포가 받는 parameter에 따라 변합니다. 게다가 이 parameter는 $\eta$라는 항으로 정의가 되었지요. 이어 $\eta=\theta^T x$입니다. 따라서 $y$는 $\theta$와 관측된 데이터 $x$에 대한 함수이죠. 아마도 이것은 여러분이 Day 1부터 알고 있었을 기계 학습의 가장 기본적인 이치일 것입니다.&lt;br /&gt;&lt;br /&gt;관측된 데이터는 고정되어있으므로, $\theta$만이 우리가 바꿀 수 있는 유일한 부분입니다. 이에 맞게 위의 argmax 식을 바꾸면 다음과 같습니다:&lt;br /&gt;$$\underset{\theta}{\arg\max}\ P(y\vert x; \theta).$$&lt;br /&gt;다만 $[0,1]$ 안의 값들을 여러 차례 곱하면 값이 매우 빠르게 작아지기 때문에 이런 현상을 방지하기 위해 log-likelihood를 사용하게 되는 것입니다. log의 성질 덕에 곱하기 연산이 더하기로 바뀌게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Linear regression&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Gaussian 분포의 log-likelihood를 최대화 해보겠습니다. $x$와 $\theta$가 함께 $\mu$를 만든 다는 것을 기억하세요; $\theta^T x=\mu$.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;\begin{align*} \log{P(y\vert x; \theta)} &amp;amp;= \log{\prod\limits_{i=1}^{m}P(y^{(i)}\vert x^{(i)}; \theta)}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{P(y^{(i)}\vert x^{(i)}; \theta)}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}} + \sum\limits_{i=1}^{m}\log\Bigg(\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}\Bigg)\\ &amp;amp;= m\log{\frac{1}{\sqrt{2\pi}\sigma}} - \frac{1}{2\sigma^2}\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\ &amp;amp;= C_1 - C_2\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\ \end{align*}&lt;br /&gt;&lt;div&gt;따라서 데이터와 $\theta$에 대해 log-likelihood를 최대화 하는 것은 관측된 $y$ 값과 우리가 예측한 값 사이의 negative mean squared error를 최대화 하는 것과 동치입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;다만 대다수의 최적화 루틴들이 최소화를 하는 방향으로 설계되어 있으므로 편의를 위해 최소화로 바꾸기만 할 뿐이죠.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the mean squared error between the observed y and our prediction thereof.&lt;/b&gt;&lt;/div&gt;&lt;h2&gt;Logistic regression&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bionomial distribution에 대해 위와 똑같은 방식으로 적용해봅시다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Negative log-likelihood:&lt;/div&gt;&lt;div&gt;\begin{align*} -\log{P(y\vert x; \theta)} &amp;amp;= -\log{\prod\limits_{i = 1}^m(\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}}\\ &amp;amp;= -\sum\limits_{i = 1}^m\log{\bigg((\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}\bigg)}\\ &amp;amp;= -\sum\limits_{i = 1}^my^{(i)}\log{(\phi^{(i)})} + (1 - y^{(i)})\log{(1 - \phi^{(i)})}\\ \end{align*}&lt;br /&gt;따라서&amp;nbsp;데이터와 $\theta$에 대해 negative log-likelihood를 최소화 하는 것은&amp;nbsp;관측된 $y$ 값과 우리가 예측한 값 사이의 binary cross-entropy (i.e. binary log loss)를 최소화 하는 것과 동치입니다.&lt;br /&gt;&lt;br /&gt;&lt;div&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the binary cross-entropy (i.e. binary log loss) between the observed y and our prediction of the probability thereof.&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;Multinomial distribution&lt;/h2&gt;&lt;br /&gt;Negative log-likelihood:&lt;br /&gt;\begin{align*} -\log{P(y\vert x; \theta)} &amp;amp;= -\log\prod\limits_{i=1}^{m}\prod\limits_{k=1}^{K}\pi_k^{y_k}\\ &amp;amp;= -\sum\limits_{i=1}^{m}\sum\limits_{k=1}^{K}y_k\log\pi_k\\ \end{align*}&lt;br /&gt;따라서&amp;nbsp;데이터와 $\theta$에 대해 negative log-likelihood를 최소화 하는 것은&amp;nbsp;관측된 $y$ 값과 우리가 예측한 값 사이의 categorical cross-entropy (i.e. multi-class log loss)를 최소화 하는 것과 동치입니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the categorical cross-entropy (i.e. multi-class log loss) between the observed y and our prediction of the probability distribution thereof&lt;/b&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross_entropy&quot;&gt;Cross-entropy&lt;/a&gt;&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;전에 확률 분포에 내재한 불확실성을 정량화하기 위해 entropy를 정의했던 것과 같이, 하나의 분포로부터 다른 분포의 사건을 예측할 때 내재한 불확실성을 정량화한 것이 바로 cross-entropy입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;red&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;green&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;blue&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;red&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;green&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;blue&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div&gt;$$(p, q) = -\sum_i p_i\log(q_i)$$&lt;/div&gt;&lt;h3&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;&gt;KL-Divergence&lt;/a&gt;&lt;/h3&gt;&lt;br /&gt;비슷한 방식으로 Kullback-Leibler Divergence도 역시 $q$를 사용하여 $p$를 근사할 때 추가적으로 생기는 불확실성을 정량화합니다.&lt;br /&gt;$$D_{KL}(p, q) = H(p, q) - H(p)$$&lt;br /&gt;이를 기계학습 모델들에서 잘 사용하지 않는 이유는 실제 분포 $p$를 알아야지만 계산이 가능하기 때문이죠. 보통은 $p$를 모르고 있기 때문에 사용을 할 수 없습니다 (애시당초 true $p$를 알고 싶어서 모델을 세우는 것인데 이렇게 되면 주객전도지요 ㅎㅎ).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum a posteriori estimation&lt;/h2&gt;&lt;br /&gt;$\theta$가 MLE를 바탕으로 estimate될 때는 별다른 제약을 걸지 않았었습니다. 좀 더 구체적으로 얘기하자면, $\theta$가 어떤 실수 값이 나오든 상관이 없었죠 ($0, 10, -20, 2.37\times10^{36}$).&lt;br /&gt;&lt;br /&gt;실제로는 이런 가정은 좀 비현실적이기도 하고 군더더기인 부분이기도 합니다. 보통은 $\theta$ (weights)가 유한범위 안에서 값을 갖기를 바라죠. 따라서 이를 위해 $\theta$에&amp;nbsp;&lt;i&gt;prior&amp;nbsp;&lt;/i&gt;를 두곤 합니다. MLE가 $\underset{\theta}{\arg\max}\ P(y|x;\theta)$일 때, maximum a posteriori estimate (MAP)는 $\underset{\theta}{\arg\max}\ P(y\vert x; \theta)P(\theta)$를 계산하게 됩니다.&lt;br /&gt;&lt;br /&gt;앞서와 마찬가지로 log를 씌운 다음 prior와 함께 joint likelihood를 풀면:&lt;br /&gt;\begin{align*}&lt;br /&gt;\theta_{MAP}&lt;br /&gt;&amp;amp;= \underset{\theta}{\arg\max}\ \log \prod\limits_{i=1}^{m} P(y^{(i)}\vert x^{(i)}; \theta)P(\theta)\\&lt;br /&gt;&amp;amp;= \underset{\theta}{\arg\max}\ \sum\limits_{i=1}^{m} \log{P(y^{(i)}\vert x^{(i)}; \theta)} + \log{P(\theta)}\\&lt;br /&gt;\end{align*}&lt;br /&gt;왼쪽 항은 앞서 다뤘던 것과 같고 남은 log prior 부분만 살펴보면 되겠군요.&lt;br /&gt;&lt;br /&gt;$\theta$의 모든 항이 continuous-valued 실수값이므로 평균 0과 분산 $V$를 갖는 Gaussian 분포를 할당해보겠습니다.&lt;br /&gt;$$\theta \sim \mathcal{N}(0, V)$$&lt;br /&gt;\begin{align*}&lt;br /&gt;\log{P(\theta\vert 0, V)}&lt;br /&gt;&amp;amp;= \log\Bigg(\frac{1}{\sqrt{2\pi}V}\exp{\bigg(-\frac{(\theta - 0)^2}{2V^2}\bigg)}\Bigg)\\&lt;br /&gt;&amp;amp;= \log{C_1} -\frac{\theta^2}{2V^2}\\&lt;br /&gt;&amp;amp;= \log{C_1} - C_2\theta^2\\&lt;br /&gt;\end{align*}&lt;br /&gt;우리의 목표는 log-likelihood와 함께 위의 항을 같이 $\theta$에 대하여 최대화하는 것입니다. $\theta$를 포함하지 않는 항을 정리하고 나면 다음과 같고:&lt;br /&gt;\begin{align*}&lt;br /&gt;\log{C_1} - C_2\theta^2&lt;br /&gt;&amp;amp;\propto - C_2\theta^2\\&lt;br /&gt;&amp;amp;\propto C\Vert \theta\Vert_{2}^{2}\\&lt;br /&gt;\end{align*}&lt;br /&gt;이것이 바로 L2 regularization라는 것을 아실 수 있습니다. 게다가 $\theta$에 대해 prior distribution을 바꾸면 또다른 regularization이 가능해집니다! 예를 들면 Laplace prior는 L1 regularization을 하는 것과 동치이지요.&lt;br /&gt;&lt;br /&gt;따라서 정리해보면, 기계학습에서 weights를 regularize한다고 함은 &quot;no weight becomes too large&quot; 하겠다는 것입니다. 즉 $y$를 예측할 때 너무 큰 영향을 미치지 못하게 만드는 것이죠. 통계적인 관점에서도 똑같이 이런 prior 항이 주어진 범위 내에서 값이 나오도록 제한하는 역할을 한다고 말할 수 있습니다. 이 범위가 scaling constant $C$로 표현되고 prior distribution 자체를 매계변수화합니다. 예를 들어 L2 regularization에서는 이 scaling constant가 Gaussian의 분산을 정하게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Going fully Bayesian&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;예측 모델의 주요 목표는 다음 분포를 계산하는 것입니다:&lt;/div&gt;$$P(y\vert x, D) = \int P(y\vert x, D, \theta)P(\theta\vert x, D)d\theta$$&lt;br /&gt;각 항을 설명해보자면:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$P(y|x,D)$: 학습 데이터 $D=((x^{(i)},y^{(i)}),\cdots,(x^{(m)},y^{(m)}))$와 새로운 관측값 $x$가 주어졌을 때, response $y$의 값에 대한 분포를 계산하는 것을 뜻합니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;기계학습에서는 보통 해당 분포의&amp;nbsp;&lt;i&gt;expected&lt;/i&gt; 값을 고르게 됩니다 (i.e. a single value, or point estimate).&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;$P(y|x,D,\theta)$: 학습 데이터 $D$, 새로운 관측값 $x$, 임의의 가능한 $\theta$ 값이 주어졌을때 (굳이 optimal이 아니더라도) $y$를&amp;nbsp; 계산하는 것을 뜻합니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;보통 주어진 모델에 대한 함수로 나타내지고 linear regression의 경우 $y=\theta^T x$와 같이 나타낼 수 있겠습니다.&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;$P(\theta|x,D)$: 학습 데이터 $D$와 새로운 관측값 $x$가 주어졌을 때 우리의 데이터를 설명할 수 있는 $\theta$ 값에 대한 분포를 계산하는 것을 뜻합니다.&lt;/li&gt;&lt;ul&gt;&lt;li&gt;여기서 x는 아무런 역할을 하지 않습니다. 그저 적분을 할 때 수식적 표현이 맞도록 들어가 있을 뿐입니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;기계학습에서는 MLE 혹은 MAP estimate을 고르게 됩니다 (i.e. a single value, or point estimate).&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;모든 것이 완벽하다면,&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\theta$에 대한 &lt;i&gt;full distribution&amp;nbsp;&lt;/i&gt;을 계산하고,&lt;/li&gt;&lt;li&gt;이 분포의 값들과 새로운 관측값 $x$를 가지고 $y$를 계산할 수 있습니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;NB: 여기서 $\theta$가 weights이므로 10-feature linear regression에서는 10개의 원소를 갖는 벡터가 됩니다. 신경망에서는 수백만이 되겠지요.&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;이로부터 가능한 모든 response $y$에 대한 full distribution을 얻을 수 있습니다.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;아쉽지만 복잡한 시스템들에서는 함수 형태가 계산이 쉽지 않으며 weights의 원소 개수가 매우 많기 때문에 위와 같은 계산이 불가능해집니다. 따라서 fully Bayesian modeling에서는 이런 분포들을 보통 근사를 하여 사용하지요. 전통적인 기계학습에서는 a single value (point estimate)를 할당하구요. 솔직히 썩 마음에 차지는 않지요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;br /&gt;이번 시리즈물이 기계학습 모델들을 이해하는데 유용한 글이었길 바랍니다. 이런 알고리즘들에 대한 보다 깊은 이해는 사실상 완전히 새로운 것은 없다는 점과 이런 알고리즘들은 보다 나은 방향으로 발전시킬 수 있는 비전을 보여주지요.&lt;br /&gt;&lt;br /&gt;긴 글 읽어주셔서 감사합니다. 이제 수영장에서 나와서 타월 하나 집고서&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;import sklearn&lt;/span&gt;하러 떠나봅시다.&lt;br /&gt;&lt;img alt=&quot;drink and towel&quot; class=&quot;img-responsive&quot; src=&quot;https://www.washingtonian.com/wp-content/uploads/2015/05/Pool520-994x664.jpg&quot; /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/3983669769096239575/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3983669769096239575'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3983669769096239575'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html' title='Minimizing the Negative Log-Likelihood, in Korean (3)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1241518821086770705</id><published>2018-02-05T18:07:00.001+09:00</published><updated>2018-08-04T22:23:53.872+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (2)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor.html&quot;&gt;저번 글&lt;/a&gt;에 이어서 output 함수들이 왜 그런 형태로 나오는지 알아보도록 하겠습니다. 잠시 복습을 하고 넘어가시죠!&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Functional form&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 글에서 다루고 있는 세 모델들은 각각 서로 다른 함수를 바탕으로 예측을 하는데요:&amp;nbsp; 각각 identity function (i.e. no-op), sigmoid function, and softmax function. Keras로 output layer를 만들어보면 명확합니다:&lt;/div&gt;&lt;div&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;softmax&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;이 단락에서는,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Gaussian, binomial 그리고 multinomial distributions가 같은 functional form으로 나타낼 수 있다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;이 common functional form에서 세 모델들의 output function (identity, sigmoid, softmax)가 자연스럽게 유도된다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;마치 다음 그림과 같이 생각할 수 있겠네요. 세 가지 분포가 들어가서 세 가지 output functions이 나오는 것이죠. (그림이 이상한데? -_-; 뭐 아무튼 하나의 functional form으로 설명이 가능해서 저렇게 표현할 수 있다고 생각하면 될 듯합니다.)&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;bottleneck&quot; class=&quot;img-responsive&quot; src=&quot;https://electric-cloud.com/wp-content/uploads/use-case-graphic_bottleneck.png&quot; /&gt;&lt;/div&gt;&lt;br /&gt;여기서 병목에 해당하는 개념은 확률 분포의&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_family&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; text-align: start; text-decoration-line: none;&quot;&gt;&quot;exponential family&quot;&lt;/a&gt;가 되겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Exponential family distributions&lt;/h2&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;In probability and statistics, an exponential family is a set of probability distributions of a certain form, specified below. This special form is chosen for mathematical convenience, on account of some useful algebraic properties, as well as for generality, as exponential families are in a sense very natural sets of distributions to consider.&lt;br /&gt;- 위키피디아&lt;/blockquote&gt;저(글쓴이)는 위의 설명을 그리 좋아하지 않습니다. 매우 모호하다는 점에서 특히&amp;nbsp;더 그렇습니다. 여기서 진실은 exponential functions이 우리가 잘 알고 사용하기 좋아하는 고전적인 activation과 loss functions을 하나의 틀에서 유도하는데 매우 좋은 도구라는 점입니다. 저는 &quot;mathematical convenience, on account of some useful algebraic properties, etc.&quot; 부분에 좀 더 집중해서 &quot;certain form&quot;이라는 것이 괴랄한 이유로 만들어진 것이 아니란 점을 얘기하고자 합니다.&lt;br /&gt;&lt;br /&gt;Exponential family에 속하는 분포는 다음과 같은 형태로 나타낼 수 있습니다:&lt;br /&gt;$$P(y; \eta) = b(y)\exp(\eta^T T(y) - a(\eta))$$ 여기서&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta$는 분포의 &lt;i&gt;canonical parameter&lt;/i&gt;입니다 (We will hereby work with the single-canonical-parameter exponential family form).&lt;/li&gt;&lt;li&gt;$T(y)$는 &lt;i&gt;sufficient statistic&lt;/i&gt;입니다. (많은 경우 $T(y)=y$입니다.)&lt;/li&gt;&lt;li&gt;$a(\eta)$는 &lt;i&gt;log partition function&lt;/i&gt;으로써 분포를 정규화하는데 쓰입니다. (더 깊은 논의는 다음 포스팅에서 보실 수 있습니다:&amp;nbsp;&lt;a href=&quot;https://cavaunpeu.github.io/2017/04/19/deriving-the-softmax-from-first-principles/&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;open sans&amp;quot;, &amp;quot;helvetica neue&amp;quot;, helvetica, arial, sans-serif; text-align: left;&quot;&gt;Deriving the Softmax from First Principles&lt;/a&gt;&lt;span style=&quot;background-color: white; font-family: &amp;quot;open sans&amp;quot; , &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; text-align: left;&quot;&gt;.&lt;/span&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;따라서 $T,a,b$를 정하면 분포의 family (or set)가 정해지고 이는 $\eta$로 parameterized 됩니다. 우리가 $\eta$를 바꿀 때마다 해당 familiy 안의 다른 분포를 만들 수 있겠죠. 이는 $Pr(heads)=0.6$인 동전이&amp;nbsp;$Pr(heads)=0.7$인 동전과는 다른 분포를 갖는 것으로 설명할 수 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s1600/bob.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;250&quot; src=&quot;https://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s400/bob.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;어때요, 참 쉽죠?&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;그럼 하나씩 살펴볼까요?&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Gaussian distribution&lt;/h2&gt;&lt;br /&gt;편의를 위해 여기서는 단일 매계변수 형태를 다루고 있기 때문에 $\sigma^2$가 $1$로 알려져있다고 가정해보겠습니다.&lt;br /&gt;$$\begin{align*}&lt;br /&gt;P(y\vert \mu, \sigma^2)&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\frac{(y - \mu)^2}{2\sigma^2}\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{(y - \mu)^2}{2}\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}(y^2 - 2\mu y + \mu^2)\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}y^2\bigg)} \cdot \exp{\bigg(\mu y - \frac{1}{2}\mu^2\bigg)}\\&lt;br /&gt;\end{align*}$$ 여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta=\mu$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = \frac{1}{2}\mu^2$&lt;/li&gt;&lt;li&gt;$b(y) = \frac{1}{\sqrt{2\pi}}\exp{(-\frac{1}{2}y^2)}$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;라고 해보겠습니다.&lt;br /&gt;&lt;br /&gt;마지막으로 $a(\eta)$는 다음과 같습니다:&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= \frac{1}{2}\mu^2\\&lt;br /&gt;&amp;amp;= \frac{1}{2}\eta^2&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;h2&gt;Binomial distribution&lt;/h2&gt;&lt;br /&gt;이항 분포에 대해 앞서 글에서 정의한 적이 있었죠? 여기서는 좀 더 단순하게 나타내서 이항 분포가 실제로 exponential familiy에 속한다는 것을 보일 것입니다. 여기서 $\phi$는 true class를 관측할 활률입니다. 즉, $Pr(cat) = 0.7&amp;nbsp;\implies \phi = 0.3$&lt;br /&gt;\begin{align*}&lt;br /&gt;P(y\vert \phi)&lt;br /&gt;&amp;amp;= \phi^y(1-\phi)^{1-y}\\&lt;br /&gt;&amp;amp;= \exp\bigg(\log\bigg(\phi^y(1-\phi)^{1-y}\bigg)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(y\log{\phi} + \log(1-\phi) - y\log(1-\phi)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\log\bigg(\frac{\phi}{1-\phi}\bigg)y + \log(1-\phi)\bigg) \\&lt;br /&gt;\end{align*}&lt;br /&gt;여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg)$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = -\log(1-\phi)$&lt;/li&gt;&lt;li&gt;$b(y) = 1$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;입니다. (어? 여기서 $\phi$가 $\eta$에 대한&amp;nbsp;&lt;b&gt;sigmoid 함수&lt;/b&gt;라는 걸 눈치채신 분?)&lt;br /&gt;&lt;br /&gt;마지막으로 분포의 매계변수 $\eta$에 대해 $a(\eta)$를 나타내면:&lt;br /&gt;$$\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg) \implies \phi = \frac{1}{1 + e^{-\eta}}$$&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= -\log(1-\phi)\\&lt;br /&gt;&amp;amp;= -\log\bigg(1-\frac{1}{1 + e^{-\eta}}\bigg)\\&lt;br /&gt;&amp;amp;= -\log\bigg(\frac{1}{1 + e^{\eta}}\bigg)\\&lt;br /&gt;&amp;amp;= \log(1 + e^{\eta}).\\&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Multinomial distribution&lt;/h2&gt;&lt;br /&gt;이항 분포처럼 다항 분포를 좀 더 단순한 형태로 표현해보겠습니다. $\pi$가 $K$ classes의 class 확률들의 벡터라 할 때, (여기서 $k$가 각 class들을 의미합니다.)&lt;br /&gt;$$P(y\vert \pi) = \prod\limits_{k=1}^{K}\pi_k^{y_k}$$&lt;br /&gt;복잡하게 보일 수 있지만 사실 저 수식이 의미하는 바는 $Pr(y=k)$가 class $k$에 대한 확률이라는 뜻입니다. 예를 들어,&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;일 때, 다음과 같이 계산하면 된다는 말이죠:&lt;br /&gt;\begin{align*}&lt;br /&gt;\Pr(y = \text{snow} = [0, 1, 0, 0])&lt;br /&gt;&amp;amp;= (.14^0 * .37^1 * .03^0 * .46^0)\\&lt;br /&gt;&amp;amp;= .37\\&lt;br /&gt;\end{align*}&lt;br /&gt;다시 exponential family 형태로 돌아가서 확장해보면:&lt;br /&gt;\begin{align*}&lt;br /&gt;P(y\vert \pi)&lt;br /&gt;&amp;amp;= \prod\limits_{k=1}^{K}\pi_k^{y_k}\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K}y_k\log{\pi_k}\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} + \bigg(1 - \sum\limits_{k=1}^{K-1}y_k\bigg)\log\bigg(1 - \sum\limits_{k=1}^{K-1}\pi_k\bigg)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} - \bigg(\sum\limits_{k=1}^{K-1}y_k\bigg) \log(\pi_K) + \log(\pi_K)), \quad \text{where}\ \pi_K = 1 - \sum\limits_{k=1}^{K-1}\pi_k\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}\log\bigg(\frac{\pi_k}{\pi_K}\bigg) y_k + \log(\pi_K)\bigg)&lt;br /&gt;\end{align*}&lt;br /&gt;여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta = \log\bigg(\frac{\pi_k}{\pi_K}\bigg)$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = -\log(\pi_K)$&lt;/li&gt;&lt;li&gt;$b(y) = 1$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;마지막으로,&lt;br /&gt;\begin{align*}&lt;br /&gt;\eta_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \log\bigg(\frac{\pi_k}{\pi_K}\bigg) \implies\\&lt;br /&gt;\frac{\pi_k}{\pi_K}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k} \implies\\&lt;br /&gt;\sum\limits_{k=1}^K \frac{\pi_k}{\pi_K}&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\frac{1}{\pi_K}\sum\limits_{k=1}^K \pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\frac{1}{\pi_K} \cdot 1&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\pi_K&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;이고, 두 번째 줄에 마지막 결론을 껴넣어주면:&lt;br /&gt;\begin{align*}&lt;br /&gt;\frac{\pi_k}{\frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k}\ \implies\\&lt;br /&gt;\pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;(짜잔! $\pi_k$가 $\eta_k$에 대한&amp;nbsp;&lt;b&gt;softmax function&lt;/b&gt;이 나오네요!)&lt;br /&gt;&lt;br /&gt;마지막으로 $a(\eta)$를 정리하면 아래와 같습니다:&lt;br /&gt;\begin{align*}&lt;br /&gt;\frac{\pi_k}{\frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k}\ \implies\\&lt;br /&gt;\pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= -\log(\pi_K)\\&lt;br /&gt;&amp;amp;= \log(\pi_K^{-1})\\&lt;br /&gt;&amp;amp;= \log\Bigg(\frac{\sum\limits_{k=1}^K e^{\eta_k}}{e^{\eta_K}}\Bigg)\\&lt;br /&gt;&amp;amp;= \log\Bigg(\sum\limits_{k=1}^K e^{\eta_k}\Bigg).\\&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 수학을 따라 오다가 길을 잃은 분들을 위해 각 모델에서 우리가 관심있는 response variable들을 $\eta$에 대해 하나로 모아 정리해보면 아래와 같습니다:&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span style=&quot;color: red;&quot;&gt;Linear regression (Gaussian distribution): $\mu = \eta$&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;Logistic regression (Binomial distribution): $\phi = \frac{1}{1 + e^{-\eta}}$&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;Softmax regression (Multinomial distribution): $\pi_k = \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}$&lt;/span&gt;&lt;/blockquote&gt;&lt;h2&gt;Generalized linear models&lt;/h2&gt;&lt;br /&gt;각 모델은 output으로 response variable을 뱉습니다. 이 response variable들이 어떤 (exponential family) 분포를 따라 퍼져있겠죠. 그러나 이 분포의 canonical parameter 즉 우리가 넣는 값은 관측마다 달라질 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;를 예측하는 logistic regression 모델을 생각해보겠습니다. 우리가 고양이 그림을 넣으면 주어진 분포에 따라 &quot;고양이&quot;라는 값이 나올 것입니다.&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;\begin{cases}&lt;br /&gt;1 - \phi &amp;amp; \text{outcome = cat}\\&lt;br /&gt;\phi &amp;amp; \text{outcome = dog}\\&lt;br /&gt;\end{cases}$$&lt;br /&gt;우리가 개 그림을 넣으면 마찬가지로 같은 분포에 따라 &quot;개&quot;가 튀어나오겠죠.&lt;br /&gt;&lt;br /&gt;당연하지만 $\phi$ 값은 각각의 경우마다 항상 달라야합니다. 앞선 경우에 대해서는&amp;nbsp; 모델의 $\phi$ 값이 작아서 $1-\phi \approx 1$의 확률로 고양이를 뱉어내야겠지만 뒤의 경우에 대해서는 $\phi$ 값이 커서 &quot;개&quot;라는 출력이 $\phi \approx 1$의 확률로 나올 수 있도록 해야겠죠.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 이 부분이 헷갈리신다면 정상입니다. 뭐 이렇게 어렵게 써두었는지... 그냥 $\phi$가 canonical parameter $\eta$를 변수로 가지는 값이라고 생각하시면 됩니다. 예를 들어 신경망같은 parametric 개/고양이 판별기 모델에 고양이 혹은 개 그림을 (즉 다른 input들을) 넣으면 나올 output probability가 그때그때 다르죠? 이 얘기를 하려는 겁니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;그러면 각 input에 대해 다음을 생각해보겠습니다:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$y_i \sim \mathcal{N}(\mu_i, \sigma^2)$일 때, Linear regression에서 $\mu_i$란?&amp;nbsp;&lt;/li&gt;&lt;li&gt;$y_i \sim \text{Binomial}(\phi_i, 1)$일 때, logistic regression에서 $\phi_i$란?&lt;/li&gt;&lt;li&gt;$y_i \sim \text{Multinomial}(\pi_i, 1)$일 때, softmax regression에서 $\pi_i$란?&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;여기서 $i$라는 인덱스가 새로 붙은 것이 보이시죠. 이 $i$ 덕에 위에서 설명하고자 한 dynamic이 좀 더 명백해집니다. 즉, 주어진 모델에서 각 입력에 따라 해당하는 canonical parameter가 정해지고 이 녀석이 response variable의 분포에 영향을 미치게 됩니다. 예를 들면 logistic regression 모델에서 고양이 그림을 보게 되면 $\phi_i\approx0$이 되도록 해야겠다는 말을 좀 더 복잡하게 한 것입니다.&lt;br /&gt;&lt;br /&gt;그럼 10-feature input $x$에서 이런 canonical parameter로 어떻게 보내면 될까요? 가장 간단하게 linear combination을 생각해볼 수 있습니다:&lt;br /&gt;$$\eta = \theta^Tx$$ &lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) Keras code에 Dense layer 하나 붙은 모델인 것만 보셔도 짐작하실 수 있습니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;h2&gt;Linear regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx=\mu_i.$ 이것이 바로 우리가 정규 분포를 만들 때 필요한 변수입니다.&lt;br /&gt;&lt;b&gt;&amp;gt; The identity function (i.e a no-op) gives us the mean of the response variable. This mean is required by the normal distribution, which dictates the outcomes of the continuous-valued target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Logistic regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx = \log\bigg(\frac{\phi_i}{1-\phi_i}\bigg).$ $\phi_i$에 대해 문제를 풀어야 하겠습니다. $\phi_i = \frac{1}{1 + e^{-\eta}}$였던 것 기억하시죠?&lt;br /&gt;&lt;b&gt;&amp;gt; The sigmoid function gives us the probability that the response variable takes on the positive class. This probability is required by the binomial distribution, which dictates the outcomes of the binary target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;결국 $\phi_i$라는 함수가 하는 녀석은 우리가 앞서 소개했던 내일의 날씨 예측하는 날씨 분포가 하는 일과 같습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 그러니까 날씨 분포의 경우 마치 lookup table처럼 각 input $x$에 대해 딱 내뱉는 확률 값이 정해져있는 일대일 대응 함수인데,&amp;nbsp;$\phi_i$의 경우는 canonical parameter $\eta=\theta^Tx$로 표현되는 함수라는 말입니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Softmax regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx = \log\bigg(\frac{\pi_k}{\pi_K}\bigg).$ $\pi_i$는 벡터이기 때문에 $\pi_i$에 대해 풀기 위해서 각 $\pi_{k,i}$에 대해 문제를 풀어야합니다.&lt;br /&gt;이 역시도 위에서 했었죠: $\pi_{k, i} = \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}.$ 바로 softmax function입니다.&lt;br /&gt;&lt;b&gt;&amp;gt; The softmax function gives us the probability that the response variable takes on each of the possible classes. This probability mass function is required by the multinomial distribution, which dictates the outcomes of the multi-class target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;좋습니다 이제 다 살펴봤네요. 흠 그런데 왜 하필 linear model, $\eta = \theta^Tx$이어야 했을까요? 앤드류 응 교수님 말을 차용하자면 이것은 &quot;모델 디자인&quot; 혹은 &quot;선택&quot;의 문제입니다. 여기서 선형 조합이 자주 사용되는 이유를 굳이 꼽자면:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;아마도 선형 조합(linear combination)이 canonical parameter에 대한 각 feature에 영향을 줄 수 있는 가장 쉬운 방법일 것이기 때문이다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;선형 조합이 단순히 $x$뿐만 아니라 $x$에 대한 함수에 대해서도 $\eta$에 대해 선형으로 변화한다고 하면 좀 더 복잡한 형태를 만들 수 있다. 즉, 우리는 모델을 $\eta = \theta^T\Phi(x)$와 같이 쓸 수 있고, 여기서 $Phi$는 우리의 feature에 대한 복잡한 변형(transformation)을 주는 operator를 의미한다. 이 부분이 선형 조합의 단순함을 조금은 덜하게 만들어준다고 할 수 있다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Loss function&lt;/h2&gt;&lt;br /&gt;이제 지금까지 각 response variable이 어떤 식으로 만들어지는지 살펴봤습니다. 그리고 분포들의 parameters가 각 input에 대해 어떻게 계산되는지도 보았죠. 그러면 뭐가 남았을까요? 맞습니다. 이제 어떻게 하면 어떤 parameters가 좋은지 정량화할 수 있을지가 궁금하실겁니다?&lt;span style=&quot;color: red;&quot;&gt; (음? ㅋㅋ)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;자! 이 부분도 매우매우 재미있지만 이번에도 역시 글이 매우 길어졌고 제 글 체력도 다하였기에 다음 글에서 이어가도록 하겠습니다.&lt;br /&gt;&lt;br /&gt;그러면! &lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html&quot;&gt;다음 글&lt;/a&gt;에서 뵙겠습니다. (To be continued)&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html&quot;&gt;Minimizing the Negative Log-Likelihood, in Korean (3)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1241518821086770705/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1241518821086770705'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1241518821086770705'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html' title='Minimizing the Negative Log-Likelihood, in Korean (2)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s72-c/bob.jpg" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1351174858330079744</id><published>2018-02-05T11:51:00.000+09:00</published><updated>2018-08-05T23:07:54.006+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (1)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;우리가 자주 쓰는 loss function들이 어떻게 나오게 되었는지, 예들 들자면 cross-entropy error와 Euclidean error는 어디서 유래한 것인지를 알려주는 좋은 글이 있어 공부할 겸 번역을 해보고자 합니다. 최대한 원 저자의 글에 가깝게 번역하려 했으며 번역을 할 때 필연적으로 생기는 어색한 표현을 피하기 위해 제가 먼저 내용을 다 소화한 이후 의역을 하였습니다. 이 외에 제가 좀 더 자세히 덧붙여 설명을 하고 싶은 부분들은 추가하되 (* 편집자 주,&amp;nbsp;빨간색)으로 명시해두겠습니다.&amp;nbsp;&lt;span style=&quot;color: red;&quot;&gt;(* 편집자 주) 2017년 6월에 시작한 글을 이제야 끝내다니... ㅎㅎ밀린 숙제하는 느낌이네요;; 졸업하니 정말 좋다!!!ㅋㅋㅋ&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/b&gt;&lt;/div&gt;&lt;h2 style=&quot;text-align: center;&quot;&gt;Minimizing the Negative Log-Likelihood, in Korean (:p)&lt;/h2&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;저(글쓴이)는 Kaggle에서부터 기계학습에 대한 공부를 시작했습니다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;Kaggle에는 데이터도 있고 모델 (즉, estimator) 그리고 loss function to optimize가 있어서 공부하기가 좋았고 여기(Kaggle)에서 많은 것을 배울 수 있었습니다.&quot;&lt;/blockquote&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그 중 몇 가지를 꼽아보자면, &quot;regression model은 continuous-valued real numbers를 예측하는데 쓰이고, classification model들은 &#39;빨강&#39; &#39;초록&#39; &#39;파랑&#39; 등을 예측하는데 쓰인다는 것&quot;, &quot;보통 regression에서는 mean absolute error를 쓰며 classification에서는 cross-entropy loss를 사용한다는 것&quot;, &quot;loss 함수들을 줄이기 위해 stochastic gradient descent를 사용한다는 것&quot; 등을 자연스래 배웠고, 마지막으로 이런 model들을 fit하고 싶다면 그저 sklearn 라이브러리를 사용하면 된다는 것도 알게 되었습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;(최소한 기술적인 측면에서는) 이 정도만 잘 알아도 데이터 사이언티스트로써 혹은 취업을 위해서도 충분했습니다. 산업 현장에서는 이런 off-the-shelf algorithm만으로도 회사의 이익을 매우 쉽게 끌어올릴 수 있지요.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;그래 이 정도면 충분해, 자동차 경주에서 이기고 있는 선수가 굳이 자동차가 어떻게 만들어지는지까지 알 필요는 없잖아?&quot;&lt;/blockquote&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&quot;scikit-learn fit and predict,&quot; 하는 것이 익숙해졌을 무렵 저는 통계를 슬슬 공부하기 시작했습니다. 두 가지 분야가 서로 겹치는 것이 많다는 것을 알고는 있었지만, 여전히 뭔가를 분석할 때는 두 분야를 서로 다른 평행한 sub-fields로 적용하곤 했습니다. 그러니까 classification model을 만들 때는 scikit-learn을 사용하고 signup counts를 추측(infer)할 때는 Poisson distribution and MCMC를 사용하는 식으로 말이죠.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;하지만 교과서 공부, 논문 읽기, 소스 코드 읽기 및 쓰기, 블로그 작성 등 기계 학습에 대해 깊이 파고 들면서 내가 한 일들을 묘사하는데 사용되는 몇몇 용어들이 생각보다 이해하기 어렵다는 것을 알게 되었습니다. 예를 들자면 categorical cross-entropy loss가 무엇인지, 어떤 일을 하며 어떤 식으로 정의되는지는 이해했지만 도대체 &lt;b&gt;&lt;i&gt;&quot;왜 이런 녀석들을 negative log-likelihood라 부르는 것인가?&quot;&lt;/i&gt;&lt;/b&gt;와 같은 의문들이 생기기 시작했습니다.&lt;br /&gt;&lt;br /&gt;시간이 지나 이제는 위 질문에 대해 적어도 두 가지 정도는 알게 되었습니다:&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;우리가 &quot;기계 학습&quot;이라 부르는 기술들(classification and regression models)은 거의 대부분 통계를 기반으로 하고 있다. 때문에 용어들이 두 분야에서 혼용되고 있다.&lt;/li&gt;&lt;li&gt;대부분의 용어가 새로 만들어진 것이 아니다.&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;이 글에서는 제가 깨달은 사실을 바탕으로 우리가 잘 알고 있고, 자주 사용하며, 어떻게 사용하는지 알고 있는 세가지 모델들이 수학적으로 어떤 역할을 하는 것인지 설명하고자 합니다. 기본적으로 독자들이 기계학습과 통계학 분야의 개념들에 대해 익숙하다는 가정 하에 글을 쓸 것이며 두 분야 사이의 연관성에 대해 더욱 깊은 이해를 위해 서서히 파고들 생각입니다. 수학이 들어가긴 하지만 딱 필요한만큼만 사용할 것이고 유도의 대부분은 결과없이 건너 뛸 수도 있습니다.&lt;br /&gt;&lt;br /&gt;어떤 predictive model을 제품화할 때는,&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;import sklearn&lt;/span&gt;으로 다른 사람이 만들어 둔 모델을 사용하는 것이 최고의 방법이자 보통 우리가 알고 있는 방식입니다. 그렇기에 이 글은 여기서 시작해서 결국에는 다시 이 지점으로 돌아올 것입니다. 다만 이전과 다른 점은 그 밑바닥을 잘 알고 사용할 수 있겠습니다.&amp;nbsp;(글쓴이는 이 과정을 마치 수영장에서 다이빙 하고, 밑바닥을 찍고, 다시 표면으로 올라오는 모습과 비슷하게 생각했는지 같은 은유를 수차례 사용합니다.) Lemma들은 굵은 글씨체로 작성되어 있습니다.&lt;br /&gt;&lt;br /&gt;먼저 우리가 앞으로 다룰 세 개의 주요 모델들을 만나보시겠습니다. 편의를 위해 코드는 Keras로 통일합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Linear regression&lt;/span&gt; with mean squared error&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;mean_squared_error&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Logistic regression&lt;/span&gt; with binary cross-entropy loss&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;binary_crossentropy&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Softmax regression&lt;/span&gt; with categorical cross-entropy loss&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;softmax&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;categorical_crossentropy&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;다음으로 response variable, functional form, loss function, loss function + regularization term 이렇게 네 가지 주요 요소들이 있는데요 앞으로 세 가지 모델들에 대해 각 요소가 어떤 통계적인 의미를 지니는지 알아보도록 하겠습니다 (수영장 밑바닥에서 한 계단씩 올라가겠습니다).&lt;br /&gt;&lt;br /&gt;잠깐! 완전히 잠수하기 전에 준비운동부터 해야겠죠? 몇 가지 중요한 개념들에 대해 정의하고 넘어가겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Random variable&lt;/h2&gt;&lt;br /&gt;저(글쓴이)는 random variable을 &quot;여러가지 다른 값들을 가질 수 있는 것&quot;이라고 정의합니다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&quot;The tenure of despotic rulers in Central Africa&quot; is a random variable. It could take on values of 25.73 years, 14.12 years, 8.99 years, ad infinitum; it could not take on values of 1.12 million years, nor -5 years.&lt;/li&gt;&lt;li&gt;&quot;The height of the next person to leave the supermarket&quot; is a random variable.&lt;/li&gt;&lt;li&gt;&quot;The color of shirt I wear on Mondays&quot; is a random variable. (Incidentally, this one only has ~3 distinct values.)&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Probability distribution&lt;/h2&gt;&lt;br /&gt;확률 분포란 random variable이 갖는 값을 관측할 likelihood에 대한 일종의 lookup table이라 할 수 있습니다. 주어진 variable이 {비, 분, 진눈깨비, 우박} 중 하나의 값을 가진다고 할 때, 다음과 같이 probability distribution으로 나타낼 수 있습니다:&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;당연하지만, 모든 값의 합은 1이어야 하지요.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;확률 질량 함수는 이산 값을 갖는 random variable 확률 분포다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;확률 밀도 함수는 연속 값을 갖는 random variable의 확률 분포를 &lt;b&gt;주는&lt;/b&gt; 함수다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;여기서 &quot;주는&quot;이라고 표현한 까닭은 이 함수 스스로는 lookup table이 아니기 때문이다. 즉 값이 [0,1] 범주 안에서 주어진 random variable에 대해 $Pr(X=0.01), Pr(X=0.001),Pr(X=0.0001),~etc.$를 정의할 수 없다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;대신 일정 &lt;i&gt;범위&lt;/i&gt;&amp;nbsp; 안에서 어떤 값을 관측할 확률을 알려줄 수 있는 함수를 하나 정의하여 사용할 수 있다: e.g. $Pr(0.01&amp;lt;X&amp;lt;0.4)$&lt;/li&gt;&lt;li&gt;이 것이 확률 밀도 함수이며 $Pr(0\leq X \leq 1)=1$을 만족한다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Entropy&lt;/h2&gt;&lt;br /&gt;엔트로피는 주어진 결과에 도달할 수 있는 방법의 가짓수를 정량화 해줍니다. 8명의 친구들이 두 대의 택시를 나눠타고 브로드웨이 쇼를 보러 가는 것을 상상해보죠. 다음과 같이 두 가지의 시나리오를 생각해보겠습니다:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;네 명씩 택시를 탄다:&lt;/li&gt;&lt;/ul&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# fill the first, then the second&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_1&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# alternate assignments&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_2&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# alternate assignments in batches of two&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_3&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# etc.&lt;/span&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;모든 친구들이 하나의 택시에 어떻게든 우겨 탄다:&lt;/li&gt;&lt;/ul&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_1&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;/pre&gt;두 번째 경우보다 첫 번째 경우가 가능한 경우의 수가 많기 때문에 첫 번째 결과(outcome)가 더 높은 엔트로피 값을 갖게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;More explicitly,&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;엔트로피를 확률 분포에 대해 계산을 해보면 다음과 같습니다:&lt;br /&gt;$$H(p)=-\sum_{i=1}^n p_i \log p_i$$&lt;br /&gt;이 때,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;총 서로 다른 n개의 이벤트가 존재한다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;각 이벤트 $i$는 $p_i$의 확률을 갖는다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;엔트로피는 가능한 이벤트들에 대한 &lt;i&gt;weighted-average log probability&lt;/i&gt;이고, (이는 수식에서 더 명백히 알 수 있는데) 분포에 내재한 불확실성을 측정하는 방법이라 할 수 있습니다. 즉, 어떤 이벤트에 대해 엔트로피가 높다는 것은 해당 결과값을 얻을 것이라는 믿음에 대한 확실성이 덜하다는 것을 뜻하죠.&lt;br /&gt;&lt;br /&gt;위에서 언급한 확률 분포에 대해 엔트로피를 계산해보겠습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 0 , 0); font-weight: bold;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;prob_dist&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;):&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;prob_dist&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;])&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1.1055291211185652&lt;/span&gt;&lt;/pre&gt;비교를 위해 두 개의 분포를 더 만들어서 각각의 엔트로피들을 계산해보겠습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_2&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_3&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;0.8304250977453105&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;0.2460287703075343&lt;/span&gt;&lt;/pre&gt;첫 번째 분포에서 우리는 내일 날씨가 어떨 지에 대해 가장 확신이 없습니다. 이에 맞게 엔트로피도 가장 높습니다. 세 번째 분포의 경우 내일의 날씨가 우박일 것이라는 것에 가장 확신을 가질 수 있을 것이고 엔트로피도 역시 작은 것을 볼 수 있습니다.&lt;br /&gt;&lt;br /&gt;마지막으로 택시 예화에서도 마찬가지로 오직 한 가지 경우만 가능한 분포에 비해 여러 갈래로 이벤트가 생길 수 있는 분포에 대해 엔트로피 값이 낮다는 것을 알 수 있습니다.&lt;br /&gt;&lt;br /&gt;이제 준비운동을 마쳤으니 수영장에 들어가야겠지요. 그럼 가장 바닥부터 찍고 다시 수면으로 올라가보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Response variable&lt;/h2&gt;&lt;br /&gt;크게 볼 때 우리가 다룰 모델은 다음과 같이 생겼다고 할 수 있습니다. 즉, 아래 그림에서 입력을 받아 출력을 받는 다이아몬드에 해당합니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://cavaunpeu.github.io/images/simple_input_output_model.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img alt=&quot;simple input/output model&quot; border=&quot;0&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/images/simple_input_output_model.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;모델들은 예측해야 하는 response variable 즉 $y$의 종류에 따라 바뀌게 되는데요&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Linear regression은 연속된 실수 값을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;temperature&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;li&gt;Logistic regression은 이진 값을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;li&gt;Softmax regression은 multi-class label을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;red or green or blue&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;각 모델에서 response variable은 서로 다른 값들을 가질 수 있습니다. 이들이 바로 random variables입니다. 그렇다면 각각의 random variable은 어떤 확률 분포를 갖을까요?&lt;br /&gt;&lt;ul&gt;&lt;li&gt;temperature는 true mean $\mu\in(-\infty,\infty)$와 true variance $\sigma^2\in(-\infty,\infty)$를 갖는다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;cat or dog는 고양이 혹은 강아지를 값으로 값는다. 공평한 동전 던지기가 언제나 $Pr(Head)=0.5$이듯이 각 결과에 대한 likelihood는 시간에 따라 변하지 않는다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;red or green or blue는 빨강, 초록, 파랑 중 하나의 값을 갖는다. 마치 공평한 육면체 주사위가 그렇듯이 시간에 따라 likelihood는 바뀌지 않는다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;이런 가정들은 사실 너무 당연해서 좀 너무 진부하기까지 하지만 앞으로 얘기할 때 중요하게 사용되니 기억해둡시다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum entropy distributions&lt;/h2&gt;&lt;br /&gt;&quot;Uber의 연간 수익&quot;이라는 연속 값 random variable을 생각해보겠습니다. 마치&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;temperature&lt;/span&gt;와 같이 이 random variable 역시&amp;nbsp;true mean $\mu\in(-\infty,\infty)$와 true variance $\sigma^2\in(-\infty,\infty)$를 갖습니다. 당연하지만 두 경우에 대한 평균과 분산은 서로 다르겠죠. 다음과 같이 가상으로 10개의 값들을 관측했다고 해보겠습니다:&lt;br /&gt;&lt;table class=&quot;table table-hover table-striped&quot; style=&quot;background-color: white; border-collapse: collapse; border-spacing: 0px; box-sizing: border-box; color: black; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; margin-bottom: 18px; max-width: 100%; width: 100%;&quot;&gt;&lt;thead style=&quot;box-sizing: border-box;&quot;&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;th style=&quot;border-bottom: 2px solid rgb(221, 221, 221); border-top: 0px; box-sizing: border-box; color: #444444; line-height: 1.42857; padding: 8px; text-align: left; vertical-align: bottom;&quot;&gt;uber&lt;/th&gt;&lt;th style=&quot;border-bottom: 2px solid rgb(221, 221, 221); border-top: 0px; box-sizing: border-box; color: #444444; line-height: 1.42857; padding: 8px; text-align: left; vertical-align: bottom;&quot;&gt;temperature&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody style=&quot;box-sizing: border-box;&quot;&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-100&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-50&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-80&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-20&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;56&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;5&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;65&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;15&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;62&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-10&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;63&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;22&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;60&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;12&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;78&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;70&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;100&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;100&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-43&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;이를 그려보면 다음과 같습니다:&lt;br /&gt;&lt;img alt=&quot;temperature random variable&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/figures/temperature_random_variable.png&quot; /&gt;&lt;br /&gt;&lt;img alt=&quot;uber random variable&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/figures/uber_random_variable.png&quot; /&gt;&lt;br /&gt;우리는 각 random variable에 대해 실제 확률 분포가 어찌 생겼는지는 모릅니다. 전반적 &quot;형태&quot;도 모르고 그 형태를 제어하는 parameters도 모릅니다. 이럴 때는 어떻게 모델을 정해야할까요? 사실 통계학의 정수가 바로 여기에(미지의 값들을 추측하는 것) 있습니다.&lt;br /&gt;&lt;br /&gt;자, 초기 모델을 정하기 위해 다음의 두 가지를 염두에 두어야합니다:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;최대한 보수적이어야 합니다. 우리는 &quot;Uber의 연간 수익&quot;에 대해 고작 10개의 값만을 보았을 뿐입니다. 아직 관측되지 않았다고 해서 다음 스무 개의 값들이 $[-60,-50]$ 사이의 범위에서 나올 수도 있다는 사실을 간과하고 싶지는 않겠죠.&lt;/li&gt;&lt;li&gt;각각에 대하여 동일한 가정(continuous)을 했기 때문에 두 random variables 모두에 대하여 같은 확률 분포 &quot;모양&quot;을 가정해야합니다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;이에 따라 매우 진부하지만 위에서 정의한 제약 조건들을 만족하는 가장 보수적인 분포를 사용하겠습니다. 이 것이 바로&lt;span style=&quot;background-color: white; font-family: &amp;quot;open sans&amp;quot; , &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; font-size: 19px;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; text-align: start; text-decoration-line: none;&quot;&gt;&lt;em style=&quot;box-sizing: border-box;&quot;&gt;maximum entropy distribution&lt;/em&gt;&lt;/a&gt;입니다.&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 그냥 이렇게 넘어가면 사실 왜 &lt;b&gt;maximum entropy distribution&lt;/b&gt;을 사용해야하는지 잘 와닿지 않을 수 있으니 제가 첨언을 좀 해보겠습니다.&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;통계나 정보 이론에서 maximum entropy probability distribution은 이름이 의미하듯 분포가 갖는 엔트로피 값이 &lt;b&gt;&lt;i&gt;해당 class의 확률 분포들이 가질 수 있는 최대 엔트로피 값과 최소한 같거나 큽니다.&lt;/i&gt;&lt;/b&gt;&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;무슨 말인고 하니, 만약 우리가 어떤 모델을 세울 때 해당 데이터에 대해 알고 있는 정보가 적다면 잘못된 &lt;b&gt;선험적 정보를 부지불식간에 모델에 넣지 않도록 주의&lt;/b&gt;를 기울여야 한다는 것입니다. (maximum entropy의 원리에 따라) 모델을 정할 때 해당 데이터가 어떤 class에 속한다는 정보 외에 분포에 대한 어떠한 정보도 없을 때는 &lt;b&gt;가장 기본적으로 최소한의 정보만을 사용하여(largest entropy) 분포를 정해야&lt;/b&gt;할 것입니다.&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;바로 여기에 해당하는 분포가 &lt;b&gt;maximum entropy distribution&lt;/b&gt;인 것이죠. 이 외에도 &lt;b&gt;많은 physical systems이 시간이 지나면서 점차 maximal entropy configuration을 향하기 때문&lt;/b&gt;에서라도&amp;nbsp;&lt;b&gt;maximum entropy distribution으로 초기 모델을 정하는 것&lt;/b&gt;이 여러 모로 장점이 있습니다.&lt;/span&gt;&lt;/blockquote&gt;&lt;br /&gt;&lt;code style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #c7254e; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; padding: 3px 5px !important; text-align: start; white-space: pre-wrap;&quot;&gt;temperature&lt;/code&gt;(continuous-valued distribution)에 대한 maximum entropy distribution은 Gaussian 분포입니다. 가우시안 분포의 확률 밀도 함수는 다음과 같죠:&lt;br /&gt;$$P(y\vert \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\frac{(y - \mu)^2}{2\sigma^2}\bigg)}$$&lt;br /&gt;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;에 대한 maximum entropy distribution은 binomial 분포입니다. 이항 분포의 확률 밀도 함수는 (for a single observation) 다음과 같습니다:&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;$\begin{cases}&lt;br /&gt;1 - \phi &amp;amp; \text{outcome = cat}\\&lt;br /&gt;\phi &amp;amp; \text{outcome = dog}\\&lt;br /&gt;\end{cases}$$ (여기서 positive event에 대한 확률을 $\phi$로 표기하였습니다.)&lt;br /&gt;&lt;br /&gt;마지막으로&amp;nbsp;&lt;code style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #c7254e; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; padding: 3px 5px !important; text-align: start; white-space: pre-wrap;&quot;&gt;red or green or blue&lt;/code&gt;에 대한 maximum entropy distribution은 multinomial distribution입니다. 다항 분포의 확률 밀도 함수는 다음과 같습니다:&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;\begin{cases}&lt;br /&gt;\phi_{\text{red}} &amp;amp; \text{outcome = red}\\&lt;br /&gt;\phi_{\text{green}} &amp;amp; \text{outcome = green}\\&lt;br /&gt;1 - \phi_{\text{red}} - \phi_{\text{green}} &amp;amp; \text{outcome = blue}\\&lt;br /&gt;\end{cases}$$&lt;br /&gt;이렇게 각 모델에 대한 &quot;maximun entropy distribution&quot;가 위와 같이 유도된다는 것을&amp;nbsp;은근슬쩍 구렁이 담넘어 가듯이 지나갔지만 사실 이 부분은 Lagrange multipliers로 매우 명료하게 설명하는 것이 가능합니다. 이 부분은 해당 글의 범위를 넘어서거니와 이 글의 목적을 명확히 하는데 오히려 방해가 될 소지가 있기에 글쓴이가 의도적으로 내용을 생략하였습니다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 실제로도 매우 쉽습니다. 다음에 기회가 되면 포스팅을 하도록 하겠습니다.&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;예를 들어 가우시안 분포는&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;&amp;nbsp;전체 실수 선 $x\in(-\infty, \infty)$를 모두 포괄하되 유한한 평균과 분산을 갖는 모든 확률 분포에 대한 maximum entropy distribution입니다. 이렇게&amp;nbsp;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;maximum entropy distribution을 유도하다보면 가우시안 분포의 적분식이 왜 그렇게 생겼는지 알 수 있습니다. 재밌겠죠!&lt;/span&gt;&lt;/blockquote&gt;&lt;br /&gt;마지막으로 &quot;Uber의 연간 수입&quot;과&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;temperature&lt;/span&gt;&amp;nbsp;값들의 실제 분포가 가우시안으로 표현될 수 있다는 가정을 사용하긴 하였으나 사실 각각에 대해 약간씩 다른 가우시안입니다. 이는 각 random variable이 서로 다른 true mean과 variance를 갖기 때문입니다. 이 값들은 각 가우시안 분포들이 더 키가 크거나 옆으로 퍼지거나 혹은 좌우로 shift되는 정도를 다르게 조정하게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Functional form&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 글에서 다루고 있는 세 모델들은 각각 서로 다른 함수를 바탕으로 예측을 하는데요:&amp;nbsp; 각각 identity function (i.e. no-op), sigmoid function, and softmax function. Keras로 output layer를 만들어보면 명확합니다:&lt;/div&gt;&lt;div&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;softmax&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;이 단락에서는,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Gaussian, binomial 그리고 multinomial distributions가 같은 functional form으로 나타낼 수 있다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;이 common functional form에서 세 모델들의 output function (identity, sigmoid, softmax)가 자연스럽게 유도된다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;마치 다음 그림과 같이 생각할 수 있겠네요. 세 가지 분포가 들어가서 세 가지 output functions이 나오는 것이죠. (그림이 이상한데? -_-; 뭐 아무튼 하나의 functional form으로 설명이 가능해서 저렇게 표현할 수 있다고 생각하면 될 듯합니다.)&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;bottleneck&quot; class=&quot;img-responsive&quot; src=&quot;https://electric-cloud.com/wp-content/uploads/use-case-graphic_bottleneck.png&quot; /&gt;&lt;/div&gt;&lt;br /&gt;여기서 병목에 해당하는 개념은 확률 분포의&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_family&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; text-align: start; text-decoration-line: none;&quot;&gt;&quot;exponential family&quot;&lt;/a&gt;가 되겠습니다.&lt;br /&gt;&lt;br /&gt;자! 이 부분이 사실 매우매우 재미있는 부분이지만 아쉽게도 글이 매우 길어지기도 했고 글을 하루에 쓸 수 있는 양이 있으니(..orz) 다음 글에서 이어가도록 하겠습니다. (드라마도 아니고....준비 운동하다 시간이 다 갔네요..ㅋㅋ 얼른 돌아오겠습니다. )&lt;br /&gt;&lt;br /&gt;그러면! 다음 글에서 뵙겠습니다. (To be continued)&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html&quot;&gt;Minimizing the Negative Log-Likelihood, in Korean (2)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1351174858330079744/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1351174858330079744'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1351174858330079744'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor.html' title='Minimizing the Negative Log-Likelihood, in Korean (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-8843525172426943088</id><published>2018-02-04T10:19:00.002+09:00</published><updated>2018-02-04T10:21:54.391+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 61. Understanding Deep Learning Requires Rethinking Generalization</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#61. Understanding Deep Learning Requires Rethinking Generalization&lt;/h2&gt;&lt;br /&gt;이 리뷰에서는 최근 ICLR 2017 Best paper award를 수상했던 Generalization에 관한 논문을 소개해보았습니다. 이 논문 역시도 현재까지 존재하던 이론들이 제대로 신경망 모델의 성능을 설명하지 못하고 있다는 매우 대담한 주장을 하여 매우 화제가 되었습니다. 다만 제 생각과는 다른 점이 몇 있고 논리에 빈틈이 있어보여서 논문의 내용을 충실히 전달하되 비판적인 입장에서 리뷰를 진행해보았습니다. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/UxJNG7ENRNg&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;슬라이드:&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-understanding-deep-learning-requires-rethinking-generalization&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-understanding-deep-learning-requires-rethinking-generalization&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/8843525172426943088/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-61-rethinking-generalization.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8843525172426943088'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8843525172426943088'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-61-rethinking-generalization.html' title='[PR12-Video] 61. Understanding Deep Learning Requires Rethinking Generalization'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/UxJNG7ENRNg/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-4531467339349946401</id><published>2018-02-04T10:13:00.002+09:00</published><updated>2018-02-04T10:21:44.575+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 56. Capsule Network</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#56. Capsule Network&lt;/h2&gt;&lt;br /&gt;이 리뷰에서는 최근 NIPS 2017에서 발표된 힌튼 교수님의 Capsule Network에 대해 소개해보았습니다. Capsule network가 기존의 CNN의 문제점에 대해 지적하며 새로운 프레임의 학습 방식인 라우팅을 들고 왔지요. 처음 읽는 분들은 생각보다 논문이 친절하지 않아서 헷갈릴 수 있는 부분이 있고 이해가 직관적이지는 않아서 어려움을 겪을 수 있습니다. 제 소개를 통해 조금이나마 이해가 쉽게 될 수 있도록 준비해보았습니다. 짧지만 제 생각도 넣어보았네요. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/_YT_8CT2w_Q&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;슬라이드:&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-capsule-networks-jaejun-yoo&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-capsule-networks-jaejun-yoo&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/4531467339349946401/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-56-capsule-network.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/4531467339349946401'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/4531467339349946401'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-56-capsule-network.html' title='[PR12-Video] 56. Capsule Network'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/_YT_8CT2w_Q/default.jpg" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-5892512519677353559</id><published>2018-02-04T10:06:00.001+09:00</published><updated>2018-02-04T10:21:36.603+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 34. Inception and Xception</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#34. Inception and Xception&lt;/h2&gt;&lt;br /&gt;그동안 블로그 글은 뜸했어도 PR12 활동은 빠지지 않으려 노력했습니다. 유튜브에는 시간에 맞춰 꼬박꼬박 올렸습니다만 블로그에 중복으로 올리는 것이 조금 품이 들어서 그런지 여기에는 업데이트가 늦었네요. 조금 여유가 생겼기에 블로그에도 정리를 해서 올립니다.&lt;br /&gt;여전히 매주 일요일마다 12명이 돌아가며 두 명씩 두 편의 논문을 40분 동안 발표하고 있습니다. 이 리뷰에서는 구글에서 발표한 모델인 Inception과 CVPR 2017에서 Keras의 저자 프랑수아 숄레가 발표한 Xception에 대해 살펴보았습니다. Inception 초기 모델부터 가장 최근의 extension인 Xception까지 한 영상으로 쭉 훑어보실 수 있도록 노력했습니다. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V0dLhyg5_Dw&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;슬라이드:&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-inception-and-xception-jaejun-yoo&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-inception-and-xception-jaejun-yoo&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/5892512519677353559/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-34-inception-and-xception.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/5892512519677353559'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/5892512519677353559'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-34-inception-and-xception.html' title='[PR12-Video] 34. Inception and Xception'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/V0dLhyg5_Dw/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-2476804623322338029</id><published>2018-02-04T10:02:00.000+09:00</published><updated>2018-02-04T10:21:17.080+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 24. Pixel Recurrent Neural Network</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#24. Pixel Recurrent Neural Network&lt;/h2&gt;&lt;br /&gt;그동안 블로그 글은 뜸했어도 PR12 활동은 빠지지 않으려 노력했습니다. 유튜브에는 시간에 맞춰 꼬박꼬박 올렸습니다만 블로그에 중복으로 올리는 것이 조금 품이 들어서 그런지 여기에는 업데이트가 늦었네요. 조금 여유가 생겼기에 블로그에도 정리를 해서 올립니다.&lt;br /&gt;여전히 매주 일요일마다 12명이 돌아가며 두 명씩 두 편의 논문을 40분 동안 발표하고 있습니다. 이 리뷰에서는 Generative Model 중 GAN과는 아예 다른 갈래에 속하는 Autoregressive Model를 소개하였습니다. 이후 DeepMind의 WaveNet의 전신이 되는 논문이지요. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/BvcwEz4VPIQ&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;슬라이드:&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-pixelrnn-jaejun-yoo&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-pixelrnn-jaejun-yoo&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/2476804623322338029/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-24-pixel-recurrent-neural.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2476804623322338029'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2476804623322338029'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/pr12-video-24-pixel-recurrent-neural.html' title='[PR12-Video] 24. Pixel Recurrent Neural Network'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/BvcwEz4VPIQ/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-7376856988057303015</id><published>2018-02-03T16:37:00.003+09:00</published><updated>2018-02-03T17:11:20.519+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>초짜 대학원생의 입장에서 이해하는 Energy-Based Generative Adversarial Networks (1)</title><content type='html'>&lt;span style=&quot;font-size: x-small;&quot;&gt;* &lt;a href=&quot;https://arxiv.org/pdf/1609.03126.pdf&quot;&gt;Energy-Based Generative Adversarial Networks J. Zhao ICLR 2017&lt;/a&gt;을 바탕으로 한 리뷰&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;오늘은 매우 오랜만에 GAN 논문을 포스팅하려 합니다. 2016년 9월에 올라왔고 ICLR 2017에서 발표된 EBGAN입니다. 우리의 연예인 Yann Lecun 교수님께서 저자로 있기에 매우 유명했던 논문이기도 하죠.&lt;br /&gt;&lt;br /&gt;NIPS 2016 당시 keynote presentation에서 여러 차례 자신의 EBGAN을 홍보하시던 Lecun 교수님을 잊을 수가 없습니다. Keynote, panel discussion, GAN 워크샵에 내내 언급할 기회가 있을 때마다 &quot;GAN은 내가 근 $x$년간 들어본 아이디어 중 최고이다&quot;라 강조하시는데 $x$가 10년씩 추가되는 재미있는 모습을 볼 수 있었습니다. 그 특유의 프랑스 억양이 섞인 말투가 아직도 기억에 남네요.&lt;br /&gt;&lt;br /&gt;이 바닥이 워낙 빠르게 발전하는지라 이미 유물이 되어 버린 느낌입니다만 GAN이 발전하는 과정에서 최소한 한 획을 그었다고 평할만한 논문이므로 EBGAN은 정리를 하고 넘어가는게 맞는 것 같습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Energy-Based Model (EBM)&lt;/h2&gt;&lt;br /&gt;제가 EBGAN이 중요한 논문 중 하나라 꼽은 이유는 아직 대다수의 GAN 모델이 Discriminator가 0 아니면 1을 뱉도록 디자인 된 기존의 probabilistic GAN에서 벗어나지 못하고 있을 때, &lt;b&gt;energy&lt;/b&gt;라는 개념을 도입하여 기존 구조를 깨는 모델을 제안했기 때문입니다.&lt;br /&gt;&lt;br /&gt;이 energy 개념을 도입하면 GAN 구조를 좀 다른 각도로 살펴볼 수 있게 되는데요 처음 보았을 때 꽤나 신선한 접근이라고 생각했기에 여기에 같이 정리하여 소개해보겠습니다.&lt;br /&gt;(아마도 이번 글은 또.... EBGAN 설명 이전에 Intro가 길어질 것 같네요...하... insight가 많은 논문은 읽기는 재미있는데 정리하기는 매우 귀찮다아...orz....이런 식으로 아직 엄두도 못내는 것들이 산더미. 말로 하면 편한데...)&lt;br /&gt;&lt;br /&gt;Statistical learning이나 machine learning의 주요 목적을 한 문장으로 정리해보자면 여러 변수들간의 상관관계를 어떻게 하면 잘 인코딩해볼까로 얘기할 수 있습니다. 이렇게 변수들간의 상관관계를 데이터로부터 잘 학습하고 나면, 모르는 변수의 값이 들어왔을 때 이미 알고 있는 변수들의 값을 바탕으로 모델이 질문에 답할 수 있겠죠 (아래 예시).&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-80piXOrv_SU/WnU4OGEmDqI/AAAAAAAACiE/qqBnSBhnH0A2Q-HwvFtFzbzhGIjEGOSMQCK4BGAYYCw/s1600/ebgan3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;253&quot; src=&quot;https://2.bp.blogspot.com/-80piXOrv_SU/WnU4OGEmDqI/AAAAAAAACiE/qqBnSBhnH0A2Q-HwvFtFzbzhGIjEGOSMQCK4BGAYYCw/s400/ebgan3.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;위 그림에서 보실 수 있듯이 우리가 $Y_1$과 $Y_2$의 관계를 알고 나면 이미 관측한 데이터가 아닌 어떤 새로운 $Y_1$값 혹은 $Y_2$ 값이 들어오더라도 서로의 관계를 바탕으로 값을 새로운 데이터가 우리가 학습한 data manifold 위에 적합한 값인지 아닌지를 알 수 있습니다. 여기서 data manifold는 $Y_2= Y_1^2$로 표현되는 curve라 할 수 있겠군요.&lt;br /&gt;&lt;br /&gt;이런 설명은 지도학습과 비지도학습을 가리지 않습니다. 다만 지도학습에서는 위 그림에서 점(데이터)들이 있을 때 그 점이 data manifold에 속하는지 속하지 않는지를 알려주는 정보가 있는 반면에 비지도학습에서는 학습 데이터셋에서조차도 어떤 점이 outlier인지 아닌지 알 정보가 주어지지 않는다는 차이가 있을뿐입니다.&lt;br /&gt;&lt;br /&gt;따라서 학습을 energy의 관점에서 얘기해보면, 데이터를 바탕으로 어떤 energy surface를 만들어 나가되 데이터가 살고 있는 부분 혹은 공간에 대해서는 낮은 energy를 할당하고 다른 부분에는 높은 energy를 할당하도록 하는 그런 과정이라고 생각할 수 있습니다. 즉, 인코딩을 해줄 값 = energy가 되는 것이고 이를 인코딩하는 함수 = energy function이 되는 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-LVfz4yoNfQY/WnU4NPNLMlI/AAAAAAAACh8/GKQaJ4fBH_Y0Hy8iQK6UhpmnCcRnzixswCK4BGAYYCw/s1600/ebgan4.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-LVfz4yoNfQY/WnU4NPNLMlI/AAAAAAAACh8/GKQaJ4fBH_Y0Hy8iQK6UhpmnCcRnzixswCK4BGAYYCw/s1600/ebgan4.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;(여기서 왜 하필 데이터 근방에서 energy가 낮도록 설정하였는지 의아하실 수 있습니다. 이는 energy가 낮을 수록 안정된 구조를 가지는&amp;nbsp;물리적인 관점에서 개념을 가져온 것으로 보입니다.)&lt;br /&gt;&lt;br /&gt;그래서 지도학습은 enegry 관점에서 $X$가 데이터 $Y$가 정답일 때, $(X,Y)$라는 쌍(pair)에서 $Y$가 제대로 된 정답이면 이 쌍의 energy에 낮은 값을 주고 반대의 경우 높은 에너지를 갖게 하는 어떤 방법론이라고 생각할 수 있습니다. 한편 비지도학습은 $X$만이 있기에 data manifold에는 작은 energy를 부여하도록 $X$를 잘 모델링 하는 것이라고 생각할 수 있습니다.&lt;br /&gt;&lt;br /&gt;매우 그럴듯하죠. 그래서 두루뭉술 아 저렇게 하면 되는구나 하고 넘어갈 수 있지만 조금만 곰곰히 생각해보면 여기서 한 가지 의문점이 생깁니다.&amp;nbsp;&amp;nbsp;위의 관점에서 비지도학습 문제를 푼다고 해보겠습니다. 그나마 $X$가 있는 부분의 값은 data manifold라 생각하여 값을 낮게 할당하면 되겠지만 &lt;b&gt;정보조차 없는 data manifold 밖의 공간은 무엇을 기준으로 어떻게 값을 할당해야할까요?&lt;/b&gt; 사실 이는 지도학습에서도 학습 데이터셋이 전체 데이터 공간을 표현할만큼 충분하지 않은 경우 똑같이 발생할 수 있는 문제입니다. 데이터를 존재할 수 있는 모든 조합에 대해 구할 수 있을리가 없죠.&lt;br /&gt;&lt;br /&gt;&lt;h3 style=&quot;text-align: center;&quot;&gt;&lt;b&gt;How do we make the energy higher outside the samples?&lt;/b&gt;&lt;/h3&gt;&lt;br /&gt;여기서 어떤 식으로 문제를 풀어나갈 것이냐에 따라 비지도학습에 속하는 알고리즘들의 갈래를 나누어 energy 관점으로 설명할 수 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Seven Strategies to Shape the Energy Function&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;1. 모델을 만들되 낮은 energy를 가질 수 있는 공간을 한정짓는다.&amp;nbsp;&lt;/b&gt;&lt;br /&gt;(Build the machine so that the volume of low energy stuff is constant)&lt;br /&gt;&amp;gt; PCA, K-mean, GMM, square ICA&lt;br /&gt;&lt;br /&gt;여기에 속하는 알고리즘들은 data manifold 밖의 공간의 energy를 explicit하게 올리지는 않습니다. 다만 디자인에 따라서 자연스럽게 그렇게 될 수 밖에 없도록 만들뿐입니다. 예를 들자면 PCA는 분산이 가장 많이 설명되는 방향을 찾고 각각 orthogonal한 basis로 표현되는 linear subspace로 data manifold를 한정짓습니다. 그렇기에 principal subspace로 설명할 수 없는 다른 공간에 해당하는 녀석들은 정보가 복원되지 않을 것이기 때문에 이 부분에서 들어온 데이터들은 모두 에너지가 높게 하는 모델이라 생각할 수 있습니다.&lt;br /&gt;K-means는 샘플에서 energy가 0이고 멀어질수록 quadratic하게 energy가 증가하도록 하는 모델이라 생각할 수 있습니다. GMM이나 ICA도 결국 위에 설명한 것과 비슷한 분류라 생각할 수 있겠죠.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-zFJDk8t__m0/WnU24D_p2KI/AAAAAAAAChc/wffozxUzcPM_t1pSBXVRuURpKcQcIURLwCK4BGAYYCw/s1600/ebgan1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zFJDk8t__m0/WnU24D_p2KI/AAAAAAAAChc/wffozxUzcPM_t1pSBXVRuURpKcQcIURLwCK4BGAYYCw/s1600/ebgan1.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;그래서 보시듯이 이런 Spiral data에 대해 PCA가 좋은 모델이 아닌 것을 금방 알 수 있습니다. K-means는 이런 경우에 좀 잘 하는 것처럼 보이지만 사실 고차원 공간으로 가면 제대로 동작하지 않을 것이 뻔히 보이죠.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;2. Parametric 모델 사용하여 샘플에서의 energy는 낮추고 다른 모든 부분에서는 올린다.&amp;nbsp;&lt;/b&gt;&lt;br /&gt;(Push down of the energy of data points, push up everywhere else)&lt;br /&gt;&amp;gt; Maximum likelihood (needs tractable partition function)&lt;br /&gt;&lt;br /&gt;우리가 흔히 아는 Maximum likelihood가 여기에 속합니다. 다만 이 경우 보통 probabilistic model을 만들기 위해 전체 domain, 모든 parameter에 대한 적분 함수를 계산해야하는데 이런 partition function이 보통 intractable한 경우가 많습니다. Tractable한 함수로 한정지어 계산하면 그만큼 모델에 한계가 생기겠죠. Variational bound를 적용해서 surrogate 함수를 만들어 사용하는 방법도 있지만 여전히 한계점들이 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;3. 2번과 달리 모든 부분에서 energy를 올리는 것이 아니라 선택된 일부에서만 올린다.&lt;/b&gt;&lt;br /&gt;(Push down of the energy of data points, push up on chosen locations)&lt;br /&gt;&amp;gt; Contrastive divergence, Ratio matching, Noise contrastive estimation, Minimum probability flow&lt;br /&gt;&lt;br /&gt;이 경우 문제가 &lt;b&gt;&quot;선택된 일부&quot;&lt;/b&gt;를 어떻게 찾을 것인가에 대한 것으로 변할뿐 본질적인 문제는 해결되지 않습니다. 기본적으로 이 분류에 속하는 알고리즘들은 현재 가지고 있는 energy 모델에 대해 샘플에 약간의 noise를 주어 근방을 탐색해서 값을 계산하고 energy 함수를 업데이트 하는 전략을 취합니다. 즉 어떤 샘플링을 하는 것으로 생각하실 수 있는데요 이 과정이 반복수가 많아지면 결국 MCMC를 하는 것과 같아집니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;4. 샘플 근방의 curvature는 극대화시키고 gradient는 최소화시킨다.&lt;/b&gt;&lt;br /&gt;(Minimize the gradient and maximize the curvature around data points)&lt;br /&gt;&amp;gt; score matching&lt;br /&gt;&lt;br /&gt;&lt;b&gt;5. 어떤 dynamical system을 학습시켜서 결국에는 data manifold로 수렴하도록 한다.&lt;/b&gt;&lt;br /&gt;(Train a dynamical system so that the dynamics go to the manifold)&lt;br /&gt;&amp;gt; denoising auto-encoder&lt;br /&gt;&lt;br /&gt;&lt;b&gt;6. Regularizer를 사용해서 낮은 enegy를 가질 수 있는 공간을 한정짓는다.&lt;/b&gt;&lt;br /&gt;(Use a regularizer that limits the volume of space that has low energy)&lt;br /&gt;&amp;gt; Sparse coding, sparse auto-encoder, Predictive Sparse Decomposition&lt;br /&gt;&lt;br /&gt;PCA나 K-means와는 다르게 loss function 혹은 energy function에 regularizer를 explicit하게&amp;nbsp;붙여서 공간을 제한하는 방식을 취합니다. Lecun 교수님은 &lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/auto-encoding-variational-bayes-vae-1.html&quot;&gt;Variational Auto-Encoder (VAE)&lt;/a&gt;도 이 관점으로 보면 중간 latent space에 noise를 넣어 code가 표현할 수 있는 정보의 양 혹은 공간을 제한하는 것으로 생각할 수 있다고 언급하고 넘어갑니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-VNs7wu8999I/WnU3a_9PIyI/AAAAAAAACho/KPfXhXSXpIg1o24ILYoZCrfjgjnvgzVSACK4BGAYYCw/s1600/ebgan2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;312&quot; src=&quot;https://2.bp.blogspot.com/-VNs7wu8999I/WnU3a_9PIyI/AAAAAAAACho/KPfXhXSXpIg1o24ILYoZCrfjgjnvgzVSACK4BGAYYCw/s320/ebgan2.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;sparse coding energy surface&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;7. If $E(Y) = ||Y-G(Y)||^2$, make $G(Y)$ as &quot;constant&quot; as possible&lt;/b&gt;&lt;br /&gt;&amp;gt; Contracting auto-encoder, saturating auto-encoder&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;So what is this all about?&amp;nbsp;&lt;/h2&gt;&lt;br /&gt;EBGAN을 설명한다면서 EBM에 대해 설명을 하다가 갑자기 비지도학습의 분류만 주구장창 설명하니 이게 무슨 뜬금포인가 할 수 있으실텐데요.&lt;br /&gt;&lt;br /&gt;GAN은 사실 3번에서 &lt;b&gt;&quot;선택된 일부&quot;&lt;/b&gt;를 찾아내는 과정을 매우 신박한 방식으로 해결한 모델이라 생각할 수 있습니다. MCMC는 이런 &lt;b&gt;선택된 일부 = contrastive data&lt;/b&gt;를 생성하는 non-parametric model이라 할 때, GAN은 이를 parametric model을 바탕으로 contrastive data를 생성하는 방법인 것이죠. 즉, GAN 학습과정에서 generator가 하는 역할을&lt;b&gt; data manifold 밖에 속하는 데이터(contrastive data, e.g. 매우 이상한 사람 사진)&lt;/b&gt;를 생성하는 것으로, 그리고 discriminator가 샘플에 energy를 할당하는 energy function 역할을 하는 것으로 생각할 수 있습니다.&lt;br /&gt;&lt;br /&gt;여기서 멋진 점은 학습이 진행됨에 따라 generator가 점차 data manifold에 가까운 샘플들을 생성하기 때문에 data manifold에서 멀리 있는 contrastive data들부터 생성해나가며 전체 energy surface를 구성할 수 있게 됩니다. 마찬가지로 discriminator 역시 data manifold에서 먼 곳의 data가 없어도 generator가 생성하는 sample로부터 이에 대한 정보를 자연스럽게 얻어내어 좋은 energy function을 학습할 수 있게 되구요.&lt;br /&gt;&lt;br /&gt;따라서 GAN이 학습 데이터셋이 없거나 불충분한 경우에도 학습이 가능하도록 하는 일종의&amp;nbsp;매우 강력한 비지도학습 방법론이라 생각할 수 있습니다. 그렇기에 지도학습의 눈부신 성과에 비해 정체되어있던 비지도학습의 연구에 GAN이 매우 큰 breakthrough를 가져올 수 있는 Clue가 되지 않을까 하며 Lecun 교수님이 매번 강조하는 것이 아닌가 싶습니다.&lt;br /&gt;&lt;br /&gt;다음 글에서는 위와 같은 관점에서 EBGAN을 분석해보도록 하겠습니다. 전반적인 구조를 설명하고 실험 결과와 Theoretical 증명에 대한 설명도 함께 넣을 예정입니다. 그럼 다음 글에서 뵙겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;참고문헌:&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;[1]&amp;nbsp;&lt;a href=&quot;https://arxiv.org/pdf/1609.03126.pdf&quot;&gt;Energy-Based Generative Adversarial Networks&lt;/a&gt; Junbo Zhao ICLR 2017&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[2] &lt;a href=&quot;https://www.youtube.com/watch?v=x4sI5qO6O2Y&amp;amp;t=266s&quot;&gt;[video] Energy-Based Adversarial Training and Video Prediction&lt;/a&gt; - Yann Lecun - NIPS&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[3] &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf&quot;&gt;A tutorial on Energy-Based Learning&lt;/a&gt; - Yann Lecun et al. 2006&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[4] &lt;a href=&quot;https://github.com/buriburisuri/ebgan&quot;&gt;Tensorflow implementation (github repo)&lt;/a&gt; -&amp;nbsp; Namju Kim&amp;nbsp;&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/7376856988057303015/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7376856988057303015'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7376856988057303015'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html' title='초짜 대학원생의 입장에서 이해하는 Energy-Based Generative Adversarial Networks (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-80piXOrv_SU/WnU4OGEmDqI/AAAAAAAACiE/qqBnSBhnH0A2Q-HwvFtFzbzhGIjEGOSMQCK4BGAYYCw/s72-c/ebgan3.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-2519313704915732718</id><published>2018-01-27T20:49:00.000+09:00</published><updated>2018-02-06T10:04:43.074+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>초짜 대학원생의 입장에서 이해하는 Support Vector Machine (1)</title><content type='html'>* &lt;a href=&quot;https://www.youtube.com/watch?v=_PwhiWxHK8o&amp;amp;t=6s&quot;&gt;Lec. 16 Learning: Support Vector Machines, Patrick Winston&lt;/a&gt; MIT OCW 6.034 Fall 2010을 바탕으로 한 리뷰&lt;br /&gt;&lt;br /&gt;오늘은 클래식한 내용을 다뤄볼까 합니다. 기계 학습 분야에서 한 시대를 풍미하였고, 여전히 매우 다양한 현장에서 사용되고 있는 Support Vector Machine (SVM)에 대해 정리해보았습니다.&lt;br /&gt;&lt;br /&gt;SVM은 이미 역사가 오래되기도 하였지만 매우 멋진!! 방법이기에 여러 학습 자료들이 있습니다. 그런데도 불구하고 제가 그 많은 자료에 하나를 더 추가하는 까닭은 이 영상만큼 간결하지만 핵심을 관통하는 자료를 본 적이 없기 때문입니다. 오직 스스로를 위해 이 강의의 Insight를 잊기 전에 정리하고자 글을 적어봅니다.&lt;br /&gt;&lt;br /&gt;MIT OCW는 정말 은혜로운데요 이 글을 찾으신 분들 중 시간이 있는 분들은 제 정리 글을 보기 보다는 시간을 내어 꼭 영상을 직접 보시는 것을 추천합니다. 이렇게 넓고 깊은 시야를 지닌 교수님께 강의를 온라인으로나마 들을 수 있다는 것은 정말 축복입니다.&lt;br /&gt;&lt;br /&gt;슬프지만 시간이 없으신 분들께서 (혹은 미래에 내용을 까먹은 내가...) 이 글만으로도 강의의 핵심을 맛볼 수 있도록 최대한 노력하여 정리해보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Support Vector Machine&lt;/h2&gt;&lt;br /&gt;SVM의 매력은 매우 아름답고 탄탄한 이론적인 배경을 바탕으로 정교하게 고안된 기계학습 알고리즘이라는 것에 있습니다. 여기에 알고리즘의 실제 적용이 여러 모로 쉽고 성능이 강력하며 따라서 실전적이라는 점이 그 매력을 더합니다.&lt;br /&gt;&lt;br /&gt;SVM에서 풀고자 하는 문제는 다음과 같습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3 style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;How do we divide the space with decision boundaries?&quot;&lt;/b&gt;&lt;/h3&gt;&lt;br /&gt;예시와 함께 보면 좀 더 구체적으로 문제를 좁힐 수 있습니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-ln7nyPwA7UE/WmwCQd-IeVI/AAAAAAAACfI/Cus1PN4tAuMUgTUqELM6yWYDBoCQeC1CgCK4BGAYYCw/s1600/svm1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;196&quot; src=&quot;https://4.bp.blogspot.com/-ln7nyPwA7UE/WmwCQd-IeVI/AAAAAAAACfI/Cus1PN4tAuMUgTUqELM6yWYDBoCQeC1CgCK4BGAYYCw/s200/svm1.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;ol&gt;&lt;li&gt;우리가 $&#39;+&#39;$ 샘플과 $&#39;-&#39;$ 샘플을 구별하고 싶다면 어떤 식으로 나눠야 하는가?&amp;nbsp;&lt;/li&gt;&lt;li&gt;만약 선을 그어 그 사이를 나눈다면 어떤 선이어야 할 것인가?&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;가장 쉽게 그리고 직관적으로 생각할 수 있는 답은 아마도 $&#39;+&#39;$와 $&#39;-&#39;$ 샘플 사이의 거리를 가장 넓게 쓰는 어떤 line으로 다음과 같은 녀석(점선)일 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-pYY6U0peR74/WmwCRbFsM7I/AAAAAAAACfQ/gwcY8_j13yU6qwkITBmgd2yrVkKd2hvQwCK4BGAYYCw/s1600/svm2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;196&quot; src=&quot;https://4.bp.blogspot.com/-pYY6U0peR74/WmwCRbFsM7I/AAAAAAAACfQ/gwcY8_j13yU6qwkITBmgd2yrVkKd2hvQwCK4BGAYYCw/s200/svm2.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&quot;widest street strategy&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;흠... 매우 직관적으로 풀 수 있는 별 것 아닌 문제로 보입니다. 하지만 이 문제에 대한 답을 구체적이고 논리정연하게 이론으로 일반화하는 것은 언뜻 보기와는 달리 쉬운 작업이 아닙니다. SVM은 지금 던진 문제에 대한 답을 찾기 위해 풀어나간 과정입니다.&lt;br /&gt;&lt;br /&gt;그래서 제가 오늘 정리하고자 하는 것은 SVM이기도 하지만 &lt;b&gt;어떤 문제를 풀기 위해 체계적으로 아이디어를 개발하고 논리를 전개하는 과정&lt;/b&gt; 그 자체라고도 얘기할 수 있겠습니다. 그만큼 SVM은 매우 정교하게 고안된 알고리즘인데요 앞으로도 이런 관점에서 어떤 식으로 문제를 설정하고 어떻게 풀어나가는 지를 염두에 두면서 정리하고자 합니다. 이제 그 과정을 하나하나 따라가 보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Decision rule&lt;/h2&gt;&lt;br /&gt;그럼 먼저 &lt;b&gt;&quot;decision boundary를 정하기 위한 decision rule은 어떤 형태여야 할 것인가?&quot;&lt;/b&gt;에 대해 생각해보겠습니다. 이를 위해 $\vec{w}$를 하나 그려볼텐데요 이 벡터는 우리가 그릴 street의 중심선에 대해 직교하는 벡터입니다. (일단 여기서 그 길이는 잠시 arbitrary로 제쳐두겠습니다.)&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-n2tSWYD_XoA/WmwE1cP5ctI/AAAAAAAACfo/3eniT7SzJioB4SdJVL-HTJSb_ouTLLQ_gCK4BGAYYCw/s1600/svm3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;196&quot; src=&quot;https://1.bp.blogspot.com/-n2tSWYD_XoA/WmwE1cP5ctI/AAAAAAAACfo/3eniT7SzJioB4SdJVL-HTJSb_ouTLLQ_gCK4BGAYYCw/s200/svm3.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;그리고 이제 모르는 샘플 $\vec{u}$ 하나가 있을 때 우리가 궁금한 것은 street를 기준으로 이 녀석이 오른쪽에 속할지 혹은 왼쪽에 속할지입니다. 자 여기서 우리가 해볼 수 있는 한 가지 방법은 $\vec{w}$와 $\vec{u}$를 내적한 후 그 값이 어떤 상수 $c$보다 큰 지를 확인하는 것입니다; $\vec{w}\cdot \vec{u} \geq c$. 혹은 일반성을 해치지 않는 범위에서 아래와 같이 얘기할 수도 있겠죠:&lt;br /&gt;\begin{align} \vec{w}\cdot \vec{u}+b \geq 0 \qquad then \quad`+&#39; \label{eq:dr}\end{align}&lt;br /&gt;논리는 매우 간단합니다. 내적을 한다는 것은 위에 그림에서 $\vec{u}$를 $\vec{w}$에 projection 한다는 것이고, 그 길이가 길어서 어떤 경계를 넘으면 오른쪽, 짧으면 왼쪽에 속할한다는 것을 생각해보면 쉽게 이해하실 수 있을 것입니다.&lt;br /&gt;&lt;br /&gt;따라서 수식 \eqref{eq:dr}이 우리의 decision rule이 됩니다. 우리가 SVM을 이해하는데 필요할 가장 첫번째 도구이기도 합니다. 하지만 아직은 부족한 점이 많죠. 아직 우리는 저 수식에서 어떤 $\vec{w}$를 정해야하는지 어떤 $b$를 잡아야하는지 전혀 모릅니다. 다만 $\vec{w}$가 우리가 원하는 street의 중심선에 직교한다는 것 하나만 알 수 있을뿐이죠.&lt;br /&gt;&lt;br /&gt;아쉽게도 그런 $\vec{w}$는 매우 다양하게 그릴 수 있기에 여기서 내릴 수 있는 판단은 아직 constraint가 부족하다는 것입니다. 그래서 앞으로 할 것은 우리가 $\vec{w}$와 $b$를 계산할 수 있도록 저 수식에 여러 제약 조건들을 추가해가는 작업이 되겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Design and add additional constraints&lt;/h2&gt;&lt;br /&gt;자 그러면 이제 위의 식에서 조금 더 나아가서 $x_+$를 $`+&#39;$ 샘플 $x_-$가 $`-&#39;$ 샘플이라 할 때 다음과 같이 적어보겠습니다:&lt;br /&gt;$$\vec{w}&amp;nbsp;\cdot \vec{x}_+&amp;nbsp;+ b \geq 1 \\ \vec{w} \cdot \vec{x}_- + b \leq -1$$&lt;br /&gt;즉, `+&#39; 샘플을 예를 들면 이 샘플에 대해서는 우리의 decision rule이 최소한 1보다는 큰 값을 주도록 해본 것입니다.&lt;br /&gt;&lt;br /&gt;흠...문제가 좀 더 구체화된 것 같기는 합니다..그런데 여전히 문제가 쉬워지지는 않았네요...안 그래도 복잡한데 따로 노는 두 개의 식들을 다루는 것은 짜증나는 일이지요. 그래서 여기에 variable 하나를 고안해서 문제를 좀 바꿔보겠습니다. (이런 variable들을 추가하는 이유는 정말 단순히 그저 수학적으로 편리하기 위함입니다)&lt;br /&gt;$$y_i=\begin{cases}\begin{align*}~1&amp;amp;\qquad for \quad `+&#39; \\ -1&amp;amp;\qquad for \quad `-&#39;&amp;nbsp; \end{align*}\end{cases}$$&lt;br /&gt;이제 이 $y_i$를 위에 수식에 각각 곱해보겠습니다.&lt;br /&gt;$$y_i(\vec{w}\cdot\vec{x}_i+b) \geq 1$$&lt;br /&gt;오! 이제 수식이 하나로 줄었습니다. 이걸 좀 정리하면 아래와 같고,&lt;br /&gt;\begin{equation}y_i(\vec{w}\cdot\vec{x}_i+b) - 1 \geq 0 \label{eq:const}\end{equation}&lt;br /&gt;여기서 등호가 성립할 때는 $\vec{x}_i$가 정확히 street의 양 쪽 노란 경계선에 정확히 걸쳐 있을 때라는 제약을 하나 더 추가해보겠습니다. 즉, 위에 그림에서 경계(노란선, gutters)에 걸칠 $`+&#39;$ 샘플 하나와 $`-&#39;$ 샘플 두 개에 대한 수식의 결과가 0이 되겠습니다.&lt;br /&gt;\begin{equation}y_i(\vec{w}\cdot\vec{x}_i+b) - 1=0 \qquad for\quad \vec{x}_i \in노란선~(gutters)\label{eq:2}\end{equation}&lt;br /&gt;이 쯤에서 다시 우리가 하고자 했던 목적을 재차 상기해보겠습니다. 우리가 하고 싶은 것은 어떤 선을 잡되 이로 인해 생기는 $`+&#39;$ 샘플과 $`-&#39;$ 샘플 사이의 거리를 가능한 최대로 넓게 하고 싶습니다. 그러면 일단 &#39;거리&#39;라는 것을 어떻게 표현할 수 있을지 고민해봐야 합니다.&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-Kb58kvRn3p0/WmwKaCgfcQI/AAAAAAAACgA/FprZTNJDE7cLr_37_7AvnPuLe0PBuW9hgCK4BGAYYCw/s1600/svm4.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;195&quot; src=&quot;https://2.bp.blogspot.com/-Kb58kvRn3p0/WmwKaCgfcQI/AAAAAAAACgA/FprZTNJDE7cLr_37_7AvnPuLe0PBuW9hgCK4BGAYYCw/s200/svm4.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;위 그림에서 보여주는대로 하면 거리를 다음과 같이 표현 할 수 있겠습니다:&lt;br /&gt;$$WIDTH = (x_+-x_-)\cdot\frac{\vec{w}}{||\vec{w}||}$$&lt;br /&gt;오! 그런데 \eqref{eq:2}번 수식 덕분에 위에 WIDTH의 분자를 계산하면,&lt;br /&gt;\begin{align}WIDTH = \frac{2}{||\vec{w}||}\label{eq:3}\end{align}&lt;br /&gt;가 된다는 것을 알 수 있습니다. 이 수식 \eqref{eq:3}이 SVM을 이해할 때 필요한 세번째 도구입니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Optimization techniques&lt;/h2&gt;&lt;br /&gt;식 \eqref{eq:3}이 있기에 우리는 WIDTH를 최대화하고 싶다는 목적을 다음과 같이 수식화하여 적을 수 있게됩니다:&lt;br /&gt;$$\max \frac{1}{||\vec{w}||} \leftrightarrow \min ||\vec{w}|| \leftrightarrow \min \frac{1}{2}||\vec{w}||^2$$&lt;br /&gt;(이렇게 표현 하는 것 역시도 오로지 최종 목적을 위해서 그리고 수학적 계산의 용이함을 위함입니다.)&lt;br /&gt;&lt;br /&gt;단, 이 문제를 풀 때 $\vec{w}$가 수식 \eqref{eq:2}이라는 제약 조건을 만족시켜야 한다는 점을 잊으면 안 됩니다. 이런 등식 제약 조건이 있는 최적화 문제는 다양하게 연구되어 왔는데, 많이들 알고 계시는 라그랑주 승수법(Lagrange Multiplier Method)를 적용하면 제약 조건을 신경쓰지 않고 풀 수 있도록 문제를 바꿀 수 있습니다:&lt;br /&gt;\begin{equation} \cal{L}(w,b,\alpha) = \frac{1}{2}||\vec{w}||^2-\sum_{i=1}^N\alpha_i[y_i(\vec{w}\cdot\vec{x}_i+b)-1]\\ minimize\quad w.r.t.\quad \vec{w}~and~b \qquad maximize\quad w.r.t.\quad \alpha_i \geq 0&amp;nbsp;&amp;nbsp;\quad \forall i\label{eq:4} \end{equation}&lt;br /&gt;여기서 $\alpha$는 Lagrange multiplier입니다.&lt;br /&gt;&lt;br /&gt;(* 나중에 얘기하게 되겠지만 $\alpha$들 중 경계에 걸친 샘플 $\vec{x}_i$(or support vector)에 대한 $\alpha_i$ 외에는 모두 값이 $0$이 됩니다. 그리고 모든 샘플들에 대해 얘기하려 하면 등식이 아닌 부등식 \eqref{eq:const}를 제약 조건으로 사용해야 하는데요 이 때는 KKT 조건이란 것을 설명해야 합니다. 엄밀히 말하면, 위 식 \eqref{eq:4}에서 $\alpha_i\geq0$라는 것과 $\alpha$에 대해 maximize 문제가 나온 이유 등이 이로부터 비롯합니다. 다만 이런 내용들을 지금 얘기하기에는 지금까지 전개해온 큰 흐름을 놓칠 우려가 있기에 당장은 이 녀석들이 해주는 역할이 제약 조건이 있는 최적화 문제를 제약 조건이 없는 문제로 바꾸어 주는 것이라는 점만 알고 넘어가겠습니다.)&lt;br /&gt;&lt;br /&gt;이제 거의 다 왔습니다. 우리가 관심있는 각각의 변수에 대해 미분을 해주면 다음 식들을 얻을 수 있습니다.&lt;br /&gt;\begin{align} \nabla_\vec{w}\cal{L} = \vec{w} - \sum_i\alpha_i y_i\vec{x}_i = 0 \label{eq:w}&lt;br /&gt;\\ \nabla_b\cal{L} = -\sum_i\alpha_i y_i = 0 \label{eq:b}\end{align}&lt;br /&gt;흠 매우 흥미로운 결론입니다. &lt;b&gt;Now the math begins to sing! &lt;/b&gt;여기서 첫번째 식을 정리해보면 $\vec{w} = \sum_i\alpha_iy_i\vec{x}_i$이므로 우리가 관심있는 decision vector $\vec{w}$가 &quot;some&quot; 샘플들의 선형 합으로 나타낼 수 있다는 점을 알 수 있습니다. $\vec{w}$는 꼭 이런 형태야 할 필요는 없었는데 말이죠. 차분히 문제를 풀어가다보니 마침내 이른 형태가 샘플들의 선형 합입니다. (제곱, log 등 별 희안한 조합이 뒤섞인 형태일 수도 있었는데 말이죠) 여기서 &quot;some&quot;이라 굳이 강조한 이유는 경계에 걸친 샘플들 외에는 $\alpha$ 값들이 0이기 때문입니다.&lt;br /&gt;&lt;br /&gt;결국 $\alpha$ 값만 알게 되면 $\vec{w}$를 구할 수 있게 되었습니다. 그럼 이제 여기서 얻은 식들을 이용해서 \eqref{eq:4}에 대입하여 $\alpha$에 대한 식으로 바꾸고 문제를 더 단순화 해보겠습니다. 식&amp;nbsp;\eqref{eq:4}에서 두번째 항의 $-1$ 부분을 밖으로 꺼내고 식\eqref{eq:b}을 이용하여 $b$ 부분을 없앨 수 있습니다. 이어 식 \eqref{eq:w}을 이용하여 $\vec{w}$ 대신 넣어주면 다음과 같이 정리가 가능합니다:&lt;br /&gt;\begin{align*} \sum_{i=1}^N \alpha_i +&amp;nbsp;\frac{1}{2}||\vec{w}||^2-\sum_{i=1}^N\alpha_iy_i\vec{w}^T\vec{x}_i&lt;br /&gt;&amp;amp;\iff \sum_{i=1}^N \alpha_i +&amp;nbsp;\frac{1}{2}\vec{w}^T\vec{w}-\vec{w}^T \vec{w}&amp;nbsp; \\&lt;br /&gt;&amp;amp;\iff \sum_{i=1}^N \alpha_i -&amp;nbsp;\frac{1}{2}\vec{w}^T \vec{w} \\&lt;br /&gt;&amp;amp;\iff \sum_{i=1}^N \alpha_i - \sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_j y_iy_j\vec{x}_i^T\vec{x}_j\\&lt;br /&gt;&amp;amp;\iff \cal{L}(\alpha).&lt;br /&gt;\end{align*}&lt;br /&gt;따라서 이제 모든 것이 $\alpha$에 대한 maximization 문제로 정리가 끝났습니다. 이 문제를 풀어 $\alpha$를 구하면, 식 \eqref{eq:w} $\vec{w} = \sum_i\alpha_iy_i\vec{x}_i$을 사용해서 $\vec{w}$를 구할 수 있게 되고 이어 식 \eqref{eq:2}을 통해 $b$도 구할 수 있게 됩니다. 식 \eqref{eq:2}에 의해 $\alpha$ 값이 0이 아니라는 것은 해당 $\vec{x}$가 경계선을 정하는 샘플이라는 뜻이고 SVM에서는 이런 샘플들을&lt;b&gt; &quot;support vector&quot;&lt;/b&gt;라고 부릅니다.&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-NXaQRDHnCM0/Wmxciwina8I/AAAAAAAACgc/T8UKdKZSx7glaauna_-_sMPjrHSSbmo6QCK4BGAYYCw/s1600/svm5.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;196&quot; src=&quot;https://1.bp.blogspot.com/-NXaQRDHnCM0/Wmxciwina8I/AAAAAAAACgc/T8UKdKZSx7glaauna_-_sMPjrHSSbmo6QCK4BGAYYCw/s200/svm5.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;support vectors&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;오 그런데 전개를 하고 보니 $\cal{L}(\alpha)$ 식은 매우 좋은 성질을 갖고 있습니다. $\alpha$에 대해 첫째 항은 선형이고 둘째 항은 quadratic이기 때문에 quadratic programming 테크닉을 사용하여 어떠한 off-the-shelf 알고리즘이든 사용하면 $\alpha$ 해를 구할 수 있습니다.&lt;br /&gt;&lt;br /&gt;즉, 이 SVM은 신경망과는 달리 local minima에 빠질 걱정을 전혀 하지 않아도 된다는 것이죠. 따라서 SVM으로 구한 해는&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;언제나 (현재 SVM이 줄 수 있는) 최적의 해라는 것이 이론적으로 보장&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;됩니다 (소름!).&lt;br /&gt;&lt;br /&gt;따라서 support vector들로 정해진 decision boundary가 가장 최적의 boundary이며, 현재 가지고 있는 데이터만으로 새로운 샘플이 들어왔을 때 일반화를 가장 잘 할 수 있는 decision rule을 찾을 수 있게 된 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;(bonus) The way to Kernel trick&lt;/h2&gt;&lt;br /&gt;짠! 우리는 이제 SVM에 대한 큰 줄기를 모두 훑었습니다. 재미있는 사실은 SVM과 관련된 핵심 수식들이 모두 샘플에 대한 &quot;내적&quot;으로 이루어져 있다는 것입니다. $\cal{L}(\alpha)$ 식에서 $\vec{x}_i^T\vec{x}_j$ 부분이 그러하고 우리가 decision rule로 정의하였던 식 \eqref{eq:dr} 역시도 식 \eqref{eq:w}을 대입하여 바꿔주면 결국 $\vec{x}\cdot\vec{u}$과 같이 sample과 모르는 unknown 샘플의 내적에 따라 값이 바뀌는 것을 보실 수 있습니다.&lt;br /&gt;&lt;br /&gt;왜 갑자기 내적을 강조하는지 의아하실 수 있는데요 지금까지 소개한 SVM은 우리가 흔히 아는 Euclidean 공간에서의 내적을 사용하고 있었습니다. 그런데 샘플들이 살고 있는 공간이 매우 복잡하여 두 샘플 간의 거리를 가늠할 때 단순한 내적을 사용하는 것이 맞지 않는 경우가 있을 수 있습니다. (사실 대다수의 흥미로운 문제들은 그렇죠) 즉, 샘플들이 linearly separable한 경우라면 지금까지 본 SVM이 매우 잘 동작하지만 그게 아닌 경우는 문제를 전혀 풀지 못하는 문제가 생기게 됩니다.&lt;br /&gt;&lt;br /&gt;바로 이 부분에서 재미있는 아이디어들이 많이 나옵니다. 현재 샘플이 살고 있는 공간에서 샘플 군간의 구별이 어렵다면, 어떤 함수 $\phi(\cdot)$을 잘 디자인하여 샘플들이 linearly separable한 공간으로 샘플들을 보내준 후 그 공간에서의 SVM을 적용하는 것을 생각해볼 수 있습니다.&lt;br /&gt;&lt;br /&gt;이를 심지어는 무한 차원을 갖는 어떤 feature space로 확장하여 생각을 해볼 수 있는데요. 이 경우 매우 큰 차원이 갖는 풍부한 표현력을 이용하면서도 실제 decision boundary에 영향을 주는 support vector들은 상대적으로 매우 적을 수 있기 때문에 일반화를 매우 잘 하는 모델을 세울 수 있게 됩니다.&lt;br /&gt;&lt;br /&gt;다만 $\phi(\cdot)$이라는 무한 차원으로 보내줄 적절한 함수를 찾는 것도 쉬운 일은 아닐테죠.&amp;nbsp;그런데 잘 생각해보면 SVM을 적용할 때 우리가 필요한 것은 사실 그 차원으로 보내는 함수가 아니라 그 공간에서의 내적값입니다. 즉, 만약 어떤 Kernel이 있어서 우리가 $K(\vec{x},\vec{y}) = \phi(\vec{x})\cdot\phi(\vec{y})$와 같이 우연히도 다른 공간에서의 내적값에 대응하는 값을 주는 녀석을 잘 디자인할 수 있다면 non-linearly separable한 경우에 있어서도 SVM이 잘 작동할 수 있을 것입니다.&lt;br /&gt;&lt;br /&gt;이게 제가 이해하고 있는 &lt;b&gt;Kernel trick&lt;/b&gt;의 흐름입니다. 아마 기회가 된다면 다음 번 글에서 앞서 자세히 소개하지 못한 최적화 부분 얘기와 함께 내용을 다룰 수 있지 않을까 싶습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;마무리&lt;/h2&gt;&lt;br /&gt;이 글을 쓰기 위해&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/watch?v=_PwhiWxHK8o&amp;amp;t=6s&quot;&gt;Patrick Winston&lt;/a&gt;&amp;nbsp;교수님의 MIT OCW 강의를 듣다 멈추다 하며 정리를 하다보니 오히려 더 배웠습니다. SVM이라는 방법론이 나오게 된 이유부터 문제 설정, 문제를 풀기 위해 필요한 요소들을 하나하나 만들어 나가는데, 별다른 강의 자료 하나 없이 그리고 복잡한 수식 따위 없이 분필 하나만을 쥐고서 처음과 끝은 잇는 커다란 흐름에 따라 칠판에 차근차근 논리를 전개하는 50분의 강의는 버릴 프레임이 단 한 프레임도 없습니다.&lt;br /&gt;&lt;br /&gt;매우 단순하고 명료한 논리를 따라가다보면 모든 수식이 모자람도 덜어낼 것도 없이 딱 필요한만큼 당연히 있어야 할 자리에 있을뿐 전혀 어렵지 않게 설명이 가능하다는 것을 알 수 있습니다. SVM이라는 키워드에 같이 따라오는 여러 수식들 때문에 두려움이 있었던 분들께 이 강의를 다시 한 번 강력히 추천합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;함께 보면 좋은 영상&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=eHsErlPJWUU&amp;amp;hd=1&quot;&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Caltech&#39;s ML cources CS 156 Lecture 14 - Support Vector Machines - Yaser Abu-Mostafa&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/2519313704915732718/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html#comment-form' title='6개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2519313704915732718'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/2519313704915732718'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html' title='초짜 대학원생의 입장에서 이해하는 Support Vector Machine (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-ln7nyPwA7UE/WmwCQd-IeVI/AAAAAAAACfI/Cus1PN4tAuMUgTUqELM6yWYDBoCQeC1CgCK4BGAYYCw/s72-c/svm1.png" height="72" width="72"/><thr:total>6</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-8221268931133222333</id><published>2017-12-24T01:27:00.000+09:00</published><updated>2017-12-26T09:42:25.988+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="en"/><title type='text'>When a ball put inside a box has a longer diameter than the box (What happens when we put a ball inside a box in a high dimensional world?)</title><content type='html'>&lt;h2&gt;When a ball put inside a box has a longer diameter than the box&lt;/h2&gt;&lt;br /&gt;I had a chance to read &lt;a href=&quot;http://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot;&gt;Ferenc&#39;s interesting post&lt;/a&gt; about counter-intuitive things happening in a high dimensional space. This reminds me a very simple but another interesting example I met in a topology class.&lt;br /&gt;&lt;br /&gt;I found this example in a series of YouTube lectures about &lt;a href=&quot;https://www.youtube.com/playlist?list=PLTBqohhFNBE_09L0i-lf3fYXF5woAbrzJ&quot;&gt;topology and geometry by professor Tadashi Tokieda&lt;/a&gt;.&amp;nbsp; This example is very easy to understand with a simple logic though it triggers a lot of interesting thoughts and broadens&amp;nbsp;my sight. I hope this would also help the readers to glimpse a deep and extraordinary&amp;nbsp;world of a high dimensional space.&lt;br /&gt;&lt;br /&gt;To start, let&#39;s begin with an easy example of 2D space. Think about the situation that you put every corner of the square (each side has a length of one, $I^2$ with a white disk. Then, try to fit a red disk in the middle.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s1600/topo1.png&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;320&quot; src=&quot;https://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s320/topo1.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;2D square example&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Then, what is the diameter of the red disk? You can solve this problem in various ways but let me introduce a very intuitive and simple way.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-y1c2m4fUZIc/Wj5wV3WHRaI/AAAAAAAACaI/KYrZ8kGF9TUc6lwR8V45bDqYsfmfe_jPwCK4BGAYYCw/s1600/topo2.png&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;319&quot; src=&quot;https://3.bp.blogspot.com/-y1c2m4fUZIc/Wj5wV3WHRaI/AAAAAAAACaI/KYrZ8kGF9TUc6lwR8V45bDqYsfmfe_jPwCK4BGAYYCw/s320/topo2.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Solution&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;As you can see in the above picture, you would immediately notice that the length of the diagonal line is equal to the sum of two white disks&#39; and two red disks&#39; diameters. Therefore, you can derive the diameter of the red ball $d_{red}$ as below:&lt;br /&gt;$$d_{red} = \frac{\sqrt{2}-1}{2}.$$&lt;br /&gt;Since the value of $\sqrt{2}$ is approximately 1.414, the diameter of the red disk is approximately 0.2,&amp;nbsp;which is definitely smaller than the length of each side of the square. This simply means that this disk in the middle is smaller than the square. Well... Of course! Because we put it in the square.&lt;br /&gt;&lt;br /&gt;What would happen when we go to 3D box $I^3$?&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-9U1Uxlw7l2M/Wj5z3Ep2p_I/AAAAAAAACaU/hm46w5UzWnkGmPg9CoZiigwln_tL6U9ogCK4BGAYYCw/s1600/topo3.png&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;246&quot; src=&quot;https://3.bp.blogspot.com/-9U1Uxlw7l2M/Wj5z3Ep2p_I/AAAAAAAACaU/hm46w5UzWnkGmPg9CoZiigwln_tL6U9ogCK4BGAYYCw/s320/topo3.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;3D box example&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Again, it is not hard to find $d_{red}$. In an analogous way with the previous solution, we can simply find the fact that the length of the diagonal line of the box would be also same with the sum of two white balls&#39; and red balls&#39; diameters.&lt;br /&gt;&lt;br /&gt;By the&amp;nbsp;Pythagorean theorem, we can easily derive the diameter of the red ball by&lt;br /&gt;$$d_{red} = \frac{\sqrt{3}-1}{2}\approx 0.35 &amp;lt;1.$$&lt;br /&gt;It is still smaller than the box though it has increased a little.&lt;br /&gt;&lt;br /&gt;Let&#39;s do the same in $I^m$. Still the length of the diagonal line across the high dimensional box would be found by the square root of the sum of the squares of all the sides it has.&lt;br /&gt;&lt;br /&gt;Therefore, the general solution for $d_{red}$ in $m$-th dimension can be derived as follows:&lt;br /&gt;$$d_{red} = \frac{\sqrt{m}-1}{2}.$$&lt;br /&gt;You may already notice that this will give a very interesting result when $m\geq 9$. Whenever $m$ goes beyond 10, we would find the ball which is put inside the box would have longer diameter than the length of each side of the box!&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;i&gt;&lt;b&gt;&quot;When a ball put inside a box has a longer diameter than the box&#39;s side!&quot;&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;br /&gt;This simple but very counter-intuitive example shows how much our intuition can be wrong when it comes to a high dimensional space. As written in the front desk of my blog, I always try to think in pictures and visualize more when I meet a new concept. However, this example always rings me a warning that I have to be very careful whenever I cross the line above three-dimensional space.&lt;br /&gt;&lt;br /&gt;I hope the readers would also find the fresh impression that I felt when I met this example for the first time. Thank you for your reading and please leave the comments if you liked it.</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/8221268931133222333/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/12/when-ball-put-inside-box-has-longer.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8221268931133222333'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/8221268931133222333'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/12/when-ball-put-inside-box-has-longer.html' title='When a ball put inside a box has a longer diameter than the box (What happens when we put a ball inside a box in a high dimensional world?)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s72-c/topo1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-7124539554694378478</id><published>2017-12-24T00:34:00.002+09:00</published><updated>2019-05-07T17:34:28.050+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><category scheme="http://www.blogger.com/atom/ns#" term="topology"/><title type='text'>박스 안에 넣은 공의 지름이 박스보다 클 때 (What happens when we put a ball inside a box in a high dimensional world?)</title><content type='html'>&lt;h2&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/h2&gt;&lt;br /&gt;(* For English speakers: &lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/12/when-ball-put-inside-box-has-longer.html&quot;&gt;En version&lt;/a&gt;)&lt;br /&gt;&lt;br /&gt;facebook의 게시글 중 &lt;a href=&quot;https://www.facebook.com/sungbin87/posts/1755077804516893&quot;&gt;임성빈 박사님이 올리신 고차원으로 생각을 확장할 때 주의할 내용에 관한 글&lt;/a&gt;을 보고 문득 떠오른 재미있는 예시가 있다.&lt;br /&gt;&lt;br /&gt;예전에 위상 수학을 혼자 공부하다 본&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLTBqohhFNBE_09L0i-lf3fYXF5woAbrzJ&quot;&gt;Tadashi Tokieda 교수님의 Topology &amp;amp; Geometry 강의&lt;/a&gt; 중 있던 예시인데 일반적인 상식이 뒤집어지는 예시면서도 매우 쉽게 보일 수 있어서 감명 깊었던 것을 공유하기 위해 정리해본다.&lt;br /&gt;&lt;br /&gt;먼저 쉬운 예부터 시작하기 위해서, 각 변의 길이가 1인 2D 사각형 $I^2$ 안에 네 귀퉁이마다 흰 공을 넣고 맨 중간에 남는 공간에 빨간 공을 채운다고 해보자.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s1600/topo1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;320&quot; src=&quot;https://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s320/topo1.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;2차원 박스 예시&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;이 때, 이 공의 지름은 어떻게 되는지 생각해보자. 다양한 방법으로 이를 구할 수 있겠지만 매우 직관적이고 깔끔한 방법 하나를 소개해보면 다음과 같다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-y1c2m4fUZIc/Wj5wV3WHRaI/AAAAAAAACaI/KYrZ8kGF9TUc6lwR8V45bDqYsfmfe_jPwCK4BGAYYCw/s1600/topo2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;319&quot; src=&quot;https://3.bp.blogspot.com/-y1c2m4fUZIc/Wj5wV3WHRaI/AAAAAAAACaI/KYrZ8kGF9TUc6lwR8V45bDqYsfmfe_jPwCK4BGAYYCw/s320/topo2.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;풀이&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;이렇게 여러 사각형을 붙여보면 대각선의 길이는 빨간 공 두 개와 흰 공 두 개의 지름을 합한 것과 같고, 흰 공 두 개의 지름의 합은 1이기 때문에 아래 수식으로 빨간 공의 지름 $d_{red}$를 쉽게 구할 수 있다:&lt;br /&gt;$$d_{red} = \frac{\sqrt{2}-1}{2}.$$&lt;br /&gt;$\sqrt{2}$의 값은 대략 1.414이므로 빨간 공의 지름은 대략 0.2이고 박스의 크기인 1보다 작다. 뭐, 당연한 일이다. 애초에 박스 안에 공을 넣었는데 박스보다 공이 클 수가 있겠는가?&lt;br /&gt;&lt;br /&gt;자, 조금 더 확장해서 3차원 박스 $I^3$가 되면 어떨까?&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-9U1Uxlw7l2M/Wj5z3Ep2p_I/AAAAAAAACaU/hm46w5UzWnkGmPg9CoZiigwln_tL6U9ogCK4BGAYYCw/s1600/topo3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;246&quot; src=&quot;https://3.bp.blogspot.com/-9U1Uxlw7l2M/Wj5z3Ep2p_I/AAAAAAAACaU/hm46w5UzWnkGmPg9CoZiigwln_tL6U9ogCK4BGAYYCw/s320/topo3.png&quot; width=&quot;320&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;3차원 박스 예시&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;이 때의 $d_{red}$ 역시도 그리 어렵지 않다. 앞서 소개한 방식으로 생각을 조금만 더 확장하면, 박스를 가로지르는 빗변의 길이가 흰 공 두 개와 빨간 공 두 개의 지름의 합과 같다는 것은 여전히 유효하다는 것을 알 수 있다. 따라서 피타고라스 정리를 생각하면 아래 사각형의 변들의 제곱과 높이의 제곱을 모두 더한 것에 루트를 씌워 쉽게 구할 수 있다:&lt;br /&gt;$$d_{red} = \frac{\sqrt{3}-1}{2}\approx 0.35 &amp;lt;1.$$&lt;br /&gt;이 역시도 여전히 박스 한 변의 길이인 1보다는 작다. 그런데 여기서 재미있는 점은 빨간 공의 지름이 조금 커졌다는 것이다.&lt;br /&gt;&lt;br /&gt;이를 임의의 $m$ 차원으로 확장하면 어떻게 될까? $m$ 차원 박스 $I^m$을 가로지르는 빗변의 길이는 피타고라스의 정리에 의해 모든 변의 제곱의 합에 루트를 씌운 것과 같다.&lt;br /&gt;&lt;br /&gt;그러면 위에 공식에 따라 $m$ 차원 구 $d_{red}$에 대한 일반 해를 다음과 같이 정리할 수 있는데:&lt;br /&gt;$$d_{red} = \frac{\sqrt{m}-1}{2}.$$&lt;br /&gt;눈치 빠른 분들은 이미 아셨겠지만, $m\geq 9$가 되는 순간 빨간 공의 지름이 박스 한 변의 길이인 1보다 크거나 같아지게 된다. 즉, 우리는 분명 박스 안 모든 귀퉁이에 흰 공들을 넣고 그 안 쪽 공간에 빨간 공을 우겨 넣었지만 빨간 공의 지름은 박스보다 크다!&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;i&gt;&quot;박스 안에 넣은 공의 지름이 박스보다 크다!&quot;&lt;/i&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;br /&gt;매우 단순하고 쉽지만 &lt;b&gt;&lt;span style=&quot;font-size: medium;&quot;&gt;고&lt;/span&gt;&lt;span style=&quot;font-size: medium;&quot;&gt;차원으로 넘어갈 때, 우리의 직관이 얼마나 틀릴 수 있는지 보여주는 좋은 예시&lt;/span&gt;&lt;/b&gt;라고 생각한다. 블로그 인사글과 같이 언제나 그림으로 상상하는 것을 즐기고 그렇게 할 수 있을 때, 가장 강력한 직관과 이해를 얻을 수 있다고 생각하지만 (Think in Pictures and Visualize More!) 고차원으로 갈 때는 이런 재미있는 일들이 자주 일어나기 때문에 매우 조심해야한다는 것도 염두에 두어야하겠다.&lt;br /&gt;&lt;br /&gt;처음 이 예시를 접했을 때 느꼈던 신선함을 다른 분들도 느끼길 바라며 초짜 공돌이의 짧은 위상 수학 산책을 마친다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/7124539554694378478/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7124539554694378478'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7124539554694378478'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html' title='박스 안에 넣은 공의 지름이 박스보다 클 때 (What happens when we put a ball inside a box in a high dimensional world?)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-1mM6mTJCdwE/Wj5urjK7nKI/AAAAAAAACZ8/3D-vWqt_LfoZW7JE15PJZlItfvLaZ4prgCK4BGAYYCw/s72-c/topo1.png" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6422670261062064048</id><published>2017-07-02T15:38:00.000+09:00</published><updated>2017-07-02T18:04:10.877+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>초짜 대학원생 입장에서 이해하는 [CVPR 2017] Learning by Association - A versatile semi-supervised training method for neural networks</title><content type='html'>&lt;span style=&quot;font-size: x-small;&quot;&gt;* &lt;a href=&quot;https://arxiv.org/pdf/1706.00909.pdf&quot;&gt;Learning by Association - A versatile semi-supervised training method for neural networks&lt;/a&gt;, Philip Haeusser et al. 2017을 바탕으로 한 리뷰&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이번 CVPR 2017에 Accept 되었다는 Learning by Association 논문을 리뷰해보겠습니다. 짧은데 재미있는 논문이에요.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;아이디어는 상당히 직관적이고 간단합니다. 구글에 &quot;Learning by Association&quot;이라고 검색하면 가장 먼저 뜨는 것은 사실 인지 심리학 쪽의 자료들입니다. 저자들도 사람이 &quot;Association&quot;을 사용하여 학습을 한다는 내용에서 착안했다고 하는군요.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이게 무슨 말이냐 하면, 사람은 기계와는 달리 자료 간의 &quot;연관성&quot;을 파악하여 학습할 수 있기 때문에 매우 많은 예제를 보지 않더라도 학습을 잘 할 수 있다는 것입니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-rg_FZZ_vnK4/WVhuVNoYNCI/AAAAAAAAB5Q/jXcUP3kAPbscVhOBNX2u0XdHb-fnQhcBgCK4BGAYYCw/s1600/lba_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-rg_FZZ_vnK4/WVhuVNoYNCI/AAAAAAAAB5Q/jXcUP3kAPbscVhOBNX2u0XdHb-fnQhcBgCK4BGAYYCw/s1600/lba_1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Learning by Association 예시 ([2],[3])&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;즉, 아이가 처음 &quot;개&quot;라는 것을 알게될 때 몇 가지 예시를 보고 나면, 후에 진돗개를 처음 보더라도 연관성을 바탕으로 유추를 하여 &quot;개&quot;라는 것을 자연스럽게 안다는 것이죠.&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그렇다면 이런 &quot;연관성&quot;을 기계학습에도 가져와서 사용할 수는 없을까?라는 것이 이 논문의 주된 아이디어입니다. 만약 이런 학습이 가능하다면 label을 얻는 것이 매우 비싸거나 (의료 영상 데이터) 아주 적은 양만 label이 있는 데이터에도 학습을 잘 할 수 있겠죠. 즉 이 논문의 주안점은 semi-supervised learning을 좀 더 잘 해보자는 것입니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Overview&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;자 그러면 이렇게 추상적인 개념인 &quot;연관성&quot;을 어떻게 기계학습에 적용을 했는지 살펴볼까요? 먼저 이 논문에서 설정한 가정 하나를 보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;b&gt;&quot;네트워크가 embedding feature vector를 제대로 만들어낸다면, 동일 클래스의 경우 feature space에서 vector간 서로 비슷하게 생겼을 것이다.&quot;&lt;/b&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br /&gt;좀 너무 당연한가요? 그래도 이 당연한 가정에서 문제를 푸는 전략이 나옵니다. Loss 함수를 잘 디자인해서 labeled와 unlabeled data가 embedding feature space에서 서로 비슷한 녀석들끼리 가깝고 다른 녀석들끼리는 거리가 멀도록 하는 네트워크를 만드는 것이 목표입니다.&lt;br /&gt;&lt;br /&gt;그러면 자연스럽게 embedding space에서 각각의 data 사이에 가깝다 멀다를 어떻게 정의해야할지에 대한 질문이 생깁니다. 이 논문에서는 이를 다음과 같이 정의했는데요.&lt;br /&gt;&lt;br /&gt;각각, $A$: Labeled data, $B$: Unlabeled data의 feature space vector를 나타낼 때, $A_i$와 $B_j$ 사이의 유사도 $M){ij}$는 다음과 같이 내적 (inner product)로 정의합니다:&lt;br /&gt;$$M_{ij}=A_i\cdot B_j$$ 여기까지만 보면 기존의 semi-supervised learning과 전혀 다를 것이 없지만, 앞으로 소개할 &quot;연관성&quot;이란 개념을 넣어 학습시키는 부분을 보시면 차이를 아실 수 있을 것 같습니다.&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-Zv_H40DrmtI/WVh9jjD2XkI/AAAAAAAAB50/CUj-usfB3yc0P4rNlzZ5Gy6nhtNKvFypACK4BGAYYCw/s1600/lba_3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Zv_H40DrmtI/WVh9jjD2XkI/AAAAAAAAB50/CUj-usfB3yc0P4rNlzZ5Gy6nhtNKvFypACK4BGAYYCw/s1600/lba_3.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;여기서부터가 중요합니다. 데이터가 들어왔을 때 embedding을 해주는 네트워크(초록색)가 있으면, 이로부터 feature space가 만들어지죠. 이런 embedding space에서 labeled data와 unlabeled 사이에 &quot;연관성&quot;을 정량화하기 위해 이 논문에서는 &quot;walking&quot;이라는 방법을 사용합니다.&lt;br /&gt;&lt;br /&gt;위에 그림에서 보실 수 있듯이 labeled data의 feature vector에서 unlabeled data의 feature vector로 갔다(visit)가 다시 labeled data의 feature vector로 돌아왔을 때(walk) labeled data의 class가 바뀌지 않도록 제약을 주는 방식으로 loss 함수를 디자인합니다. 이 얘기들을 좀 더 수식화하여 나타내면 다음과 같습니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;h3&gt;Transition Probability&lt;/h3&gt;$$\begin{align*}P^{ab}_{ij} = P(B_j|A_i) &amp;amp;:=(softmax_{cols}(M))_{ij} \\ &amp;amp;= exp(M_{ij})/\sum_{j&#39;}exp(M_{ij&#39;})\end{align*}$$&lt;br /&gt;&lt;h3&gt;Round Trop Probability&lt;/h3&gt;$$\begin{align*}P^{aba}_{ij} &amp;amp;:= (P^{ab}P^{ba})_{ij} \\ &amp;amp;= \sum_{k}P^{ab}_{ik}P^{ba} _{kj}\end{align*}$$&lt;br /&gt;&lt;h3&gt;Probability for correct walks&lt;/h3&gt;&lt;div style=&quot;text-align: center;&quot;&gt;$$P(correct~walk) = \frac{1}{|A|}\sum_{i\sim j}P^{aba}_{ij}$$ where $i\sim j\Longleftrightarrow class(A_i) = class(A_j)$.&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;만약 우리의 가정대로 네트워크가 잘 학습을 하고 있다면 embedding feature space를 만들 때, walking하고 돌아왔을 때 여전히 class가 유지되야한다는 제약 때문에 자연스럽게 목표를 달성할 수 있겠다는 것이 key idea입니다.&lt;br /&gt;&lt;br /&gt;이렇게 기본적으로 loss를 잘 디자인해서 연관성이라는 추상적인 개념을 실제 계산이 가능한 형태로 잘 녹여낸 것이 이 논문의 신선한 점이라 할 수 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$\cal{L}_{total} = &amp;nbsp;\cal{L}_{walker}+\cal{L}_{visit}+\cal{L}_{classification}$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;총 세 부분으로 loss 함수가 나누어져있는 것을 알 수 있는데요 사실 이를 $\cal{L}_{walker}+\cal{L}_{visit}$와 $\cal{L}_{classification}$ 이렇게 두 부분으로 묶어 보시면 좀 더 이해가 편합니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;앞의 $\cal{L}_{walker}+\cal{L}_{visit}$ 부분이 오늘 소개할 association을 표현하는 loss 함수에 해당하구요 뒤의&amp;nbsp;$\cal{L}_{classification}$ 부분이 일반적으로 지도학습에서 사용하는 classfication loss가 되겠습니다. Label이 있는 녀석들에 대해서는 이런 loss 함수가 적용이 됩니다. (제가 예전에 정리해둔 &lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;DANN&lt;/a&gt;을 보신 분들이라면 좀 더 이해가 쉬울 수 있습니다.)&lt;br /&gt;&lt;br /&gt;그래서 (아직까지는 어떻게 만들었는지는 모르지만) loss 함수를 잘 minimize하면 마법처럼 unlabeled data도 labeled data와 함께 잘 분류가 되게 하자는 것입니다. 그럼 하나하나 loss 함수를 이해해보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;h2&gt;Walker loss&lt;/h2&gt;&lt;br /&gt;먼저 $\cal{L}_{walker}$입니다. 여기서 walk라는 이름은 제가 짐작하기로는 graph theory 쪽 용어를 가져온 것 같습니다. Graph theory 쪽 공부를 하다보면 data 하나를 점으로 보았을 때, 한 점에서 다른 점으로 가는 것을 &quot;walk&quot;라는 용어로 표현합니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-LyW2_8eJAIM/WVh28xJ2T2I/AAAAAAAAB5o/uwE3dmOHYd0esfkxgQE77lDUk1KYJhQIgCK4BGAYYCw/s1600/lba_2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-LyW2_8eJAIM/WVh28xJ2T2I/AAAAAAAAB5o/uwE3dmOHYd0esfkxgQE77lDUk1KYJhQIgCK4BGAYYCw/s1600/lba_2.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;위 그림이 walker loss에서 하고자 하는 일을 잘 설명해주고 있습니다. Labeled data의 class인 &quot;개&quot;에서 unlabeled loss를 방문한 후 다시 Labeled data로 돌아갔을 때 class가 여전히 &quot;개&quot;로 유지되길 바라는 것입니다. 여기서 주의하실 점은 돌아온 labeled data가 꼭 시작점의 labeled data와 정확히 일치할 필요는 없지만, class는 유지되기를 바라는 것입니다.&lt;br /&gt;&lt;br /&gt;그래서 $\cal{L}_{walker}$에서는 만약 갔다가 돌아온 class가 달라지면 penalty를 주게 디자인 되어있습니다:$$\cal{L}_{walker}:=H(T,P^{aba})$$&lt;br /&gt;여기서&amp;nbsp;$H$는 cross entropy이고 $T_{ij}$는 $class(A_i)=class(A_j)$일 때, $1/\#class(A_i)$이고 아닐 때는 0인 uniform distribution입니다. $P^{aba}$가 닮기를 바라는 $T$가 uniform distribution인 이유는 동일한 class로만 돌아오면 언제나 값이 같도록 하고 싶기 때문이죠. (동일한 class의 다른 이미지로 돌아왔다고 penalty를 주고 싶지 않을 것입니다.)&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Visit loss&lt;/h2&gt;&lt;br /&gt;이제 visit loss입니다.&lt;br /&gt;$$\cal{L}_{visit}:=H(V,P^{visit})$$&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;where, $ P_j^{visit} :=&amp;lt;P_{ij}^{ab}&amp;gt;_i, V:=1/|B|$&lt;/div&gt;&lt;br /&gt;이 녀석이 하고자 하는 것도 그리 어렵지 않습니다 최대한 많은 sample을 다 골고루 봤으면 좋겠다는 것이죠. 대부분의 semi-supervised 방식에서는 자기가 고른 labeled data를 기준으로 가까이에 있는 unlabeled data만 보는데 그러지 말고 모두 다 보자는 것입니다. (그래서 $V$가 uniform distriction이지요. 그림을 통해보면 다음과 같습니다:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-bxyMldhd7pI/WViOF8MMrnI/AAAAAAAAB6M/Ix__Gom7-Ew0v-iiDDE1MCr4vQ1AyOTKQCK4BGAYYCw/s1600/lba_4.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-bxyMldhd7pI/WViOF8MMrnI/AAAAAAAAB6M/Ix__Gom7-Ew0v-iiDDE1MCr4vQ1AyOTKQCK4BGAYYCw/s1600/lba_4.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;즉, 그림의 중간 동그라미 안에 들어가 있는 녀석들처럼 애매한 부분도 효과적으로 활용하고 싶다는 것이죠. 단, 여기서 unlabeled data가 너무 다른 경우 이 visit loss가 악영향을 끼치기 때문에 적절히 weight를 주는 것이 필요하다고 하네요.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;h2&gt;실험 결과&amp;nbsp;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;&lt;/h3&gt;&lt;h3&gt;MNIST&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;실험 결과도 상당히 놀랍습니다. 먼저 MNIST 결과에 대해서 학습 전후로 association이 어떻게 바뀌어 가는지 시각화해서 보여주면 다음과 같습니다:&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-fE0ElFd9EKI/WViPCbIj9WI/AAAAAAAAB6U/jYtXp33PeaE978MLlY5Vi-cDbpnTTO2YACK4BGAYYCw/s1600/lba_5.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-fE0ElFd9EKI/WViPCbIj9WI/AAAAAAAAB6U/jYtXp33PeaE978MLlY5Vi-cDbpnTTO2YACK4BGAYYCw/s1600/lba_5.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Evolution of Associations&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Top 부분이 학습을 시작해서 아주 약간 iteration을 돌렸을 때고 Bottom이 네트워크가 수렴한 후를 의미합니다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-PSMjVN9uhS0/WViPFAwjBmI/AAAAAAAAB6c/PBwepXBvODs_qYVuQyblvtnnn94Rryf6QCK4BGAYYCw/s1600/lba_6.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PSMjVN9uhS0/WViPFAwjBmI/AAAAAAAAB6c/PBwepXBvODs_qYVuQyblvtnnn94Rryf6QCK4BGAYYCw/s1600/lba_6.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;이 실험 이후 MNIST에서 분류가 얼마나 잘 되었는지 확인을 해보면, test error가 0.96%로 매우 낮게 나왔는데요. 심지어 이렇게 틀린 경우도 설명이 가능하다고 얘기합니다. 우측에서 보이는 것이 confusion matrix인데요 여기서 틀린 부분을 좌하단에서 가져와 보여주면 사람이 봐도 왜 틀렸는지 이해가 갈만한 비슷비슷한 숫자들을 헷갈린 것이라고 애기하고 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;STL-10&lt;/h3&gt;&lt;br /&gt;저는 개인적으로 이 실험 결과가 매우 흥미롭습니다. STL-10은 RGB 이미지로 10개의 class가 있는 데이터셋인데요 약 5000개의 labeled 학습 이미지와 10만개의 unlabeled 학습 이미지가 있습니다. 재미있는 점은 이 unlabeled 이미지에 labeled 학습 이미지에 존재하지 않는 class의 이미지들도 있다는 것이죠.&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-Bw1BjiOXSiI/WViPHbiftZI/AAAAAAAAB6k/j1FJZeYjwIQd6O10ZfzfGq4BPtWkxbbWQCK4BGAYYCw/s1600/lba_7.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Bw1BjiOXSiI/WViPHbiftZI/AAAAAAAAB6k/j1FJZeYjwIQd6O10ZfzfGq4BPtWkxbbWQCK4BGAYYCw/s1600/lba_7.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;그래서 결과를 보시면 매우 신기합니다. 위 두 줄이 labeled 이미지에 class가 있는 녀석의 nearest neighbor를 5개 뽑아본 것으로 상당히 잘 되는 것을 보실 수 있죠. 아래 두 줄이 제가 흥미롭게 생각한 부분입니다. Labeled 이미지 데이터셋에 존재하지 않는 class인 돌고래와 미어켓을 보여주니 네트워크가 내놓은 5개의 nearest neighbor인데요. 나름 비슷합니다. 돌고래의 삼각 지느러미 부분이 돛이나 비행기의 날개와 비슷하다 생각했는지 그런 이미지들이 같이 있고 미어켓은 신기하게도 동물들을 뽑아 온 것을 보실 수 있죠.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;h3&gt;SVHN&lt;/h3&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;이어서 SVHN에 대해 적용한 결과도 보여줍니다.&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-QpZtMXTB1Ig/WViTGv_jFyI/AAAAAAAAB60/evqV5B5de-Iyb0vpmvQQj2kCJ7AsfdLGQCK4BGAYYCw/s1600/lba_8.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-QpZtMXTB1Ig/WViTGv_jFyI/AAAAAAAAB60/evqV5B5de-Iyb0vpmvQQj2kCJ7AsfdLGQCK4BGAYYCw/s1600/lba_8.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;이 테이블이 보여주는 점은 자신들의 method가 unlabeled 데이터셋이 점점 많이 주어질 수록 에러율이 매우 내려간다는 것입니다. 즉, unlabeled 데이터로부터 실제로 연관 정보를 잘 뽑아내고 있다는 것이죠.&lt;br /&gt;&lt;br /&gt;더욱 놀라운 점은 SVHN 데이터로 MNIST 데이터에 대한 Domain Adaptation 효과를 보여준 것입니다. 아래 테이블을 보시면 각각 SVHN에서만 학습시켰을 때, SVHN에서 학습시킨 후 MNIST로 Domain Adaptation 시켜줬을 때, MNIST에서만 학습시켰을 때, 세 가지 경우에서 MNIST 데이터셋에 대한 classification error를 알 수 있습니다.&amp;nbsp;&lt;/div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-4WVnZ9B9bDs/WViPJGVwfVI/AAAAAAAAB6s/b7wYZjNhyvwhLNeBIQjlvhUMpU4dN_D0gCK4BGAYYCw/s1600/lba_9.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-4WVnZ9B9bDs/WViPJGVwfVI/AAAAAAAAB6s/b7wYZjNhyvwhLNeBIQjlvhUMpU4dN_D0gCK4BGAYYCw/s1600/lba_9.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;이를 자신들의 method와 Domain Adaptation에서 최근 유명했던 &lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;DANN&lt;/a&gt;, Domain Separation Nets 두 가지와 성능을 비교했는데 상당히 잘 되는 것을 볼 수 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;지금까지 쭉 빠르게 논문을 살펴보았는데요 이 논문의 contibution을 정리해보자면 다음과 같습니다:&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;단순하지만 신선한 semi-supervised training method를 제안하였다.&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Tensorflow implentation이 있고 arbitray network architecture에 add-on처럼 범용적으로 붙여 사용할 수 있다.&amp;nbsp;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;SOTA methods에 비해 최대 64% 가까이의 성능 향상을 보였다.&amp;nbsp;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Label이 매우 적을 때, SOTA methods를 매우 큰 차이로 이기는 결과를 확인하였다 (MNIST, SVHN)&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;게다가 심지어 ResNet 같은 복잡한 구조를 사용한 것도 아닌데 이런 결과가 나왔다는 것을 보면, 아직 성능이 더 개선이 될 여지가 충분하다는 것도 짚고 넘어가야할 것 같네요&lt;br /&gt;&lt;br /&gt;이 논문을 읽고 아이디어가 새록새록 생기는데...일단 이 아이디어들은 나중에 졸업부터 하고 해야겠죠...지금 제 코가 석자라 ㅎㅎ 그래도 정말 재미있게 읽은 논문이었습니다.&lt;/div&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;Auto-Encoding Variational Bayes (VAE)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;Generative Adversarial Nets&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;Deep Convolutional Generative Adversarial Network (DCGAN)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;Unrolled Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;InfoGAN&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;&lt;i&gt;f&lt;/i&gt;-GAN&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;LSGAN&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;BEGAN: Boundary Equilibrium Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;Domain-Adversarial Training of Neural Networks (DANN)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;The Marginal Value of Adaptive Gradient Methods in Machine Learning&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;참고문헌:&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;[1] &lt;a href=&quot;https://arxiv.org/pdf/1706.00909.pdf&quot;&gt;Learning by Association - A versatile semi-supervised training method for neural networks&lt;/a&gt;&lt;span id=&quot;goog_394610992&quot;&gt;&lt;/span&gt;&lt;a href=&quot;https://www.blogger.com/&quot;&gt;&lt;/a&gt;&lt;span id=&quot;goog_394610993&quot;&gt;&lt;/span&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;, Philip Haeusser et al. 2017&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[2]&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/DeepLearningJP2016/dllearning-by-association-a-versatile-semisupervised-training-method-for-neural-networkscvpr2017&quot;&gt;[DL輪読会]Learning by Association - A versatile semi-supervised training method for neural networks[CVPR2017]&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[3] &lt;a href=&quot;https://www.slideshare.net/ssuser06e0c5/learning-by-association&quot;&gt;[Slideshare] Learning by Association - 김홍배&lt;/a&gt; - 김홍배 박사님 번역&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6422670261062064048/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/07/learning-by-association-versatile-semi-supervised-training.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6422670261062064048'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6422670261062064048'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/07/learning-by-association-versatile-semi-supervised-training.html' title='초짜 대학원생 입장에서 이해하는 [CVPR 2017] Learning by Association - A versatile semi-supervised training method for neural networks'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-rg_FZZ_vnK4/WVhuVNoYNCI/AAAAAAAAB5Q/jXcUP3kAPbscVhOBNX2u0XdHb-fnQhcBgCK4BGAYYCw/s72-c/lba_1.png" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6327880665008945683</id><published>2017-07-01T01:49:00.000+09:00</published><updated>2017-07-01T10:57:53.188+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>초짜 대학원생의 입장에서 이해하는 f-GAN (3)</title><content type='html'>&lt;span style=&quot;font-size: x-small;&quot;&gt;* &lt;a href=&quot;https://arxiv.org/pdf/1606.00709.pdf&quot;&gt;f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization&lt;/a&gt;, Sebastian Nowozin et al. 2016을 바탕으로 한 리뷰&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;자 오늘은 &lt;i&gt;f&lt;/i&gt;-GAN의 main theorem을 증명하고 저자가 NIPS 2016 workshop에서 발표할 때 전해줬던 insight 하나를 소개하는 것으로 &lt;i&gt;f&lt;/i&gt;-GAN에 대한 설명을 마무리하겠습니다. 먼저 설명의 편의를 위해 오늘 증명할 Theorem 1과 그 조건을 다시 가져와보겠습니다.&lt;br /&gt;&lt;br /&gt;지난 글에서 f-GAN 저자들이 Single-Step 알고리즘을 제안하였던 것을 기억하실겁니다:&lt;br /&gt;&lt;img src=&quot;https://3.bp.blogspot.com/-0nm5F3MuzH4/WUqhS3lT2iI/AAAAAAAAB1c/MCELAjG9qxYeFDdZIhGmK2xwmtQgKwF9QCK4BGAYYCw/s1600/fgan_12.png&quot; /&gt;&lt;br /&gt;&lt;br /&gt;우리가 풀고자 하는 GAN objective 함수 $F$에 대하여, 우리가 찾고 싶은 saddle point의 근방(neighborhood)에서 $F$가 strongly convex in $\theta$ 그리고 strongly concave in $w$일 때, 이 알고리즘이 실제로 그 saddle point $(\theta^t,w^t)$에 수렴한다는 것을 확인해보겠습니다. 이 조건들을 수식으로 나타내면 다음과 같습니다:&lt;br /&gt;\begin{equation}\nabla_\theta F(\theta*,w*)=0, \nabla_w F(\theta*,w*)=0, \nabla^2_\theta F(\theta,w) \succeq \delta I, \nabla^2_w F(\theta,w)\preceq&amp;nbsp;-\delta I.\label{cond}\end{equation}&lt;br /&gt;이 가정들은 &quot;strong&quot;하다는 부분만 빼면 &lt;i&gt;f&lt;/i&gt;-GAN 형태로 도출된 saddle point를 정의하기 위해서 필수적인 조건들입니다. 따라서 deep networks의 구조로 인해 생기는 수많은 saddle point들이 있습니다만 대부분이 이 조건을 만족하지 않습니다.&lt;br /&gt;&lt;br /&gt;저는 이 부분을 GAN이 원하는 saddle point가 독특하고 GAN objective를 알고리즘을 적용하여 풀어서 나오는 solution들은 이러한 조건을 만족하는 point로 수렴한다는 것을 말하고자한 것으로 해석했습니다.&lt;br /&gt;&lt;br /&gt;이제 이 조건이 성립한다는 가정하에 다음 정리가 성립하게 됩니다.&lt;br /&gt;&lt;div class=&quot;theorem&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;Suppose that there is a saddle point $\pi^*=(\theta^t,w^t)$ with a neighborhood that satisfies conditions \ref{cond}. Moreover, we define $J(\pi)=\frac{1}{2}||\nabla F(\pi)||^2_2$ and assume that in the above neighborhood, $F$ is sufficiently smooth so that there is a constant $L&amp;gt;0$ such that $||\nabla J(\pi&#39;)-\nabla J(\pi)||_2 \leq L||\pi&#39;-\pi||_2$ for any $\pi,\pi&#39;$ in the neighborhood of $\pi^*$. Then using the step-size $\eta=\delta/L$ in Algorithm 1, we have&lt;br /&gt;$$J(\pi^t)\leq \left(1-\frac{\delta^2}{2L}\right)^t J(\pi^0).$$&lt;br /&gt;That is, the squared norm of the gradient $\nabla F(\pi)$ decreases geometrically.&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;(우와 어려워보인다...) 아닙니다! 생각보다 쉬워요!&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;본격적인 증명에 앞서 이 복잡해보이는 정리가 의미하는 바를 좀 정리해보겠습니다. 이 정리는 알고리즘의 &quot;local&quot; convergence를 증명해주고 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$J(\pi) \overset{\Delta}{=}\frac{1}{2}||\nabla F(\pi)||^2_2$로 정의한 것을 곰곰히 생각해보면 됩니다. 결국 이 정리에서 결론으로 내리는 부등호가 하고자 하는 말은 우리가 구하고자 하는 GAN objective $F$의 gradient인 $\nabla F(\pi)$의 크기가 점차점차 줄어든다는 것입니다. 즉, 수렴한다는 것이죠.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;https://4.bp.blogspot.com/-RxEJ1UyeYj4/WUqSmYSiroI/AAAAAAAAB1A/4K8qNE4fFvY3hcH9HO_wN1DPSWQr-qRjgCK4BGAYYCw/s400/bob.jpg&quot; /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;어때요 참 쉽죠?&quot;&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;다만, 우리가 saddle point의 &lt;b&gt;근방&lt;/b&gt;에 있다면 언제나 saddle point로 수렴한다는 것을 증명한 것이지 global convergence를 증명해주진 못했습니다.&amp;nbsp;그러면 자연스럽게 떠오르는 의문이 있죠? &quot;어떻게 그 근방에 갈껀데?&quot; 네...그건 뭐 저자들도 &quot;일단 practically 잘 되니까 쓰자&quot;고 하네요 -_-ㅎㅎ (이전 글에서 두 가지 예를 보여드렸었죠?)&lt;/div&gt;&lt;div class=&quot;proof&quot;&gt;&lt;br /&gt;먼저 몇 가지 notation을 정하고 가겠습니다. 편의상 $\pi=(\theta^t,w^t)$라 정의하고 각각의 편미분을 다음과 같이 나타내겠습니다:&lt;br /&gt;$$\nabla F(\pi) = \begin{pmatrix} \nabla_\theta F(\theta,w) \\ \nabla_w F(\theta,w) \end{pmatrix}, \tilde{\nabla} F(\pi) = \begin{pmatrix} -\nabla_\theta F(\theta,w) \\ \nabla_w F(\theta,w) \end{pmatrix}.$$&lt;br /&gt;그러면 Algorithm 1은 다음과 같이 쓸 수 있게 됩니다:&lt;br /&gt;\begin{equation}\pi^{t+1} = \pi^t + \eta \tilde{\nabla} F(\pi^t)\label{eq2}\end{equation}&lt;br /&gt;&lt;br /&gt;이제 본격적으로 증명을 시작해보겠습니다. 기본적으로 증명에 쓰이는 가장 어려운 수준의 수학은 Taylor series 전개입니다. Taylor series를 이용하면,&lt;br /&gt;\begin{equation}J(\pi&#39;)\approx J(\pi)+&amp;lt;\nabla J(\pi),\pi&#39;-\pi&amp;gt;+\frac{1}{2}(\pi&#39;-\pi)^T H(J(\pi))(\pi&#39;-\pi). \label{eq3}\end{equation}&lt;br /&gt;여기서 $H$는 Hessian matrix를 뜻합니다. 주어진 조건을 바탕으로 다음과 같은 부등호를 얻을 수 있고:&lt;br /&gt;$$||\nabla J(\pi&#39;)-\nabla J(\pi)||_2 \leq L||\pi&#39;-\pi||_2 $$&lt;br /&gt;$$\lim_{\pi&#39;\rightarrow \pi}\frac{||\nabla J(\pi&#39;)-\nabla J(\pi)||_2}{||\pi&#39;-\pi||_2} \leq L $$&lt;br /&gt;\begin{equation}\therefore H(J(\pi)) \leq L \label{eq4}\end{equation}&lt;br /&gt;이렇게 얻은 부등호 eq.\ref{eq4}을 eq.\ref{eq3}에 적용하면,&lt;br /&gt;\begin{equation}J(\pi&#39;)\leq J(\pi)+&amp;lt;\nabla J(\pi),\pi&#39;-\pi&amp;gt;+\frac{L}{2}(\pi&#39;-\pi)^T (\pi&#39;-\pi). \label{eq5}\end{equation}&lt;br /&gt;여기서 $J(\pi) \overset{\Delta}{=}\frac{1}{2}||\nabla F(\pi)||^2_2$이므로, $\nabla J(\pi)=\nabla^2 F(\pi)\nabla F(\pi)$입니다.&lt;br /&gt;&lt;br /&gt;따라서, 다음과 같은 전개가 가능해집니다:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-qbu38TNdB1U/WVZr5U48YXI/AAAAAAAAB3Y/XT7WE6Dtz3sSqVki2vWnm4wiG3s01LrRACK4BGAYYCw/s1600/f-gan-pf1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-qbu38TNdB1U/WVZr5U48YXI/AAAAAAAAB3Y/XT7WE6Dtz3sSqVki2vWnm4wiG3s01LrRACK4BGAYYCw/s1600/f-gan-pf1.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;text-align: justify;&quot;&gt;자, 이걸 곰곰히 생각해보시면 Algorithm 1이 해주는 일이란 것이 결국 $||\nabla F(\pi)||_2^2$에 비례하는 양으로 $J$를&amp;nbsp;줄여주고 있는 것이란 것을 아실 수 있습니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;안 되요 안 되요! 정신줄 놓아버리시면 안 됩니다!! ㅋㅋ 뜬금없이 뭔소리냐 위에 부등식은 왜 갑자기 푸는가?가 궁금하시죠? Eq.\ref{eq2}와 eq.\ref{eq3}를 조금만 바꾸면 아래 과정을 왜 하는지 이해할 수 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;Algorithm 1이 eq. \ref{eq2}로 나타내진다고 했었죠? 이를 $\pi^{t+1} - \pi^t = \eta \tilde{\nabla} F(\pi^t)$로 조금만 바꾸고 eq.\ref{eq3}에 대입하면 이 짓을 왜 하는지 이해하실 수 있습니다:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$J(\pi^{t+1})\leq J(\pi^t)+&amp;lt;\nabla J(\pi^t),\eta\tilde{\nabla} F(\pi^t)&amp;gt;+\frac{L\eta^2}{2}\tilde{\nabla} F(\pi^t)^T \tilde{\nabla} F(\pi^t).&amp;nbsp;$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;자, 이렇게 하고 나니 아래의 수식 전개에서 두번째 부등호가 위에서 구한 부등호 때문이란 것을 알 수 있게 되는 것입니다:&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-Xb2Ia7jowTE/WVZyx771KeI/AAAAAAAAB3w/-J3x9Hg_Ii8zLUgq5x6cXJHPTZ-B_n2hACK4BGAYYCw/s1600/f-gan-pf.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;128&quot; src=&quot;https://1.bp.blogspot.com/-Xb2Ia7jowTE/WVZyx771KeI/AAAAAAAAB3w/-J3x9Hg_Ii8zLUgq5x6cXJHPTZ-B_n2hACK4BGAYYCw/s400/f-gan-pf.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;여기서 마지막 equality는 $\eta = \delta/L$일 때 성립합니다. 그래서 step size $\eta$를 이렇게 정하면 위 부등식에 의해 local convergence가 보장되는 것이죠.&lt;br /&gt;&lt;br /&gt;드디어 증명이 끝났군요 (에고 힘들다).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Discussion&lt;/h2&gt;&lt;br /&gt;그래요 이제 증명도 되었고 (local이긴 하지만), 여러가지 함수로 divergence를 바꿔가며 GAN을 해보면 그 때마다 새로운 녀석이 나올 것이고, 수학적으로는 어떤 divergence가 어떤 녀석보다 더 나은지 등등이 연구가 되어있기 때문에 이제 내 상황에서 가장 적절한 &lt;i&gt;f&lt;/i&gt;-divergence를 만들어서 쓰기만 하면 될 것 같습니다.&lt;br /&gt;&lt;br /&gt;그런데...대다수의 divergence가 잘 동작하긴 하는데....결과를 일단 먼저 보여드리자면:&lt;br /&gt;(* LSUN dataset의 classroom에 대해서 학습을 시킨 것이고 각각 Jensen-Shannon, Hellinger, Kullback-Leibler divergence를 사용한 결과입니다)&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-7DHU-DdmiyE/WVZ87nCjINI/AAAAAAAAB4c/akG6pEvWD8M_Y8UNvKHcU63_aFOEJtlAwCK4BGAYYCw/s1600/fgan_js.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-7DHU-DdmiyE/WVZ87nCjINI/AAAAAAAAB4c/akG6pEvWD8M_Y8UNvKHcU63_aFOEJtlAwCK4BGAYYCw/s1600/fgan_js.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;GAN (Jensen-Shannon)&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-g1Kk1wJs4MA/WVZ85rNWgHI/AAAAAAAAB4U/JJ_AKU6YZ0UxkdmVkF_7-oe_1LiE2eBOwCK4BGAYYCw/s1600/fgan_hell.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-g1Kk1wJs4MA/WVZ85rNWgHI/AAAAAAAAB4U/JJ_AKU6YZ0UxkdmVkF_7-oe_1LiE2eBOwCK4BGAYYCw/s1600/fgan_hell.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Hellinger&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-vjM0i_V-56k/WVZ9ABqSekI/AAAAAAAAB4k/AVKm_PybcGwy90fTrs90X_Y6gr6_57vpgCK4BGAYYCw/s1600/fgan_kl.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-vjM0i_V-56k/WVZ9ABqSekI/AAAAAAAAB4k/AVKm_PybcGwy90fTrs90X_Y6gr6_57vpgCK4BGAYYCw/s1600/fgan_kl.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Kullback-Leibler&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;생각보다 결과가 그놈이 그놈이더라...하는 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-kPeJx1GBBvM/WVZ3msAMYqI/AAAAAAAAB4E/xOdP4BBrz80NGAijL5gAFYVZOelXE7ZvACK4BGAYYCw/s1600/%25ED%2597%25891.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-kPeJx1GBBvM/WVZ3msAMYqI/AAAAAAAAB4E/xOdP4BBrz80NGAijL5gAFYVZOelXE7ZvACK4BGAYYCw/s1600/%25ED%2597%25891.jpg&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;왜?!! 어째서?!!!&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Insights from the Authors&lt;/h2&gt;&lt;br /&gt;자연스래 아래와 같은 질문이 나올 수 밖에 없죠.&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&lt;span style=&quot;font-size: large;&quot;&gt;&quot;Does the divergence REALLY matter?&quot;&lt;/span&gt;&lt;/b&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br /&gt;그래서 저자가 한 가지 추측을 내놓는데 다음과 같습니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-dxK8sxDB-yE/WVZ-lkNM2AI/AAAAAAAAB40/lyJJPIIS1fMGXpLqeWdgkIRc6DWkb_fIACK4BGAYYCw/s1600/fgan_16.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;79&quot; src=&quot;https://3.bp.blogspot.com/-dxK8sxDB-yE/WVZ-lkNM2AI/AAAAAAAAB40/lyJJPIIS1fMGXpLqeWdgkIRc6DWkb_fIACK4BGAYYCw/s200/fgan_16.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;각각의 색으로 나타낸 점이 서로 다른 divergence로 학습한 수렴점이라고 생각하시면 됩니다. 이와 같이 우리가 세운 모델의 공간과 실제 확률 분포 $P$가 이렇게 꽤나 가까이에 있을 때는 divergence 간에 수렴점이 차이가 있습니다. 그런데 이게 아니라 다음과 같이 멀리 떨어져 있다고 해봅시다:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-i5xons9s2v4/WVZ_bXKp6tI/AAAAAAAAB48/WnKp1vf9no4v3YF56VBs6iqMB1xeKqniACK4BGAYYCw/s1600/fgan_17.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-i5xons9s2v4/WVZ_bXKp6tI/AAAAAAAAB48/WnKp1vf9no4v3YF56VBs6iqMB1xeKqniACK4BGAYYCw/s1600/fgan_17.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;이러면 마치 태양에서 오는 빛은 직선이라고 생각할 수 있듯이 divergence 간에 차이가 매우 적어집니다. 즉, 저자들은 우리의 모델이 생각보다 실제 분포와 매우 멀리 떨어져 있는 것이 아닌가 하는 추측을 내놓는 것입니다.&lt;br /&gt;&lt;br /&gt;매우 직관적이고 그럴 듯하죠? 이에 대한 토론이 NIPS 2016 Workshop 영상에서 보이듯이 발표 이후로도 이어졌습니다. 실제도 이런 추측이 최근 GAN에 대한 연구 결과들과도 어느 정도 부합하는 것 같습니다.&lt;br /&gt;&lt;br /&gt;이로써 &lt;i&gt;f&lt;/i&gt;-GAN에 대한 설명을 모두 마쳤네요. 슬슬 그래도 제가 생각한 골격을 하나하나 따라 올라가고 있습니다. 다음은 EBGAN을 리뷰할 생각입니다. EBGAN까지 하면 어느 정도 제가 구상했던 커다란 틀이 80% 정도는 완성되는 것입니다. 참 오래 걸리네요. 역시 이론 위주의 논문은 글을 쓰기가 힘듭니다. 수식도 많고...-_-;; 아무쪼록 이 글이 읽는 분들께도 많은 도움이 되었길 기대합니다. 다음 글에서 뵙겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 Generative Adversarial Nets (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Deep Convolutional Generative Adversarial Network (DCGAN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled Generative Adversarial Networks (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN: Boundary Equilibrium Generative Adversarial Networks (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;참고문헌:&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;[1] &lt;a href=&quot;https://arxiv.org/pdf/1606.00709.pdf&quot;&gt;f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization&lt;/a&gt;&lt;span id=&quot;goog_394610992&quot;&gt;&lt;/span&gt;&lt;a href=&quot;https://www.blogger.com/&quot;&gt;&lt;/a&gt;&lt;span id=&quot;goog_394610993&quot;&gt;&lt;/span&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;, Sebastian Nowozin et al. 2016&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[2] &lt;a href=&quot;https://www.youtube.com/watch?v=kQ1eEXgGsCU&quot;&gt;[video] NIPS 2016 Workshop on Adversarial Training&lt;/a&gt; - Sebastian Nowozin - f-GAN&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[3] &lt;a href=&quot;https://tensorflowkorea.files.wordpress.com/2016/12/f-gan-workshop-nowozin.pptx&quot;&gt;[slide] NIPS 2016 Workshop on Adversarial Training&lt;/a&gt; - Sebastian Nowozin - f-GAN&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6327880665008945683/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/07/f-gan-3.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6327880665008945683'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6327880665008945683'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/07/f-gan-3.html' title='초짜 대학원생의 입장에서 이해하는 f-GAN (3)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-0nm5F3MuzH4/WUqhS3lT2iI/AAAAAAAAB1c/MCELAjG9qxYeFDdZIhGmK2xwmtQgKwF9QCK4BGAYYCw/s72-c/fgan_12.png" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6520823018345344049</id><published>2017-06-22T23:01:00.000+09:00</published><updated>2017-06-22T23:02:43.204+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="DANN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 13. Domain Adversarial Training of Neural Networks</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#13. Domain Adversarial Training of Neural Nets&lt;/h2&gt;&lt;br /&gt;여전히 매주 일요일마다 12명이 돌아가며 두 명씩 두 편의 논문을 40분 동안 발표하고 있습니다. 벌써 한 번 순서가 다 돌아서 다시 제 차례가 되어 이번에는 GAN과도 관련이 있지만 또 다른 커다란 분야인 Domain Adaptation 연구를 소개하였습니다. 아직도 이런 경험이 부족하고 전달하고픈 내용은 많고 하필 논문에는 수식이 많아 발표 시간이 부족하네요. 그래도 이번에는 끝까지 다 발표를 마쳤습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/n2J7giHrS-Y&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;슬라이드:&amp;nbsp;&lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-dann-jaejun-yoo&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-dann-jaejun-yoo&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;동영상이 너무 길다 싶으신 분은 아래 링크에서 DANN 포스팅을 읽으셔도 됩니다 :)&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 Generative Adversarial Nets (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Deep Convolutional Generative Adversarial Network (DCGAN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled Generative Adversarial Networks (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN: Boundary Equilibrium Generative Adversarial Networks (2)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6520823018345344049/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/06/pr12-video-13-domain-adversarial-neural-net.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6520823018345344049'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6520823018345344049'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/06/pr12-video-13-domain-adversarial-neural-net.html' title='[PR12-Video] 13. Domain Adversarial Training of Neural Networks'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/n2J7giHrS-Y/default.jpg" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-339975962706190506</id><published>2017-06-22T02:28:00.001+09:00</published><updated>2017-07-01T02:02:09.755+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><title type='text'>초짜 대학원생의 입장에서 이해하는 f-GAN (2)</title><content type='html'>&lt;span style=&quot;font-size: x-small;&quot;&gt;* &lt;a href=&quot;https://arxiv.org/pdf/1606.00709.pdf&quot;&gt;f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization&lt;/a&gt;, Sebastian Nowozin et al. 2016을 바탕으로 한 리뷰&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;지난 글에서&amp;nbsp;&lt;i&gt;f&lt;/i&gt;-divergence를 estimate하기 위해 시작한 전개로부터 일반적인 GAN objective까지 전개하는 것을 따라가 보았습니다. 이제는 이를 풀 알고리즘과 convergence를 증명하는 부분이 남았는데요. 본격적으로 들어가기 전에 지난 내용을 리뷰하고 GAN formulation과의 관계에 대해 약간 더 구체적으로 이해하기 위해 조금 더 설명을 해보도록 하겠습니다.&lt;br /&gt;&lt;br /&gt;먼저 설명의 편의를 위해 지난 글에서 전개했던 variational representation을 가져오면 다음과 같고:&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-zFyxrdM0pNw/WUqGW7NvO_I/AAAAAAAAB0Y/OoWiONncCI0dyWoqDOfi1hjArvOxtoqAwCK4BGAYYCw/s1600/fgan_7.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;107&quot; src=&quot;https://3.bp.blogspot.com/-zFyxrdM0pNw/WUqGW7NvO_I/AAAAAAAAB0Y/OoWiONncCI0dyWoqDOfi1hjArvOxtoqAwCK4BGAYYCw/s400/fgan_7.png&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;여기서 우리는 맨 마지막 식을 사용하여 true distribution $P$를 generative model $Q$로 estimate할 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;a name=&#39;more&#39;&gt;&lt;/a&gt;&lt;h2&gt;Variational Divergence Minimization (VDM)&lt;/h2&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;앞서 소개한 f-divergence $D_f(P||Q)$에 대한 lower bound를 살펴보면 식이 상당히 GAN objective와 닮았습니다. 여기서부터는 마치 GAN과 같이 $Q$와 $T$를 neural network를 사용하여 모델링 해보겠습니다.&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 때, $Q$는 random vector를 input으로 받아 우리가 원하는 sample을 내보내는 generative parametric model로 $Q_\theta$라 표현할 수 있고 $T$는 input으로 sample을 받아 scalar 값을 내보내는 variational function으로 $T_\omega$라 표현할 수 있습니다:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;$$F(\theta,\omega) = \mathbb{E}_{x\sim P}[T_\omega(x)]+\mathbb{E}_{x\sim Q_\theta}[-f^*(T_\omega(x))]$$&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이제 여기에 다양한 종류의&amp;nbsp;&lt;i&gt;f&lt;/i&gt;-divergence를 사용하여 껴넣으면 새로운 GAN objective가 만들어지는 것입니다. 단, 조건이 있죠. 앞서 &lt;i&gt;f&lt;/i&gt;-divergence에 사용된&amp;nbsp;&lt;i&gt;f&lt;/i&gt;에 대한 conjugate 함수 $f^*$를 사용하였기 때문에 variational function $T_\omega$의 domain이 $dom_{f^*}$이 되도록 해야합니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이 수식을 조금 더 GAN 형태와 비슷하게 만들기 위해 함수를 함수 $T_\omega(x)$를 output activation function $g_f: \mathbb{R}\rightarrow dom_{f^*}$와 discriminator MLP에 해당할 $V_\omega: \cal{X}\rightarrow\mathbb{R}$로&amp;nbsp;나누어 생각해보겠습니다: &amp;nbsp;$T_\omega(x) = g_f(V_\omega(x))$. 그러면 이제 아래와 같은 table에서 이에 맞게 activation function만 잘 조정해주면 원하는 divergence에 대해 새로운 GAN을 만들 수 있게 됩니다:&lt;/div&gt;&lt;br /&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-Y_a7oQO3nAY/WUqQlsuoukI/AAAAAAAAB0o/1__TYHv3lcAwn5ohzbTggesfjOAQWkKpgCK4BGAYYCw/s1600/fgan_9.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Y_a7oQO3nAY/WUqQlsuoukI/AAAAAAAAB0o/1__TYHv3lcAwn5ohzbTggesfjOAQWkKpgCK4BGAYYCw/s1600/fgan_9.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;이렇게 table의 수식으로만 보면 이해가 좀 잘 안 될 수 있으니 함수들이 실제로 어떻게 생겼는지를 보면서 설명을 해드리겠습니다:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-Z0qpXQ8Hbjs/WUqRHJSIuWI/AAAAAAAAB00/b9gBNcisjOgeFrUcuZN6cNMq9NQJgJAnACK4BGAYYCw/s1600/fgan_10.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Z0qpXQ8Hbjs/WUqRHJSIuWI/AAAAAAAAB00/b9gBNcisjOgeFrUcuZN6cNMq9NQJgJAnACK4BGAYYCw/s1600/fgan_10.png&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;GAN으로 따지면 $v$ 값이 discriminator MLP인 $V_\omega(x)$에서 나온 값이라 생각하시면 이해가 쉽습니다. 즉, $V_\omega(x)$는 $x$가 실제 distribution에서 나왔을 확률을 보낸다고 생각하시면 됩니다. 위 그림에서 왼쪽 그래프는 실제 distribution에서 sample이 나왔을 때는 $g_f(\cdot)$ 값이 양수이지만 잘못 분류한 경우($v$ 값이 음수)에 대해서는 penalty를 주는 것을 확인하실 수 있습니다. 오른쪽 그래프로부터는 반대인 경우를 보실 수 있지요.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-RxEJ1UyeYj4/WUqSmYSiroI/AAAAAAAAB1A/4K8qNE4fFvY3hcH9HO_wN1DPSWQr-qRjgCK4BGAYYCw/s1600/bob.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;250&quot; src=&quot;https://4.bp.blogspot.com/-RxEJ1UyeYj4/WUqSmYSiroI/AAAAAAAAB1A/4K8qNE4fFvY3hcH9HO_wN1DPSWQr-qRjgCK4BGAYYCw/s400/bob.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;&quot;어때요 참 쉽죠?&quot;&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Example: Univariate Mixture of Gaussian&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;물론 앞서 아름답게 논리를 전개해왔지만, 예측한 것과 같이 실제로도 하한 값이 잘 계산되는지 그리고 진짜 solution에 대한 obejective 값과 variational representation으로 얻은 값 사이의 차이가 얼마나 되는지 등을 확인해볼 필요가 있겠죠. 다양한&amp;nbsp;&lt;i&gt;f&lt;/i&gt;-divergence들에 대한 objective 함수를 GAN 알고리즘으로 문제를 풀었을 때, 간단한 예제에 대해 결과를 확인해보면 다음과 같습니다:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-il-xUz7gz-0/WUqVgpLETdI/AAAAAAAAB1M/ItMZhYFEWssUFL13zEmNdpecZUbuNqAqQCK4BGAYYCw/s1600/fgan_11.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-il-xUz7gz-0/WUqVgpLETdI/AAAAAAAAB1M/ItMZhYFEWssUFL13zEmNdpecZUbuNqAqQCK4BGAYYCw/s1600/fgan_11.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;왼쪽 테이블을 보시면, 하한(lower bound)인 $F(\hat{\omega},\hat{\theta})$ 값이 실제로 true parameter에 대한 objective 값인 $D_f(P||Q_{\theta^*})$보다 약간 작습니다. 이 차이가 알고리즘을 사용하여 찾은 parameter와 실제 parameter의 차이와도 잘 대응됩니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;그런데 사실 저는 이 부분보다는 오른쪽 테이블에 정리된 실험이 더 중요한 것 같습니다. 이 테이블은 학습(train)할 때는 특정 divergence로 학습을 시킨 후 generator인 $Q_\theta$를 고정시키고 새로운 divergence에 대해 $T_\omega$를 바꿔 discriminator를 재 학습(test)시킨 다음 true distribution에 대한 objective 값을 비교한 것입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이렇게 하면 기존에 학습시 사용된 divergence를 이용한 값이 가장 작게 나오는 것을 볼 수 있습니다. 어찌보면 당연하죠. 그런데 이 결과를 곰곰히 생각해보면 상당히 의미있는 결론을 얻을 수 있습니다. 즉, generative model이 덜 학습되어 true distribution을 충분히 잘 포함하고 있지 못하면 모델을 학습할 때 사용된 divergence가 무엇이었는지 그리고 estimation에 어떤 divergence를 사용하냐에 따라 objective function의 값이 매우 다를 수 있다는 것입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;간혹 GAN을 학습하면서 다른 measure를 사용해서 objective 값이 어떻게 나오나 보면, 예를 들어 KL-divergence는 아직 한참 내려가는 중인데 Wasserstein distance는 이미 0이 나오는 경우를 볼 수 있습니다. 즉, measure에 따라 값이 다를 수 있으니 그 measure가 0이라고 해서 실제로 model이 true distribution을 충분히 비슷하게 모사했다고 얘기할 수 없다는 것을 이 실험이 잘 보여주고 있는 것이 아닌가...하고 생각했습니다 (이 부분은 전적으로 제 사견입니다).&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;Algorithms for Variational Divergence Minimization&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;GAN objective 함수를 정의했으니 이를 풀 알고리즘도 봐야겠죠. Vanilla GAN의 경우 이를 alternative methods로 문제를 풉니다. &lt;i&gt;f&lt;/i&gt;-GAN의 관점으로 보면 이 방식은 double loop로 이루어진 알고리즘으로 inner loop는 lower bound와 &lt;i&gt;f&lt;/i&gt;-divergence 사이의 차이(gap)를 최대한 줄이는 것으로 이해할 수 있고 outer loop는 generator function을 좀 더 낫게 만드는 과정이라고 생각할 수 있습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그런데 vanilla GAN을 실제로 학습시킬 때는 inner loop 부분은 한 번만 update하는 경우가 많습니다 (당시 기준입니다). 이유는 여러가지가 있을 수 있지만 가장 큰 것으로는 computational cost입니다. 여기에 대해&amp;nbsp;&lt;i&gt;f&lt;/i&gt;-GAN 저자들은 vanilla GAN paper에서 이론적으로 local convergence를 증명한 alternative approach와는 다르게 practical implementation에서 실제로 사용되고 있는 알고리즘은 뭔가 misleading이 있는 것이 아니냐는 의혹을 제기합니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;i&gt;f&lt;/i&gt;-GAN 관점에서 바라보면 굳이 double loop 알고리즘이 아니더라도 괜찮기 때문에 아래와 같은 single-step gradient method를 제안하는데요:&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-0nm5F3MuzH4/WUqhS3lT2iI/AAAAAAAAB1c/MCELAjG9qxYeFDdZIhGmK2xwmtQgKwF9QCK4BGAYYCw/s1600/fgan_12.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-0nm5F3MuzH4/WUqhS3lT2iI/AAAAAAAAB1c/MCELAjG9qxYeFDdZIhGmK2xwmtQgKwF9QCK4BGAYYCw/s1600/fgan_12.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;이렇게 하면 back-propagation을 한 번만 하면 된다는 장점?이 있다고 얘기합니다. 다만 새로운 알고리즘을 사용했을때는 이 알고리즘이 우리가 원하는 saddle point로 수렴하는지를 확인해줘야겠죠? 이에 관한 내용이 아래 Theorem입니다:&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-XT3To4-tP6g/WUql5g6uEUI/AAAAAAAAB1o/zuAfF5mo9JU8Ygm9myQN2nRv43Rz5UZJgCK4BGAYYCw/s1600/fgan_13.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-XT3To4-tP6g/WUql5g6uEUI/AAAAAAAAB1o/zuAfF5mo9JU8Ygm9myQN2nRv43Rz5UZJgCK4BGAYYCw/s1600/fgan_13.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;그런데 잘 보시면 이 theorem은 몇 가지 가정하에서 그것도 local convergence만을 증명해주고 있습니다. 즉, 우리가 saddle point의 근방에 있다면 언제나 saddle point로 수렴한다는 것을 증명한 것이지 global convergence를 증명해주진 못했습니다. 이 부분에 대해서는&amp;nbsp;&lt;i&gt;f&lt;/i&gt;-GAN 저자도 NIPS 2016 workshop에서 다음과 같이 언급하였습니다:&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&amp;nbsp;&quot;우리가 제안한 알고리즘이 멍청한 것은 아니란 것은 증명하였지만 여전히 improve 할 여지가 많이 남아있다.&quot;&lt;/blockquote&gt;&lt;div&gt;다만 아래와 같이 간단한 예제에서는 별 문제 없이 saddle point를 잘 찾아간다며 뭐 practically 잘 되니까...하면서 넘어갑니다 ㅋㅋ&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 theorem에 대한 증명은 논문에 supplementary에 들어있는데 아무래도 다음 글에서 다뤄야할 것 같습니다. 생각보다 크게 어렵지 않으니 한 번 혼자 해보시는 것도 나름 재미있는 연습문제가 될 것 같네요.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;물론 저는 paper에 &quot;it is trivial to show...&quot;, &quot;it is left as an exercise for the readers...&quot;와 같은 말들을 매우! 싫어하기 때문에 (이 때문에 몇 번이나 좌절했던지...) 다음 글에서 꼭 풀어드리겠습니다ㅋㅋ 걱정마세요. 그럼 다음 글에 이어서 뵙겠습니다.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;1.&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-_iOuCMg75tg/WUqpvud2_RI/AAAAAAAAB2Q/qP97_7lOm5E64zTdsxyHhJu4gyGxmLIAgCK4BGAYYCw/s1600/fgan_14.gif&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-_iOuCMg75tg/WUqpvud2_RI/AAAAAAAAB2Q/qP97_7lOm5E64zTdsxyHhJu4gyGxmLIAgCK4BGAYYCw/s1600/fgan_14.gif&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;$V(x,y) =xy+\frac{\delta}{2}(x^2-y^2)$&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: left;&quot;&gt;&lt;b&gt;2.&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-6d-bMsuYYNQ/WUqp_RGZqTI/AAAAAAAAB2Y/SGuFWqbrSQgjmJshqZU9vYRs3XT6kKadQCK4BGAYYCw/s1600/fgan_15.gif&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-6d-bMsuYYNQ/WUqp_RGZqTI/AAAAAAAAB2Y/SGuFWqbrSQgjmJshqZU9vYRs3XT6kKadQCK4BGAYYCw/s1600/fgan_15.gif&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;$V(x,y) =xy^2+\frac{\delta}{2}(x^2-y^2)$&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/07/f-gan-3.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (3)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Auto-Encoding Variational Bayes (VAE) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 Generative Adversarial Nets (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Deep Convolutional Generative Adversarial Network (DCGAN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled Generative Adversarial Networks (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN: Boundary Equilibrium Generative Adversarial Networks (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;참고문헌:&lt;/b&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;[1] &lt;a href=&quot;https://arxiv.org/pdf/1606.00709.pdf&quot;&gt;f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization&lt;/a&gt;&lt;span id=&quot;goog_394610992&quot;&gt;&lt;/span&gt;&lt;a href=&quot;https://www.blogger.com/&quot;&gt;&lt;/a&gt;&lt;span id=&quot;goog_394610993&quot;&gt;&lt;/span&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;, Sebastian Nowozin et al. 2016&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[2] &lt;a href=&quot;https://www.youtube.com/watch?v=kQ1eEXgGsCU&quot;&gt;[video] NIPS 2016 Workshop on Adversarial Training&lt;/a&gt; - Sebastian Nowozin - f-GAN&lt;/span&gt;&lt;br /&gt;&lt;span start=&quot;&quot; text-align:=&quot;&quot;&gt;[3] &lt;a href=&quot;https://tensorflowkorea.files.wordpress.com/2016/12/f-gan-workshop-nowozin.pptx&quot;&gt;[slide] NIPS 2016 Workshop on Adversarial Training&lt;/a&gt; - Sebastian Nowozin - f-GAN&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/339975962706190506/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2017/06/f-gan-2.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/339975962706190506'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/339975962706190506'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2017/06/f-gan-2.html' title='초짜 대학원생의 입장에서 이해하는 f-GAN (2)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://3.bp.blogspot.com/-zFyxrdM0pNw/WUqGW7NvO_I/AAAAAAAAB0Y/OoWiONncCI0dyWoqDOfi1hjArvOxtoqAwCK4BGAYYCw/s72-c/fgan_7.png" height="72" width="72"/><thr:total>3</thr:total></entry></feed>