<?xml version='1.0' encoding='UTF-8'?><?xml-stylesheet href="http://www.blogger.com/styles/atom.css" type="text/css"?><feed xmlns='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd="http://schemas.google.com/g/2005" xmlns:thr='http://purl.org/syndication/thread/1.0'><id>tag:blogger.com,1999:blog-6029100972813152037</id><updated>2019-05-12T16:27:01.936+09:00</updated><category term="kr"/><category term="machine learning"/><category term="GAN"/><category term="PR12"/><category term="bloggertip"/><category term="mathematics"/><category term="DANN"/><category term="setup"/><category term="ICLR2018"/><category term="en"/><category term="skimpaper"/><category term="dsp"/><category term="topology"/><category term="개발"/><category term="cs231n"/><title type='text'>Jaejun Yoo&#39;s Playground</title><subtitle type='html'>READ A LOT, THINK IN PICTURES, CODE IT, VISUALIZE MORE!</subtitle><link rel='http://schemas.google.com/g/2005#feed' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/posts/default'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/'/><link rel='hub' href='http://pubsubhubbub.appspot.com/'/><link rel='next' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default?start-index=26&amp;max-results=25'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><generator version='7.00' uri='http://www.blogger.com'>Blogger</generator><openSearch:totalResults>65</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1797523556505861360</id><published>2019-05-11T20:30:00.000+09:00</published><updated>2019-05-12T15:20:47.941+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (0)</title><content type='html'>이 시리즈는 signal processing을 학부 때 배웠으나 여러 이유로 이해를 잘 하지 못하다가 뒤늦게서야 유용성을 깨닫고 개인적으로 공부하며 정리한 흔적이다.&lt;br /&gt;&lt;br /&gt;결국 machine learning을 하든 deep learning을 하든 모두 신호를 다루기 위한 도구일 따름이고, 내가 주로 다루는 신호가 이미지라는 형태를 띄고 있을뿐 근본적으로 디지털 신호 처리에서 다루는 내용에서 벗어나지 않는다는 생각이 들었다.&lt;br /&gt;&lt;br /&gt;이런 맥락에서 신호 처리에 대해 좀 더 잘 알고 싶다는 생각에 정리를 시작하였는데, 대부분의 글은 주로 EPFL의 Martin Vetterli 교수님이 저술하신 textbook을 기반으로 요약하였다.&lt;br /&gt;&lt;br /&gt;앞으로 쓸 글들은 (얼마나 걸릴지는 모르겠지만) 모두 신호처리의 기본에 대해 대학교 학부생을 위한 기초 수준으로 작성될 것이다. 스스로가 그 이상을 설명할만큼 잘 알고 있다고 생각하지도 않는만큼 차후 시간이 흘러 내가 다시 이 글을 보더라도 이해가 쉽게 하겠다는 목적을 갖고 글을 정리한다.&lt;br /&gt;&lt;br /&gt;약간의 선형대수학, 신호처리에 대한 기초 지식 그리고 더 나가서 해석학을 들어본 적이 있다면 보다 깊은 이해에 도움이 될 것이지만, 그런 선행 지식이 없이도 어렵지 않게 이해할 수 있는 수준으로 작성하고자 노력하였다.&lt;br /&gt;&lt;br /&gt;간단한 예시 그리고 덜 형식적인 설명을 바탕으로 신호처리라는 딱딱한 주제에 대해 쉽게 접근할 수 있도록 작성하였으며 이해하기 쉬운 설명을 위해 수학적 엄밀성 강조하지는 않겠지만 언제나 정확한 설명을 하는 것에 주안점을 두었다. 계획된 목차는 아래와 같다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;목차 (planned)&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing?&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;다만, 꼭 순서대로 글이 작성되리라는 보장은 없으며, 각 글의 제목 뒤에 붙은 숫자는 책에서 해당 내용이 다뤄진 chapter를 따랐다. 따라서 모든 chapter를 정리하지는 않을 예정이므로 숫자가 다 채워질 이유도 순서대로 나열될 이유도 없다. (e.g., 현재 이 글은 서문과 같은 역할이므로 chapter 0라 임의로 칭했고, 따라서 제목이 다음과 같다; Signal Processing For Communications (0))&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1797523556505861360/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1797523556505861360'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications.html' title='Signal Processing For Communications (0)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-9158657182315759528</id><published>2019-05-11T20:03:00.001+09:00</published><updated>2019-05-11T20:30:47.667+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="dsp"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><title type='text'>Signal Processing For Communications (1)</title><content type='html'>&lt;div&gt;&lt;h2&gt;What Is Digital Signal Processing?&lt;/h2&gt;&lt;/div&gt;&lt;br /&gt;신호(signal)와 신호 처리(signal processing) 대해서 정의를 내리자면 각각 다음과 같다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;div style=&quot;background-color: #eff0f1; height: 100%; padding: 15px; width: auto;&quot;&gt;&lt;b&gt;신호:&lt;/b&gt; 시간 혹은 공간에 대해 변화하는 현상에 대한 formal description&lt;br /&gt;&lt;b&gt;신호 처리:&lt;/b&gt; 신호에 들어있는 정보를 바꾸거나 분석하는 any operation.&lt;/div&gt;&lt;/blockquote&gt;예를 들어 주변 온도를 우리가 Celsius degree라는 물리적 변수를 기준으로 시간에 따른 온도의 변화를 기록하는 경우, 이렇게 만들어진 data set은 온도 &quot;신호&quot;가 될 것이다. 이 신호에 대한 가장 단순한 &quot;처리&quot;로는 월간 온도 평균과 같은 어떤 파라미터를 계산하는 것이 있겠다.&lt;br /&gt;&lt;br /&gt;또한 신호 처리는 어떤 물리적인 값 자체에 직접 가해지는 것이 아니라 물리적인 값의 &quot;abstract representation&quot;을 기반으로 수행된다는 점이 중요하다. 이런 abstract representation의 방식에 따라서 신호 처리의 기본 단위(unit)가 정해진다.&lt;br /&gt;&lt;br /&gt;한편 &quot;디지털 (digital)&quot;이라는 수식어구는 라틴어 digitus에서 유래한 것으로 손가락을 의미하는데, counting은 가장 기초적이고 오래된 abstraction이다. 즉, 디지털 신호 처리는 시간을 포함한 모든 것들에 정수(integer number)와 같이 countable한 abstraction representation을 사용한다는 것을 의미한다.&lt;br /&gt;&lt;br /&gt;좀 더 구체적 예시로는, 주변 온도를 측정한 각각의 관측(instants)이 셀 수 있는 집합(the days in a month)을 이루고 각 관측값(measure)들 역시도 온도계의 눈금 단위와 같이 유한한 수의 집합으로 표현되는 것을 생각해보면 된다.&lt;br /&gt;&lt;br /&gt;재미있는 점은 디지털 신호 처리에서는 신호가 &quot;어디서 유래한 것인가에 관계없이&quot;&amp;nbsp;이를 &quot;정수로 표현 가능한&quot;&amp;nbsp;abstract representation을 사용한다는 것이다. 지금은 이 사실이 별 달리 중요해보이지 않을 수 있으나, 이 특징이 디지털 신호처리가 지금과 같이 크게 발전할 수 있었던 큰 동력이라는 점은 앞으로 차차 분명해지리라 생각한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Analog vs. Digital worlds&lt;/h2&gt;&lt;br /&gt;세계에 대한 &quot;digital&quot; 혹은 정수를 이용한 표현 방식은 우리가 다루는 문제가 가축이나 날짜를 세는 것과 같이 간단할 때까지는 아무 문제가 없이 잘 동작했으나, 점차 세상이 복잡해지고 이를 설명하는 모델 역시도 복잡해질 필요가 생기면서 한계에 부닥쳤다.&lt;br /&gt;&lt;br /&gt;신호 처리 쪽 용어로 얘기하자면 정수로 표현되는 세계가 &quot;analog&quot;와 같이 연속적인 세계를 설명하는 잣대로 사용하기에는 너무 초보적이고 거칠어서 마치 시계공이 망치를 들고 있는 것과 같다는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 무한대와 무한소로 나눠질 수 있는 연속적인 analog 세계의 analytical 모델을 사용하면 이론적으로 분석하기는 편할지언정 실제로 이를 사용하기 위해서는 언제나 유한하고 이산적인 digital 세계로 내려와야한다는 점이다.&lt;br /&gt;&lt;br /&gt;예를 들어 온도를 측정하는 것만해도 우리가 얻을 수 있는 것은 언제나 일정 간격(time)을 두고 측정한 관측값들뿐 임의의 시간에 대해 해당하는 온도에 대한 관계를 보여주는 analytical 모델이 아니다.&lt;br /&gt;&lt;br /&gt;따라서 analog와 digital representation이 서로 만족할만한 합의에 이르기 위한 부단한 노력들이 이루어져 왔고, series expansion이나 numerical integration과 같은 알고리즘들이 analytic 결과를 practically computable한 형태로&amp;nbsp;만들기 위한 노력의 예시들이다.&lt;br /&gt;&lt;br /&gt;디지털 신호 처리가 멋진 것은 이렇게 양분된 두 세계가 서로 가장 만족스러운 형태로 합의에 이를 수 있도록 한다는 점이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Discrete Time&lt;/h2&gt;&lt;br /&gt;아날로그 기록 방식의 가장 큰 문제점은 신호를 추상화 하여 기록하는 것이 아닌 하나의 물리적인 현상을 또 다른 물리적 현상으로 옮기는 것에 불과하다는 점이다. 이 때문에 근본적으로 아날로그 신호는 기록(recording)의 형태에 따라 각각 다른 신호 처리 시스템이 필요하다. 예를 들어 우리가 온도 변화 함수 $f(t)$를 알고 있고,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s1600/fig1-5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;275&quot; src=&quot;https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s400/fig1-5.PNG&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Analytical and empirical averages&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;일정 간격 $[T_0, T_1]$ 사이에 일어난 온도 변화의 평균값을 알고싶다면 이에 대한 analytical solution은 다음과 같은 적분 방적식을 푸는 것이다: $$\bar{C} = \frac{1}{T_1-T_0}\int_{T_0}^{T_1} f(t) dt.$$ 그러나 analytic model이 없는 현실에서는 어떤 기기를 사용하여 온도를 측정, 기록하였을 것이고 그 데이터를 가지고 평균 온도를 계산할 것이다. 만약 온도가 thermograph를 이용하여 그래프의 형태로 기록되었다면 plainmeter라는 면적을 구하는 기계적 도구를 사용하여 면적을 알 수 있을 것이다. 그러나 온도 변화가 thermocouple과 같이 전압을 이용하여 기록을 하는 경우 학부 전자기초 시간에 배우는 RC 네트워크로 voltage integration 회로를 만들어 평균값을 계산해야 할 것이다. 이렇듯 아날로그 신호에서는 평균을 구하는 매우 단순한 예에서도 각 경우마다 특정한 디자인이 필요하기에 범용적으로 사용할 수 있는 방식을 고안하기 어렵다는 것을 알 수 있다.&lt;br /&gt;&lt;br /&gt;한편, 디지털 방식과 같이 하루에 한 번씩 측정한 온도에 대해 평균을 구하는 것은 매우 쉽다: $$\hat{C}=\frac{1}{D}\sum^D_{n=1}c_n.$$ 단순히 초보적인 덧셈과 나눗셈만 수행하면 원하는 값을 얻을 수 있다! 그렇다면,&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;$\bar{C}$와 $\hat{C}$의 차이가 (만약 있다면) 얼마나 되는가?&quot;&lt;/blockquote&gt;만약 저 자연계 어딘가에 $f(t)$라는 온도 함수가 있다는 것을 받아들인다면 하루 주기($T_s$)마다 측정한 $c_n$ 온도 측정값들은 이 함수의 $samples$라고 할 수 있다: $$c_n=f(nT_s).$$ 이런 맥락에서 보면 $\hat{C}$는 $\bar{C}$의 Riemann approximation이라고 할 수 있으며 앞선 질문은 이 approximation의 질 즉, continuous-time 함수에서 일부 샘플들만 취함으로써 우리가 얼마나 정보를 버렸는지에 대해 묻는 것과 같다.&lt;br /&gt;&lt;br /&gt;이에 대한 정답은 놀랍게도 해당 물리적 현상이 &quot;그렇게 빨리 변하지 않는다&quot;는 가정 하에,&amp;nbsp; 두 representation이 &quot;완벽히 일치한다&quot;는 것이다. 즉, continuous-time function과 우리가 얻은 측정 샘플들 간의 정보 손실이 전혀 없다.&lt;br /&gt;&lt;br /&gt;잠시 가정에 대한 걱정을 내려놓고 이 사실이 얘기해주는 것에만 집중해보면 매우 놀랍게도&lt;br /&gt;&lt;ol&gt;&lt;li&gt;아날로그와 디지털 세계가 완전히 공존하는 것이 가능하다는 뜻이며&amp;nbsp;&lt;/li&gt;&lt;li&gt;우리가 두 세계 사이를 오갈 수 있는 매우 강력한 도구를 갖고 있다는 것이다 (sampling theorem).&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;20세기 초에 발견된 이 놀라운 정리는 우리가 가진 샘플들을 바탕으로 임의의 continous-time function를 알아내는 것이 가능하다는 것을 말해준다:&lt;br /&gt;$$f(t)=\sum_{n=-\infty}^\infty c_n \frac{\sin(\pi(t-nT_s)/T_s)}{\pi(t-nT_s)/T_s}.$$ 따라서 이론적으로는 우리가 측정값들을 가지고만 있다면 이를 바탕으로 continous-time 형태로 표현하는 것이 가능하며, 이것은 이어서 우리가 갖고 있는 매우 강력한 수학적 도구인 미분을 사용하여 함수를 분석하는 것이 가능해진다는 것을 뜻한다. 더 좋은 점은 continous-time에서 이루어진 미분과 같은 분석이 항상 discrete-time에 대응하는 방식이 존재하여 굳이 우리가 얻은 측정값들을 가지고 continous domain으로 옮겨서 분석한 후 다시 discrete domain으로 내려오는 복잡한 방식을 취할 것 없이 discrete domain에서 바로 분석을 하면 된다는 것이다.&lt;br /&gt;&lt;br /&gt;Discrete과 continuous representations 사이의 equivalence는 우리가 샘플을 얻는 속도에 비해&amp;nbsp;다루는 신호가 얼마나 충분히 &quot;느린가&quot;에 달려 있다. 즉, 연속된 샘플을 측정하는 사이에 신호가 갑자기 이상하게 움직이지 않고 충분히 부드럽게 (smooth and well behaved) 움직인다면 문제가 없다는 뜻이다.&lt;br /&gt;&lt;br /&gt;그래서 sampling theorem이 해주는 역할은 (좀 더 쉽게 설명하자면) 신호가 갖는 최대 주파수와 우리가 얼마나 자주 혹은 빨리 샘플을 얻어야 하는지에 대한 정량적인 기준을 알려주는 것이다. 대다수의 학부 수준 디지털 신호 처리 과목의 반절 혹은 그 이상은 이 sampling theorem을 배우기 위한 준비와 theorem의 의미에 대해 공부하는 것이다. 특히 주파수 영역은 Fourier transform을 사용하여 알아낼 수 있기에 이를 신호 처리 과목에서 중요하게 다루며 배우는 것이라 할 수 있는데, 재미있는 점은 Fourier transform이라는 것 자체가 주기성을 띄는 함수들을 &lt;i&gt;&quot;셀 수 있는&quot;&lt;/i&gt; 값들로 표현하기 위한 도구로서 사용된다는 것이다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;Everything comes together.&quot;&lt;/blockquote&gt;&lt;h2&gt;Discrete Amplitude&lt;/h2&gt;&lt;br /&gt;시간 연속성에 대한 문제는 sampling theorem으로 어느 정도 해결이 되었지만, 여전히 남아있는 문제가 하나 있다. 현실 세계의 한계로 인해 실제 측정을 할 때 생기는 오차는 우리가 어찌 할 수 없는 문제다.&lt;br /&gt;&lt;br /&gt;만약 우리가 analytical model을 다룬다면 시간축뿐만 아니라 함수 값 역시도 연속적인 성격을 갖고 있다. 그러나 현실에서는 절대로 이와 같은 무한대의 정밀성을 얻을 수 없다는 것은 자명하다. (아무리 온도계의 눈금을 잘게 쪼개어 기록을 하더라도 한계가 있는 것처럼)&lt;br /&gt;&lt;br /&gt;따라서 실제로는 우리가 얻는 측정값들도 결국 유한한 숫자들의 집합이고 그렇다면 이들은 셀 수 있기에 정수로 mapping하는 것이 가능하다. 이러한 과정을 quantization이라고 부르고 이는 sampling과 함께 digital signal을 얻는데 필수적인 요소가 된다.&lt;br /&gt;&lt;br /&gt;Quantization은 정보 손실을 어쩔 수 없는 것으로 받아들인다는 점에서 연속체 문제를 시간에 비해 매우 거칠게 해결하는 것이라 할 수 있다. 여기에는 그럴 수 밖에 없는 이유가 있는데 그게 바로 신호 처리를 하다보면 언제나 만나게 되는 &quot;noise&quot;이다.&lt;br /&gt;&lt;br /&gt;우리가 어떠한 기계적 기록 장치를 쓴다고 해도 아날로그 기록을 하는 기기라면 언제나 noise가 함께하게 된다. Noise는 자연에서 오는 것이고 이를 완전히 제거하는 것은 불가능하기 때문에 신호 처리를 할 때 일정 수준의 정밀성으로 만족하는 정도로 합의를 하는 것이다.&lt;br /&gt;&lt;br /&gt;문제는 noise가 단순히 측정에서만의 문제가 아니라 처리를 할 때도 함께한다는 점이다.&lt;br /&gt;여기서 디지털 신호 처리의 또 다른 장점이 나오는데, 디지털 신호 처리는 언제나 셀 수 있는 정수의 수열을 다루기 때문에 디지털 영역에서는 processing으로 인한 noise가 생기지 않는다.&lt;br /&gt;&lt;br /&gt;매우 자명한 예로 신호를 복제하는 것을 생각해보면, 테이프를 복사하는 것은 원본 테이프를 복사본과 그 복사본을 이용한 다음 복사본으로 넘어갈 때마다 추가적인 nosie가 더해져서 점점 음질이 열화하는 것을 알 수 있지만 mp3의 경우 원본과 복사본이 근본적으로 차이가 없다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Terminology&lt;/h2&gt;&lt;br /&gt;마지막으로 용어에 대해 한가지 짚고 넘어가겠다. Amplitude에 대한 정확성은 사실 하드웨어에 달린 문제로 예를 들자면 CD와 DVD는 서로 precision 즉 샘플 당 담는 정보량에 차이가 있다. 이렇게 amplitude에 대한 정밀성은 하드웨어에 의존적이므로 사실상 신호 처리 이론에 대해 배우거나 개발할 때는 quantization을 고려하지 않고 마치 연속된 실수 값인 것 마냥 취급한다. 따라서 사실상 우리가 앞으로 배우는 것은 엄밀히 말하자면 모두 discrete-time signal processing이라 불러야 맞고 digital signal processing은 실제 기기의 영역에서 이뤄지는 일임을 알아야한다. 그러나 quantization을 고려하지 않는 것이 좀 더 이론적으로 다루기도 쉽고 일반적인 분석이 가능하기 때문에 이를 잘 구별하지 않고 digital signal processing이라 얘기한다는 점을 분명히 알아야한다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b&gt;To be continued ... (planned)&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html&quot; target=&quot;_blank&quot;&gt;What is Digital Signal Processing?&lt;/a&gt;&amp;nbsp;(done)&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Signals and Hilbert Spaces&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Fourier Analysis&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Interpolation and Sampling&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Interpolation&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Sampling theorem&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Aliasing&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Multirate Signal Processing&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Downsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Upsampling&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Oversampling&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/9158657182315759528/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/9158657182315759528'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/signal-processing-for-communications-1.html' title='Signal Processing For Communications (1)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://1.bp.blogspot.com/-8IjQkWnA0So/XNaRjwhBf5I/AAAAAAAADXA/L0-JcIEL-SkWVPaYnq9qIxFjzGqQjL2QQCK4BGAYYCw/s72-c/fig1-5.PNG" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-243971491237100208</id><published>2019-05-07T17:31:00.001+09:00</published><updated>2019-05-07T17:35:17.718+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><category scheme="http://www.blogger.com/atom/ns#" term="topology"/><title type='text'>공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)</title><content type='html'>&lt;h2&gt;공이 점점 비눗방울처럼 변할 때&lt;/h2&gt;&lt;br /&gt;이전에 소개했던&amp;nbsp;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;처럼&amp;nbsp;고차원으로 갈 때 우리의 직관이 얼마나 달라질 수 있는지를 알려주는 또 다른 좋은 예시를 소개해보자.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구의 부피&lt;/h3&gt;&lt;br /&gt;또다시 &lt;a href=&quot;https://en.wikipedia.org/wiki/Ball_(mathematics)&quot; target=&quot;_blank&quot;&gt;공(ball)&lt;/a&gt;이다! 수학적인 용어에서의 공은 간단히 말해 겉껍질이 자기보다 한차원 낮은 &lt;a href=&quot;https://en.wikipedia.org/wiki/N-sphere&quot;&gt;구(sphere)&lt;/a&gt;로 쌓여있는 닫힌 공간 전체, 즉, 안이 꽉 찬 공간을 뜻한다. 1차원 공(ball)은 선(line segment)이고 2차원 공은 원반(disk), 3차원 공은 음...공(ordinary ball)이다. 대응되는 구(sphere)를 생각해보면 0차원 구는 시작과 끝 점(point), 1차원 구는 원(circle), 2차원 구는 구(ordinary sphere)다.&lt;br /&gt;&lt;br /&gt;이런 공의 부피를 바탕으로 초등학교 시절 배운 내용 수준만으로 아주 쉽고 간단하게 고차원에서는 직관이 우리를 배반한다는 것을 보일 수 있다.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; target=&quot;_blank&quot;&gt;이전 글&lt;/a&gt;과 같이 먼저 쉽고 우리 직관이 잘 통하는 2차원에서부터 시작해보자:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s1600/high_dim_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s200/high_dim_1.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;우리 모두 초등학교 때, 원의 부피, 즉 2차원에서의 넓이를 구하는 것은 배웠을 것이다: $$V_2(r)=\pi r^2.$$ 한 차원 더 나가서,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s1600/high_dim_2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;170&quot; src=&quot;https://2.bp.blogspot.com/-54kOhWunGxQ/XNE781irJXI/AAAAAAAADUs/AZpUOb7nWXA3gAwrEL5pJuY91MDRMD4ZACK4BGAYYCw/s200/high_dim_2.png&quot; width=&quot;200&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;3차원 공의 부피는 $$V_3=\frac{4\pi}{3}r^3$$이라는 것도 열심히 외웠을 것이다.&lt;br /&gt;&lt;br /&gt;그리고 아마도 이걸 $d$차원에 대해 일반화하는 공식은 테이블 형태로 &quot;심화 학습&quot; 뭐 이런 형태로 가볍게 보여주고 지나갔을 것이다: $$V_d(r)=k_d r^d.$$ 여기서 $k_d$는 상수다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;구각 (Spherical shell)&lt;/h3&gt;&lt;br /&gt;이제부터 좀 재미있는 실험을 할텐데, 원점을 중심으로 반지름이 1인 구와 반지름이 $1-\epsilon$으로 그보다 아주 약간 ($\epsilon\ll 1$만큼) 공 두 개를 준비하고 이 두 공 부피의 차를 구해보자: $$V_d(1) - V_d(1-\epsilon).$$&lt;br /&gt;이걸 겉 껍데기를 구하는 것이라 해서 구각(spherical shell)이라 하는데 두 공의 반지름의 차이가 $\epsilon$만큼 나기 때문에 우리가 생각하는 겉껍질(구각)이 차지하는 부피는 매우 작다.&lt;br /&gt;&lt;br /&gt;만약 정확히 그 비율이 얼마나 되는지 알고 싶다면 반지름이 1인 구와 위에서 구한 구각의 비율을 구하면 될텐데 이 비율은 간단히: $$\frac{V_d(1) - V_d(1-\epsilon)}{V_d(1)}=1-(1-\epsilon)^d$$가 될 것이다.&lt;br /&gt;&lt;br /&gt;이제 준비물은 모두 모았으니 사고 실험을 해보면 재미있는 일이 벌어지는 것을 알 수 있다.&amp;nbsp; 점점 고차원으로 갈수록 ($d\rightarrow \infty$) 두번째 항의 값이 0에 가까워지고 공과 구각의 비율이 1로 수렴한다! 즉, &lt;i&gt;&quot;공이 점점 비눗방울처럼 바뀌는 것&quot;&amp;nbsp;&lt;/i&gt;이다.&lt;br /&gt;&lt;br /&gt;모든 부피가 껍데기에만 몰려있고 안이 텅텅 비어있는 매우 요상한 &quot;속이 꽉찬&quot; 공이 될 것이다. 이 역시도&amp;nbsp;고차원으로 넘어갈 때, 우리의 직관이 얼마나 틀릴 수 있는지 보여주는 좋은 예시로 이 글을 읽는 다른 분들에게도 brain candy가 되었길 기대한다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;딴 이야기 (for those who are interested in GANs)&lt;/h3&gt;&lt;br /&gt;재미있는 GAN blog 글로 유명한&amp;nbsp;inFERENCe가 &quot;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;&quot;라는 제목으로 글을 써서 화제가 된 적이 한 번 있는데, 생각보다 복잡하게 설명을 해서 이해하기 어려울 수 있지만 사실 지금 한 얘기를 다른 방식으로 열심히 적은 것이다.&lt;br /&gt;&lt;br /&gt;GAN 모델을 학습시킨 다음 High dimensional Gaussian latent space에서 walking을 하기 위해 두 latent vector간의 interpolation을 할 때, 왜 linear interpolation을 하면 문제가 될 수 있는지 이 글을 읽으신 분들이 이해가 쉽게 될 것이라 생각한다.&lt;br /&gt;&lt;br /&gt;어떤 의미에서는 중간이 텅 비어있는데 겉껍질을 타고(polar) 움직여야지(interpolate) 중간을 쑥 뚫고(linear) 움직이면 본적이 없는 latent vector가 model로 들어갈 수 있기 때문이다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2017/12/what-happens-in-high-dim-box-with-a-ball-inside.html&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;박스 안에 넣은 공의 지름이 박스보다 클 때&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/&quot; style=&quot;text-align: start;&quot; target=&quot;_blank&quot;&gt;Gaussian Distributions are Soap Bubbles&lt;/a&gt;,&amp;nbsp;&lt;span style=&quot;text-align: start;&quot;&gt;inFERENCe&lt;/span&gt;&amp;nbsp;2017. 11. 09.&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/243971491237100208/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/243971491237100208'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2019/05/when-ball-becomes-soap-bubble.html' title='공이 점점 비눗방울처럼 변할 때 (When ball becomes a soap bubble)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-feNcnBlYdqw/XNE6bemnk1I/AAAAAAAADUg/Qorots5Hn5krQkcV4dR4EIZURNqUWddGACK4BGAYYCw/s72-c/high_dim_1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-6213532524610182574</id><published>2018-09-02T22:18:00.002+09:00</published><updated>2018-09-02T22:18:57.919+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;표면적인 수준에서의 개선&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;표면적 수준이란 좋은 이름을 짓고, 좋은 설명을 달고, 코드를 보기 좋게 정렬하는 따위를 의미한다.&quot;&lt;/blockquote&gt;&lt;br /&gt;책의 첫 단락은 표면적인 수준에서의 개선부터 시작합니다. 이런 수정은 코드를 통째로 바꾸거나 동작하는 방식을 변화시키지 않고 &#39;그 자리에서&#39; 곧바로 만들 수 있기에 첫 시작으로 매우 적절하다 생각합니다.&lt;br /&gt;&lt;br /&gt;물론 가독성에 관련된 논의는 이 수준보다 더 나아가 많은 내용을 담고 있겠으나 이는 차차 살펴갈 것이며 먼저 1부에서는 폭넓게 적용할 수 있고, 그다지 많은 노력을 요구하지 않는 내용을 우선적으로 다룹니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이름에 정보 담기&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;변수, 함수, 혹은 클래스 등의 이름을 결정할 때는 항상 같은 원리가 적용합니다.&amp;nbsp;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;이름을 일종의 설명문으로 간주해야 한다.&quot;&lt;/blockquote&gt;충분한 공간은 아니지만, 좋은 이름을 선택하면 생각보다 많은 정보를 전달할 수 있다는 것이죠. 구체적으로는 아래의 여섯 가지 방법을 제안합니다.&lt;br /&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;특정한 단어 고르기&lt;/li&gt;&lt;li&gt;보편적인 이름 피하기 (혹은 언제 그런 이름을 사용해야 하는지 깨닫기)&lt;/li&gt;&lt;li&gt;추상적인 이름 대식 구체적인 이름 사용하기&lt;/li&gt;&lt;li&gt;접두사 혹은 접미사로 이름에 추가적인 정보 덧붙이기&lt;/li&gt;&lt;li&gt;이름이 얼마나 길어져도 좋은지 결정하기&lt;/li&gt;&lt;li&gt;추가적인 정보를 담을 수 있게 이름 구성하기&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;앞으로는 책에 나온 내용을 모두 다 소개하기 보다는 개중 제가 재미있었던 내용들을 좀 골라서 예시와 함께 알아보겠습니다.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;특정한 단어 고르기&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;매우 구체적인 단어를 선택하여 &quot;무의미한&quot; 단어를 피하자.&amp;nbsp;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;예를 들어 &quot;get&quot;은 지나치게 보편적입니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;def GetPage(url):&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;여기서 &quot;get&quot;보다는 메소드가 어디에서 페이지를 가져오는 지 알려줄 수 있게 FetchPage() 혹은 DownloadPage()와 같이 구체적으로 명명하는 것이 더 좋습니다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;사실 위 예시보다 다음 예시가 더 좋았는데요. 다음과 같이 BinaryTree 클래스에서&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;class BinaryTree {&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; int Size();&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; ...&lt;/div&gt;&lt;div&gt;} &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;우리는 Size() 메소드가 반환하는 것이 무엇일 지 이름만 봐서는 알 수 없습니다. 트리의 높이, 노드의 개수, 혹은 트리의 메모리 사용량이 될 수도 있겠죠.&amp;nbsp; 따라서 Height(), NumNodes(), 혹은 MemoryBytes() 등이 더 의미 있는 이름이라는 것에는 모두 동의하리라 생각합니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;같은 맥락에서 저자들은 thesaurus를 뒤져보고 더 나은 이름을 생각하기를 권합니다. 다만 너무 &quot;재치&quot; 있는 이름보다는 명확하고 간결한 이름이 더 좋습니다. 다음에 이어지는 내용들도 사실 같은 내용인데 예제들과 소소한 팁 위주로 살펴보곘습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;tmp나 retval 같은 표편적인 이름 피하기&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&quot;변수값을 설명하는 이름을 사용하라&quot;&lt;/blockquote&gt;&lt;br /&gt;예를 들어, 다음과 같이 Euclidean norm을 계산하는 자바스크립트 코드에서&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;var euclidean_norm = function (v) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; var &lt;b&gt;retval&lt;/b&gt; = 0.0;&lt;br /&gt;&amp;nbsp; &amp;nbsp; for (var = i = 0; i&amp;lt;v.length; i+=1)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;b&gt;retval&lt;/b&gt; += v[i];&lt;br /&gt;&amp;nbsp; &amp;nbsp; return Math.sqrt(&lt;b&gt;retval&lt;/b&gt;);&lt;br /&gt;};&lt;/div&gt;&lt;div&gt;&lt;br /&gt;retval보다는 sum_squares라고 이름을 붙여준다면 변수의 목적을 바로 이해할 수 있으며 나중에 버그를 잡을 때도 용의합니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;retval&lt;/b&gt;&amp;nbsp;+= v[i]; 부분이&amp;nbsp;&lt;b&gt;sum_squares&lt;/b&gt; += v[i]; 였다면 훨씬 눈에 잘 띄었겠죠.&lt;br /&gt;&lt;br /&gt;물론 아래와 같이 정말로 대상이 짧게 임시적으로만 존재하고, 임시적 존재 자체가 변수의 가장 중요한 용도일 때는 tmp와 같은 변수를 사용할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;두 변수를 서로 교환하는 알고리즘 예:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (right&amp;lt;left) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;b&gt;tmp&lt;/b&gt; = right;&lt;br /&gt;&amp;nbsp; &amp;nbsp; right = left;&lt;br /&gt;&amp;nbsp; &amp;nbsp; left = &lt;b&gt;tmp&lt;/b&gt;;&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;같은 맥락으로 i, j, iter, it 같은 이름이 인덱스나 루프 반복자로 사용되는 것은 충분히 괜찮습니다. 다만 이 역시도 디버깅의 용이성을 위해서 아래와 같이 소속을 표현해준다면 더 좋겠죠.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;(i, j, k) -&amp;gt; (club_i, members_j, users_i) or (ci, mj, ui)&lt;br /&gt;&lt;br /&gt;활용 예:&lt;br /&gt;if (clubs[ci].members[ui] == users[mi]) # 버그! 처음 문자가 일치 하지 않는다.&lt;/div&gt;&lt;br /&gt;따라서 표편적인 이름이 항상 나쁜 것은 아니지만, 이를 사용하려면 &lt;b&gt;꼭 그렇게 해야하는 이유가 있어야 합니다.&amp;nbsp;&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;br /&gt;&lt;h3&gt;추가적인 정보를 이름에 추가하기&lt;span style=&quot;font-weight: normal;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;단위(sec, millisecond, kg 등)를 포함하거나 다른 중요한 속성(unsafe, utf_8 등)이 있을 때는 변수에 그런 내용을 추가해주면 좋습니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;start -&amp;gt; start_ms, elapsed -&amp;gt; elapsed_ms&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;html -&amp;gt; html_utf-8 # html의 바이트가 UTF-8으로 변환되었다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;h3&gt;이름은 얼마나 길어야 하는가?&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;만일 변수가 좁은 scope (예: 끽해야 몇 줄 안의 함수 scope)에서 사용된다면 멤버 변수가 &quot;m&quot;과 같이 매우 짧은 이름을 사용해도 별 문제가 없으나 이 변수의 scope이 클래스나 전역으로 넓어지면 가독성이 매우 떨어지게 되므로 상황에 따라 잘 사용하라고 하는군요.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;게다가 요즘은 긴 이름을 입력하는 것이 자동완성 기능으로 매우 편해져서 그리 주저할 일이 아닙니다. 그렇기 때문에 약어와 축약형은 매우 보편적인 경우(string-&amp;gt; str과 같이)를 제외하고는 지양하는 편이 좋겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이에 좀 더 더한다면 ConvertToString()에서 ToString()과 같이 불필요한 단어를 제거해서 간결하게 만드는 등의 팁이 있으나 앞의 내용들이 더 핵심에 가까운 것으로 보입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이로써 이름에 정보를 넣는 방법에 대해 요약해보았습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;책에서 다음 장은 의미를 오해하기 쉬운 이름들에 대한 팁입니다만 사실 오늘 소개한 내용에 어느 정도 포함되는 것 같습니다. 다음 글에서는 미학(Aesthetics) 즉 &quot;눈을 편하게&quot; 하는 코드에 대해 정리하겠습니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/6213532524610182574/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/6213532524610182574'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-2.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  2. 이름에 정보 담기'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-643283542644223785</id><published>2018-09-02T12:32:00.000+09:00</published><updated>2018-09-02T12:34:46.558+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="PR12"/><title type='text'>[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax</title><content type='html'>&lt;br /&gt;TensorFlowKR facebook comunity에서 모인 12명의 paper readers (&lt;b&gt;PR12&lt;/b&gt;)가 읽어주는 &lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;Deep &lt;/a&gt;&lt;a href=&quot;https://github.com/terryum/awesome-deep-learning-papers&quot;&gt;learning paper awesome list 100선&amp;nbsp;by Terry Um&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;#71. Categorical Reparameterization with Gumbel Softmax&lt;/h2&gt;&lt;br /&gt;이 리뷰에서는 NIPS 2016 workshop에 같이 발표되었고 최근 ICLR 2017에 발표된 두 편의 논문을 리뷰하겠습니다. 재미있는 점은 이 두 편의 논문들이 똑같은 아이디어를 바탕으로 정확히 같은 수식을 사용하여 arXiv에도 고작 하루 차이로 올라왔다는 것입니다. 아이디어가 공중에 떠다닌다는 말이 정말 맞는가 싶습니다. 즐겁게 들어주시면 감사하겠습니다.&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ty3SciyoIyk&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;(추신) 24분 부분에 질문 주신 부분에 대해 답이 미진한것 같아 끝나고 곰곰히 생각해본 답글을 여기에 추가합니다.&amp;nbsp; 둘 다 categorical dist를 만드는데 다른 방법을 사용할 뿐이라는것이 맞는 답인것 같습니다. 우리가 nn으로부터 샘플링을 하고 싶으면 logit을 받아서 softmax를 통과시켜서 확률값을 얻어서 이를 바탕으로 분포에 값을 넣어주고 그 분포로부터 샘플을 뽑는 방법이 있겠구요 (이 방법이 준범님이 말씀하신 보통의 방식인 것 같습니다. 결국 마지막 단에서 softmax하여 확률 값을 주니까요) 다만 샘플링을 하지 않고 확률값 자체를 라벨과 빼서 에러를 계산하는데 사용되는 것이라 백프롭에서는 문제가 없는것 같습니다. 자기자신으로 1이니까 그렇다고 생각하는데 혹 이상하면 말씀주세요. 그리고 두번째 방법이 logit에 검벨에서 뽑은 노이즈를 더하여 argmax를 통과시켜서 값을 얻으면 그 자체가 discrete categorical dist에서 나온 샘플입니다. 여기서 argmax를 softmax로 relaxation한 것이 gumbel softmax trick이구요 그래서 이렇게 복잡하게 과정을 거친 이유는 말씀드린 바와 같이 미분이 가능하게 해서 중간에 node가 껴있을때 gradient를 계산하기 위해서인 것으로 이해하면 되지 않을까 싶습니다.﻿&lt;br /&gt;&lt;br /&gt;&lt;b&gt;(paper1)&lt;/b&gt; Categorical Reparameterization with Gumbel Softmax and&lt;br /&gt;&lt;b&gt;(paper2)&lt;/b&gt; The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables&lt;br /&gt;&lt;br /&gt;Paper1: &lt;a href=&quot;https://arxiv.org/abs/1611.01144&quot;&gt;https://arxiv.org/abs/1611.01144&lt;/a&gt;&lt;br /&gt;Paper2: &lt;a href=&quot;https://arxiv.org/abs/1611.00712&quot;&gt;https://arxiv.org/abs/1611.00712&lt;/a&gt;&lt;br /&gt;슬라이드: &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&quot;&gt;https://www.slideshare.net/thinkingfactory/pr12-categorical-reparameterization-with-gumbel-softmax&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;다음에 또 다른 주제로 뵈어요~!&lt;br /&gt;&lt;br /&gt;다른 분들의 발표도 보고 싶다면:&amp;nbsp;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&quot;&gt;PR12 딥러닝 논문읽기 모임&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/643283542644223785/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html#comment-form' title='1개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/643283542644223785'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/pr12-video-71-gumbel-softmax.html' title='[PR12-Video] 71. Categorical Reparameterization with Gumbel Softmax'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/ty3SciyoIyk/default.jpg" height="72" width="72"/><thr:total>1</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-868743091536295491</id><published>2018-09-01T18:40:00.001+09:00</published><updated>2018-09-02T14:56:38.765+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="개발"/><title type='text'>[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. </title><content type='html'>많은 분들이 그러실텐데 저 역시도 항상 좋은 코드란 어떤 것인지 알고 싶었습니다. 이런 고민을 듣고 최근 회사 동료인 전상혁님이 &quot;The Art of Readable Code&quot;라는 책을 추천해주시기에 책을 도서관에서 빌려 읽고 있는데 정말 많이 배우고 있습니다. 책의 내용이 좋아서 한 권 사서 두고두고 읽으려 합니다.&lt;br /&gt;&lt;br /&gt;이런 내용들을 코드에 직접 적용하면서 체득하는 것이 가장 좋겠지만 당장 단기간에 이뤄질 수 있는 일은 아니기에, 일단은 좋은 내용들이 머리에 좀 더 오래 남기를 바라며 책 내용을 정리해서 올리고자 합니다.&lt;br /&gt;&lt;br /&gt;나중에 이 글을 찾은 분 혹은 미래의 나 스스로에게 초심자의 입장에서 어떤 점들이 도움이 되었는지를 보여줄 수 있을거라 기대합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;이 책은 무엇에 대한 것인가?&lt;/h2&gt;&lt;br /&gt;이 책은 매우 읽기 편한 코드를 작성하는 방법을 설명하는데요. C++, 파이썬, 자바스크립트, 자바 등을 포함한 다양한 언어로 작성된 코드를 예로 들며 설명해줍니다. 중간중간 껴있는 삽화들도 매우 재치있고 각 장의 주제와 연관되어 있어 이해를 도와줍니다.&lt;br /&gt;&lt;br /&gt;재밌는 점은 언어들을 다 알지 못하더라도 책을 읽는 데는 별 어려움이 없다는 것입니다.&lt;br /&gt;저자들이 얘기하기론 &quot;코드의 가독성&quot;이라는 개념 자체가 언어로부터 독립적이기 때문이라고 하지만 제가 보기엔 여기서 저자들의 내공이 드러나는 것이 아닌가 싶습니다.&lt;br /&gt;&lt;br /&gt;크게 아래와 같이 4부로 나누어&lt;br /&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;표면적인 수준에서의 개선&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;루프와 로직를 단순화하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;코드를 재작성하기&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;선택된 주제들&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;div&gt;여러 측면에서 코드를 이해하기 쉽게 만드는 방법을 설명해줍니다.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;가독성의 기본 정리&lt;/h2&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;b&gt;&quot;코드는 다른 사람이 그것을 이해하는 데 들이는 시간을 최소화하는 방식으로 작성되어야 한다.&quot;&lt;/b&gt;&lt;/blockquote&gt;&lt;br /&gt;분량이 적다고 항상 좋은 것이 아닙니다. 좋은 예로 주석도 사실은 &quot;코드를 더하는 행위&quot;지만 코드를 더 빨리 이해하게 도와줍니다. 적은 분량으로 코드를 작성하는 것이 좋은 목표긴 하지만, 이해를 위한 시간을 최소화하는 것이 더 좋은 목표입니다.&lt;br /&gt;&lt;br /&gt;또 다른 예로,&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;return exponent &amp;gt;=0 ? mantissa * (1 &amp;lt;&amp;lt;exponent) : mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;/div&gt;&lt;br /&gt;라는 코드보다는&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;if (exponent &amp;gt;=0) {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa * (1 &amp;lt;&amp;lt; exponent);&lt;br /&gt;} else {&lt;br /&gt;&amp;nbsp; &amp;nbsp; return mantissa / (1 &amp;lt;&amp;lt; -exponent);&lt;br /&gt;}&lt;/div&gt;&lt;br /&gt;이렇게 바꾼 코드가 앞서보다 간결하진 않지만 더 이해하기 쉽습니다.&lt;br /&gt;&lt;br /&gt;이해를 위한 시간은 코드의 효율성, 아키텍처, 테스트의 용이성과 같은 다른 목표와 충돌할까봐 걱정할 수도 있으나, 저자들의 경험에 따르면 대다수의 경우 이러한 조건은 거의 아무런 방해가 되지 않다고 합니다.&lt;br /&gt;&lt;br /&gt;가장 기본적인 대원칙은 코드를 &quot;읽기 쉽게&quot; 만드는 원리가 적용될 때마다 의심의 여지가 생기면 언제나 가독성의 기본 정리가 다른 어떤 규칙보다 앞선다는 점입니다.&lt;br /&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;&quot;이 코드는 이해하기 쉬운가?&quot;&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;br /&gt;만일 정리가 되지 않을 코드를 고치고 싶을 때는 먼저 뒤로 한 걸음 물러나서 스스로에게 물어보는 것이 중요합니다: &quot;이 코드는 이해하기 쉬운가?&quot;. 만약 그렇다면 다른 코드로 건너뛰어도 별 상관이 없습니다.</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/868743091536295491/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/868743091536295491'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/09/the-art-of-readable-code-intro.html' title='[The Art of Readable Code, 읽기 좋은 코드가 좋은 코드다]  Intro. 코드는 이해하기가 쉬워야 한다. '/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-649523289300133464</id><published>2018-08-04T18:02:00.000+09:00</published><updated>2018-09-02T15:04:31.122+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>What is the relationship between orthogonal, correlation and independence?</title><content type='html'>제게는 마주칠 때마다 헷갈려서 다시 고민하게 되는 개념들이 있는데, 그 중 대표적인 것이 바로 이 세 가지 녀석들입니다:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;h3&gt;&lt;b&gt;Orthogonality, Correlation, Independence.&lt;/b&gt;&lt;/h3&gt;&lt;/blockquote&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;오늘도 다시 한 번 마주칠 일이 있어서 또 하루종일 공부하는 우매한 짓을 저지른 후, 다시는 이러지 않도록(....이러고선 또 언젠가 다시 이 포스트를 보고 공부하겠지...뻔해...) 정리를 해보고자 합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Independence&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Independence&quot;&lt;/b&gt;는 통계적인 개념입니다. 두 random variables X와 Y의 joint distribution이 marginal distribution의 곱으로 표현이 될 때 statistically independent하다고 말한다. 각 variable의 density를 $f$라고 하면:&lt;/div&gt;&lt;div&gt;$$f(x,y) = f(x)f(y),$$&lt;/div&gt;&lt;div&gt;좀 더 일반적으로는 cumulative distribution function을 $F$라고 할 때,&amp;nbsp;&lt;/div&gt;&lt;div&gt;$$F(x,y) = F(x)F(y)$$&lt;/div&gt;&lt;div&gt;라고 표현할 수 있겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Correlation&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&quot;Correlation&quot;&lt;/b&gt;은 independence와 관련이 있으나 좀 더 약한 통계적 개념으로 두 random variables 간 (Pearson) correlation은 정규화된(standardized) variables의 곱의 기대값을 말합니다:&lt;/div&gt;&lt;div&gt;$$\begin{align*}\rho_{XY} &amp;amp;= \mathbf{E}\left[\frac{X-\mathbf{E}[X]}{\sqrt{\mathbf{E}[(X-\mathbf{E}[X])^2]}}\frac{Y-\mathbf{E}[Y]}{\sqrt{\mathbf{E}[(Y-\mathbf{E}[Y])^2]}}\right]\\&lt;br /&gt;&amp;amp;= \frac{cov(X,Y)}{\sigma_X\sigma_Y}.\end{align*}$$&lt;br /&gt;이 때, $\rho_{XY}=0$는 variables X와 Y가 서로&lt;i&gt; uncorrelated&lt;/i&gt; 되어있다는 말입니다. 한 가지 유의할 점은 두 random variables가 independent하면 항상 uncorrelated이지만 그 역은 성립하지 않는다는 점입니다. (순방향은 정의에 맞게 식을 전개해보면 되고, 역은 counter example을 들어 쉽게 증명할 수 있습니다.)&lt;br /&gt;&lt;br /&gt;순방향에 대한 식 전개:&lt;br /&gt;&lt;div class=&quot;proof&quot;&gt;$$\begin{align*}\mathbf{E}[XY]&amp;amp;=\int\int xyP_{X,Y}(x,y)dxdy \\&lt;br /&gt;&amp;amp; = \int\int xyP_X(x)P_Y(y)dxdy\\&lt;br /&gt;&amp;amp;=\mathbf{E}[X]\mathbf{E}[Y] \end{align*}$$&lt;br /&gt;역방향에 대한 counter examples:&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;여기서 한 가지 헷갈리는 부분이 나오는데요. 지금까지 얘기한 independence는 statistical independence인데 이게 linear independence랑 서로 관련이 있으면서도 다르다는 것입니다. Linear dependent한 경우 statistically dependent 입니다. 이는 $\alpha X = Y$를 만족하는 non-zero scalar $\alpha$가 있을 때,&lt;br /&gt;$$cov(X,Y)=cov(\frac{1}{\alpha}Y,Y) = \frac{1}{\alpha}Var(Y) \neq 0 $$&lt;br /&gt;인 것으로 확인할 수 있습니다. 그러나&amp;nbsp; X와 Y가 linear independent할지라도 $\rho_{XY}\neq 0$일 수 있기 떄문에 linear independence가 statistical independence를 보장해주지는 않죠.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Orthogonality&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;&quot;Orthogonality&quot;&lt;/b&gt;는 기하에서 온 개념으로 선형 대수학에서 일반적인 정의를 배울 수 있습니다.&amp;nbsp; 선형대수학에서 정의하는 것을 보면, 두 벡터 $u$ 와 $v$가 서로 orthogonal하다는 것은 두 벡터 간의 내적 $&amp;lt;u,v&amp;gt;$이 정의된 내적 공간(inner product spaces)에서 다음 조건을 만족한다는 것입니다:&lt;br /&gt;$$&amp;lt;u,v&amp;gt;=0.$$&lt;br /&gt;즉, 어떤 벡터 간의 orthogonality는 정의한 내적에 따라 달라지기 때문에 주의해야 합니다.&lt;br /&gt;&lt;br /&gt;내적은 여러 방식으로 정의될 수 있는데, 한 예로 벡터들이 다음과 같이 수열로 나타내질 때는 우리가 흔히 아는 dot product를 골라서 사용할 수 있겠습니다:&lt;br /&gt;$$u=(u_1,u_2,\cdots,u_n), &amp;lt;u,v&amp;gt;=\sum_{i=1}^{n}u_i v_j.$$&lt;br /&gt;앞서 설명을 유심히 봤으면 알겠지만 orthogonality는 본질적으로 통계적인 개념이 아닙니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;background-color: #eff0f1; height: auto; padding: 15px; width: auto;&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;blockquote class=&quot;tr_bq&quot; style=&quot;text-align: center;&quot;&gt;&lt;b&gt;Orthogonality&lt;/b&gt;는 본질적으로 &lt;b&gt;통계적인 개념이 아니다!&lt;/b&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br /&gt;그래서 우리가 헷갈리는 이유가 보통 선형대수학에서의 개념을 통계로 가져오면서 생기는 것에서 기인하는 경우가 많습니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;A)&lt;/h3&gt;&lt;br /&gt;형식상 random variables의 공간은 vector space로 생각할 수 있습니다. 그러면 당연히 그 공간에서 내적을 다양한 방식으로 정의할 수도 있을텐데, 그 중 &lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot; target=&quot;_blank&quot;&gt;한 가지 방식&lt;/a&gt;이 바로 covariance를 내적으로 사용하는 것입니다:&lt;br /&gt;$$&amp;lt;X,Y&amp;gt; = cov(X,Y) = \mathbf{E}(X-\mathbf{E}[X])\mathbf{E}(Y-\mathbf{E}[Y]).$$&lt;br /&gt;두 random variables간 correlation이 0이면 covariance도 0이기 때문에, &lt;i&gt;이 정의에 의해서&lt;/i&gt;&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Uncorrelated_random_variables&quot; target=&quot;_blank&quot;&gt;($\mathbf{E}[X]$나 $\mathbf{E}[Y]$ 중 하나가 0인 경우) uncorrelatedness가 orthogonality와 정확히 같아집니다.&lt;/a&gt; 따라서 두 random variables가&amp;nbsp;&lt;b&gt;independent하면&amp;nbsp;&lt;/b&gt;&lt;b&gt;(그리고 둘 중 하나는 zero-centered일 때)&amp;nbsp;&lt;/b&gt;&lt;b&gt;서로 uncorrelated이며&lt;/b&gt; &lt;b&gt;orthogonal 하다&lt;/b&gt;고 얘기할 수 있습니다.&amp;nbsp;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot; target=&quot;_blank&quot;&gt;다른 방식&lt;/a&gt;으로는 $\mathbf{E}[XY]$으로도 내적을 정의할 수도 있습니다 (결국 같은 얘기).&lt;br /&gt;&lt;br /&gt;다만, 앞서 얘기한 바와 같이 그 역은 항상 성립하지는 않는데요. 즉, 두 random variable이 orthogonal하다고 해서 independent하지는 않습니다. 이 부분에서 헷갈리는 것이 &quot;음? 직교하는데 independent하지 않는 경우가 어떤게 있지?&quot; 하는 생각이 바로 들게 되죠.&lt;br /&gt;&lt;br /&gt;이 부분이 매우 어색하고 이상하다고 여겨지는 이유는 random variable을 어느 순간 fixed variable과 dot product를 가지고 노는 선형 벡터 쪽 영역으로 은근슬쩍 넘어가서 생각하기 때문입니다. 여기서의 직교는 내적을 covariance로 정의하였을 때를 기준으로 얘기하기 때문에 우리가 흔히 생각하던 fixed variable vectors 둘을 골라서 dot product한 기준으로 얘기하면 안 됩니다. 즉, 정의대로 orthogonal = uncorrelated인 경우만을 생각하면 uncorrelated이나 dependent인 경우는 쉽게 받아들일 수 있습니다.&lt;br /&gt;&lt;br /&gt;예를 들어 $X$가 $\{-1,0,1\}$ 중 하나의 값을 동일한 확률로 뽑는 random variable일 때 $Y=X^2$에 대해 $\rho_{XY}=0$이지만 dependent임을 쉽게 알 수 있습니다. 사실 $X$가 0을 기준으로 symmetric pdf를 가지면 그 모든 예시에 대해 $X$와 $Y$는 서로 (covariance-wise) orthogonal하지만 dependent합니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;B)&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;그러나 &lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/156554#156554&quot; target=&quot;_blank&quot;&gt;통계에서 다루는 모든 variables가 random variables는 아니라는 점&lt;/a&gt;에 주의해야 합니다. 특히, 선형 회귀 문제를 생각해보면 거기서 사용하는 입력값과 같은 독립 변수(independent variables)들은 random이 아니라 이미 &quot;정해진&quot; 값들입니다. Independent variables는 보통 수열로 주어지고 위에서 얘기한 바와 같이 자연스럽게 dot product를 내적으로 사용할 수 있겠습니다. 이 때, independent variables가 regression line에 대해 orthogonal인지 아닌지 등을 얘기하는데 이런 맥락에서 보면 애시당초 orthogonality는 statistical definition도 갖지 않고 random variable에 적용되는 얘기도 아니죠. (ANOVA에서의 &lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot; target=&quot;_blank&quot;&gt;orthogonal contrasts&lt;/a&gt; 등)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;정리해보자면 A)에서는 uncorrelatedness와 orthogonality는 사실 같은 것에 대한 다른 이름일뿐입니다. 따라서 가장 좋은 것은 random variable에 대해 uncorrelatedness를 말할 때는 orthogonality라는 용어를 사용하지 않는 것입니다. 그리고 같은 논지로 B)의 맥락에서는 non-random variable에 대해 correlation이라는 용어를 사용하는 것을 지양하는 것이 좋겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;더 읽어볼 것...&lt;/h2&gt;&lt;br /&gt;아래 reference로 달아둔 링크 중 &lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot; target=&quot;_blank&quot;&gt;&quot;Linearly Independent, Orthogonal, and Uncorrelated Variables&quot;&lt;/a&gt;라는 제목의 레포트가 있습니다. Non-random variable에 대해 내적으로 dot product를 사용하여&amp;nbsp;지금까지 본문에서 바라본 statistical 관점이 아니라 대수적 혹은 기하적 관점에서 바라본 논문 형태의 레포트인데요. 내용을 매우 잘 설명한 좋은(짧은) 논문이지만, 이 경우 내적이 dot product로 달라졌으므로, &lt;b&gt;orthogonality와 uncorrelatedness가 같지 않으며&lt;/b&gt; 자칫하면 지금까지 간신히 잡아둔 개념들이 더 헷갈릴 수 있습니다. 따라서 분명한 차이가 있다는 것을 염두에 두고 봐야 합니다.&lt;br /&gt;&lt;br /&gt;* 그리고 위 레포트에서는 non-random variable에 대해서도 correlation의 개념을 사용합니다. 엄밀히 말하자면 이는 지금까지가 우리가 얘기했던 population에 대한 correlation coefficient가 아닌 &lt;a href=&quot;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#For_a_sample&quot; target=&quot;_blank&quot;&gt;sample correlation coefficient일 때 성립합니다.&lt;/a&gt;&amp;nbsp;앞서는 random variable이 표본 공간(sample space)에 대해 정의된 함수이며, 이 때 함수(random variables)들에 대한 내적을 얘기한 것이었다면, 위 레포트에서는 fixed or predefined variable 즉, sample에 대한 얘기이므로 분명히 다릅니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;References&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/171347&quot;&gt;https://stats.stackexchange.com/a/171347&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&quot;&gt;https://math.stackexchange.com/questions/917313/the-difference-between-statistically-independent-and-linearly-independent&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&quot;&gt;https://stats.stackexchange.com/questions/129600/linear-independence-vs-statistical-independence-pca-and-ica&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&quot;&gt;https://stats.stackexchange.com/questions/134310/independence-and-orthogonality/134317#134317&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&quot;&gt;https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/29172#29172&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&quot;&gt;https://stats.stackexchange.com/questions/12128/what-does-orthogonal-mean-in-the-context-of-statistics/16315#16315&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stats.stackexchange.com/a/303798&quot;&gt;https://stats.stackexchange.com/a/303798&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&quot;&gt;https://web.archive.org/web/20100709201307/http://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&quot;&gt;https://en.wikipedia.org/wiki/Contrast_(statistics)#Definitions&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/649523289300133464/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/649523289300133464'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/08/what-is-relationship-between-orthogonal.html' title='What is the relationship between orthogonal, correlation and independence?'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-7046349279022556648</id><published>2018-05-09T15:08:00.001+09:00</published><updated>2018-06-04T10:27:02.126+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Spectral Normalization for Generative Adversarial Networks</title><content type='html'>&lt;h2&gt;Spectral Normalization for Generative Adversarial Networks&lt;/h2&gt;&lt;h2&gt;&lt;div&gt;&lt;span style=&quot;font-size: small;&quot;&gt;TL;DR: A novel weight normalization technique called spectral normalization to stabilize the training of the discriminator of GANs.&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Keywords: Generative Adversarial Networks, Deep Generative Models, Unsupervised Learning&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Accept: (Oral)&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-size: small;&quot;&gt;Rating: 8-8-8&lt;/span&gt;&lt;br /&gt;&lt;b style=&quot;font-size: medium;&quot;&gt;Review:&lt;/b&gt;&lt;span style=&quot;font-size: small; font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;a href=&quot;https://openreview.net/forum?id=B1QRgziT-&quot; style=&quot;font-size: medium; font-weight: 400;&quot;&gt;https://openreview.net/forum?id=B1QRgziT-&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium;&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Preferred network 그룹에서 나온 논문. (최근 핫한 일본 그룹) 그리고 Ian Goodfellow의 홍보 (보증?...) 개인적으로 매우 취향인 논문. &lt;/span&gt;(이후 더 자세히 리뷰 예정)&lt;span style=&quot;font-weight: 400;&quot;&gt;&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-weight: 400;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s1600/SNGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;GANs를 안정적으로 학습시키는 것을 새로운 weight normalization으로 해결해보고자 함. Spectral normalization이라 불리는 이 방법은,&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;ul style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;li&gt;Intensive hyper parameter이 필요없음. Lipshitz&amp;nbsp;constant가 유일한&amp;nbsp;hyperparameter&amp;nbsp;to be tuned. (심지어는 tuning 안 해도 잘 됨)&lt;/li&gt;&lt;li&gt;Implementation이 단순하고 computational cost가 적음.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Batch normalization이나 weight decay, feature matching on the discriminator와 같은 regularization tech.가 없이도 working 잘 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;2. Spectral Normalization&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;각 레이어의 spectral norm을 제약함으로써 Discriminator function $f$의 Lipschitz constant를 컨트롤 함.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;ReLU와 같은 activation function의 Lipschitz norm은 1이기 때문에 네트워크 전체를 볼 때 고려하지 않아도 되고, 결국 Weight의 Lipschitz norm을 나눠줌으로써 각 weight matrix $W$의 Lipschitz constant $\sigma(W)=1$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;$$\bar{W}_{SN}(W):=W/\sigma(W).$$&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;이를 바탕으로 $||f||_{Lip}$가 1로 상계를 갖도록(upper bounded) 함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h3&gt;Gradient Analysis of the Spectrally&amp;nbsp;Normalized Weights&lt;/h3&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;The gradient of $\bar{W}_{SN}(W)$ w.r.t. $W_{ij}$:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align} \frac{\partial\bar{W}_{SN}(W)}{\partial W_{ij}}&amp;nbsp; &amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{1}{\sigma(W)^2}\frac{\partial \sigma(W)}{\partial W_{ij}}W \\&amp;amp;= \frac{1}{\sigma(W)}E_{ij} - \frac{[u_1v_1^T]_{ij}}{\sigma(W)^2}W \\&amp;amp;= \frac{1}{\sigma(W)} (E_{ij} - [u_1v_1^T]_{ij}\bar{W}_{SN}) \end{align}&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 $E_{ij}$는 $(i,j)$-th entry는 1 나머지는 0인 행렬이고 $u_1$과 $v_1$이 first left and right singular vecotrs of $W$. $h$를 hidden layer라고 하면 아래가 성립함:&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;\begin{align}\frac{\partial V(G,D)}{\partial W}&amp;amp;=\frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-(\hat{E}[\delta^T\bar{W}_{SN}h])u_1v_1^T)\\&lt;br /&gt;&amp;amp;= \frac{1}{\sigma(W)}(\hat{E}[\delta h^T]-\lambda u_1v_1^T) \end{align}&lt;br /&gt;여기서 $\delta:=(\partial V(G,D)/ \partial(\bar{W}_{SN}h))^T, \lambda:=\hat{E}[\delta^T(\bar{W}_{SN}h)]$이고 $\hat{E}[\cdot]$은 각 미니 배치의 empirical expectiation을 나타냄.&lt;br /&gt;For some $k\in \mathbb{R}$, $\hat{E}[\delta h^T]=ku_1v_1^T$일 때 $\frac{\partial V}{\partial W}=0$이 성립함.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;여기서 식 (5)의 해석이 매우 재미있는데, 식의 첫번째 항은 normalize되지 않은 weights에 대한 미분이므로 별다를 것이 없고 두번째 항이 추가된 것으로 생각해보면, 이를&amp;nbsp;adaptive regularization coefficient $\lambda$만큼 첫번째 singular component를 penalize하는 regularization 항으로 본다면 다음과 같은 해석이 가능함:&lt;br /&gt;&lt;br /&gt;$\lambda$가 양수라는 얘기는 $\delta$와 $\bar{W}_{SN}h$가 비슷한 방향을 가르키고 있다는 것을 의미함. 즉, $W$의 column space가 한 쪽 방향으로만 집중해서 update되는 것을 막아준다고 해석할 수 있음. 논문에서는 이를 통해 spectral normalization이 네트워크의 각 layer가 한 방향으로만 sensitive하지 않도록 막는다고 얘기함.&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;/h2&gt;&lt;h2&gt;3. Spectral Normalization vs Other Regularization Techniques&lt;/h2&gt;&lt;h2&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;Weight normalization은 결과적으로 너무 강한 constraint를 걸어버리는 경향이 있음. Weight normalization은 weight matrix의 rank를 1이 되도록 강제함 (matrix norm과 weight normalization definition에 의해 수식을 보면 확인할 수 있음).&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;그런데 이렇게 하면 discriminator가 하나의 feature만을 보고 probability distribution을 구별해야하기 때문에 discriminator가 매우 sensitive하고 unstable하게 만드는 경향이 있음.&lt;br /&gt;&lt;br /&gt;Orthonormal regularization on each weight는 spectral normalization과 유사하면서도 학습을 안정화해주기는 하지만,&lt;br /&gt;$$||W^TW-I||_F^2$$&lt;br /&gt;weights를 orthonormal하게 하므로써 (모든 singular value를 1로 강제하기 때문에) spectrum의 envelop을 망치고 중요한 정보를 잃어버리는 경향이 있음. Spectral normalization은 spectrum의 scale만을 조절하기 때문에 (최대 값을 1) 이와는 다름.&lt;br /&gt;&lt;br /&gt;GP와 같은 경우는 위에서 설명한 다른 normalization tech.들과 같은 문제는 없지만 현재 generative distribution의 support에 매우 강하게 엮여있다는 약점이 있음. 이 때문에 학습이 진행됨에 따라 generative distribution의 support도 바뀌기 때문에 학습 과정이 불안정적이 된다는 단점이 생김. Spectral normalization은 학습하는 함수를 operator space에서 regularize하기 때문에 들어오는 데이터 batch에 보다 덜 민감한 것을 볼 수 있음.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;4. Experiments&lt;/h2&gt;&lt;br /&gt;최초로 단일 네트워크로 이미지넷 1000개 범주의 이미지를 생성한 방법인 것만으로도 큰 의미를 지님.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-1y_O1cz9f3I/WvKP5QfVk6I/AAAAAAAACuE/1xkIn4De4uEwXE3sO87cle_Fy7iMNX_XACK4BGAYYCw/s1600/SNGAN1.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;font-size: medium; font-weight: 400;&quot;&gt;&lt;/div&gt;&lt;/h2&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/7046349279022556648/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/7046349279022556648'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-spectral-normalization-for-gan.html' title='[Paper Skim] Spectral Normalization for Generative Adversarial Networks'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/--Nxb92w42nc/WvKQGe6c7LI/AAAAAAAACuM/v5rnhTd0O9gOUJFHXp6ys033WEUubqNcgCK4BGAYYCw/s72-c/SNGAN2.png" height="72" width="72"/><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1857320262473439791</id><published>2018-05-01T08:09:00.001+09:00</published><updated>2018-05-01T10:07:50.973+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements</title><content type='html'>&lt;h2 style=&quot;height: 0px;&quot;&gt;AmbientGAN: Generative Models From Lossy Measurements&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;How to learn GANs from noisy, distorted, partial observations&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt; Generative models, Adversarial networks, Lossy measurements&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Rating: 8-7-7&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Review:&amp;nbsp;&lt;/b&gt;&lt;a href=&quot;https://openreview.net/forum?id=Hy7fDog0b&quot;&gt;https://openreview.net/forum?id=Hy7fDog0b&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;GAN을 학습시키기 위해서 고퀄리티 샘플들이 필요한데 (예시: 노이즈가 없는 사진들) 보통 그런 경우가 많지 않다는 것을 지적하고 이를 해결하고자 한 논문.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;즉, 샘플에 occlusion이나 noise, blur 등의 문제가 있는 데이터셋만으로도 원래와 같이 고퀄리티 샘플(occulusion noise blur 혹은 unknown any noise가 없는)을 생성할 수 있는 Generative model을 학습하고자 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;직관적인 이해를 위해 결과부터 좀 소개하자면:&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s1600/ambiGAN1.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이렇게 맨 왼쪽과 같이 patch가 잘려서 zero가 되는 noise function으로 더럽혀진 데이터셋만 있는 경우에도 generator가 맨 오른쪽과 같이 어느정도 얼굴 형태를 생성해내는 모델을 학습함. (중간은 baseline)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;개인적으로 재미있었던 실험은 MNIST 데이터를 패딩을 바탕으로 크기를 키운 다음 임의의 각도로 회전하고 한쪽 방향으로 sum 된 1D 데이터로 squash한 데이터들을 바탕으로 학습을 해도 generator가 아래와 같이 어느정도 숫자를 generate하는 모델을 학습해내는 것.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-p3IGxbiiXws/WuefgK2M7_I/AAAAAAAACso/H5gKiiocpNgDKv34Wx1asYin0VBRYprmgCK4BGAYYCw/s1600/ambiGAN2.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;추가 정보로 회전각을 넣어주었을 때 더 잘 복원됨. (오른쪽, 사실 이건 의료 영상에서 CT와 같은 projection으로 생각해보면 자명함)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 논문이 재미있는건 이렇게 이미지가 복원이 되는 조건을 명확하게 하고 수학적으로 증명을 하였다는 점.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-JBN_Xjc92P4/WuefJ6O2JFI/AAAAAAAACsY/GBcsxRb6tb0KveFJ_mBT9cqh6lWhnwFvACK4BGAYYCw/s1600/ambiGAN3.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;네트워크 구조도&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;Generator가 먼저 깨끗한 이미지 $X_g$를 만들면 $f_{\theta}$가 이를 corrupt하는 noise function을 학습해서 $Y_g$를 만들어내고 Discriminator가 corrupt된 real data $Y_r$와 이를 비교하게 하는 구조.&lt;br /&gt;&lt;br /&gt;풀고자 하는 문제를 참 잘 특정해서 잡았다고 생각하는 것이, 우리가 얻을 수 있는 데이터는 실제로는 이미 어떤 unknown noise function에 의해 corrupt 되어 나온 것인 경우가 많다는 것이 기본 바탕.&lt;br /&gt;&lt;br /&gt;AmbientGANs에서는 데이터가 충분히 많기만 하다면, 이런 noise function을 학습하고 기존의 data distribution을 복원하는 것이 가능하다는 것을 analytically &amp;amp; empirically 보임.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이거 보고 나서 결과를 improve해볼 수 있는 idea들이 몇 개 생각나긴 했는데 해보고 싶은것들이 막 생깁니다ㅋㅋ 당장 recon loss와 cyclic loss를 붙여볼 수 있겠네요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;참고자료&lt;/h2&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;(slideshare) &lt;a href=&quot;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&quot;&gt;https://www.slideshare.net/thinkingfactory/introduction-to-ambient-gan&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1857320262473439791/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html#comment-form' title='0개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1857320262473439791'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-ambientgan-generative-models.html' title='[Paper Skim] AmbientGAN: Generative Models From Lossy Measurements'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-ZgMxy3ce5Rw/WuefGHdG55I/AAAAAAAACsI/9SfwaPBzt_oJRbZROty_JHsH1FWb9H5iQCK4BGAYYCw/s72-c/ambiGAN1.png" height="72" width="72"/><thr:total>0</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-673973366306707726</id><published>2018-05-01T07:28:00.000+09:00</published><updated>2018-05-01T10:23:16.712+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="GAN"/><category scheme="http://www.blogger.com/atom/ns#" term="ICLR2018"/><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="skimpaper"/><title type='text'>[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation</title><content type='html'>&lt;h2&gt;&lt;b&gt;Progressive Growing of GANs for Improved Quality, Stability, and Variation&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;b&gt;TL;DR:&lt;/b&gt;&amp;nbsp;Train generative adversarial networks in a progressive fashion, enabling us to generate high-resolution images with high quality.&lt;/div&gt;&lt;div&gt;&lt;b&gt;Keywords:&lt;/b&gt;&amp;nbsp;generative adversarial networks, unsupervised learning, hierarchical methods&lt;/div&gt;&lt;b&gt;Accept: (Oral)&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Rating: 8-8-8&lt;/b&gt;&lt;br /&gt;&lt;b&gt;Review:&lt;/b&gt;&amp;nbsp;&lt;a href=&quot;https://openreview.net/forum?id=Hk99zCeAb&quot;&gt;https://openreview.net/forum?id=Hk99zCeAb&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;GANs를 학습하는 새로운 방법을 제안.&lt;br /&gt;핵심 아이디어는 generator와 discriminator를 점진적으로 키운다는 것: 저해상도에서 시작해서 세밀한 점들을 배울 수 있도록 새로운 레이어들을 추가하는 방식.&lt;br /&gt;이런 방식을 취함으로 인해 GANs을 보다 안정적이면서 빠르게 학습하는 것이 가능해졌다고 얘기함; CelebA 1024^2 해상도 이미지를 만들어 내는 네트워크 학습.&lt;br /&gt;또한 CIFAR10에서 비지도학습 방식으로 생성된 이미지들의 종류가 다양하도록 할 수 있는 간단한 방법을 제안함. Inception score가 8.80에 달한다고 함.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;1. Introduction&lt;/h2&gt;&lt;br /&gt;고해상도 이미지를 만드는 것은 매우 어려운데 그 이유는 해상도가 높을 수록 생성한 이미지인지를 구분하는 것이 쉬워지기 때문.&lt;br /&gt;게다가 큰 해상도 이미지로 인해 메모리 문제로 더 작은 minibatches를 사용하게되고 학습 안정성에 문제가 됨.&lt;br /&gt;여기서 저자들의 주요 insight는 generator와 discriminator를 점진적(progressively)으로 키우는 것.&lt;br /&gt;&lt;br /&gt;기존의 GAN 수식은 학습된 생성 모델이 굳이 학습 데이터 분포 전체를 모두 표현할 필요가 없었음. (?)&lt;br /&gt;기존의 공통된 의견은 이미지의 질과 다양성이 서로 tradeoff 관계라는 것이었으나 최근 Odena et al. 2017에 의해 다른 의견이 제기됨. (확인 필요)&lt;br /&gt;다양성에 대한 측정 방법에 대해 매우 많은 방식들이 제안되고 있는데:&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;including inception score (Salimans et al., 2016), multi-scale structural similarity (MS-SSIM) (Odena et al., 2017; Wang et al., 2003), birthday paradox (Arora &amp;amp; Zhang, 2017), and explicit tests for the number of discrete modes discovered (Metz et al., 2016).&amp;nbsp;&lt;/blockquote&gt;PGGAN에서는 이 외에 다양성을 보다 북돋기 위해 사용한 방법을 설명하고 이미지의 질과 다양성을 측정하기 위한 새로운 metric을 제안하였음.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;2. Progressive Growing of GANs&lt;/h2&gt;&lt;br /&gt;&lt;b&gt;키 아이디어 정리: 단계별 학습 (구몬??!)&lt;/b&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;The complex mapping from latents to high-resolution images is easier to learn in steps&quot;&amp;nbsp;&lt;/blockquote&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s1600/pggan1.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;아래 그림에서 볼 수 있듯이 점진적으로 네트워크 레이어를 추가할 때 sudden shock이 일어나지 않도록 새로 추가하는 레이어를 부드럽게 (fade in) 넣어줌.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-SkNSj3dGOyE/WuSEeMByscI/AAAAAAAACrI/N1MweSP6q-AAtmfTBW6KhKXJ2hQNaIOFgCK4BGAYYCw/s1600/pggan2.PNG&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;3. Increasing Variation using Minibatch Standard Deviation&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이미지가 다양하게 생성되도록 하기 위해 GANs이 학습 데이터의 일부분만 집중하는 성질이 있는 것을 고려하여 Salimans et al. (2016)에서는 Minibatch discrimination 방식을 제안했었음. Feature statistics를 계산할 때 각각의 이미지만 보는 것이 아니라 minibatch 전체에 대해 계산하므로써 생성된 이미지와 학습 이미지들이 비슷한 statistics를 갖도록 하자는게 아이디어였음. (구체적 방식은 다시 &lt;b&gt;체크&lt;/b&gt;) PGGAN에서는 이 접근 방식을 보다 단순하게 만들면서도 다양성은 증대하는 방법을 제안함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 방식은 parameter 학습이 필요하거나 새로운 hyperparameter가 필요하지 않음. 먼저 minibatch에 있는 각 spatial location에서의 feature 각각의 stardard deviation을 계산함. 이 estimates를 모든 features와 spatical locations에 대해 평균을 내고 하나의 값을 계산함. 이 값을 복사해서 모든 spatial locations와 minibatch에 대해 concat하는 방식으로 (constant) feature map을 하나 추가함. 이 레이어는 discriminator의 어느 위치에도 들어갈 수 있으나 inset it towards the end가 가장 좋은 성능을 보였음.&amp;nbsp;&lt;/div&gt;&lt;div&gt;Parallel work으로 Lin et al. (2017)이 이와 유사한 방식(multiple images를 discriminator에 보여주는 것이 좋은 이유)을 이론적으로 설명한 바 있음. (&lt;b&gt;체크&lt;/b&gt;)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;4. Normalization in Generation and Discriminator&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;GANs에서의 normalization은 signal magnitude와 competition을 제한하는 쪽에 주안점을 두어야한다고 생각함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.1 Equalized Learning Rate&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;기존의 방식들이 weight initialization에 심혈을 기울이는 것과는 달리 여기서는 초기값은 대충 표준정규분포로 주되 runtime 중 weights의 scale을 조절하는 방향을 취함.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;4.2 Pixelwise Feature Vector Normalization in Generator&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Generator와 Discriminator가 서로 경쟁한 끝에 발산하는 경우를 막기 위해서 generator에서 하나의 conv layer를 지날때마다 각 pixel의 feature vector를 정규화.&amp;nbsp;&lt;/div&gt;&lt;div&gt;이 방식이 실험 결과는 크게 바꾸지 않았지만 signal magnitude가 급격히 커지는 현상을 매우 효과적으로 없애주었다고 함.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;5. Multi-Scale Statistical Similarity for Assesing GAN results&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;서로 다른 GAN을 비교하는 것은 여러모로 쉽지 않음. MS-SSIM(Odena et al., 2017)과 같은 방식은 large-scale mode collapse를 잘 발견하지만 color나 texture의 작은 loss들을 발견하지 못하는 단점들이 알려져있음. 그리고 학습 데이터와의 유사한 정도를 직접적으로 고려하지 않기 때문에 문제가 있음.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;PGGAN에서는 각 scale 별로 학습데이터와 생성 데이터의 local structure가 서로 유사해야한다는 intuition을 바탕으로 local image patches의 분포 간의 multi-scale statistical similarity를 확인하는 방식을 취함(Laplacian pyramid, Burt &amp;amp; Adelson, 1987 다시 &lt;b&gt;체크&lt;/b&gt;).&amp;nbsp;&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;6. Experiments&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&amp;nbsp;판타스틱함!&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-O3xwR2CISPc/WuSKmX4LqHI/AAAAAAAACrY/QAI81FW6WRE9bw0wmyPF5SlvUaHvWd-2QCK4BGAYYCw/s1600/pggan3.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Dpvmlxcfe40/WuSLAM1ZuoI/AAAAAAAACrk/zrUNwJnpSmgidOv6z8Ju1BwSxJYzlnXegCK4BGAYYCw/s1600/pggan4.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GZhLarAlXdw/WuSLGDX1gHI/AAAAAAAACrs/hu7ZoogQR7U8jCFwGkuhZMSlY0Tm1cQbwCK4BGAYYCw/s1600/pggan5.PNG&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;h2&gt;Stillcut from ICLR oral presentation&amp;nbsp;&lt;/h2&gt;&lt;a href=&quot;http://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uCBmO7Bw9ao/WufAWjb8hCI/AAAAAAAACs4/wMgShNPn238JdxM__H8yhWEqgareoY-mQCK4BGAYYCw/s1600/PGGAN0.jpg&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;br /&gt;&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;Video presentation&lt;/h2&gt;&lt;h2 style=&quot;clear: both; text-align: left;&quot;&gt;&lt;iframe allowfullscreen=&#39;allowfullscreen&#39; webkitallowfullscreen=&#39;webkitallowfullscreen&#39; mozallowfullscreen=&#39;mozallowfullscreen&#39; width=&#39;530&#39; height=&#39;266&#39; src=&#39;https://www.blogger.com/video.g?token=AD6v5dwAgXjJRWvqU_PHFNLPHAVndoFNHNCxHlsrkhjkXGalB5SpEFnckruf3WrsChlGGyCaztfvbN19VVgd7xxzdA&#39; class=&#39;b-hbp-video b-uploaded&#39; frameborder=&#39;0&#39; /&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/673973366306707726/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/673973366306707726'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/05/paper-skim-progressive-growing-of-gans.html' title='[Paper Skim] Progressive Growing of GANs for Improved Quality, Stability, and Variation'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://4.bp.blogspot.com/-SQGekqMG6l4/WuR_pd8811I/AAAAAAAACq4/BgLAPRotsZ0z6TqHoD9vYllXT-5AUC3SwCK4BGAYYCw/s72-c/pggan1.PNG" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-3983669769096239575</id><published>2018-02-24T15:00:00.001+09:00</published><updated>2018-08-04T22:24:05.873+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (3)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html&quot;&gt;저번 글&lt;/a&gt;까지 하여 우리는 이제 드디어 parameter의 좋고 나쁨을 정량화할 방법에 대해 얘기해볼 때가 되었습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Loss function&lt;/h2&gt;&lt;br /&gt;지금까지는 response variable이 어떻게 생성되고 각각의 관찰값에 따라 각 분포에 대한 parameters를 어떻게 계산하는지에 대해 알아보았습니다. 자, 그럼 어떤 parameters가 좋은 것인지 어떻게 정량화할 수 있을까요?&lt;br /&gt;&lt;br /&gt;시작하기에 앞서, 잠시&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;를 예측하는 것을 상기해보겠습니다. 만약 우리가 고양이 그림을 모델에게 넣어준다면 다음의 binomial distribution가 주어졌을 때, $\phi\approx0$이도록 계산을 해야겠지요.&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;\begin{cases}&lt;br /&gt;1 - \phi &amp;amp; \text{outcome = cat}\\&lt;br /&gt;\phi &amp;amp; \text{outcome = dog}\\&lt;br /&gt;\end{cases}$$&lt;br /&gt;가장 완벽한 경우, $\phi=0$가 될 것입니다. 그리고 loss function이 우리가 얼마나 답에 가까이 갔는지 정량화해주겠지요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum likelihood estimation&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;앞서 글들에서 소개하였던 세 개의 분포들 각각은 $\mu,\phi,\pi$와 같은 parameter를 갖습니다. 임의의 $y$를 주면 각 분포가 현재 우리가 관찰한 값이 나올 확률을 알려주게 되지요. (예를 들어 continuous-valued random variables의 경우, 분포는 확률 밀도 함수가 되고 이 함수가 우리가 찾는 확률 값에 비례하는 어떤 값을 내뱉습니다.)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;만약 $y$를 고정하고 parameter 값들이 바뀌도록 설정한다면 같은 함수가 이제는 likelihood function이 됩니다. 이 함수가 하는 일은 고정된 $y$ 값에 대해서 현재 parameter의 likelihood에 대해 알려주는 것이죠.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;위에 설명히 명확하지 않다면 아래의 예시들을 생각해보시면 됩니다:&lt;/div&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;모로코 사람 한 명이 바(bar)에 들어왔다. 그는 소매 한 짝이 없어진 축구 저지를 입고 있다. 눈에는 멍이 들었고 바지에는 피가 묻어있었다. 이 사람은 오늘 어떤 하루를 보냈을까?&lt;br /&gt;&lt;ol&gt;&lt;li&gt;집에서 책을 읽었을 것이다.&lt;/li&gt;&lt;li&gt;자전거 경주를 연습 중이었을 것이다.&lt;/li&gt;&lt;li&gt;축구 경기에서 (타 팀을 경멸하며 모두 종합격투기 선수인) 그의 친구들과 맥주를 마시며 놀았을 것이다.&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;우리는 현재 우리가 갖고 있는 데이터가 가장 나옴직한 parameter를 고르고 싶을 것이고, 바로 이게 &lt;i&gt;maximum likelihood estimate&amp;nbsp;&lt;/i&gt;입니다. 수학적으로는 다음과 같이 정의할 수 있습니다:&lt;br /&gt;$$\underset{\text{parameter}}{\arg\max}\ P(y\vert \text{parameter})$$&lt;br /&gt;지금까지 지겹도록 얘기한 것과 같이 $y$는 분포가 받는 parameter에 따라 변합니다. 게다가 이 parameter는 $\eta$라는 항으로 정의가 되었지요. 이어 $\eta=\theta^T x$입니다. 따라서 $y$는 $\theta$와 관측된 데이터 $x$에 대한 함수이죠. 아마도 이것은 여러분이 Day 1부터 알고 있었을 기계 학습의 가장 기본적인 이치일 것입니다.&lt;br /&gt;&lt;br /&gt;관측된 데이터는 고정되어있으므로, $\theta$만이 우리가 바꿀 수 있는 유일한 부분입니다. 이에 맞게 위의 argmax 식을 바꾸면 다음과 같습니다:&lt;br /&gt;$$\underset{\theta}{\arg\max}\ P(y\vert x; \theta).$$&lt;br /&gt;다만 $[0,1]$ 안의 값들을 여러 차례 곱하면 값이 매우 빠르게 작아지기 때문에 이런 현상을 방지하기 위해 log-likelihood를 사용하게 되는 것입니다. log의 성질 덕에 곱하기 연산이 더하기로 바뀌게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Linear regression&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Gaussian 분포의 log-likelihood를 최대화 해보겠습니다. $x$와 $\theta$가 함께 $\mu$를 만든 다는 것을 기억하세요; $\theta^T x=\mu$.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;\begin{align*} \log{P(y\vert x; \theta)} &amp;amp;= \log{\prod\limits_{i=1}^{m}P(y^{(i)}\vert x^{(i)}; \theta)}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{P(y^{(i)}\vert x^{(i)}; \theta)}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}}\\ &amp;amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}} + \sum\limits_{i=1}^{m}\log\Bigg(\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}\Bigg)\\ &amp;amp;= m\log{\frac{1}{\sqrt{2\pi}\sigma}} - \frac{1}{2\sigma^2}\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\ &amp;amp;= C_1 - C_2\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\ \end{align*}&lt;br /&gt;&lt;div&gt;따라서 데이터와 $\theta$에 대해 log-likelihood를 최대화 하는 것은 관측된 $y$ 값과 우리가 예측한 값 사이의 negative mean squared error를 최대화 하는 것과 동치입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;다만 대다수의 최적화 루틴들이 최소화를 하는 방향으로 설계되어 있으므로 편의를 위해 최소화로 바꾸기만 할 뿐이죠.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the mean squared error between the observed y and our prediction thereof.&lt;/b&gt;&lt;/div&gt;&lt;h2&gt;Logistic regression&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bionomial distribution에 대해 위와 똑같은 방식으로 적용해봅시다.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Negative log-likelihood:&lt;/div&gt;&lt;div&gt;\begin{align*} -\log{P(y\vert x; \theta)} &amp;amp;= -\log{\prod\limits_{i = 1}^m(\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}}\\ &amp;amp;= -\sum\limits_{i = 1}^m\log{\bigg((\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}\bigg)}\\ &amp;amp;= -\sum\limits_{i = 1}^my^{(i)}\log{(\phi^{(i)})} + (1 - y^{(i)})\log{(1 - \phi^{(i)})}\\ \end{align*}&lt;br /&gt;따라서&amp;nbsp;데이터와 $\theta$에 대해 negative log-likelihood를 최소화 하는 것은&amp;nbsp;관측된 $y$ 값과 우리가 예측한 값 사이의 binary cross-entropy (i.e. binary log loss)를 최소화 하는 것과 동치입니다.&lt;br /&gt;&lt;br /&gt;&lt;div&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the binary cross-entropy (i.e. binary log loss) between the observed y and our prediction of the probability thereof.&lt;/b&gt;&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;/div&gt;&lt;h2&gt;Multinomial distribution&lt;/h2&gt;&lt;br /&gt;Negative log-likelihood:&lt;br /&gt;\begin{align*} -\log{P(y\vert x; \theta)} &amp;amp;= -\log\prod\limits_{i=1}^{m}\prod\limits_{k=1}^{K}\pi_k^{y_k}\\ &amp;amp;= -\sum\limits_{i=1}^{m}\sum\limits_{k=1}^{K}y_k\log\pi_k\\ \end{align*}&lt;br /&gt;따라서&amp;nbsp;데이터와 $\theta$에 대해 negative log-likelihood를 최소화 하는 것은&amp;nbsp;관측된 $y$ 값과 우리가 예측한 값 사이의 categorical cross-entropy (i.e. multi-class log loss)를 최소화 하는 것과 동치입니다.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&amp;gt; Minimizing the negative log-likelihood of our data with respect to θ is equivalent to minimizing the categorical cross-entropy (i.e. multi-class log loss) between the observed y and our prediction of the probability distribution thereof&lt;/b&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross_entropy&quot;&gt;Cross-entropy&lt;/a&gt;&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;전에 확률 분포에 내재한 불확실성을 정량화하기 위해 entropy를 정의했던 것과 같이, 하나의 분포로부터 다른 분포의 사건을 예측할 때 내재한 불확실성을 정량화한 것이 바로 cross-entropy입니다.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;red&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;green&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;blue&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;red&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;green&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;blue&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div&gt;$$(p, q) = -\sum_i p_i\log(q_i)$$&lt;/div&gt;&lt;h3&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;&gt;KL-Divergence&lt;/a&gt;&lt;/h3&gt;&lt;br /&gt;비슷한 방식으로 Kullback-Leibler Divergence도 역시 $q$를 사용하여 $p$를 근사할 때 추가적으로 생기는 불확실성을 정량화합니다.&lt;br /&gt;$$D_{KL}(p, q) = H(p, q) - H(p)$$&lt;br /&gt;이를 기계학습 모델들에서 잘 사용하지 않는 이유는 실제 분포 $p$를 알아야지만 계산이 가능하기 때문이죠. 보통은 $p$를 모르고 있기 때문에 사용을 할 수 없습니다 (애시당초 true $p$를 알고 싶어서 모델을 세우는 것인데 이렇게 되면 주객전도지요 ㅎㅎ).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum a posteriori estimation&lt;/h2&gt;&lt;br /&gt;$\theta$가 MLE를 바탕으로 estimate될 때는 별다른 제약을 걸지 않았었습니다. 좀 더 구체적으로 얘기하자면, $\theta$가 어떤 실수 값이 나오든 상관이 없었죠 ($0, 10, -20, 2.37\times10^{36}$).&lt;br /&gt;&lt;br /&gt;실제로는 이런 가정은 좀 비현실적이기도 하고 군더더기인 부분이기도 합니다. 보통은 $\theta$ (weights)가 유한범위 안에서 값을 갖기를 바라죠. 따라서 이를 위해 $\theta$에&amp;nbsp;&lt;i&gt;prior&amp;nbsp;&lt;/i&gt;를 두곤 합니다. MLE가 $\underset{\theta}{\arg\max}\ P(y|x;\theta)$일 때, maximum a posteriori estimate (MAP)는 $\underset{\theta}{\arg\max}\ P(y\vert x; \theta)P(\theta)$를 계산하게 됩니다.&lt;br /&gt;&lt;br /&gt;앞서와 마찬가지로 log를 씌운 다음 prior와 함께 joint likelihood를 풀면:&lt;br /&gt;\begin{align*}&lt;br /&gt;\theta_{MAP}&lt;br /&gt;&amp;amp;= \underset{\theta}{\arg\max}\ \log \prod\limits_{i=1}^{m} P(y^{(i)}\vert x^{(i)}; \theta)P(\theta)\\&lt;br /&gt;&amp;amp;= \underset{\theta}{\arg\max}\ \sum\limits_{i=1}^{m} \log{P(y^{(i)}\vert x^{(i)}; \theta)} + \log{P(\theta)}\\&lt;br /&gt;\end{align*}&lt;br /&gt;왼쪽 항은 앞서 다뤘던 것과 같고 남은 log prior 부분만 살펴보면 되겠군요.&lt;br /&gt;&lt;br /&gt;$\theta$의 모든 항이 continuous-valued 실수값이므로 평균 0과 분산 $V$를 갖는 Gaussian 분포를 할당해보겠습니다.&lt;br /&gt;$$\theta \sim \mathcal{N}(0, V)$$&lt;br /&gt;\begin{align*}&lt;br /&gt;\log{P(\theta\vert 0, V)}&lt;br /&gt;&amp;amp;= \log\Bigg(\frac{1}{\sqrt{2\pi}V}\exp{\bigg(-\frac{(\theta - 0)^2}{2V^2}\bigg)}\Bigg)\\&lt;br /&gt;&amp;amp;= \log{C_1} -\frac{\theta^2}{2V^2}\\&lt;br /&gt;&amp;amp;= \log{C_1} - C_2\theta^2\\&lt;br /&gt;\end{align*}&lt;br /&gt;우리의 목표는 log-likelihood와 함께 위의 항을 같이 $\theta$에 대하여 최대화하는 것입니다. $\theta$를 포함하지 않는 항을 정리하고 나면 다음과 같고:&lt;br /&gt;\begin{align*}&lt;br /&gt;\log{C_1} - C_2\theta^2&lt;br /&gt;&amp;amp;\propto - C_2\theta^2\\&lt;br /&gt;&amp;amp;\propto C\Vert \theta\Vert_{2}^{2}\\&lt;br /&gt;\end{align*}&lt;br /&gt;이것이 바로 L2 regularization라는 것을 아실 수 있습니다. 게다가 $\theta$에 대해 prior distribution을 바꾸면 또다른 regularization이 가능해집니다! 예를 들면 Laplace prior는 L1 regularization을 하는 것과 동치이지요.&lt;br /&gt;&lt;br /&gt;따라서 정리해보면, 기계학습에서 weights를 regularize한다고 함은 &quot;no weight becomes too large&quot; 하겠다는 것입니다. 즉 $y$를 예측할 때 너무 큰 영향을 미치지 못하게 만드는 것이죠. 통계적인 관점에서도 똑같이 이런 prior 항이 주어진 범위 내에서 값이 나오도록 제한하는 역할을 한다고 말할 수 있습니다. 이 범위가 scaling constant $C$로 표현되고 prior distribution 자체를 매계변수화합니다. 예를 들어 L2 regularization에서는 이 scaling constant가 Gaussian의 분산을 정하게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Going fully Bayesian&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;예측 모델의 주요 목표는 다음 분포를 계산하는 것입니다:&lt;/div&gt;$$P(y\vert x, D) = \int P(y\vert x, D, \theta)P(\theta\vert x, D)d\theta$$&lt;br /&gt;각 항을 설명해보자면:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$P(y|x,D)$: 학습 데이터 $D=((x^{(i)},y^{(i)}),\cdots,(x^{(m)},y^{(m)}))$와 새로운 관측값 $x$가 주어졌을 때, response $y$의 값에 대한 분포를 계산하는 것을 뜻합니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;기계학습에서는 보통 해당 분포의&amp;nbsp;&lt;i&gt;expected&lt;/i&gt; 값을 고르게 됩니다 (i.e. a single value, or point estimate).&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;$P(y|x,D,\theta)$: 학습 데이터 $D$, 새로운 관측값 $x$, 임의의 가능한 $\theta$ 값이 주어졌을때 (굳이 optimal이 아니더라도) $y$를&amp;nbsp; 계산하는 것을 뜻합니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;보통 주어진 모델에 대한 함수로 나타내지고 linear regression의 경우 $y=\theta^T x$와 같이 나타낼 수 있겠습니다.&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;$P(\theta|x,D)$: 학습 데이터 $D$와 새로운 관측값 $x$가 주어졌을 때 우리의 데이터를 설명할 수 있는 $\theta$ 값에 대한 분포를 계산하는 것을 뜻합니다.&lt;/li&gt;&lt;ul&gt;&lt;li&gt;여기서 x는 아무런 역할을 하지 않습니다. 그저 적분을 할 때 수식적 표현이 맞도록 들어가 있을 뿐입니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;기계학습에서는 MLE 혹은 MAP estimate을 고르게 됩니다 (i.e. a single value, or point estimate).&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;모든 것이 완벽하다면,&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\theta$에 대한 &lt;i&gt;full distribution&amp;nbsp;&lt;/i&gt;을 계산하고,&lt;/li&gt;&lt;li&gt;이 분포의 값들과 새로운 관측값 $x$를 가지고 $y$를 계산할 수 있습니다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;NB: 여기서 $\theta$가 weights이므로 10-feature linear regression에서는 10개의 원소를 갖는 벡터가 됩니다. 신경망에서는 수백만이 되겠지요.&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;이로부터 가능한 모든 response $y$에 대한 full distribution을 얻을 수 있습니다.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;아쉽지만 복잡한 시스템들에서는 함수 형태가 계산이 쉽지 않으며 weights의 원소 개수가 매우 많기 때문에 위와 같은 계산이 불가능해집니다. 따라서 fully Bayesian modeling에서는 이런 분포들을 보통 근사를 하여 사용하지요. 전통적인 기계학습에서는 a single value (point estimate)를 할당하구요. 솔직히 썩 마음에 차지는 않지요.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;br /&gt;이번 시리즈물이 기계학습 모델들을 이해하는데 유용한 글이었길 바랍니다. 이런 알고리즘들에 대한 보다 깊은 이해는 사실상 완전히 새로운 것은 없다는 점과 이런 알고리즘들은 보다 나은 방향으로 발전시킬 수 있는 비전을 보여주지요.&lt;br /&gt;&lt;br /&gt;긴 글 읽어주셔서 감사합니다. 이제 수영장에서 나와서 타월 하나 집고서&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;import sklearn&lt;/span&gt;하러 떠나봅시다.&lt;br /&gt;&lt;img alt=&quot;drink and towel&quot; class=&quot;img-responsive&quot; src=&quot;https://www.washingtonian.com/wp-content/uploads/2015/05/Pool520-994x664.jpg&quot; /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/3983669769096239575/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html#comment-form' title='3개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3983669769096239575'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/3983669769096239575'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html' title='Minimizing the Negative Log-Likelihood, in Korean (3)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><thr:total>3</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1241518821086770705</id><published>2018-02-05T18:07:00.001+09:00</published><updated>2018-08-04T22:23:53.872+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (2)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;https://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor.html&quot;&gt;저번 글&lt;/a&gt;에 이어서 output 함수들이 왜 그런 형태로 나오는지 알아보도록 하겠습니다. 잠시 복습을 하고 넘어가시죠!&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;h2&gt;Functional form&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;이 글에서 다루고 있는 세 모델들은 각각 서로 다른 함수를 바탕으로 예측을 하는데요:&amp;nbsp; 각각 identity function (i.e. no-op), sigmoid function, and softmax function. Keras로 output layer를 만들어보면 명확합니다:&lt;/div&gt;&lt;div&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;softmax&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;이 단락에서는,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Gaussian, binomial 그리고 multinomial distributions가 같은 functional form으로 나타낼 수 있다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;이 common functional form에서 세 모델들의 output function (identity, sigmoid, softmax)가 자연스럽게 유도된다는 것을 보이겠습니다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;마치 다음 그림과 같이 생각할 수 있겠네요. 세 가지 분포가 들어가서 세 가지 output functions이 나오는 것이죠. (그림이 이상한데? -_-; 뭐 아무튼 하나의 functional form으로 설명이 가능해서 저렇게 표현할 수 있다고 생각하면 될 듯합니다.)&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;bottleneck&quot; class=&quot;img-responsive&quot; src=&quot;https://electric-cloud.com/wp-content/uploads/use-case-graphic_bottleneck.png&quot; /&gt;&lt;/div&gt;&lt;br /&gt;여기서 병목에 해당하는 개념은 확률 분포의&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_family&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; text-align: start; text-decoration-line: none;&quot;&gt;&quot;exponential family&quot;&lt;/a&gt;가 되겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Exponential family distributions&lt;/h2&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;In probability and statistics, an exponential family is a set of probability distributions of a certain form, specified below. This special form is chosen for mathematical convenience, on account of some useful algebraic properties, as well as for generality, as exponential families are in a sense very natural sets of distributions to consider.&lt;br /&gt;- 위키피디아&lt;/blockquote&gt;저(글쓴이)는 위의 설명을 그리 좋아하지 않습니다. 매우 모호하다는 점에서 특히&amp;nbsp;더 그렇습니다. 여기서 진실은 exponential functions이 우리가 잘 알고 사용하기 좋아하는 고전적인 activation과 loss functions을 하나의 틀에서 유도하는데 매우 좋은 도구라는 점입니다. 저는 &quot;mathematical convenience, on account of some useful algebraic properties, etc.&quot; 부분에 좀 더 집중해서 &quot;certain form&quot;이라는 것이 괴랄한 이유로 만들어진 것이 아니란 점을 얘기하고자 합니다.&lt;br /&gt;&lt;br /&gt;Exponential family에 속하는 분포는 다음과 같은 형태로 나타낼 수 있습니다:&lt;br /&gt;$$P(y; \eta) = b(y)\exp(\eta^T T(y) - a(\eta))$$ 여기서&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta$는 분포의 &lt;i&gt;canonical parameter&lt;/i&gt;입니다 (We will hereby work with the single-canonical-parameter exponential family form).&lt;/li&gt;&lt;li&gt;$T(y)$는 &lt;i&gt;sufficient statistic&lt;/i&gt;입니다. (많은 경우 $T(y)=y$입니다.)&lt;/li&gt;&lt;li&gt;$a(\eta)$는 &lt;i&gt;log partition function&lt;/i&gt;으로써 분포를 정규화하는데 쓰입니다. (더 깊은 논의는 다음 포스팅에서 보실 수 있습니다:&amp;nbsp;&lt;a href=&quot;https://cavaunpeu.github.io/2017/04/19/deriving-the-softmax-from-first-principles/&quot; style=&quot;background-color: white; box-sizing: border-box; color: #d9230f; font-family: &amp;quot;open sans&amp;quot;, &amp;quot;helvetica neue&amp;quot;, helvetica, arial, sans-serif; text-align: left;&quot;&gt;Deriving the Softmax from First Principles&lt;/a&gt;&lt;span style=&quot;background-color: white; font-family: &amp;quot;open sans&amp;quot; , &amp;quot;helvetica neue&amp;quot; , &amp;quot;helvetica&amp;quot; , &amp;quot;arial&amp;quot; , sans-serif; text-align: left;&quot;&gt;.&lt;/span&gt;)&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;따라서 $T,a,b$를 정하면 분포의 family (or set)가 정해지고 이는 $\eta$로 parameterized 됩니다. 우리가 $\eta$를 바꿀 때마다 해당 familiy 안의 다른 분포를 만들 수 있겠죠. 이는 $Pr(heads)=0.6$인 동전이&amp;nbsp;$Pr(heads)=0.7$인 동전과는 다른 분포를 갖는 것으로 설명할 수 있습니다.&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s1600/bob.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;250&quot; src=&quot;https://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s400/bob.jpg&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;b&gt;어때요, 참 쉽죠?&lt;/b&gt;&lt;/div&gt;&lt;br /&gt;그럼 하나씩 살펴볼까요?&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Gaussian distribution&lt;/h2&gt;&lt;br /&gt;편의를 위해 여기서는 단일 매계변수 형태를 다루고 있기 때문에 $\sigma^2$가 $1$로 알려져있다고 가정해보겠습니다.&lt;br /&gt;$$\begin{align*}&lt;br /&gt;P(y\vert \mu, \sigma^2)&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\frac{(y - \mu)^2}{2\sigma^2}\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{(y - \mu)^2}{2}\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}(y^2 - 2\mu y + \mu^2)\bigg)}\\&lt;br /&gt;&amp;amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}y^2\bigg)} \cdot \exp{\bigg(\mu y - \frac{1}{2}\mu^2\bigg)}\\&lt;br /&gt;\end{align*}$$ 여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta=\mu$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = \frac{1}{2}\mu^2$&lt;/li&gt;&lt;li&gt;$b(y) = \frac{1}{\sqrt{2\pi}}\exp{(-\frac{1}{2}y^2)}$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;라고 해보겠습니다.&lt;br /&gt;&lt;br /&gt;마지막으로 $a(\eta)$는 다음과 같습니다:&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= \frac{1}{2}\mu^2\\&lt;br /&gt;&amp;amp;= \frac{1}{2}\eta^2&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;h2&gt;Binomial distribution&lt;/h2&gt;&lt;br /&gt;이항 분포에 대해 앞서 글에서 정의한 적이 있었죠? 여기서는 좀 더 단순하게 나타내서 이항 분포가 실제로 exponential familiy에 속한다는 것을 보일 것입니다. 여기서 $\phi$는 true class를 관측할 활률입니다. 즉, $Pr(cat) = 0.7&amp;nbsp;\implies \phi = 0.3$&lt;br /&gt;\begin{align*}&lt;br /&gt;P(y\vert \phi)&lt;br /&gt;&amp;amp;= \phi^y(1-\phi)^{1-y}\\&lt;br /&gt;&amp;amp;= \exp\bigg(\log\bigg(\phi^y(1-\phi)^{1-y}\bigg)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(y\log{\phi} + \log(1-\phi) - y\log(1-\phi)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\log\bigg(\frac{\phi}{1-\phi}\bigg)y + \log(1-\phi)\bigg) \\&lt;br /&gt;\end{align*}&lt;br /&gt;여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg)$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = -\log(1-\phi)$&lt;/li&gt;&lt;li&gt;$b(y) = 1$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;입니다. (어? 여기서 $\phi$가 $\eta$에 대한&amp;nbsp;&lt;b&gt;sigmoid 함수&lt;/b&gt;라는 걸 눈치채신 분?)&lt;br /&gt;&lt;br /&gt;마지막으로 분포의 매계변수 $\eta$에 대해 $a(\eta)$를 나타내면:&lt;br /&gt;$$\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg) \implies \phi = \frac{1}{1 + e^{-\eta}}$$&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= -\log(1-\phi)\\&lt;br /&gt;&amp;amp;= -\log\bigg(1-\frac{1}{1 + e^{-\eta}}\bigg)\\&lt;br /&gt;&amp;amp;= -\log\bigg(\frac{1}{1 + e^{\eta}}\bigg)\\&lt;br /&gt;&amp;amp;= \log(1 + e^{\eta}).\\&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Multinomial distribution&lt;/h2&gt;&lt;br /&gt;이항 분포처럼 다항 분포를 좀 더 단순한 형태로 표현해보겠습니다. $\pi$가 $K$ classes의 class 확률들의 벡터라 할 때, (여기서 $k$가 각 class들을 의미합니다.)&lt;br /&gt;$$P(y\vert \pi) = \prod\limits_{k=1}^{K}\pi_k^{y_k}$$&lt;br /&gt;복잡하게 보일 수 있지만 사실 저 수식이 의미하는 바는 $Pr(y=k)$가 class $k$에 대한 확률이라는 뜻입니다. 예를 들어,&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;일 때, 다음과 같이 계산하면 된다는 말이죠:&lt;br /&gt;\begin{align*}&lt;br /&gt;\Pr(y = \text{snow} = [0, 1, 0, 0])&lt;br /&gt;&amp;amp;= (.14^0 * .37^1 * .03^0 * .46^0)\\&lt;br /&gt;&amp;amp;= .37\\&lt;br /&gt;\end{align*}&lt;br /&gt;다시 exponential family 형태로 돌아가서 확장해보면:&lt;br /&gt;\begin{align*}&lt;br /&gt;P(y\vert \pi)&lt;br /&gt;&amp;amp;= \prod\limits_{k=1}^{K}\pi_k^{y_k}\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K}y_k\log{\pi_k}\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} + \bigg(1 - \sum\limits_{k=1}^{K-1}y_k\bigg)\log\bigg(1 - \sum\limits_{k=1}^{K-1}\pi_k\bigg)\bigg)\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} - \bigg(\sum\limits_{k=1}^{K-1}y_k\bigg) \log(\pi_K) + \log(\pi_K)), \quad \text{where}\ \pi_K = 1 - \sum\limits_{k=1}^{K-1}\pi_k\\&lt;br /&gt;&amp;amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}\log\bigg(\frac{\pi_k}{\pi_K}\bigg) y_k + \log(\pi_K)\bigg)&lt;br /&gt;\end{align*}&lt;br /&gt;여기서,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$\eta = \log\bigg(\frac{\pi_k}{\pi_K}\bigg)$&amp;nbsp;&lt;/li&gt;&lt;li&gt;$T(y)=y$&lt;/li&gt;&lt;li&gt;$a(\eta) = -\log(\pi_K)$&lt;/li&gt;&lt;li&gt;$b(y) = 1$&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;마지막으로,&lt;br /&gt;\begin{align*}&lt;br /&gt;\eta_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \log\bigg(\frac{\pi_k}{\pi_K}\bigg) \implies\\&lt;br /&gt;\frac{\pi_k}{\pi_K}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k} \implies\\&lt;br /&gt;\sum\limits_{k=1}^K \frac{\pi_k}{\pi_K}&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\frac{1}{\pi_K}\sum\limits_{k=1}^K \pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\frac{1}{\pi_K} \cdot 1&lt;br /&gt;&amp;nbsp; &amp;amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\&lt;br /&gt;\pi_K&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;이고, 두 번째 줄에 마지막 결론을 껴넣어주면:&lt;br /&gt;\begin{align*}&lt;br /&gt;\frac{\pi_k}{\frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k}\ \implies\\&lt;br /&gt;\pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;(짜잔! $\pi_k$가 $\eta_k$에 대한&amp;nbsp;&lt;b&gt;softmax function&lt;/b&gt;이 나오네요!)&lt;br /&gt;&lt;br /&gt;마지막으로 $a(\eta)$를 정리하면 아래와 같습니다:&lt;br /&gt;\begin{align*}&lt;br /&gt;\frac{\pi_k}{\frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}}&lt;br /&gt;&amp;nbsp; &amp;amp;= e^{\eta_k}\ \implies\\&lt;br /&gt;\pi_k&lt;br /&gt;&amp;nbsp; &amp;amp;= \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}&lt;br /&gt;\end{align*}&lt;br /&gt;\begin{align*}&lt;br /&gt;a(\eta)&lt;br /&gt;&amp;amp;= -\log(\pi_K)\\&lt;br /&gt;&amp;amp;= \log(\pi_K^{-1})\\&lt;br /&gt;&amp;amp;= \log\Bigg(\frac{\sum\limits_{k=1}^K e^{\eta_k}}{e^{\eta_K}}\Bigg)\\&lt;br /&gt;&amp;amp;= \log\Bigg(\sum\limits_{k=1}^K e^{\eta_k}\Bigg).\\&lt;br /&gt;\end{align*}&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 수학을 따라 오다가 길을 잃은 분들을 위해 각 모델에서 우리가 관심있는 response variable들을 $\eta$에 대해 하나로 모아 정리해보면 아래와 같습니다:&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span style=&quot;color: red;&quot;&gt;Linear regression (Gaussian distribution): $\mu = \eta$&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;Logistic regression (Binomial distribution): $\phi = \frac{1}{1 + e^{-\eta}}$&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&quot;color: red;&quot;&gt;Softmax regression (Multinomial distribution): $\pi_k = \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}$&lt;/span&gt;&lt;/blockquote&gt;&lt;h2&gt;Generalized linear models&lt;/h2&gt;&lt;br /&gt;각 모델은 output으로 response variable을 뱉습니다. 이 response variable들이 어떤 (exponential family) 분포를 따라 퍼져있겠죠. 그러나 이 분포의 canonical parameter 즉 우리가 넣는 값은 관측마다 달라질 것입니다.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;를 예측하는 logistic regression 모델을 생각해보겠습니다. 우리가 고양이 그림을 넣으면 주어진 분포에 따라 &quot;고양이&quot;라는 값이 나올 것입니다.&lt;br /&gt;$$P(\text{outcome}) =&lt;br /&gt;\begin{cases}&lt;br /&gt;1 - \phi &amp;amp; \text{outcome = cat}\\&lt;br /&gt;\phi &amp;amp; \text{outcome = dog}\\&lt;br /&gt;\end{cases}$$&lt;br /&gt;우리가 개 그림을 넣으면 마찬가지로 같은 분포에 따라 &quot;개&quot;가 튀어나오겠죠.&lt;br /&gt;&lt;br /&gt;당연하지만 $\phi$ 값은 각각의 경우마다 항상 달라야합니다. 앞선 경우에 대해서는&amp;nbsp; 모델의 $\phi$ 값이 작아서 $1-\phi \approx 1$의 확률로 고양이를 뱉어내야겠지만 뒤의 경우에 대해서는 $\phi$ 값이 커서 &quot;개&quot;라는 출력이 $\phi \approx 1$의 확률로 나올 수 있도록 해야겠죠.&lt;br /&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 이 부분이 헷갈리신다면 정상입니다. 뭐 이렇게 어렵게 써두었는지... 그냥 $\phi$가 canonical parameter $\eta$를 변수로 가지는 값이라고 생각하시면 됩니다. 예를 들어 신경망같은 parametric 개/고양이 판별기 모델에 고양이 혹은 개 그림을 (즉 다른 input들을) 넣으면 나올 output probability가 그때그때 다르죠? 이 얘기를 하려는 겁니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;그러면 각 input에 대해 다음을 생각해보겠습니다:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;$y_i \sim \mathcal{N}(\mu_i, \sigma^2)$일 때, Linear regression에서 $\mu_i$란?&amp;nbsp;&lt;/li&gt;&lt;li&gt;$y_i \sim \text{Binomial}(\phi_i, 1)$일 때, logistic regression에서 $\phi_i$란?&lt;/li&gt;&lt;li&gt;$y_i \sim \text{Multinomial}(\pi_i, 1)$일 때, softmax regression에서 $\pi_i$란?&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;여기서 $i$라는 인덱스가 새로 붙은 것이 보이시죠. 이 $i$ 덕에 위에서 설명하고자 한 dynamic이 좀 더 명백해집니다. 즉, 주어진 모델에서 각 입력에 따라 해당하는 canonical parameter가 정해지고 이 녀석이 response variable의 분포에 영향을 미치게 됩니다. 예를 들면 logistic regression 모델에서 고양이 그림을 보게 되면 $\phi_i\approx0$이 되도록 해야겠다는 말을 좀 더 복잡하게 한 것입니다.&lt;br /&gt;&lt;br /&gt;그럼 10-feature input $x$에서 이런 canonical parameter로 어떻게 보내면 될까요? 가장 간단하게 linear combination을 생각해볼 수 있습니다:&lt;br /&gt;$$\eta = \theta^Tx$$ &lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) Keras code에 Dense layer 하나 붙은 모델인 것만 보셔도 짐작하실 수 있습니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;h2&gt;Linear regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx=\mu_i.$ 이것이 바로 우리가 정규 분포를 만들 때 필요한 변수입니다.&lt;br /&gt;&lt;b&gt;&amp;gt; The identity function (i.e a no-op) gives us the mean of the response variable. This mean is required by the normal distribution, which dictates the outcomes of the continuous-valued target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Logistic regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx = \log\bigg(\frac{\phi_i}{1-\phi_i}\bigg).$ $\phi_i$에 대해 문제를 풀어야 하겠습니다. $\phi_i = \frac{1}{1 + e^{-\eta}}$였던 것 기억하시죠?&lt;br /&gt;&lt;b&gt;&amp;gt; The sigmoid function gives us the probability that the response variable takes on the positive class. This probability is required by the binomial distribution, which dictates the outcomes of the binary target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;결국 $\phi_i$라는 함수가 하는 녀석은 우리가 앞서 소개했던 내일의 날씨 예측하는 날씨 분포가 하는 일과 같습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;span style=&quot;color: red;&quot;&gt;* (편집자 주) 그러니까 날씨 분포의 경우 마치 lookup table처럼 각 input $x$에 대해 딱 내뱉는 확률 값이 정해져있는 일대일 대응 함수인데,&amp;nbsp;$\phi_i$의 경우는 canonical parameter $\eta=\theta^Tx$로 표현되는 함수라는 말입니다.&amp;nbsp;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Softmax regression&lt;/h2&gt;&lt;br /&gt;$\eta = \theta^Tx = \log\bigg(\frac{\pi_k}{\pi_K}\bigg).$ $\pi_i$는 벡터이기 때문에 $\pi_i$에 대해 풀기 위해서 각 $\pi_{k,i}$에 대해 문제를 풀어야합니다.&lt;br /&gt;이 역시도 위에서 했었죠: $\pi_{k, i} = \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}.$ 바로 softmax function입니다.&lt;br /&gt;&lt;b&gt;&amp;gt; The softmax function gives us the probability that the response variable takes on each of the possible classes. This probability mass function is required by the multinomial distribution, which dictates the outcomes of the multi-class target $y$.&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;좋습니다 이제 다 살펴봤네요. 흠 그런데 왜 하필 linear model, $\eta = \theta^Tx$이어야 했을까요? 앤드류 응 교수님 말을 차용하자면 이것은 &quot;모델 디자인&quot; 혹은 &quot;선택&quot;의 문제입니다. 여기서 선형 조합이 자주 사용되는 이유를 굳이 꼽자면:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;아마도 선형 조합(linear combination)이 canonical parameter에 대한 각 feature에 영향을 줄 수 있는 가장 쉬운 방법일 것이기 때문이다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;선형 조합이 단순히 $x$뿐만 아니라 $x$에 대한 함수에 대해서도 $\eta$에 대해 선형으로 변화한다고 하면 좀 더 복잡한 형태를 만들 수 있다. 즉, 우리는 모델을 $\eta = \theta^T\Phi(x)$와 같이 쓸 수 있고, 여기서 $Phi$는 우리의 feature에 대한 복잡한 변형(transformation)을 주는 operator를 의미한다. 이 부분이 선형 조합의 단순함을 조금은 덜하게 만들어준다고 할 수 있다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Loss function&lt;/h2&gt;&lt;br /&gt;이제 지금까지 각 response variable이 어떤 식으로 만들어지는지 살펴봤습니다. 그리고 분포들의 parameters가 각 input에 대해 어떻게 계산되는지도 보았죠. 그러면 뭐가 남았을까요? 맞습니다. 이제 어떻게 하면 어떤 parameters가 좋은지 정량화할 수 있을지가 궁금하실겁니다?&lt;span style=&quot;color: red;&quot;&gt; (음? ㅋㅋ)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;자! 이 부분도 매우매우 재미있지만 이번에도 역시 글이 매우 길어졌고 제 글 체력도 다하였기에 다음 글에서 이어가도록 하겠습니다.&lt;br /&gt;&lt;br /&gt;그러면! &lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html&quot;&gt;다음 글&lt;/a&gt;에서 뵙겠습니다. (To be continued)&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2&gt;&lt;b style=&quot;text-align: justify;&quot;&gt;다음 읽을거리&lt;/b&gt;&lt;/h2&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;ul&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html&quot;&gt;Minimizing the Negative Log-Likelihood, in Korean (3)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/backpropagation.html&quot;&gt;Backpropagation 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/rnn-implementation-using-only-numpy.html&quot;&gt;RNN 설명 예제와 함께 완전히 이해하기&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/auto-encoding-variational-bayes-vae-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 VAE (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html&quot; target=&quot;_blank&quot;&gt;초짜 대학원생 입장에서 이해하는 GANs (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/01/domain-adversarial-training-of-neural.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Domain-Adversarial Training of Neural Networks (DANN) (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는&amp;nbsp;DCGAN&amp;nbsp;(1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 Unrolled GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/03/infogan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 InfoGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/04/lsgan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 LSGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.kr/2017/04/began-boundary-equilibrium-gan-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 BEGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/06/f-gan.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 f-GAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/02/energy-based-generative-adversarial-nets-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 EBGAN (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2017/05/marginal-value-of-adaptive-gradient-methods-in-ML.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 The Marginal Value of Adaptive Gradient Methods in Machine Learning (1)&lt;/a&gt;&lt;/li&gt;&lt;li style=&quot;text-align: justify;&quot;&gt;&lt;a href=&quot;http://jaejunyoo.blogspot.com/2018/01/support-vector-machine-1.html&quot;&gt;초짜 대학원생의 입장에서 이해하는 SVM (1)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content><link rel='replies' type='application/atom+xml' href='http://jaejunyoo.blogspot.com/feeds/1241518821086770705/comments/default' title='댓글'/><link rel='replies' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html#comment-form' title='2개의 덧글'/><link rel='edit' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1241518821086770705'/><link rel='self' type='application/atom+xml' href='http://www.blogger.com/feeds/6029100972813152037/posts/default/1241518821086770705'/><link rel='alternate' type='text/html' href='http://jaejunyoo.blogspot.com/2018/02/inimizing-negative-log-likelihood-in-kor-2.html' title='Minimizing the Negative Log-Likelihood, in Korean (2)'/><author><name>Jaejun Yoo</name><uri>http://www.blogger.com/profile/10226095526284477166</uri><email>noreply@blogger.com</email><gd:image rel='http://schemas.google.com/g/2005#thumbnail' width='32' height='32' src='//3.bp.blogspot.com/-kqpPqzNBid0/XNATqTaP9SI/AAAAAAAADIE/eDvlrj9Gq6wKjCr6d1jc0HGlLRCmWmBYgCK4BGAYYCw/s61/profile.jpg'/></author><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://2.bp.blogspot.com/-mftpDg6NOus/Wnfze261bhI/AAAAAAAACiw/UsVc7paA_QAr5t2fEQ0gXRTLfW2ebyIawCK4BGAYYCw/s72-c/bob.jpg" height="72" width="72"/><thr:total>2</thr:total></entry><entry><id>tag:blogger.com,1999:blog-6029100972813152037.post-1351174858330079744</id><published>2018-02-05T11:51:00.000+09:00</published><updated>2018-08-05T23:07:54.006+09:00</updated><category scheme="http://www.blogger.com/atom/ns#" term="kr"/><category scheme="http://www.blogger.com/atom/ns#" term="machine learning"/><category scheme="http://www.blogger.com/atom/ns#" term="mathematics"/><title type='text'>Minimizing the Negative Log-Likelihood, in Korean (1)</title><content type='html'>&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;span style=&quot;color: blue; font-size: small;&quot;&gt;* This is the Korean translation of the original post by &lt;a href=&quot;http://willwolf.io/&quot;&gt;will wolf&lt;/a&gt; under his permission. You can find the English version at his blog: &lt;a href=&quot;http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;span style=&quot;font-size: xx-small;&quot;&gt;저자의 허락을 득하고 번역하여 옮깁니다.&amp;nbsp;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;우리가 자주 쓰는 loss function들이 어떻게 나오게 되었는지, 예들 들자면 cross-entropy error와 Euclidean error는 어디서 유래한 것인지를 알려주는 좋은 글이 있어 공부할 겸 번역을 해보고자 합니다. 최대한 원 저자의 글에 가깝게 번역하려 했으며 번역을 할 때 필연적으로 생기는 어색한 표현을 피하기 위해 제가 먼저 내용을 다 소화한 이후 의역을 하였습니다. 이 외에 제가 좀 더 자세히 덧붙여 설명을 하고 싶은 부분들은 추가하되 (* 편집자 주,&amp;nbsp;빨간색)으로 명시해두겠습니다.&amp;nbsp;&lt;span style=&quot;color: red;&quot;&gt;(* 편집자 주) 2017년 6월에 시작한 글을 이제야 끝내다니... ㅎㅎ밀린 숙제하는 느낌이네요;; 졸업하니 정말 좋다!!!ㅋㅋㅋ&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;b&gt;&lt;span style=&quot;color: red;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/b&gt;&lt;/div&gt;&lt;h2 style=&quot;text-align: center;&quot;&gt;Minimizing the Negative Log-Likelihood, in Korean (:p)&lt;/h2&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;저(글쓴이)는 Kaggle에서부터 기계학습에 대한 공부를 시작했습니다.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;Kaggle에는 데이터도 있고 모델 (즉, estimator) 그리고 loss function to optimize가 있어서 공부하기가 좋았고 여기(Kaggle)에서 많은 것을 배울 수 있었습니다.&quot;&lt;/blockquote&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;그 중 몇 가지를 꼽아보자면, &quot;regression model은 continuous-valued real numbers를 예측하는데 쓰이고, classification model들은 &#39;빨강&#39; &#39;초록&#39; &#39;파랑&#39; 등을 예측하는데 쓰인다는 것&quot;, &quot;보통 regression에서는 mean absolute error를 쓰며 classification에서는 cross-entropy loss를 사용한다는 것&quot;, &quot;loss 함수들을 줄이기 위해 stochastic gradient descent를 사용한다는 것&quot; 등을 자연스래 배웠고, 마지막으로 이런 model들을 fit하고 싶다면 그저 sklearn 라이브러리를 사용하면 된다는 것도 알게 되었습니다.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;(최소한 기술적인 측면에서는) 이 정도만 잘 알아도 데이터 사이언티스트로써 혹은 취업을 위해서도 충분했습니다. 산업 현장에서는 이런 off-the-shelf algorithm만으로도 회사의 이익을 매우 쉽게 끌어올릴 수 있지요.&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&quot;그래 이 정도면 충분해, 자동차 경주에서 이기고 있는 선수가 굳이 자동차가 어떻게 만들어지는지까지 알 필요는 없잖아?&quot;&lt;/blockquote&gt;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&quot;scikit-learn fit and predict,&quot; 하는 것이 익숙해졌을 무렵 저는 통계를 슬슬 공부하기 시작했습니다. 두 가지 분야가 서로 겹치는 것이 많다는 것을 알고는 있었지만, 여전히 뭔가를 분석할 때는 두 분야를 서로 다른 평행한 sub-fields로 적용하곤 했습니다. 그러니까 classification model을 만들 때는 scikit-learn을 사용하고 signup counts를 추측(infer)할 때는 Poisson distribution and MCMC를 사용하는 식으로 말이죠.&amp;nbsp;&lt;/div&gt;&lt;div style=&quot;text-align: justify;&quot;&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;하지만 교과서 공부, 논문 읽기, 소스 코드 읽기 및 쓰기, 블로그 작성 등 기계 학습에 대해 깊이 파고 들면서 내가 한 일들을 묘사하는데 사용되는 몇몇 용어들이 생각보다 이해하기 어렵다는 것을 알게 되었습니다. 예를 들자면 categorical cross-entropy loss가 무엇인지, 어떤 일을 하며 어떤 식으로 정의되는지는 이해했지만 도대체 &lt;b&gt;&lt;i&gt;&quot;왜 이런 녀석들을 negative log-likelihood라 부르는 것인가?&quot;&lt;/i&gt;&lt;/b&gt;와 같은 의문들이 생기기 시작했습니다.&lt;br /&gt;&lt;br /&gt;시간이 지나 이제는 위 질문에 대해 적어도 두 가지 정도는 알게 되었습니다:&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;우리가 &quot;기계 학습&quot;이라 부르는 기술들(classification and regression models)은 거의 대부분 통계를 기반으로 하고 있다. 때문에 용어들이 두 분야에서 혼용되고 있다.&lt;/li&gt;&lt;li&gt;대부분의 용어가 새로 만들어진 것이 아니다.&amp;nbsp;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;이 글에서는 제가 깨달은 사실을 바탕으로 우리가 잘 알고 있고, 자주 사용하며, 어떻게 사용하는지 알고 있는 세가지 모델들이 수학적으로 어떤 역할을 하는 것인지 설명하고자 합니다. 기본적으로 독자들이 기계학습과 통계학 분야의 개념들에 대해 익숙하다는 가정 하에 글을 쓸 것이며 두 분야 사이의 연관성에 대해 더욱 깊은 이해를 위해 서서히 파고들 생각입니다. 수학이 들어가긴 하지만 딱 필요한만큼만 사용할 것이고 유도의 대부분은 결과없이 건너 뛸 수도 있습니다.&lt;br /&gt;&lt;br /&gt;어떤 predictive model을 제품화할 때는,&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; white-space: pre-wrap;&quot;&gt;import sklearn&lt;/span&gt;으로 다른 사람이 만들어 둔 모델을 사용하는 것이 최고의 방법이자 보통 우리가 알고 있는 방식입니다. 그렇기에 이 글은 여기서 시작해서 결국에는 다시 이 지점으로 돌아올 것입니다. 다만 이전과 다른 점은 그 밑바닥을 잘 알고 사용할 수 있겠습니다.&amp;nbsp;(글쓴이는 이 과정을 마치 수영장에서 다이빙 하고, 밑바닥을 찍고, 다시 표면으로 올라오는 모습과 비슷하게 생각했는지 같은 은유를 수차례 사용합니다.) Lemma들은 굵은 글씨체로 작성되어 있습니다.&lt;br /&gt;&lt;br /&gt;먼저 우리가 앞으로 다룰 세 개의 주요 모델들을 만나보시겠습니다. 편의를 위해 코드는 Keras로 통일합니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Linear regression&lt;/span&gt; with mean squared error&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;mean_squared_error&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Logistic regression&lt;/span&gt; with binary cross-entropy loss&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;binary_crossentropy&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;&lt;span style=&quot;color: #990000;&quot;&gt;Softmax regression&lt;/span&gt; with categorical cross-entropy loss&lt;/h2&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,))&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;softmax&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;categorical_crossentropy&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;br /&gt;다음으로 response variable, functional form, loss function, loss function + regularization term 이렇게 네 가지 주요 요소들이 있는데요 앞으로 세 가지 모델들에 대해 각 요소가 어떤 통계적인 의미를 지니는지 알아보도록 하겠습니다 (수영장 밑바닥에서 한 계단씩 올라가겠습니다).&lt;br /&gt;&lt;br /&gt;잠깐! 완전히 잠수하기 전에 준비운동부터 해야겠죠? 몇 가지 중요한 개념들에 대해 정의하고 넘어가겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Random variable&lt;/h2&gt;&lt;br /&gt;저(글쓴이)는 random variable을 &quot;여러가지 다른 값들을 가질 수 있는 것&quot;이라고 정의합니다.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&quot;The tenure of despotic rulers in Central Africa&quot; is a random variable. It could take on values of 25.73 years, 14.12 years, 8.99 years, ad infinitum; it could not take on values of 1.12 million years, nor -5 years.&lt;/li&gt;&lt;li&gt;&quot;The height of the next person to leave the supermarket&quot; is a random variable.&lt;/li&gt;&lt;li&gt;&quot;The color of shirt I wear on Mondays&quot; is a random variable. (Incidentally, this one only has ~3 distinct values.)&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Probability distribution&lt;/h2&gt;&lt;br /&gt;확률 분포란 random variable이 갖는 값을 관측할 likelihood에 대한 일종의 lookup table이라 할 수 있습니다. 주어진 variable이 {비, 분, 진눈깨비, 우박} 중 하나의 값을 가진다고 할 때, 다음과 같이 probability distribution으로 나타낼 수 있습니다:&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;/pre&gt;당연하지만, 모든 값의 합은 1이어야 하지요.&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;확률 질량 함수는 이산 값을 갖는 random variable 확률 분포다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;확률 밀도 함수는 연속 값을 갖는 random variable의 확률 분포를 &lt;b&gt;주는&lt;/b&gt; 함수다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;여기서 &quot;주는&quot;이라고 표현한 까닭은 이 함수 스스로는 lookup table이 아니기 때문이다. 즉 값이 [0,1] 범주 안에서 주어진 random variable에 대해 $Pr(X=0.01), Pr(X=0.001),Pr(X=0.0001),~etc.$를 정의할 수 없다.&amp;nbsp;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;대신 일정 &lt;i&gt;범위&lt;/i&gt;&amp;nbsp; 안에서 어떤 값을 관측할 확률을 알려줄 수 있는 함수를 하나 정의하여 사용할 수 있다: e.g. $Pr(0.01&amp;lt;X&amp;lt;0.4)$&lt;/li&gt;&lt;li&gt;이 것이 확률 밀도 함수이며 $Pr(0\leq X \leq 1)=1$을 만족한다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Entropy&lt;/h2&gt;&lt;br /&gt;엔트로피는 주어진 결과에 도달할 수 있는 방법의 가짓수를 정량화 해줍니다. 8명의 친구들이 두 대의 택시를 나눠타고 브로드웨이 쇼를 보러 가는 것을 상상해보죠. 다음과 같이 두 가지의 시나리오를 생각해보겠습니다:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;네 명씩 택시를 탄다:&lt;/li&gt;&lt;/ul&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# fill the first, then the second&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_1&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# alternate assignments&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_2&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# alternate assignments in batches of two&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_3&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;c1&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 153 , 136); font-style: italic;&quot;&gt;# etc.&lt;/span&gt;&lt;/pre&gt;&lt;ul&gt;&lt;li&gt;모든 친구들이 하나의 택시에 어떻게든 우겨 탄다:&lt;/li&gt;&lt;/ul&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;assignment_1&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]&lt;/span&gt;&lt;/pre&gt;두 번째 경우보다 첫 번째 경우가 가능한 경우의 수가 많기 때문에 첫 번째 결과(outcome)가 더 높은 엔트로피 값을 갖게 됩니다.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;More explicitly,&lt;/h3&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;엔트로피를 확률 분포에 대해 계산을 해보면 다음과 같습니다:&lt;br /&gt;$$H(p)=-\sum_{i=1}^n p_i \log p_i$$&lt;br /&gt;이 때,&lt;br /&gt;&lt;ul&gt;&lt;li&gt;총 서로 다른 n개의 이벤트가 존재한다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;각 이벤트 $i$는 $p_i$의 확률을 갖는다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;엔트로피는 가능한 이벤트들에 대한 &lt;i&gt;weighted-average log probability&lt;/i&gt;이고, (이는 수식에서 더 명백히 알 수 있는데) 분포에 내재한 불확실성을 측정하는 방법이라 할 수 있습니다. 즉, 어떤 이벤트에 대해 엔트로피가 높다는 것은 해당 결과값을 얻을 것이라는 믿음에 대한 확실성이 덜하다는 것을 뜻하죠.&lt;br /&gt;&lt;br /&gt;위에서 언급한 확률 분포에 대해 엔트로피를 계산해보겠습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;46&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot; style=&quot;box-sizing: border-box; color: rgb(153 , 0 , 0); font-weight: bold;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;prob_dist&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;):&lt;/span&gt;&lt;br /&gt;    &lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 134 , 179);&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot; style=&quot;box-sizing: border-box; color: #007020; font-weight: bold;&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;prob_dist&lt;/span&gt;&lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;])&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;1.1055291211185652&lt;/span&gt;&lt;/pre&gt;비교를 위해 두 개의 분포를 더 만들어서 각각의 엔트로피들을 계산해보겠습니다.&lt;br /&gt;&lt;pre style=&quot;background-color: rgb(247, 247, 255) !important; border-radius: 3px !important; border: 1px solid rgb(232, 232, 232) !important; box-sizing: border-box; color: #444444; font-family: Menlo, Monaco, Consolas, &amp;quot;Courier New&amp;quot;, monospace; font-size: 13px !important; line-height: 1.42857; margin-bottom: 24px; margin-top: 24px; overflow-x: auto !important; overflow-y: auto; padding: 8px 12px !important; text-align: start; white-space: pre-wrap; word-break: break-all; word-wrap: break-word;&quot;&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_2&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_3&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;rain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;snow&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;sleet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mo&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;03&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot; style=&quot;box-sizing: border-box; color: rgb(221 , 17 , 68);&quot;&gt;&#39;hail&#39;&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot; style=&quot;box-sizing: border-box; color: #666666; font-weight: bold;&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;}&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;0.8304250977453105&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;p_3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;&lt;span class=&quot;n&quot; style=&quot;box-sizing: border-box;&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot; style=&quot;box-sizing: border-box;&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mf&quot; style=&quot;box-sizing: border-box; color: rgb(0 , 153 , 153);&quot;&gt;0.2460287703075343&lt;/span&gt;&lt;/pre&gt;첫 번째 분포에서 우리는 내일 날씨가 어떨 지에 대해 가장 확신이 없습니다. 이에 맞게 엔트로피도 가장 높습니다. 세 번째 분포의 경우 내일의 날씨가 우박일 것이라는 것에 가장 확신을 가질 수 있을 것이고 엔트로피도 역시 작은 것을 볼 수 있습니다.&lt;br /&gt;&lt;br /&gt;마지막으로 택시 예화에서도 마찬가지로 오직 한 가지 경우만 가능한 분포에 비해 여러 갈래로 이벤트가 생길 수 있는 분포에 대해 엔트로피 값이 낮다는 것을 알 수 있습니다.&lt;br /&gt;&lt;br /&gt;이제 준비운동을 마쳤으니 수영장에 들어가야겠지요. 그럼 가장 바닥부터 찍고 다시 수면으로 올라가보겠습니다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Response variable&lt;/h2&gt;&lt;br /&gt;크게 볼 때 우리가 다룰 모델은 다음과 같이 생겼다고 할 수 있습니다. 즉, 아래 그림에서 입력을 받아 출력을 받는 다이아몬드에 해당합니다:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://cavaunpeu.github.io/images/simple_input_output_model.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img alt=&quot;simple input/output model&quot; border=&quot;0&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/images/simple_input_output_model.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;모델들은 예측해야 하는 response variable 즉 $y$의 종류에 따라 바뀌게 되는데요&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Linear regression은 연속된 실수 값을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;temperature&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;li&gt;Logistic regression은 이진 값을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;cat or dog&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;li&gt;Softmax regression은 multi-class label을 예측.&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;red or green or blue&lt;/span&gt;라고 하자.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;각 모델에서 response variable은 서로 다른 값들을 가질 수 있습니다. 이들이 바로 random variables입니다. 그렇다면 각각의 random variable은 어떤 확률 분포를 갖을까요?&lt;br /&gt;&lt;ul&gt;&lt;li&gt;temperature는 true mean $\mu\in(-\infty,\infty)$와 true variance $\sigma^2\in(-\infty,\infty)$를 갖는다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;cat or dog는 고양이 혹은 강아지를 값으로 값는다. 공평한 동전 던지기가 언제나 $Pr(Head)=0.5$이듯이 각 결과에 대한 likelihood는 시간에 따라 변하지 않는다.&amp;nbsp;&lt;/li&gt;&lt;li&gt;red or green or blue는 빨강, 초록, 파랑 중 하나의 값을 갖는다. 마치 공평한 육면체 주사위가 그렇듯이 시간에 따라 likelihood는 바뀌지 않는다.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;이런 가정들은 사실 너무 당연해서 좀 너무 진부하기까지 하지만 앞으로 얘기할 때 중요하게 사용되니 기억해둡시다.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Maximum entropy distributions&lt;/h2&gt;&lt;br /&gt;&quot;Uber의 연간 수익&quot;이라는 연속 값 random variable을 생각해보겠습니다. 마치&amp;nbsp;&lt;span style=&quot;background-color: #f7f7ff; color: #c7254e; font-family: &amp;quot;menlo&amp;quot; , &amp;quot;monaco&amp;quot; , &amp;quot;consolas&amp;quot; , &amp;quot;courier new&amp;quot; , monospace; font-size: 13px; text-align: left; white-space: pre-wrap;&quot;&gt;temperature&lt;/span&gt;와 같이 이 random variable 역시&amp;nbsp;true mean $\mu\in(-\infty,\infty)$와 true variance $\sigma^2\in(-\infty,\infty)$를 갖습니다. 당연하지만 두 경우에 대한 평균과 분산은 서로 다르겠죠. 다음과 같이 가상으로 10개의 값들을 관측했다고 해보겠습니다:&lt;br /&gt;&lt;table class=&quot;table table-hover table-striped&quot; style=&quot;background-color: white; border-collapse: collapse; border-spacing: 0px; box-sizing: border-box; color: black; font-family: &amp;quot;Open Sans&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Helvetica, Arial, sans-serif; font-size: 19px; margin-bottom: 18px; max-width: 100%; width: 100%;&quot;&gt;&lt;thead style=&quot;box-sizing: border-box;&quot;&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;th style=&quot;border-bottom: 2px solid rgb(221, 221, 221); border-top: 0px; box-sizing: border-box; color: #444444; line-height: 1.42857; padding: 8px; text-align: left; vertical-align: bottom;&quot;&gt;uber&lt;/th&gt;&lt;th style=&quot;border-bottom: 2px solid rgb(221, 221, 221); border-top: 0px; box-sizing: border-box; color: #444444; line-height: 1.42857; padding: 8px; text-align: left; vertical-align: bottom;&quot;&gt;temperature&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody style=&quot;box-sizing: border-box;&quot;&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-100&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-50&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-80&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;5&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-20&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;56&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;5&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;65&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;15&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;62&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-10&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;63&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;22&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;60&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;12&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;78&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;background-color: #f9f9f9; box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;70&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;100&lt;/td&gt;&lt;/tr&gt;&lt;tr style=&quot;box-sizing: border-box;&quot;&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;100&lt;/td&gt;&lt;td style=&quot;border-top: 1px solid rgb(221, 221, 221); box-sizing: border-box; line-height: 1.42857; padding: 8px; vertical-align: top;&quot;&gt;-43&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;이를 그려보면 다음과 같습니다:&lt;br /&gt;&lt;img alt=&quot;temperature random variable&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/figures/temperature_random_variable.png&quot; /&gt;&lt;br /&gt;&lt;img alt=&quot;uber random variable&quot; class=&quot;img-responsive&quot; src=&quot;https://cavaunpeu.github.io/figures/uber_random_variable.png&quot; /&gt;&lt;br /&gt;우리는 각 random variable에 대해 실제 확률 분포가 어찌 생겼는지는 모릅니다. 전반적 &quot;형태&quot;도 모르고 그 형태를 제어하는 parameters도 모릅니다. 이럴 때는 어떻게 모델을 정해야할까요? 사실 통계학의 정수가 바로 여기에(미지의 값들을 추측하는 것) 있습니다