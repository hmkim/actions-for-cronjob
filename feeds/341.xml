<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><description>for getting things done</description><title>Lifehacks</title><generator>Tumblr (3.0; @likejazz)</generator><link>https://likejazz.com/</link><item><title>『파킨슨의 법칙』은 깜짝 놀랄 정도로 독설로 가득한 책이다. 여기에는 총 10가지 주제가 등장하는데, 그 중 첫...</title><description>&lt;img src="https://66.media.tumblr.com/f152b22fde06e05cd8e0f84d856df62a/tumblr_pq1rpggGE21qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;『파킨슨의 법칙』은 깜짝 놀랄 정도로 독설로 가득한 책이다. 여기에는 총 10가지 주제가 등장하는데, 그 중 첫 번째가 바로 우리가 잘 아는 ‘파킨슨의 법칙'이다.&lt;/p&gt;

&lt;p&gt;대영제국의 식민지는 1935년과 1939년 사이에 큰 변화가 없었다. 그러나 식민성 직원은 20% 증가했다. 놀라운 점은 1943년 까지 식민지가 크게 줄었고 몇몇 지역은 적에게 넘어갔음에도 불구하고 식민성 직원은 그 사이 두 배가 됐다는 점이다. 1947년 이후에는 식민지들이 속속 자치 정부를 수립하면서 식민성의 관할 지역은 꾸준히 줄어들었다. 하지만 식민성 직원은 그러한 갖가지 상황 속에서도 꾸준히 늘어 원래의 5배 수준이 됐다. 놀랍게도 식민성 직원의 증가 수치는 제국의 규모, 심지어 식민지의 존속 여부와도 아무런 관련이 없었던 것이다.&lt;/p&gt;</description><link>https://likejazz.com/post/184282198948</link><guid>https://likejazz.com/post/184282198948</guid><pubDate>Fri, 19 Apr 2019 08:30:05 +0900</pubDate></item><item><title>이번 달에 읽고 싶은 책은 중국에서 가장 유명한 AI 연구자였던 그리고 지금은 가장 유명한 VC가 된 리카이푸가 쓴 『AI 슈퍼파워』. 그리고 작년부터 아마존 베스트셀러에 올라가...</title><description>&lt;p&gt;이번 달에 읽고 싶은 책은 중국에서 가장 유명한 AI 연구자였던 그리고 지금은 가장 유명한 VC가 된 리카이푸가 쓴 『AI 슈퍼파워』. 그리고 작년부터 아마존 베스트셀러에 올라가 있어 번역서가 나오면 사봐야지 마음 먹었던 월터 아이작슨의 『레오나르도 다빈치』 이다.&lt;/p&gt;

&lt;p&gt;그러나, 이번 달은 책을 사지 않고 건너뛰기로 했다.&lt;/p&gt;

&lt;p&gt;왜냐면 아직 읽지 못하고 쌓아둔 책이 벌써 10여권을 넘어서는등 심각한 수준에 이르렀기 때문. 매우 제한적인 분야의 책만 구입하고, 매일 꾸준히 읽는데도 불구하고 책을 읽는 속도가 새 책이 출간되는 속도를 훨씬 따라가지 못한다.&lt;/p&gt;

&lt;p&gt;한때는 공부하고 싶어도 책을 구할 수 없어 공부할 수 없었던 시절이 있었는데, 이제는 넘쳐나는 책을 다 읽지 못해 공부할 수 없다는 고민을 하고 있다니 &amp;hellip;&lt;/p&gt;</description><link>https://likejazz.com/post/184259427186</link><guid>https://likejazz.com/post/184259427186</guid><pubDate>Thu, 18 Apr 2019 08:30:29 +0900</pubDate></item><item><title>

르쿤, 힌튼, 벤지오 2018 튜링상 수상자로 선정</title><description>&lt;iframe src="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Fyann.lecun%2Fposts%2F10155864810017143&amp;amp;width=500" width="500" height="592" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allow="encrypted-media"&gt;&lt;/iframe&gt;

&lt;p&gt;르쿤, 힌튼, 벤지오 2018 튜링상 수상자로 선정&lt;/p&gt;</description><link>https://likejazz.com/post/184236688912</link><guid>https://likejazz.com/post/184236688912</guid><pubDate>Wed, 17 Apr 2019 08:30:01 +0900</pubDate></item><item><title>한식에 대해 좀 더 알아보고 싶어 집어든 책. 그러나 음식 얘기가 전혀 없고, 음식을 둘러싼 문화 특히 한식 문화에...</title><description>&lt;img src="https://66.media.tumblr.com/7ac1b80a7deae2b09e85949fa3396fd3/tumblr_popn8frVSk1qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;한식에 대해 좀 더 알아보고 싶어 집어든 책. 그러나 음식 얘기가 전혀 없고, 음식을 둘러싼 문화 특히 한식 문화에 대해 얘기한다. 무엇보다 엄청난 레퍼런스가 돋보인다. 교수인 저자는 학자 답게 마치 논문 모음집을 보듯 레퍼런스로 책 전체를 장식한다. 때로는 읽는데 방해가 될 정도로 지나치지만 사실에 기반한 내용이라는 신뢰를 준다. 한 가지 아쉬운 점은 지나치게 레퍼런스 중심의 팩트에만 몰두하다 보니 정작 저자의 의견이 별로 보이지 않는다는 점이다. 책을 다 읽었건만 저자의 의견이 무엇인지는 기억에 남아있지 않다. 아울러 책 형식이 논문과 유사한데다 내용조차 쉽지 않아 굳이 음식을 얘기하는데 이렇게 어렵게 얘기할 필요가 있나 싶다. 조금만 더 쉽게 적었다면 하는 아쉬움이 있다.&lt;/p&gt;</description><link>https://likejazz.com/post/183638507451</link><guid>https://likejazz.com/post/183638507451</guid><pubDate>Sat, 23 Mar 2019 08:30:11 +0900</pubDate></item><item><title>


  체스, 바둑 같은 역사적 사례에서 볼 수 있듯이 인공지능의 혁신은 언제나 computation에 있었다는 것. General하고 scalable한 알고리즘만이 생존하고...</title><description>&lt;iframe src="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Fcarpedm20%2Fposts%2F2102786876467493&amp;amp;width=500" width="500" height="356" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allow="encrypted-media"&gt;&lt;/iframe&gt;

&lt;blockquote&gt;
  &lt;p&gt;체스, 바둑 같은 역사적 사례에서 볼 수 있듯이 인공지능의 혁신은 언제나 computation에 있었다는 것. General하고 scalable한 알고리즘만이 생존하고 세상을 바꾼다는 것.&lt;/p&gt;
  
  &lt;p&gt;세상의 &amp;lsquo;진짜&amp;rsquo; 문제를 '직접&amp;rsquo; 풀고 싶지만, 논문을 읽고 구현하는데 매너리즘에 빠져다면, import tensorflow에서 벗어나 compute에 대해 고민해보는게 도움이 될 것 같다.&lt;/p&gt;
  
  &lt;p&gt;그리고 Transformer-XL, BigGAN, GPT-2와 같은 논문들 뒤에 보이지 않는 엔지니어링을 생각하고, 찾아보고, 구현하는 것.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근에 동료들 과도 이런 얘기를 자주하는데 앞으로 인공지능의 진화는 도메인 지식이 아닌 computation에서 나올 것 같다 라는 얘기. 이는 모든 분야에 해당되며, 지금 내가 하고 있는 NLP 또한 마찬가지. 얼마전에는 당연히 해야할 것 같았던 '형태소 분석&amp;rsquo; 없이도 좋은 결과가 나와 적잖이 당황했던 기억이 난다. 점점 더 general-purpose를 목표로 한 computation이 진화의 핵심이 될 것이며, &amp;ldquo;GPT-2가 보여주었듯 scalable한 모델을 만들고 다룰 수 있느냐 없느냐에 따라 풀 수 있는 문제의 범위와 결과가 크게 바뀐다. 세상이 바뀌듯 우리도 변해야 한다.&amp;rdquo;&lt;/p&gt;</description><link>https://likejazz.com/post/183617811212</link><guid>https://likejazz.com/post/183617811212</guid><pubDate>Fri, 22 Mar 2019 08:30:01 +0900</pubDate></item><item><title>저희 팀에서 만든 “문장 유사도 판별 엔진: 심슨"에 대한 소개 영상이 오늘 공개 되었습니다....</title><description>&lt;iframe width="400" height="225"  id="youtube_iframe" src="https://www.youtube.com/embed/fzXwGQeVNI4?feature=oembed&amp;enablejsapi=1&amp;origin=https://safe.txmblr.com&amp;wmode=opaque" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;저희 팀에서 만든 “문장 유사도 판별 엔진: 심슨"에 대한 소개 영상이 오늘 공개 되었습니다. "심슨"은 카카오 고객 센터 챗봇에 도입된 문장 유사도 판별 엔진으로, 상담원에게 직접 문의 하기 전에 기계가 적절한 질문과 응답을 찾아주는 NLU 엔진입니다. 실제로 도입 이후 고객센터 업무가 10% 정도 줄어들었습니다.&lt;/p&gt;

&lt;p&gt;관련 기사: &lt;a href="https://news.v.daum.net/v/20180808103058187"&gt;https://news.v.daum.net/v/20180808103058187&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;도입 이후 고객에게 좋은 반응을 얻고 있으며, 고객센터 업무에도 도움을 주는 등 양쪽 모두에게 긍정적인 반응을 얻고 있습니다.&lt;/p&gt;

&lt;p&gt;영상을 제작하기 위해 영상팀과 기술팀이 여러차례 미팅을 거쳤고, 덕분에 좋은 영상이 나올 수 있었네요. 홍보팀에서도 일반인 들을 위해 쉬운 소개글을 적어주시는 등 많은 분들이 "심슨"에 도움을 주셨습니다.&lt;/p&gt;

&lt;p&gt;브런치 소개글: &lt;a href="https://brunch.co.kr/@andkakao/98"&gt;https://brunch.co.kr/@andkakao/98&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;여전히 갈 길이 멀지만 보다 똑똑한 NLU 엔진을 만들어, 고객과 고객센터 모두에게 도움이 되도록 지속적으로 노력하겠습니다 ^^&lt;/p&gt;</description><link>https://likejazz.com/post/183528746389</link><guid>https://likejazz.com/post/183528746389</guid><pubDate>Mon, 18 Mar 2019 08:30:13 +0900</pubDate></item><item><title>

EDA(Exploratory Data Analysis)의 중요성</title><description>&lt;iframe src="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Fyoonforh%2Fposts%2F2346969845322546&amp;amp;width=500" width="500" height="525" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allow="encrypted-media"&gt;&lt;/iframe&gt;

&lt;p&gt;EDA(Exploratory Data Analysis)의 중요성&lt;/p&gt;</description><link>https://likejazz.com/post/183504817721</link><guid>https://likejazz.com/post/183504817721</guid><pubDate>Sun, 17 Mar 2019 08:30:12 +0900</pubDate></item><item><title>소프트웨어의 1세대 개발 패러다임이 Debugging-driven이었다면, 2세대는 Test-driven, 3세대는 REPL-driven이 될거라 확신한다.

대표적인...</title><description>&lt;p&gt;소프트웨어의 1세대 개발 패러다임이 Debugging-driven이었다면, 2세대는 Test-driven, 3세대는 REPL-driven이 될거라 확신한다.&lt;/p&gt;

&lt;p&gt;대표적인 Compiled languages인 Java, C++도 jshell, cling의 활약으로 REPL 환경을 갖추기 시작했으며, REPL의 놀라운 생산성은 기존 개발 패러다임을 압도한다.&lt;/p&gt;</description><link>https://likejazz.com/post/183482284274</link><guid>https://likejazz.com/post/183482284274</guid><pubDate>Sat, 16 Mar 2019 08:30:11 +0900</pubDate></item><item><title>굳이 중국책의 번역서까지 읽어야 하나 싶었지만, 칭화대를 나와 JHU에서 박사를 받고 구글에서 근무했다는 저자의...</title><description>&lt;img src="https://66.media.tumblr.com/06cd82cc66221d6b5d89a5c3ddf57adb/tumblr_pnjavnmKVS1qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;굳이 중국책의 번역서까지 읽어야 하나 싶었지만, 칭화대를 나와 JHU에서 박사를 받고 구글에서 근무했다는 저자의 이력에 흥미가 갔고, 아밋 싱할과 함께 일했다는 얘기에 주목했다. 아밋 싱할은 빅 군도트라, 순다 피차이와 함께 한때 구글내 인도계 트로이카 였고, 잘 알다시피 이 중 순다 피차이는 구글의 대표가 됐다.&lt;/p&gt;

&lt;p&gt;무엇보다 책의 목차에 흥미가 갔다. 랭기지 모델 부터 시작해 히든 마르코프 모델, 정보 이론, 형태소 분석 등 책 제목은 “수학의 아름다움"이지만 사실상 "NLP 알고리즘의 아름다움"을 설명하는 책이고, 교과서에서나 볼 수 있는 기초 이론에 대해 딱딱한 설명을 지양하고 일상속의 예제를 곁들여 누구나 알기 쉽게 설명한다. 예를 들어 월드컵 32개국 중 우승팀을 맞출 확률은 이진 검색으로 탐색시 5회가 나온다. 그런데 만약 역대 우승국을 중심으로 우승 후보를 미리 추려낸다면 4회 이내가 될 수도 있다. 섀넌의 엔트로피 수식 &lt;code&gt;H(E)=-\sum_{j=1}^{c}p_j{\log}p_j&lt;/code&gt;에 대입하면 마찬가지로 모든 팀의 우승 확률이 동일할 경우 information entropy는 5비트가 되지만 만약 어느 한 팀의 우승 확률이 높다면 엔트로피는 5비트 미만으로 낮아질 수 있다는 식이다.&lt;/p&gt;

&lt;p&gt;교과서에서나 볼 수 있는 내용을 이렇게 쉽게 설명하는 책은 처음이었고, 구글에서 NLP 연구자로 근무한 저자의 이력 또한 전업 작가나 중국 수준이 아닌 소위 ‘월드 클래스'다. 검색(IR)과 NLP 분야에 조금이라도 관심이 있다면 반드시 읽어야 하는 책으로, 아직 2019년은 10여개월이나 남았지만 이 책은 내가 생각하는 2019년 최고의 책이라고 자신있게 말할 수 있다.&lt;/p&gt;</description><link>https://likejazz.com/post/183104310187</link><guid>https://likejazz.com/post/183104310187</guid><pubDate>Thu, 28 Feb 2019 08:30:13 +0900</pubDate></item><item><title>“알고리즘, 인생을 계산하다"와 비슷하게 일상속의 수학을 다룬다. 그러나 책 분량에 비해 주제를...</title><description>&lt;img src="https://66.media.tumblr.com/8b368d6ff4b6f790586719f3353dd83f/tumblr_pnf8oqNXfn1qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;“알고리즘, 인생을 계산하다"와 비슷하게 일상속의 수학을 다룬다. 그러나 책 분량에 비해 주제를 무려 50여가지로 너무 많이 잡았고, 그러다 보니 하나의 주제를 불과 2-3페이지만 다루고 지나간다. 쉽게 설명한 것 까진 좋지만 수학과 교수가 썼다고는 믿기지 않을 정도로 깊이가 없다. 무엇보다 이 책은 저자가 여성이란 점을 지나치게 강조한다. 저자의 성별을 내세우고, 왜 여성이 육아를 해야 하는지, 여자가 남자와 살면 변기 뚜껑을 몇 번 들어올려야 하는지 따위의 주제가 등장한다. 정작 독자들은 저자의 성별에는 아무런 관심이 없고 그저 수학을 읽고 싶을 뿐인데, 수학책에서 페미니즘을 마주해야 하다니. 가뜩이나 부실한 책 내용이 일견 더 돋보일 뿐이라 아쉽다.&lt;/p&gt;</description><link>https://likejazz.com/post/183081089741</link><guid>https://likejazz.com/post/183081089741</guid><pubDate>Wed, 27 Feb 2019 08:30:14 +0900</pubDate></item><item><title>"권력은 소수의 엘리트가 차지할 것이다. 권력이 그들 손에 들어가는 이유는, 그들은 수학을 알고 당신은 모르기 때문이다."</title><description>“권력은 소수의 엘리트가 차지할 것이다. 권력이 그들 손에 들어가는 이유는, 그들은 수학을 알고 당신은 모르기 때문이다.”&lt;br/&gt;&lt;br/&gt; - &lt;em&gt;에드워드 프렌켈&lt;/em&gt;</description><link>https://likejazz.com/post/183058190528</link><guid>https://likejazz.com/post/183058190528</guid><pubDate>Tue, 26 Feb 2019 08:30:09 +0900</pubDate></item><item><title>빠른 피드백</title><description>&lt;a href="http://likejazz.com/post/167331226235/%EB%B9%A0%EB%A5%B8-%ED%94%BC%EB%93%9C%EB%B0%B1"&gt;빠른 피드백&lt;/a&gt;: &lt;p&gt;항상 얘기하지만 일 잘하는 원칙 첫 번째는 ‘빠른 피드백'이다.&lt;/p&gt;

&lt;p&gt;현대인은 누구나 바쁘다. '바빠서 연락하지 못했다'는건 더 이상 핑계 거리가 되지 않는다. 어차피 아무리 바빠도 무슨 일이든 한 가지 이상은 꼭 하게된다. 바꿔 말하자면 '바빠서 연락하지 못했다'는 얘기는 '당신 일은 다른 일보다 우선 순위가 낮다'는 얘기이기도 하다.&lt;/p&gt;

&lt;p&gt;물론, 내 일이 꼭 최우선이 되어야 할 필요는 없다. 그러나, 우선 순위가 낮다면 적어도 응답을 기다리는 사람을 위해 빠른 피드백을 줘야 한다. 여기서 피드백이란 '문제를 해결했습니다'가 아니라 '문제를 확인했습니다'를 말한다. 그 정도면 충분하다.&lt;/p&gt;

&lt;p&gt;오늘도 4시간 동안 메시지를 보내며, 1시간씩 응답을 기다렸다. 도대체 이 사람은 뭘 하고 있길래 이렇게 응답이 늦을까. 예전 같았으면 당장 전화라도 걸던가 당장 찾아 갔을텐데 몇 번이나 참았는지 모르겠다. 이래서야 원격 근무 따위는 요원한 일 일 수밖에 없다.&lt;/p&gt;</description><link>https://likejazz.com/post/183034796209</link><guid>https://likejazz.com/post/183034796209</guid><pubDate>Mon, 25 Feb 2019 08:30:25 +0900</pubDate></item><item><title>OpenAI GPT-2 단상</title><description>&lt;p&gt;&lt;em&gt;DISCLAIMER: 사내에 올린 글을 편집하여 게시합니다. 이 글의 내용은 개인적인 의견이며 회사의 입장과 무관합니다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;OpenAI가 GPT에 이어 GPT-2를 내놓았습니다. 기존 GPT에 비해 크게 달라진건 없어보이는데, 대신 네트워크 사이즈를 엄청나게 키우고 여러가지 실험을 많이 했네요. 파라미터 수 만 15억개입니다. BERT-Large가 3.4억개이니 단순히 파라미터만 비교하면 GPT-2가 BERT-Large에 비해 4.5배 더 큰 모델이라는 얘기이기도 합니다. Bert-Base에 비해서는 무려 13.6배 더 크네요.&lt;/p&gt;

&lt;p&gt;랭기지 모델은 기존의 전통적인 Statistical Language Modeling을 그대로 따랐습니다. 이 말은 BERT가 Masked Language Model 방식으로 bidirectional 하게 처리하여 성능을 끌어올렸다고 강조하는데 반해 여전히 directional 모델을 고수한다는 얘기이기도 합니다. 아마도 전통적인 모델에 대한 믿음을 실험으로 그대로 이어나간거 같네요.&lt;/p&gt;

&lt;p&gt;domain-specific training을 하지 않았다는 zero-shot 셋팅을 강조합니다. 심지어 QA, translation등의 태스크에서 fine-tuning 없이 그대로 적용한 결과라고 합니다. 그래서인지 성능을 보면 MRC나 QA 쪽은 그다지 높지 않습니다. 하지만 fine-tuning 하지 않았다는 점에서 무척 실용적이고 고무적인 결과입니다. 논문 서두에 &amp;ldquo;However, multitask training in NLP is still nascent.&amp;quot;라 했는데 이제 자신들이 NLP에서 진정한 multi-task learning의 시대를 본격적으로 열어젖혔다는 점을 강조하는거 같네요.&lt;/p&gt;

&lt;p&gt;무엇보다 NLG에서 놀랄만한 성능을 보여줍니다. 원래 랭기지 모델은 여러 NLP tasks의 밑바탕이 되지만 그 자체가 독립적으로 활용될 수도 있습니다. 특히 NLG는 구현 방식이 랭기지 모델의 학습 방식과 일치합니다. 엄청난 데이터로, 엄청난 네트워크로 next tokens를 위한 joint probabilities를 극대화 하니 잘 구축된 랭기지 모델의 성능은 어마어마합니다. 그래서인지 악용될 우려로 인해 학습된 모델은 공개하지 않겠다고 선언합니다. 심지어 학습 코드도 공개하지 않습니다. 대신 작은 데이터셋으로 학습된 별도의 작은 모델만 공개했네요. 이 작은 모델도 상당한 성능을 보이긴 하지만 한글 모델이 없고 학습 코드를 공개하지 않아서 한글은 어떻게 구축해야 할지 좀 막막하긴 합니다. 하지만, 기존 GPT와 큰 차이가 없고 논문에서 상세히 설명한 만큼 새로운 후속 연구들과 3rd-party 구현이 곧 쏟아져 나올 것 같은 예감은 듭니다.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/"&gt;https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;학습 모델 비공개에 대한 의견이 분분한데 하루만에 와이어드에 컬럼이 올라왔습니다. 기업 인터뷰 까지 따서 올린걸 보면 비공개에 대한 당위성을 알리기 위해 미리 준비한게 아닐까 싶기도 해요. 악용될 우려가 있다 뿐이지 이 기술이 핵폭탄 처럼 나쁜 기술은 아닙니다. 비공개로 한다고 언제까지나 감춰질 기술도 아니라고 생각해요. 결국은 credit에 목 말라할 3rd-party에서 빠르게 구현을 시도할 것이란 점을 생각해본다면 비공개 결정은 사실상 기술 격차(데이터 격차, 인프라 격차)를 두어 포석을 깔아두려는 의도가 더 커보입니다.&lt;/p&gt;</description><link>https://likejazz.com/post/182924169896</link><guid>https://likejazz.com/post/182924169896</guid><pubDate>Wed, 20 Feb 2019 08:30:05 +0900</pubDate></item><item><title>많은 이들에게 게임이론은 뷰티풀마인드의 주인공 존 내쉬의 내쉬 균형으로 유명하지만 공학도들에겐 지금의 컴퓨터 구조를...</title><description>&lt;img src="https://66.media.tumblr.com/43e3b47858a687e9818dfdfcf3e63ed2/tumblr_pmww8oPogI1qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;많은 이들에게 게임이론은 뷰티풀마인드의 주인공 존 내쉬의 내쉬 균형으로 유명하지만 공학도들에겐 지금의 컴퓨터 구조를 설계한 불세출의 천재 폰 노이만이 창안한 이론으로 훨씬 더 유명하다. 특히 ‘경제'가 들어간 책에서는 좋든 싫든 한 번씩은 마주치게 되고, 최근에는 수학, 컴퓨터 공학, 물리학, 진화 생물학 책에서도 한 번씩 마주치게 된다.&lt;/p&gt;

&lt;p&gt;무수한 명서를 제쳐두고 번역서도 아닌 국내서를 택했다. 첫 출간 이후 무려 20년 동안 8번이나 개정을 거듭한 명성과 대학원생들의 교과서에 대한 좋은 평가를 신뢰했다. 지난 번 KAIST 강의를 들은 이후 이 번이 두 번째 공부인데, 제대로 공부하고 싶은 학문인 만큼 열심히 해서 아무쪼록 머리에 오래도록 남기고 싶다.&lt;/p&gt;</description><link>https://likejazz.com/post/182855738735</link><guid>https://likejazz.com/post/182855738735</guid><pubDate>Sun, 17 Feb 2019 08:30:01 +0900</pubDate></item><item><description>&lt;iframe src="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Flgcnskorea%2Fposts%2F2435430776531100&amp;amp;width=500" width="500" height="713" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowtransparency="true" allow="encrypted-media"&gt;&lt;/iframe&gt;</description><link>https://likejazz.com/post/182834031013</link><guid>https://likejazz.com/post/182834031013</guid><pubDate>Sat, 16 Feb 2019 08:30:17 +0900</pubDate></item><item><title>카카오 AI, 한국어 독해능력 평가 인간 앞질렀다</title><description>&lt;a href="https://news.v.daum.net/v/20190131112332313"&gt;카카오 AI, 한국어 독해능력 평가 인간 앞질렀다&lt;/a&gt;: &lt;p&gt;지난 번 KorQuAD에서 Human Performance를 넘어 1등을 기록한 이후 보도 자료를 배포했습니다. 때마침 얼마전에 EM 점수가 2위로 잠시 밀렸었는데, 그 동안 꾸준히 개선하던 모델을 다시 한 번 제출하여 EM, F1 모두 SOTA를 다시 한 번 갱신하였습니다.&lt;/p&gt;

&lt;p&gt;점수 앞자리가 달라서 이제 안정권이지 않을까 싶은데, 훌륭하신 분들이 계속 점수를 높이고 있어서, 이번 보도 자료도 1등 보다는 Human Performance를 넘어서는 최초의 모델이란 점을 보다 강조했습니다. 아마 저는 더 이상은 점수를 높이진 않을듯 한데 1등이 뒤집히는 날이 어서 빨리 찾아오면 좋겠네요. 좋은 대회 운영해주시는 LG CNS 팀과 보도 자료 배포에 신경 써주신 PR팀에 다시 한 번 감사드립니다.&lt;/p&gt;</description><link>https://likejazz.com/post/182813076504</link><guid>https://likejazz.com/post/182813076504</guid><pubDate>Fri, 15 Feb 2019 08:30:06 +0900</pubDate></item><item><title>저희팀이 이번에 KorQuAD에 참여하여 SOTA를 달성하였습니다. EM, F1 모두 1위를 기록함은 물론...</title><description>&lt;img src="https://66.media.tumblr.com/c7e020d5c27cff8f1803b844241d34aa/tumblr_pm2u1kkCxJ1qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;저희팀이 이번에 &lt;a href="http://korquad.github.io/"&gt;KorQuAD&lt;/a&gt;에 참여하여 SOTA를 달성하였습니다. EM, F1 모두 1위를 기록함은 물론 Human Performance를 능가하는 첫 번째 모델을 제출하였습니다.&lt;/p&gt;

&lt;p&gt;얼마전에 저희팀에서 공개한 오픈소스 형태소 분석기 &lt;a href="https://github.com/kakao/khaiii"&gt;KHAIII&lt;/a&gt;를 함께 활용하였으며, 이외에도 한국어 특성에 적합하도록 BERT의 랭기지 모델을 많이 튜닝했습니다. 뿐만 아니라 300MB에 불과한 single 모델을 제출해 성능 뿐만 아니라 바로 서비스 가능한 수준의 사이즈와 속도를 구현하여 실용성을 높였습니다. (ensemble 모델의 경우 10G가 넘습니다)&lt;/p&gt;

&lt;p&gt;저희팀은 오랫동안 카카오에서 자연어 처리를 담당 해왔으며 형태소 분석 뿐만 아니라 카카오 미니의 발화 문장 분류, 카카오톡 챗봇의 유사 문장 판별 등의 업무를 하며 쌓아올린 자연어 처리 노하우를 이번에 십분 활용하여 구현해보았습니다. 모델 구현에 쓰인 기술은 하나씩 공개하여 NLP 커뮤니티에도 도움이 되도록 해보겠습니다. 무엇보다 좋은 데이터셋을 공개해준 KorQuAD 팀에 다시 한 번 깊이 감사드립니다.&lt;/p&gt;</description><link>https://likejazz.com/post/182435218265</link><guid>https://likejazz.com/post/182435218265</guid><pubDate>Thu, 31 Jan 2019 08:30:01 +0900</pubDate></item><item><title>일본책은 문장이 쉽고 빨리 읽힌다. 정독을 했음에도 기차가 도착하기 전에 다 읽을 수 있었다. 특히나 한 가지...</title><description>&lt;img src="https://66.media.tumblr.com/ce887d4575094159ecd1b1ec4c53ad4c/tumblr_pm2tznbH031qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;일본책은 문장이 쉽고 빨리 읽힌다. 정독을 했음에도 기차가 도착하기 전에 다 읽을 수 있었다. 특히나 한 가지 분야를 집요하게 파고드는 장인 정신은 일본책의 특징이라 할만하다. 이 책 또한 ‘인과관계’, ‘상관관계’ 두 가지에 대해서만 집중적으로 파고든다. 실용적인 예제를 설정하여 하나씩 주제를 꺼내드는 서술 방식 또한 매력적이다. 유일한 문제는 한자어로 된 용어다. ‘중회귀분석’으로 공부하던 시절은 이미 지났다. 한자의 의미 또한 더 이상 알기 어렵다. 이제는 multiple regression analysis가 훨씬 더 직관적이고 이해가 잘 된다. 무엇보다 책을 읽은 후 추가 자료를 더 찾아보기 위해서는 영어가 필수적이다.&lt;/p&gt;</description><link>https://likejazz.com/post/182409030997</link><guid>https://likejazz.com/post/182409030997</guid><pubDate>Wed, 30 Jan 2019 08:30:05 +0900</pubDate></item><item><title>리만가설과 마이클 아티야</title><description>&lt;a href="http://m.snunews.com/news/articleView.html?idxno=18730"&gt;리만가설과 마이클 아티야&lt;/a&gt;: &lt;p&gt;리만 가설을 증명했다고 발표한지 불과 3개월만에 향년 89세의 나이로 작고. 비록 증명은 해프닝으로 끝난듯 하여 안타깝지만 필즈상 까지 받았던 위대한 노학자의 마지막을 추모하며 …&lt;/p&gt;</description><link>https://likejazz.com/post/182390294915</link><guid>https://likejazz.com/post/182390294915</guid><pubDate>Tue, 29 Jan 2019 14:01:34 +0900</pubDate></item><item><title>안내지가 들어있는걸 보니 기분좋게도 이 책은 새 책이고 내가 첫 대출자다. 경영학에서는 비판도 많은 책이고...</title><description>&lt;img src="https://66.media.tumblr.com/62832038720bd2fa7f3b6d820481d411/tumblr_pkwc3jn6g61qzjoe5o1_500.jpg"/&gt;&lt;br/&gt;&lt;br/&gt;&lt;p&gt;안내지가 들어있는걸 보니 기분좋게도 이 책은 새 책이고 내가 첫 대출자다. 경영학에서는 비판도 많은 책이고 아카데미아 입장에서는 비지니스에서 이런 책이 나오는게 달갑지 않겠지만 엄연히 지금의 삼성을 있게 한 실전이 담긴 책인 만큼 당연히 구매할 생각이었는데, 마침 스마트 도서관에서 발견하게 되어 바로 빌렸다.&lt;/p&gt;

&lt;p&gt;요즘 경기도에는 지하철 역마다 스마트 도서관이 설치되어 있어 도서관에 들르지 않고도 편하게 책을 빌릴 수 있다. 정말 훌륭한 기획이고 이런데 쓰이는 세금은 전혀 아깝지 않다. 좀 더 많은 사람들이 지하철에서 책을 읽으면 좋겠고, 이런 멋진 기획을 한 공무원은 포상하면 좋겠다.&lt;/p&gt;</description><link>https://likejazz.com/post/181935318385</link><guid>https://likejazz.com/post/181935318385</guid><pubDate>Sat, 12 Jan 2019 08:30:26 +0900</pubDate></item></channel></rss>
