<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by 전무익 (Ed Jeon) on Medium]]></title>
        <description><![CDATA[Stories by 전무익 (Ed Jeon) on Medium]]></description>
        <link>https://medium.com/@muik?source=rss-4ec151bbc608------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/0*Mc8J1nD66AcNuncC.jpg</url>
            <title>Stories by 전무익 (Ed Jeon) on Medium</title>
            <link>https://medium.com/@muik?source=rss-4ec151bbc608------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Mon, 13 May 2019 07:21:50 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/@muik" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[딥러닝 추천 시스템 in production]]></title>
            <link>https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-in-production-fa623877e56a?source=rss-4ec151bbc608------2</link>
            <guid isPermaLink="false">https://medium.com/p/fa623877e56a</guid>
            <category><![CDATA[딥러닝]]></category>
            <category><![CDATA[추천시스템]]></category>
            <category><![CDATA[머신러닝]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[kubeflow-pipelines]]></category>
            <dc:creator><![CDATA[전무익 (Ed Jeon)]]></dc:creator>
            <pubDate>Thu, 09 May 2019 00:57:24 GMT</pubDate>
            <atom:updated>2019-05-09T00:57:24.765Z</atom:updated>
            <content:encoded><![CDATA[<p>이전 글로 <a href="https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9D%B8%ED%99%94-%EC%B6%94%EC%B2%9C-1eda682c2e8c">딥러닝 기반 개인화 추천 시스템</a>의 모델에 대한 부분을 소개 했었어요. 이번에는 당근마켓에서 추천 시스템을 지속적으로 업데이트하는 파이프라인과 서빙 시스템을 구축한 내용을 소개하려고 합니다.</p><h3>Kubeflow Pipelines</h3><p><a href="https://www.kubeflow.org/docs/pipelines/pipelines-overview/">Kubeflow Pipelines</a>은 Kubernetes에서 동작하는 Docker 컨테이너 기반 머신러닝 워크플로우 플랫폼입니다. 구글에서 오픈소스로 만들고 있다니 더 관심이 갔어요.</p><p>문제는 회사에서 아직 Kubernetes를 사용하지 않았기에 설치/관리에 대한 부담이 있었습니다. 그래서 처음에는 많이 사용하는 Airflow로 워크플로우를 작성했는데, 기존에 작성한 코드를 <a href="https://airflow.apache.org/concepts.html#dags">DAG</a>로 변환하는 작업량이 꽤 많아 번거로웠습니다. 그리고 웹 관리 페이지는 처음 접하기에 복잡하고 쉽게 이해되지 않은 부분이 많았습니다. 힘들게 작업했지만 앞으로 계속 쓰기에는 만족적이지 않았습니다.</p><p>그래서 Kubeflow Pipelines도 비교해보기 위해 시도해봤습니다. 일단 간편해보이는 <a href="https://deploy.kubeflow.cloud/">웹으로 설치하는 방법</a>을 따라 해봤는데 무척 간편하고 쉬웠습니다. 단순히 웹에서 몇가지 설정만 하고 클릭하면 잠시 후에 url을 통해 접속할 수 있어요!</p><h4>파이프라인 만들기</h4><p>다음으로는 추천 시스템 워크플로우를 Kubeflow Pipelines에서 동작하도록 파이프라인을 만들어야 합니다. 기존 추천 시스템 작업들을 컨테이너 기반으로 작성했었기 때문에 Kubeflow 파이프라인을 보다 쉽게 만들 수 있었습니다. 파이프라인 만드는 방법은 Kubeflow Pipelines SDK를 설치하여 python으로 작성하며 관련 문서는 <a href="https://www.kubeflow.org/docs/pipelines/sdk/">여기</a>를 참고해주세요.</p><p>작성된 파이프라인을 Kubeflow Pipelines에 업로드하면 아래와 같이 웹 화면에서 확인할 수 있고, ‘Create run’ 버튼으로 바로 실행해볼 수 있습니다!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Tr10wVLJOd2zhAFYpNMcgg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TiUWfhp8ixPpCkb5A7h6jg.png" /></figure><p>위의 오른쪽 이미지처럼 하이퍼 파라미터를 테스트 해볼 때 옵션 값을 변경하여 실험을 간편히 실행할 수 있습니다.</p><h4>Scheduling</h4><p>추천 시스템 파이프라인에서 꼭 필요한 부분으로 파이프라인을 지속적으로 업데이트하기 위해서는 cron 작업 같이 주기적으로 자동 실행을 해야 합니다. 이 부분은 Kubeflow Pipelines에서 제공하는 Recurring runs 기능으로 간편히 설정할 수 있었습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ezRj76XdD0mEGJ64uEcmgw.png" /></figure><p>위의 화면은 하루 두번 추천시스템을 업데이트하도록 설정한 화면입니다. 참고로 trigger 시간은 아직 지역 시간이 지원되지 않아 GMT 시간 기준으로 설정했습니다.</p><h4>Pipelines API</h4><p>추천 시스템 파이프라인 패키지 파일을 만든 후 Pipelines 웹화면에서 설정하는 단계를 정리해보겠습니다.</p><ol><li>패키지 파일을 업로드</li><li>Experiment 만들기 (초기 한번)</li><li>새로운 파이프라인으로 반복 실행 설정</li><li>기존 반복 실행 중지/삭제</li><li>기존 파이프라인 삭제</li></ol><p>아직 기존 파이프라인과 반복 실행을 변경할 수 있는 기능을 제공하지 않아 중지/삭제합니다.</p><p>문제는 추천 시스템을 계속 개선해나가면서 파이프라인이 변경될 때마다 웹에서 설정해야하는 단계를 거쳐야 합니다. 이 부분은 매우 번거로웠고, Kubeflow Pipelines을 다시 한번 고려해야 하는 생각까지 했었어요.</p><p>그래서 다른 더 간편한 방법을 찾던 중 공식 문서에는 문서화가 아직 안되었지만, 다행히 공식 코드에서 <a href="https://github.com/kubeflow/pipelines/blob/0.1.18/sdk/python/kfp/_client.py">Pipelines API를 사용할 수 있는 예제</a>를 찾을 수 있었습니다. 지금은 Pipelines API로 배포 설정의 모든 단계를 처리하는 스크립트로 만들어서 파이프라인을 변경하면 스크립트를 실행하여 손쉽게 파이프라인을 배포하고 있습니다.</p><h3>머신러닝 파이프라인</h3><p>추천 시스템의 머신러닝 워크플로우 작업들은 다음과 같은 순서로 연결되어 있고, 단계별로 더 자세히 알아보겠습니다.</p><ol><li>데이터 수집</li><li>전처리</li><li>학습</li><li>유사 검색 학습 / 모델 저장소 복사</li><li>배포</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6M2Ybf_FUPOZU2qxeKA1XQ.png" /></figure><h4>데이터 수집</h4><p>당근마켓 안드로이드/iOS 클라이언트에서 firebase를 통해 기록된 이벤트 로그는 <a href="https://firebase.google.com/docs/projects/bigquery-export">BigQuery에 저장</a>되고 있습니다. 추천 시스템에서 필요한 사용자가 본 글에 대한 로그는 클라이언트에서 이벤트가 발생하도록 구현했고, 이제 BigQuery에서 필요한 데이터를 수집할 수 있습니다. 최종 수집된 데이터 테이블은 BigQuery에서 제공하는 csv 추출 기능으로 Cloud Storage로 저장하도록 했습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-d034BSasBhAErGfWRsoog.png" /></figure><p>여기서 중요하게 고려해야 하는 건 BigQuery 테이블이 매우 크다는 점입니다. 모든 이벤트 로그의 많은 정보가 한 테이블에 기록되기 때문에 스캔해야하는 테이블 용량이 커서 자주 요청한다면 시간과 비용이 높아지기 때문입니다. 물론 날짜 단위로 파티션되지만 일간 방문자수가 많아져서 고려하지 않을 수 없습니다.</p><p>하루에 여러번 반복적으로 모든 데이터가 아닌 필요한 데이터만 조회하기 위해 중간 단계의 테이블을 수집하도록 했습니다. 이 단계는 외부 cron 작업으로 준비했고, 새로운 필요한 데이터만 지속적으로 수집하여 업데이트하고 있습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zL17WQ4xmTVL3NuJMar6ew.png" /></figure><p>결과로 현재의 데이터 수집 작업에서는 필요한 데이터로 축소된 테이블을 통해 수집하여 시간/비용 문제를 해결할 수 있었습니다.</p><h4>전처리</h4><p>수집된 csv는 실제 학습에 쓰이기 전에 다음과 같은 데이터 변환 처리가 필요합니다.</p><ul><li>글/지역 ID 사전 구축</li><li>x개 이하 존재하는 데이터 제외</li><li>ID를 index 번호로 변환</li><li>빠르게 읽기 위한 tfrecords 형식으로 저장</li></ul><p>위의 작업을 학습 모델에 포함할 수도 있지만, 반복적인 학습 처리 속도가 느려지기 때문에 미리 해야 할 필요가 있습니다.</p><p>전처리를 구현하는 방법으로는 <a href="https://github.com/tensorflow/transform">Tensorflow Transform</a>(tft)를 사용했습니다. tft는 초기 실험적인 머신러닝 프로젝트에서 사용할 때는 불필요할 수 있지만, 배포 시스템에서는 많은 이점을 얻을 수 있습니다.</p><ul><li>사전과 함께 전처리 작업을 최종 배포 모델에 포함</li><li>전처리 과정을 tensorflow 모델에 추가</li><li>사전 파일 자동 구축</li><li>Cloud Dataflow 환경에서 병렬로 실행하여 시간 단축</li><li>쉽게 사용할 수 있는 전처리 함수 제공</li></ul><p>전처리 과정을 tensorflow 모델에 간편히 포함시킬 수 있는 점이 매우 편리했습니다. 예측할 때 데이터를 전처리 할 필요없이 csv의 데이터 형식으로 바로 사용할 수 있기 때문입니다.</p><p>아래는 전처리 파이프라인의 과정 그래프를 볼 수 있고, Cloud Dataflow에서 병렬 처리로 14개 인스턴스 확장하여 실행된 결과 18분으로 소요시간을 단축할 수 있었습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*akt8hJee_3XRu_gE-HGi-A.png" /></figure><h4>학습</h4><p>모델을 개발할 때는 사내 워크스테이션에서 학습을 실행했지만, 실제 서비스에 안정적으로 학습되기 위해서 클라우드 학습 환경인 <a href="https://cloud.google.com/ml-engine/">Cloud ML Engine</a>(CMLE)을 사용하고 있습니다.</p><p>기존 다른 프로젝트의 모델도 Tensorflow Estimator API 작성하여 CMLE 환경에서 분산 학습을 보다 쉽게 사용하고 있었습니다. 이번 추천 모델도 동일한 방식으로 작성하여 사내 워크스테이션에서 클라우드 학습 환경으로 실행하기 편했습니다. 앞으로는 TF 2.0의 Keras model도 production에 강화됐다니 고려해보려고 해요.</p><p>학습된 모델은 Cloud Storage에 저장이 되며 추가 작업으로 모델에서 학습된 글 embeddings 값을 추출합니다. 추출된 데이터는 binary 파일로 Cloud Storage에 저장하고, 이후 유사 벡터 인덱스의 학습과 서빙에서 사용합니다.</p><p><a href="https://www.kubeflow.org/docs/pipelines/metrics/pipelines-metrics/"><strong>Pipeline Metrics</strong></a><strong><br></strong>일반적으로 학습이 완료된 후 실행하는 evaluation과 prediction 작업이 있습니다. evaluation으로 학습에 대한 metric 측정값으로 평가할 수 있고, prediction은 샘플을 뽑아서 예측을 실행해 볼 수 있습니다.</p><p>이러한 evaluation 값은 Kubeflow Pipelines의 형식에 맞게 파일로 저장하면 다음과 같이 쉽게 볼 수 있습니다. 그리고 prediction도 markdown, html 형식 등의 파일로 저장한다면 학습 완료된 결과를 Kubeflow 웹 화면에서 쉽게 확인할 수 있습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Rd7l86R-ydTdMYi92rjfYA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wJ-NWb-5ZPs9wIVQLqMHHA.png" /><figcaption>왼쪽 : 각 학습에 따른 metrics 확인, 오른쪽 : 학습 후 예측 결과 확인 (이미지를 클릭하면 크게 볼 수 있어요.)</figcaption></figure><p><a href="https://www.kubeflow.org/docs/pipelines/metrics/output-viewer/"><strong>Output Viewer</strong></a><strong><br></strong>Tensorboard는 이제 머신러닝 프로젝트에 빠질 수 없는 거의 필수 도구가 된 것 같습니다. Kubeflow Pipelines의 Output Viewer 기능으로 Tensorboard를 아주 쉽게 실행해볼 수 있습니다! ‘Start Tensorboard’ 버튼 클릭만으로 자동으로 Kubernetes 노드에서 Tensorboard를 실행하고 proxy를 연결하여 바로 웹으로 접속할 수 있는 환경을 만들어줍니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*WHc1iaHcwbo8DgL_wlSrVw.gif" /></figure><h4>유사 검색 학습</h4><p>빠르게 후보를 뽑기 위해서 실제 예측에는 벡터 인덱스를 사용합니다. 이렇게 설계한 부분에 대해 더 자세한 내용은 <a href="https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9D%B8%ED%99%94-%EC%B6%94%EC%B2%9C-1eda682c2e8c">이전 글</a>을 참고해주세요.</p><p>당근마켓에서는 예전부터 <a href="https://github.com/facebookresearch/faiss">faiss</a> 라이브러리를 사용해서 유사 벡터 검색 서버인 <a href="https://github.com/daangn/faiss-server">faiss-server</a>를 개발하여 안정적으로 사용하고 있었습니다. 추천 시스템에서도 같은 목적으로 이미 개발한 서버를 활용합니다.</p><p>faiss index에 데이터가 많아지면 검색속도가 느려지고 메모리 사용량이 늘어나게 됩니다. 이러한 부분은 faiss index 학습을 통해 해결할 수 있어서 배포하기전에 학습을 하게 됩니다.</p><h4>모델 저장소 복사</h4><p>학습한 Tensorflow 모델은 Google Cloud Storage에 저장되는데, 추천 서버는 AWS에 배포되어 있어 AWS S3 저장소로 복사합니다. 이 작업은 유사 검색 학습과 의존성이 없어서 동시에 실행합니다.</p><h4>배포</h4><p>추천 서버는 <a href="https://aws.amazon.com/ko/ecs/">AWS ECS</a>에 배포되어 있습니다. 이 작업에서는 aws cli 명령으로 ECS 서비스를 재시작 요청하여 새롭게 학습된 모델 데이터를 추천 서버에 적용하고 있습니다.</p><p>여기까지 머신러닝 워크플로우의 모든 작업이 끝나고 새로운 추천 시스템이 업데이트가 모두 완료되었습니다! 이제 사용자에게 계속해서 최신의 글로 개인화 추천이 가능하게 되었습니다.😃</p><h3>서빙</h3><p><a href="https://cloud.google.com/dataflow/">Cloud Dataflow</a>, <a href="https://cloud.google.com/ml-engine/">ML Engine</a>을 활용하기 위해 머신러닝 워크플로우는 Google Cloud에서 실행되지만, 당근마켓 서버는 AWS seoul region에서 운영되고 있습니다. 서버 간 직접적인 빠른 통신을 위해 머신러닝 관련 서버는 당근마켓 서버와 동일한 AWS에서 동작하도록 했습니다.</p><p>서버 간 동작하는 상황을 알아보겠습니다. 당근마켓 서버에서 사용자의 정보를 입력으로 추천 후보를 요청하면 추천 서버는 해당 사용자에게 추천할 만한 글 후보 200개를 다음과 같이 처리하여 응답합니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gW2yvfiCOP1wMIWGlSGOJw.png" /></figure><p>추천 후보 결과를 받기 위해서 2단계를 거치지만 총 응답 시간은 0.01초 이하로 매우 빠르게 처리됩니다. 아직은 CPU만으로 충분해서 GPU를 사용하지 않고 있습니다. 그리고 접속량이 늘어도 자동으로 확장되는 Auto Scaling 기능을 적용하여 빠른 추천 처리 시간이 유지됩니다.</p><p>워크플로우 작업과 마찬가지로 머신러닝 관련 서버도 컨테이너 기반으로 개발하여 AWS ECS에 배포하고 <a href="https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/service-auto-scaling.html">Auto Scaling</a> 기능을 적용하여 운영하기도 간편했습니다. 그럼 계속해서 관련 서버에 대해서 알아보겠습니다.</p><h4>당근마켓 서버</h4><p>접속하는 사용자마다 즉시 개인화된 추천 요청을 하기 위해 필요한 사용자 정보(최근 본 글 50개)를 빠르게 읽어야 합니다. 이 정보는 BigQuery에 저장되어 있지만 빠르게 읽을 수 없고, 기본 저장소인 RDBMS에서는 부담이 될 수 있어 <a href="https://redis.io/">Redis</a> 메모리 저장소를 활용하여 사용자 정보를 빠르게 읽을 수 있도록 구현했습니다.</p><h4>Tensorflow Serving</h4><p>학습된 추천 시스템 tensorflow 모델은 <a href="https://hub.docker.com/r/tensorflow/serving">tensorflow-serving</a> Docker 이미지를 사용하여 컨테이너 기반 서버를 실행했습니다. tensorflow-serving은 tesorflow에서 공식 제공하는 Docker 이미지로 production 서빙하기에 가장 쉽고 빠른 방법인 것 같습니다.</p><p>배포된 추천 모델 서버는 네트워크 전체를 실행하지 않고, 중간 부분인 user vector까지만 생성하여 응답하는 역할을 합니다. 빠른 속도를 위해서 네트워크의 나머지 뒷 부분 연산은 유사 검색 서버로 대체하도록 설계되었습니다.</p><h4>Faiss Server</h4><p>faiss 라이브러리로 faiss index 기능을 서비스하는 <a href="https://grpc.io/docs/tutorials/basic/python/">gRPC python</a> 서버를 만들어 사용하고 있습니다. 서버 실행 시 학습된 faiss index 데이터 파일을 로드하고, vector값으로 검색 요청을 받으면 가장 유사한 벡터의 상위 ID 목록을 응답하도록 구현하였습니다.</p><h3>마치며</h3><p>Kubeflow Pipelines 0.4.1 버전부터 지금은 0.5.0 버전으로 업데이트해서 사용한 경험으로 만족하고 있습니다. 아직 1.0 버전이 안되었지만 실서비스 머신러닝 파이프라인으로 큰 부족함이 없었습니다. 앞으로 새로운 프로젝트에서도 계속 사용하고, 더불어 Kubeflow의 학습/서빙 등 기능을 다양하게 활용할 예정입니다.</p><p>혹시 당근마켓 개인화 추천 기능을 사용해보고 싶으신가요? 당근마켓 앱에서 글 상세 화면 하단에 나오는 ‘…님, 이건 어때요?’ 에서 확인할 수 있습니다. 참고로 글 상세 화면 하단에는 ‘함께 봤어요’ 연관 상품 추천이 준비되지 않았을 때 ‘이건 어때요?’ 개인화 추천을 노출하고 있습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*NGXX7fxMzIlnC-HcO-DoYQ.png" /></figure><p>그리고 첫 화면의 시간 순인 글 목록 중간에 개인화 추천 글을 노출하는 A/B 테스트 중이며, 곧 당근마켓 첫화면 피드에서 자연스럽게 개인화 추천을 접하실 수 있도록 할 예정입니다.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fa623877e56a" width="1" height="1"><hr><p><a href="https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-in-production-fa623877e56a">딥러닝 추천 시스템 in production</a> was originally published in <a href="https://medium.com/daangn">당근마켓 팀블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[딥러닝 개인화 추천]]></title>
            <link>https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9D%B8%ED%99%94-%EC%B6%94%EC%B2%9C-1eda682c2e8c?source=rss-4ec151bbc608------2</link>
            <guid isPermaLink="false">https://medium.com/p/1eda682c2e8c</guid>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[개인화추천]]></category>
            <category><![CDATA[딥러닝]]></category>
            <category><![CDATA[추천시스템]]></category>
            <category><![CDATA[머신러닝]]></category>
            <dc:creator><![CDATA[전무익 (Ed Jeon)]]></dc:creator>
            <pubDate>Wed, 08 May 2019 02:38:22 GMT</pubDate>
            <atom:updated>2019-05-09T00:59:59.771Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AeiVY5pbkCJVo8GfV_BJPQ.jpeg" /></figure><p><strong>당근마켓 첫화면</strong>은 동네 사람들이 사용하는 다양한 물품을 보는 재미가 있어요. 누군가에겐 이제 필요없지만 나에게 유용한 물건들을 발견하게 되고 더불어 저렴하게 득템 할 기회도 종종 있죠. 매일 새로운 글이 올라오는 첫 화면의 스크롤을 내리며 탐색하는 즐거움이 일상이 되어가고 있습니다.</p><p>이러한 화면을 저희는 피드(feed)라고 부릅니다. 비슷하게 첫 화면을 탐색하는 피드 관련된 서비스인 페이스북, 인스타그램, 유튜브 등은 이미 개인화된 추천으로 피드 탐색을 더욱 흥미있게 해주고 있습니다.</p><p>당근마켓도 사용자 개인의 취향과 관심에 맞는 물건을 발견할 수 있도록 도와주는 개인화 추천 시스템을 도입하면 좋을 것 같았어요! 문제는 저희 팀에 아직 추천 시스템을 만들어 본 사람이 없어서 알아보고 배워야 했었지만, 다행히 의지가 충만했어요🙂</p><h4>추천 시스템 알아보기</h4><p>추천 시스템을 찾아보면 대표적으로 협업 필터링(Collaborative filtering), 내용 기반 필터링(Content-based filtering), 하이브리드 등 같은 방법이 있습니다. 그리고 CF를 구현하는 방법 중 행렬 분해(Matrix Factorization)로 구현된 라이브러리도 쉽게 찾을 수 있었습니다.</p><p>하지만 이러한 방법과 라이브러리 만으로는 실시간 개인화 추천 시스템을 구축하기에는 다음과 같은 문제로 충분하지 않았습니다.</p><ul><li>학습 데이터가 많아지면 메모리 사용량이 급격히 늘어나거나 학습 속도가 느려짐</li><li>사용자 정보를 ID의 단일 값이 아닌 다양한 정보를 활용하기 유연하지 않음</li><li>실시간으로 빠른 추천 구현에 대한 고려가 부족</li></ul><p>그래서 실제 서비스 중인 전체적인 추천 시스템에 대한 이해가 필요했었고, 유튜브에서 <a href="https://ai.google/research/pubs/pub45530">딥러닝 추천 시스템에 대한 논문</a>을 공개한 것을 보게 되었습니다. 이 시스템은 다양한 사용자 정보를 활용하고 실시간으로 빠르게 추천할 수 있도록 고려되어 있어 당근마켓 개인화 추천 시스템으로 적합했어요!</p><p>또한 핀터레스트에서도 공개한 <a href="https://www.youtube.com/watch?v=hN995d7g4us">홈 피드 추천 시스템</a>을 참고하면서 도움이 되었습니다. 공개해준 기업들 감사합니다!</p><p>그럼 공개된 논문을 훑어보고 관련 글과 영상들을 참고해보며 구현한 내용을 계속 소개해보겠습니다.</p><h3>딥러닝 추천 시스템</h3><h4>two-stage</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*awyN4FIgv_zvpJGhhU88XQ.png" /><figcaption>출처: <a href="https://research.google.com/pubs/archive/45530.pdf">Deep Neural Networks for YouTube Recommendations</a> 논문</figcaption></figure><p>유튜브, 핀터레스트의 추천 시스템의 공통된 점은 2단계로 나눠있다는 점입니다. 우선 사용자에게 추천할 후보군을 수백개 뽑는 1단계 후보 모델, 그리고 그 수백개의 후보들이 사용자가 얼마나 관심있을지 점수를 계산하는 2단계 랭킹 모델이 있습니다.</p><p>이렇게 2단계로 나눈 이유를 생각해보면 추천할 대상이 많아 사용자가 모든 글에 대한 관심 점수를 계산하기에는 너무 오래 걸리기 때문에 추천할 후보를 대략적으로 빠르게 추린 후 랭킹 점수를 계산하여 다시 정렬하는 것 입니다.</p><h3>후보 모델</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rT2pvUhFnxsjovigZblf8Q.png" /></figure><p>학습 데이터는 유튜브 추천 시스템과 비슷하고 단순하게 초기 모델을 학습 시작했습니다. 단순하게 설명해보면 Input에 대한 Target의 확률을 높이는 방식입니다.</p><ul><li>Input : 최근 본 글 ID 50개, 지역, 다음 글을 본 시간</li><li>Target : 다음 본 글 ID</li></ul><p>후보 모델은 기존 머신러닝 기법이 잘 조화된 모델인 것 같습니다. 계속해서 후보 모델에 포함된 주요 기법을 소개합니다.</p><h4><strong>Matrix Factorization</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*29orNN3LKwq_z96K6pexyg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PmGawAJHGgRWxZ5RCD73aw.png" /><figcaption>Matrix Factorization for CF, 출처: <a href="https://ogrisel.github.io/decks/2017_dotai_neural_recsys/#17">https://ogrisel.github.io/decks/2017_dotai_neural_recsys/#17</a></figcaption></figure><p>학습 원리는 Matrix Factorization(MF)과 비슷했습니다. MF는 사용자x아이템 행렬이 있을 때 사용자 벡터와 아이템 벡터로 분해하고, 다시 사용자 벡터와 아이템 벡터를 dot product 연산을 하여 나온 값으로 점수를 예측할 수 있습니다.</p><p>다양한 사용자 정보를 Neural network으로 학습하여 사용자 벡터를 생성하는 부분만 다르고 결과적으로 사용자 벡터와 컨텐츠 벡터를 dot product 연산되는 원리는 같습니다.</p><h4><strong>Language Model</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*IaYSN2RKTyUyXkQcxF2Fsg.png" /><figcaption>출처: <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/lecture8.pdf">https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/lecture8.pdf</a></figcaption></figure><p>문장에서 이전 단어들로 다음 단어를 예측하는 Language model를 볼 수 있었습니다. 사용자가 봤던 글 목록을 문장으로 보고, 이전에 봤던 50개의 글을 기반으로 다음 글을 예측하는 방식이 비슷합니다. 그래서 Language model의 학습 기법처럼 negative sampling과 binary cross entropy loss를 사용해서 학습했습니다.</p><h4><strong>Nearest neighbor index</strong></h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TgPH2Wp2ZoDn61WmSgCGrw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*RrWrLA4tpoSPx8Bj43oYww.png" /></figure><p>빠른 실서비스에 고려된 중요한 부분은 유사 벡터 검색을 예측할 때 사용한 부분입니다. 학습할 때는 negative sampling 으로 연산 부담이 적지만, 예측할 때는 한 사용자 벡터와 전체 글을 모두 연산을 해야하는데 글이 많다면 오래 걸릴 수 밖에 없습니다.</p><p>dot product 연산은 가까운, 유사성을 찾기 위한 계산으로 볼 수 있는데, 유사 벡터 검색으로 대체할 수 있습니다. 유사 벡터 검색은 학습을 통해 매우 빠르게 찾을 수 있고 이런 부분은 잘 구현된 라이브러리가 있어서 구현 부담을 덜 수 있습니다. 참고로 저희는 <a href="https://github.com/facebookresearch/faiss">faiss</a> 라이브러리를 만족적으로 잘 사용하고 있어요.</p><h4><strong>Metric</strong></h4><p>성능 측정하기 위해 Mean Average Precision(MAP)와 Top 50을 사용했습니다. 두가지 수치 모두, 전체 글 중 target 글을 예측한 순위가 얼마나 높은지 나타내기 위함입니다.</p><p>아래 그래프는 3일간의 사용자가 글을 본 로그로 학습하고, 그 다음날 하루의 미래 데이터로 테스트를 해본 결과입니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/690/1*wkoGDxZUr5LiCS-cy4GL3w.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/710/1*yB5YDFLhrwHqs-WfzkVyNA.png" /></figure><ul><li>2 epochs</li><li>전체 target 글 수 : 315,714</li><li>MAP : 0.12</li><li>top 50 : 12%</li></ul><p>수치를 해석해보면 학습한 모델로 50개를 추천했을 때 12% 사용자가 클릭을 했을 거라 예상해 볼 수 있을 것 같습니다. 실제 추천 후 클릭률 측정은 아직 준비 중입니다.</p><h3>랭킹 모델</h3><p>후보 모델과 다르게 사용자 정보와 글 정보 등을 모두 concat하여 학습합니다. 그리고 최종 결과값은 dot product가 아닌 Neural network layer에서 나와 더 정확하게 선호도를 예측할 수 있고 값의 정도를 나타내는 regression 모델로 볼 수 있습니다.</p><p>전체적인 추천 시스템의 복잡도가 높아 단계적으로 프로젝트를 나누었습니다. 현재 후보 모델까지 구현하여 추천 시스템을 서비스에 적용하였고, 다음 단계로 랭킹 모델은 준비 후 추천 시스템을 더욱 향상 시킬 예정입니다.</p><h3>예측 결과</h3><h4>사용자 별 이해</h4><p>한 지역에서 사용자를 뽑아 개인별 추천이 어떻게 다른지 보겠습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BkOfFD4e-ShdYoGktpDtSA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Py9d4XMIVHXJ7rVa7buHqw.png" /><figcaption>왼쪽 A : 아기엄마, 오른쪽 B : 인테리어 관심있는 직장인 (이미지 클릭하면 확대해서 볼 수 있어요.)</figcaption></figure><p>옥수동의 두 사용자가 다른 글을 봤을 때 각각 최근 본 글을 기반하여 다르게 추천할 수 있는 걸 볼 수 있습니다.</p><h4>지역 조건 글 이해</h4><p>당근마켓은 지역 한정으로 사용자가 위치한 주변 동네의 글만 볼 수 있습니다. 학습 데이터를 지역으로 구분해서 학습하지 않은 이유는 지역간 볼 수 있는 범위가 서로 겹치는 부분 많고, 2개의 지역을 번갈아 볼 수 있어서 전체 지역을 함께 학습했습니다. 대신 학습할 때 지역 정보를 주어 조건부 확률을 학습하도록 했습니다.</p><p>위에서 뽑은 사용자가 다른 지역으로 변경했을 때 어떻게 추천하는지 보겠습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-CReUJmn1h2uQ0AJ0KHWYw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ernQuFr5UPWZDf5Ie3jWUg.png" /><figcaption>(이미지 클릭하면 확대해서 볼 수 있어요.)</figcaption></figure><p>두 사용자 모두 아직 서초동의 글을 본 적이 없지만, 다른 지역에서도 본 취향을 반영하여 개인화 추천하는걸 알 수 있습니다.</p><h4>시간 경향 이해</h4><p>유튜브와 비슷하게 당근마켓의 상품 글도 최신 글의 소비가 매우 높습니다. 기존에 최신 순으로 글을 표시한 이유가 크겠지만, 인기 있는 글은 시간이 지남에 따라 이미 예약중이나 거래완료가 되었기 때문입니다. 따라서 시간이 지날 수록 볼만한 글은 적어집니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/493/1*4OuqY2dmszkdhaX4cvgkuw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/640/1*vpOm9lJqp6w5XuGq0uPSWg.png" /></figure><p>왼쪽의 그래프는 학습 데이터에서 사용자가 본 글의 등록된 후 지난 시간에 대한 분포를 나타냅니다. 사용자가 얼마나 최신 글을 많이 보는지 나타내고, 사용자가 보는 글의 70%는 7.3시간 이내의 글입니다.</p><p>오른쪽의 그래프는 학습한 모델에서 테스트 데이터로 예측했을 때 첫 번째 결과로 나오는 글에 대한 시간 분포를 나타냅니다. 학습 데이터(왼쪽)과 비슷하게 최신 글을 추천하는 경향을 보이고 있습니다.</p><p>참고로 분포에서 음수(-)값은 끌올 기능으로 글의 등록 시간이 변경되어 잡음 데이터로 무시하시기 바랍니다. 사용자가 글을 봤을 때 글의 등록 후 지난 시간을 정확히 측정하는 기록은 아직 준비중입니다.</p><h3>마치며</h3><p>개인화 추천 시스템을 최대한 단순화시켜서 개발을 해봤습니다. 현재 baseline 모델로도 개인화 추천 가능성을 확인하고, 빠르고 점진적으로 나아가기 위해 간단히 서비스에 적용 후 A/B 테스트 그리고 개선을 반복해 나가고 있습니다.</p><p>앞으로 사용자 정보를 추가해보는 실험, 랭킹 모델 추가 등 계속 성능을 개선해나갈 예정입니다.</p><p>다음으로 추천 시스템을 지속적으로 업데이트하는 파이프라인과 서빙 시스템을 구축한 내용을 소개해보려고 합니다~!!</p><p><a href="https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-in-production-fa623877e56a">딥러닝 추천 시스템 in production</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1eda682c2e8c" width="1" height="1"><hr><p><a href="https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9D%B8%ED%99%94-%EC%B6%94%EC%B2%9C-1eda682c2e8c">딥러닝 개인화 추천</a> was originally published in <a href="https://medium.com/daangn">당근마켓 팀블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[이미지 탐지기 쉽게 구현하기]]></title>
            <link>https://medium.com/daangn/%EC%9D%B4%EB%AF%B8%EC%A7%80-%ED%83%90%EC%A7%80%EA%B8%B0-%EC%89%BD%EA%B2%8C-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0-abd967638c8e?source=rss-4ec151bbc608------2</link>
            <guid isPermaLink="false">https://medium.com/p/abd967638c8e</guid>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[전무익 (Ed Jeon)]]></dc:creator>
            <pubDate>Tue, 19 Jun 2018 02:37:29 GMT</pubDate>
            <atom:updated>2018-06-19T02:37:29.114Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://www.daangn.com/">당근마켓</a>에서 딥러닝을 활용해서 이미지 탐지기를 만들어 사용하고 있는데, Tensorflow Hub로 쉽게 구현한 방법을 공유해보려 합니다.</p><h3>당근이</h3><p>먼저 <strong>이미지 탐지기</strong>를 만들게 된 계기를 설명해드릴게요. 당근마켓에는 당근이라는 캐릭터가 있습니다. 당근이는 당근마켓의 <a href="https://www.daangn.com/articles/8880137">나눔의 날</a>, <a href="https://www.daangn.com/articles/3464911">주목할 만한 소식</a> 그리고 <a href="https://www.daangn.com/articles/3928185">크리스마스 같은 특별한 날</a>에 당근마켓에서 사용자와 소통하는 캐릭터예요.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/256/1*ScCQRqiRp2NZK0yHN-moGQ.jpeg" /><figcaption>당근이</figcaption></figure><p>이렇게 귀엽고 친근하게 생겼죠:)</p><p>하지만 간혹 당근이가 좋거나 의도치 않게 당근이 캐릭터의 사진이나 당근이라는 명사로 닉네임을 지어 사용자에게 당근이와 혼돈될 수 있는 여지가 있어요. 그래서 닉네임에 ‘<strong>당근</strong>’ 명사를 사용하지 못하게 제한을 두었어요.</p><p>닉네임 글자는 쉽게 텍스트 제한할 수 있지만, 이미지는 픽셀로 구성되어 있어 기존의 간단한 프로그램 로직으로 구별하기 쉽지 않았어요.</p><p>이제 이런 것을 쉽게 가능한 방법으로 <strong>딥러닝</strong>이 있어요. 딥러닝은 이미 사람의 사진 구별능력을 넘어선지 꽤 됐으니 이미지 구별에 사용하면 됩니다.</p><h3>딥러닝 모델의 이미지 탐지기 만들기</h3><h4>1. 이미지 특징 추출 모델 준비</h4><p>이미지의 특징을 추출하려면 많은 양의 이미지를 수시간에서 몇일정도 학습시켜야하는데요. 얼마전 미리 학습된 모델을 쉽게 사용할 수 있는 <a href="https://www.tensorflow.org/hub/">Tensorflow Hub</a>가 공개되었어요. TF Hub의 <a href="https://www.tensorflow.org/hub/modules/image">Image Modules</a>을 사용하면 학습할 필요없이 코드 몇줄로 구현이 아주 간단합니다.</p><pre>import tensorflow_hub as hub<br>module = hub.Module(&quot;<a href="https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/1">https://tfhub.dev/google/imagenet/.</a>..&quot;)</pre><h4>2. 당근이 이미지의 특징 추출</h4><p>탐지할 타켓의 이미지인 당근이 이미지를 위에서 준비한 모듈을 사용하여 당근이 이미지의 특징을 추출합니다. 이 작업은 처음 한번만 하고 이후 재사용합니다.</p><pre>outputs = module(dict(images=daangn_profile_image), signature=&quot;image_feature_vector&quot;, as_dict=True)<br>target_image = outputs[&#39;default&#39;]</pre><h4>3. 사용자의 이미지의 특징 추출</h4><p>사용자가 당근이 이미지 사용하는지 비교하기 위해 사용자의 이미지의 특징 추출합니다. 이 작업은 사용자의 프로필 이미지를 변경할 때 비동기로 작업을 실행하고 있습니다.</p><pre>outputs = module(dict(images=user_profile_images), signature=&quot;image_feature_vector&quot;, as_dict=True)<br>input_image = outputs[&#39;default&#39;]</pre><h4>4. 당근이 이미지와 사용자의 이미지 비교</h4><p>학습된 모듈에서 추출된 이미지의 특징은 벡터의 값으로 유사도를 비교하기 위해 <a href="https://ko.wikipedia.org/wiki/%EC%BD%94%EC%82%AC%EC%9D%B8_%EC%9C%A0%EC%82%AC%EB%8F%84">Cosine similarity</a>를 사용했습니다.</p><pre>dot = tf.tensordot(target_image, tf.transpose(input_image), 1)<br>similarity = dot / (tf.norm(target_image, axis=1) * tf.norm(input_image, axis=1))<br>similarity = tf.reshape(similarity, [-1])</pre><p>양수인 두 벡터의 cosine similarity 값은 0.0 ~ 1.0 인데 유사한 정도에 따라 1.0에 가깝습니다.</p><h4>5. 유사도에 따라 검출</h4><p>실제 몇개 이미지를 비교해본 결과 다음과 같이 나왔습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/880/1*DNQFHyZydIkj-cdDSRsFqg.png" /><figcaption>이미지 별 유사도</figcaption></figure><p>첫번째 당근이 이미지는 동일하기 때문에 유사도 1.0이 나왔고, 당근이 이미지와 비슷한 순서대로 유사도 값이 높게 나온걸 알 수 있습니다.</p><p>3번째 이미지는 당근이와 꽤 유사하기 때문에 검출 기준값을 0.71이상으로 설정하면 되겠습니다. 당근마켓에서는 유사도 기준값 이상인 사용자 프로필 이미지가 발견되면 slack으로 알림을 받아 관리자가 확인하고, 유사도 기준값을 조정하여 후처리를 자동화하고 있습니다.</p><h3>구현</h3><p>위의 방법으로 당근마켓에서 실제 구현에 사용한 코드를 colab 노트북으로 공개했습니다. 자세한 코드는 아래 링크를 참고해주세요~!</p><p><a href="https://colab.research.google.com/github/daangn/notebooks/blob/master/daangn/profile_image_detector_using_tf_hub.ipynb">Google Colaboratory</a></p><p>참고로 구현된 모델을 <a href="https://cloud.google.com/ml-engine/">Cloud ML Engine</a> 에 배포하여 서비스 서빙하는 코드도 포함되어 있으니 참고하여 서비스 운영에 사용해보세요.</p><p><a href="https://medium.com/n42-corp/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93%EC%97%90%EC%84%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-3b48844eba62">당근마켓에서는 딥러닝을 활용</a>하여 사용자 만족도/편의성을 높이고, 효율적으로 운영되도록 시스템을 개선해나가고 있어요. 서비스 개선에 흥미가 있나요?</p><p>PS. 지금 당근마켓에서 마케터, 개발자를 모시고 있습니다. 채용공고를 살펴봐주세요. <a href="https://www.rocketpunch.com/companies/daangn/jobs">https://www.rocketpunch.com/companies/daangn/jobs</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=abd967638c8e" width="1" height="1"><hr><p><a href="https://medium.com/daangn/%EC%9D%B4%EB%AF%B8%EC%A7%80-%ED%83%90%EC%A7%80%EA%B8%B0-%EC%89%BD%EA%B2%8C-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0-abd967638c8e">이미지 탐지기 쉽게 구현하기</a> was originally published in <a href="https://medium.com/daangn">당근마켓 팀블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[안녕하세요~ 글 잘 보셨다니 감사합니다!]]></title>
            <link>https://medium.com/@muik/%EC%95%88%EB%85%95%ED%95%98%EC%84%B8%EC%9A%94-%EA%B8%80-%EC%9E%98-%EB%B3%B4%EC%85%A8%EB%8B%A4%EB%8B%88-%EA%B0%90%EC%82%AC%ED%95%A9%EB%8B%88%EB%8B%A4-1fa03a79c9?source=rss-4ec151bbc608------2</link>
            <guid isPermaLink="false">https://medium.com/p/1fa03a79c9</guid>
            <dc:creator><![CDATA[전무익 (Ed Jeon)]]></dc:creator>
            <pubDate>Mon, 01 Jan 2018 06:52:06 GMT</pubDate>
            <atom:updated>2018-01-01T06:52:06.731Z</atom:updated>
            <content:encoded><![CDATA[<p>안녕하세요~ 글 잘 보셨다니 감사합니다!</p><p>빠르게 적용하고 싶으시다면 일단 풀려고 하는 간단한 미션을 정하고, 필요한 기술에 관련된 내용을 찾아 집중적으로 학습해나가시면 힘들지만 단기간에 성취를 할 수 있을 것 같아요.</p><p>또는 학습을 조금씩 꾸준히 해나가면서 이해된 부분을 천천히 적용 시도해보면서 흥미를 가지실 수 있을 것 같습니다. 일단 입문용 책을 보시거나 유튜브에서 딥러닝 강의를 검색해보세요~!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1fa03a79c9" width="1" height="1">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[당근마켓에서 딥러닝 활용하기]]></title>
            <link>https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93%EC%97%90%EC%84%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-3b48844eba62?source=rss-4ec151bbc608------2</link>
            <guid isPermaLink="false">https://medium.com/p/3b48844eba62</guid>
            <category><![CDATA[deep-learning]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[전무익 (Ed Jeon)]]></dc:creator>
            <pubDate>Fri, 22 Dec 2017 05:39:30 GMT</pubDate>
            <atom:updated>2017-12-22T05:39:30.765Z</atom:updated>
            <content:encoded><![CDATA[<p>안녕하세요, 당근마켓 소프트웨어 엔지니어 Ed 입니다.</p><p>요새 인공지능/딥러닝이 정말 많이 거론되고 있는데요. 저희 당근마켓에서도 이러한 기술을 적극 활용하려 하고, 그동안 서비스에 적용한 내용을 공유하고자 합니다.</p><p>아직 당근마켓을 모르시는 분들을 위해 소개하면,</p><p>당근마켓은 우리 동네 주민들과 중고 직거래를 위한 스마트폰 앱 서비스예요. 주변 맘들은 이젠 익히 아실지도 :)</p><p><a href="https://www.daangn.com/">https://www.daangn.com/</a></p><h3>게시글 분류</h3><p>당근마켓 사용자들로부터 게시글이 판매금지 품목에 해당한다면 신고 기능으로 제보받고 있습니다. 이렇게 제보받은 항목을 저희 당근마켓 팀은 검토하여 수락/거부 후 규정에 따라 처리하고 있습니다. 문제는 서비스가 성장하면서 저희 소규모 인원만으로는 감당할 수 없을 정도로 신고량이 늘어나게 되었습니다. 그렇다고 스타트업에서 운영인력을 선형적으로 채용하기 부담이 될 수 밖에 없었습니다.</p><p>그래서 딥러닝을 이용하여 해결하려 했습니다. 기존에 신고 처리한 내역을 학습 데이터로 사용하여 Tensorflow 분류 모델을 만들 수 있었습니다. 새로운 게시글이 등록되면 학습 모델에 예측을 하여 정해놓은 확률에 따라 신고받기 전 선조치, 다수 신고 자동처리에 활용하여 운영량을 대폭 줄일 수 있었습니다.</p><p>더불어 확실한 광고 같은 게시글은 등록 후 바로 미노출되어 사용자에게 불쾌감을 주지도 않게 되어 서비스 품질/만족도를 높일 수 있는 이점도 생겼습니다.</p><p><strong>예측 결과</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GgR2BOn4ZTEeo6kgpyozKA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*OwDBMFAdNNamFu0bU0WOcQ.png" /><figcaption>전문 판매업자/홍보, 가품/이미테이션</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*vLIPkNavMEArMPpBKoctMg.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DtyyJftKztWosqig8UB2hQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*boULkkb9UnaxvgoZO2I56Q.png" /><figcaption>주류/담배, 동물, 일반</figcaption></figure><p>전체 분류 테스트 정확도 accuracy는 88% 결과가 나왔습니다. 중요하게 생각한 것은 일반 게시글 재현율 recall 95% 입니다.</p><p>일반 게시글이 다른 분류로 예측되는 피해를 입지 않도록 다른 분류의 정확도 precision를 높이는 것보다 일반 게시글 재현율을 높이는데 중점을 둔 결과입니다.</p><p><a href="https://www.tensorflow.org/">Tensorflow</a> 기반의 CNN, RNN, Fully connected layers로 네트워크를 구성하여 모델을 학습합니다. 이 모델은 Cloud Machine Learning Engine에 <a href="https://cloud.google.com/ml-engine/docs/online-predict">배포하여 예측</a>에 사용하고 있으며, <a href="https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/flowers">cloudml-samples/flowers</a> 예제를 참고하여 모델 배포까지 시스템을 보다 쉽게 구축할 수 있었습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*eEFYtWNQPb6tAeXqjNfRnA.png" /><figcaption>게시글 분류 모델 네트워트</figcaption></figure><h3>유사한 게시글 찾기</h3><p>당근마켓은 따뜻한 지역거래를 위해 사기꾼이거나 비매너 사용자를 적극 제재하고 있습니다. 일부는 제재를 받고도 악의적이거나 제재를 피해 새로운 계정을 만들어 활동하여 당근마켓 사용자에게 지속적으로 피해를 주고 있는 문제가 있습니다. 대비책으로 이용 제재 받은 사용자의 게시글과 유사한 글을 올리는 사용자는 같은 사용자일 확률이 높으므로 적극 모니터링 관리 / 자동 처리하고 있습니다.</p><p>또한 유사한 게시글을 찾는 기능을 통해 비슷한 게시글을 계속 올리는 사용자를 찾아낼 수 있었습니다. 예를 들어 스마트폰만 계속 올리는 전문 판매업자, 다량의 가품 핸드백 판매자가 있었는데 이런 사용자를 쉽게 검출하고 제재하여 반복적인 게시글과 수익의 목적인 사용자를 방지할 수 있었습니다.</p><p><strong>특징 추출</strong></p><p>유사한 정도를 비교하기 위해 게시글의 특징을 뽑아야 합니다. 사진은 미리 학습하여 공개된 모델인 <a href="https://github.com/tensorflow/models/tree/master/research/slim/">Inception V4</a> 모델을 사용하였고, 텍스트는 doc2vec (<a href="https://github.com/facebookresearch/StarSpace#articlespace-learning-sentence-and-article-embeddings">StarSpace — ArticleSpace</a>)을 사용하여 전체 게시글 내용을 학습 데이터로 모델을 비지도 학습 시킨 뒤 특징 embedding을 추출했습니다. 참고로 Inception V4 모델은 1년전부터 이미지 특성 추출하고 있어 그대로 사용한 것으로 이후 더 가볍고 성능이 좋은 새로운 모델로 전환을 하면 좋을 것 같습니다.</p><p><strong>인덱스 서버</strong></p><p>특징 embedding은 [0.12, 0.48, …, 0.9] 벡터 형태로 기존 데이터베이스에 저장할 순 있지만 비슷한 항목을 검색할 수 없습니다. 모든 벡터를 메모리에 올려서 가장 가까운 벡터를 찾는 방법이 있는데, 메모리 사용량과 검색 시간의 문제를 해결해야 합니다. 이에 매우 적합한 라이브러리인 <a href="https://github.com/facebookresearch/faiss">Faiss</a>를 사용하여 메모리를 적게 사용하며 매우 빠르게 검색할 수 있는 특징 embedding 인덱스를 구축할 수 있었습니다. 추가적으로 당근마켓 서버에서 사용하기 위해 서버간 통신은 <a href="https://grpc.io/">gRPC</a> 라이브러리를 활용했습니다.</p><h3>고객 문의 분류</h3><p>사용자들은 당근마켓 이용 중 문의사항이 있을 때 텍스트 글을 적어 질문을 보내고 있습니다. 이러한 문의 중 공통된 답변이 많을 경우 FAQ로 정리를 해놓고, 답변시 FAQ 링크를 보내주고 있습니다. 답변을 보낼 때 관련 참고 FAQ 링크를 찾는 작업은 단순하여 더욱 빠르고 편하게 하기 위해 학습 모델을 만들었습니다. 학습 데이터 구성은 답변에서 FAQ 링크를 라벨로 추출하여 문의 내용을 텍스트 분류로 지도 학습했습니다.</p><p>텍스트 분류로 사용한 <a href="https://fasttext.cc/">fastText</a>는 간편하고 빠르며 다른 분류 방법에 비해서도 성능도 괜찮게 나왔습니다.</p><p>학습 데이터에는 총 142개의 분류(FAQ)에서 각 분류 당 학습 데이터가 많지 않아 분류 테스트 정확도 accuracy는 64%로 높지 않게 나왔습니다. 하지만 앞으로 학습데이터인 FAQ에 대한 답변이 늘어남에 따라 더 높아질거라 예상합니다.</p><p>현재 문의 내용의 FAQ 예측이 일정 확률 이상이면 FAQ 추천을 표시하여 답변에 활용하고 있습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/379/1*An33D1CQkZ9AwbvcyDbMDQ.png" /><figcaption>FAQ 검색 전 추천링크를 클릭하여 쉽게 선택</figcaption></figure><h3>유사 고객 문의 찾기</h3><p>위의 FAQ 답변할 수 있는 고객 문의처럼 간단한 질문도 있지만, 복잡하고 다양한 질문도 많이 있습니다.</p><p>저희 당근마켓팀은 운영팀이 따로 있지 않고 팀원 모두 서로 돌아가면서 고객 문의에 답변합니다. 이렇게 여러 사람이 답변하다보니 이미 비슷한 질문에 답변을 한 경우, 참고면 더욱 간편하게 답변을 할 수 있어서 관련 답변이 있는지 여러 키워드로 검색을 해야하는 번거로움이 있었습니다. 이 부분도 텍스트 학습을 통해 더 효율적으로 빠르고 간편하게 찾을 수 있도록 적용해봤습니다.</p><p>유사한 질문을 찾기 위해 위의 유사 게시글 찾기처럼 질문의 특징을 추출하여 인덱스 구축하여 찾았습니다.</p><p><a href="http://projector.tensorflow.org/">Embedding Projector</a>로 시각화 해본 결과, 아래처럼 비슷한 질문들의 특징이 가깝게 분포되어 비슷한 질문들을 찾을 수 있는 걸 확인할 수 있었습니다.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JvY0Sb_RdKk5d0_f43z6QA.png" /><figcaption>문의내용의 t-SNE 시각화</figcaption></figure><p>가능성을 확인 후 실제 서비스에 적용으로 문의사항 답변 화면에서 유사 질문의 답변을 표시했습니다. 이제 저를 포함해서 고객문의 담당자는 이미 답변한 비슷한 문의에 대해서 손쉽게 답변할 수 있게 되었습니다. 야호^^!</p><h3>마치며</h3><p>당근마켓과 같이 일반 서비스에도 딥러닝을 도입/활용하면서 좋은 점이 많아 공유하게 되었습니다. 위에 언급한 라이브러리와 플랫폼 덕분에 딥러닝 시스템을 구축하기 생각보다 많이 편해진 것 같습니다. 아직 사용해보지 않은 분에게 활용해보시길 추천드립니다.</p><p>앞으로도 당근마켓 개인화 / 추천 등 다양한 분야에도 딥러닝을 적극 활용해 볼 계획입니다~!</p><p>우리 동네 중고 직거래 마켓 사용해보세요~ <a href="https://dngn.kr/2CV0Ztc">https://dngn.kr/2CV0Ztc</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3b48844eba62" width="1" height="1"><hr><p><a href="https://medium.com/daangn/%EB%8B%B9%EA%B7%BC%EB%A7%88%EC%BC%93%EC%97%90%EC%84%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0-3b48844eba62">당근마켓에서 딥러닝 활용하기</a> was originally published in <a href="https://medium.com/daangn">당근마켓 팀블로그</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>